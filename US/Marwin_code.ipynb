{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRdkUxDEoTHL"
      },
      "source": [
        "**1 Collecting Data**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqWAq7nVFmr5"
      },
      "source": [
        "## Improve thing\n",
        "  1) Chowlin model to expand data frequency\n",
        "  2) A. ‡∏™‡∏£‡πâ‡∏≤‡∏á Environment ‡πÅ‡∏•‡∏∞ State Vector (‡∏ï‡∏≤‡∏°‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ 5. Method ‡πÉ‡∏ô Paper)‡πÅ‡∏ú‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ Reinforcement Learning (RL) ‡∏ã‡∏∂‡πà‡∏á‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ \"‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏° (Environment)\" ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à ‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô Code ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏™‡∏≠‡∏á‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô‡πÄ‡∏õ‡πá‡∏ô $S_t$:Macro Signal ($m_t$): ‡πÄ‡∏≠‡∏≤‡∏ú‡∏• Forecast ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡πà‡∏≤ ECT/Coefficients ‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• ARDL-ECM ‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏≥‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô FeatureTechnical Signal ($b_t$): ‡πÄ‡∏≠‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô ($P_{bull}, P_{bear}, P_{neutral}$) ‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• LSTM/GRU ‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô FeaturePortfolio State: ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô (‡∏ñ‡∏∑‡∏≠‡πÄ‡∏á‡∏¥‡∏ô‡∏™‡∏î, ‡∏ñ‡∏∑‡∏≠‡∏´‡∏∏‡πâ‡∏ô, ‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô)‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥: ‡∏™‡∏£‡πâ‡∏≤‡∏á Class Environment (‡πÄ‡∏ä‡πà‡∏ô‡∏™‡∏∑‡∏ö‡∏ó‡∏≠‡∏î‡∏à‡∏≤‡∏Å gym.Env) ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ Step\n",
        "  3) B. ‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏™‡πà‡∏ß‡∏ô Reinforcement Learning (PPO Algorithm)‡πÉ‡∏ô Code ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô PPO (Proximal Policy Optimization) ‡∏´‡∏£‡∏∑‡∏≠ Agent ‡∏ó‡∏µ‡πà‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à \"‡∏ã‡∏∑‡πâ‡∏≠/‡∏Ç‡∏≤‡∏¢/‡∏ñ‡∏∑‡∏≠\"Action: ‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≥‡∏´‡∏ô‡∏î Action Space ‡πÄ‡∏õ‡πá‡∏ô {Buy, Hold, Sell}Reward Function: ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏™‡∏°‡∏Å‡∏≤‡∏£ Reward ‡∏ï‡∏≤‡∏°‡πÅ‡∏ú‡∏ô: $\\text{Reward} = \\text{Portfolio Value} - (\\lambda \\times \\text{Drawdown Penalty})$Implementation: ‡πÉ‡∏ä‡πâ Library ‡πÄ‡∏ä‡πà‡∏ô stable-baselines3 ‡∏´‡∏£‡∏∑‡∏≠ rllib ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á PPO Agent ‡πÅ‡∏•‡πâ‡∏ß‡∏™‡∏±‡πà‡∏á Train ‡∏î‡πâ‡∏ß‡∏¢ Environment ‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠ A\n",
        "  4) C. ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÇ‡∏°‡πÄ‡∏î‡∏• CNN (Optional ‡∏ï‡∏≤‡∏°‡πÅ‡∏ú‡∏ô)\n",
        "‡πÉ‡∏ô‡πÅ‡∏ú‡∏ô‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ CNN (Convolutional Neural Networks) ‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö LSTM ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏ö Pattern ‡∏Å‡∏£‡∏≤‡∏ü ‡πÅ‡∏ï‡πà‡πÉ‡∏ô Code ‡∏û‡∏ö‡πÅ‡∏Ñ‡πà LSTM/GRU\n",
        "\n",
        "\n",
        "5) D. ‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°‡∏£‡∏∞‡∏ö‡∏ö‡πÅ‡∏•‡∏∞ Backtesting (Phase 4)\n",
        "Rolling Window Training: ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô Loop ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• Train ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏µ 2010-2024 ‡πÅ‡∏•‡∏∞ Test ‡∏õ‡∏µ 2025 (Out-of-sample)\n",
        "\n",
        "Performance Metrics: Code ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏ß‡∏±‡∏î‡πÅ‡∏Ñ‡πà‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ (Accuracy/MSE) ‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏£‡∏≤‡∏Ñ‡∏≤ ‡πÅ‡∏ï‡πà‡∏ï‡∏≤‡∏°‡πÅ‡∏ú‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏ß‡∏±‡∏î Trading Performance ‡∏Ç‡∏≠‡∏á‡∏ö‡∏≠‡∏ó ‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πà:\n",
        "\n",
        "Cumulative Return (‡∏Å‡∏≥‡πÑ‡∏£‡∏™‡∏∞‡∏™‡∏°)\n",
        "\n",
        "Sharpe Ratio (‡∏ú‡∏•‡∏ï‡∏≠‡∏ö‡πÅ‡∏ó‡∏ô‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á)\n",
        "\n",
        "Maximum Drawdown (‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏î‡∏ó‡∏∏‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m32krxZ3oYCD",
        "outputId": "45914a2d-bcfe-41a7-993d-51f9adc55a4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fredapi\n",
            "  Downloading fredapi-0.5.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from fredapi) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas->fredapi) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->fredapi) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->fredapi) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->fredapi) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->fredapi) (1.17.0)\n",
            "Downloading fredapi-0.5.2-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: fredapi\n",
            "Successfully installed fredapi-0.5.2\n"
          ]
        }
      ],
      "source": [
        "!pip install fredapi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZOQsga5cvLN"
      },
      "source": [
        "| Component               | Description                                    | Paper                 |\n",
        "| ----------------------- | ---------------------------------------------- | --------------------- |\n",
        "| Proxy selection         | Dynamic Factor / PCA on macro dataset          | Stock & Watson (2002) |\n",
        "| Temporal disaggregation | Chow-Lin linear regression                     | Chow & Lin (1971)     |\n",
        "| Extrapolation           | AR(1) residual correction (Fernandez model)    | Fernandez (1981)      |\n",
        "| Ratio preservation      | Denton (1971) for % variables (e.g., Debt/GDP) | Denton (1971)         |\n",
        "\n",
        "üìò Academic Framework (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö citation ‡πÉ‡∏ô report)\n",
        "\n",
        "Chow & Lin (1971) ‚Äì Best Linear Unbiased Interpolation by Related Series\n",
        "\n",
        "Stock & Watson (2002) ‚Äì Macroeconomic Forecasting Using Diffusion Indexes\n",
        "\n",
        "Mariano & Murasawa (2003) ‚Äì A New Coincident Index of Business Cycles Based on Monthly and Quarterly Series\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GDP Data\n",
        "(https://)https://lookerstudio.google.com/u/0/reporting/52a283c8-91f9-4b35-8157-2b2b42312602/page/p_l7cxsbayvc"
      ],
      "metadata": {
        "id": "38oP341GrfFn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhTALLCnoY74",
        "outputId": "8d3a2bae-4c87-43a3-aede-24ab5e2d6c64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            Close_AMGN  Close_GILD  Close_VRTX  Close_REGN  Close_BIIB  \\\n",
            "Date                                                                     \n",
            "2015-02-01  157.720001  103.529999  119.430000  413.839996  409.589996   \n",
            "2015-03-01  159.850006   98.129997  117.970001  451.480011  422.239990   \n",
            "2015-04-01  157.910004  100.510002  123.279999  457.459991  373.929993   \n",
            "2015-05-01  156.259995  112.269997  128.289993  512.559998  396.989990   \n",
            "2015-06-01  153.520004  117.080002  123.480003  510.130005  403.940002   \n",
            "...                ...         ...         ...         ...         ...   \n",
            "2025-09-01  282.200012  111.000000  391.640015  562.270020  140.080002   \n",
            "2025-10-01  298.429993  119.790001  425.570007  651.799988  154.270004   \n",
            "2025-11-01  345.459991  125.839996  433.609985  780.190002  182.089996   \n",
            "2025-12-01  327.309998  122.739998  453.359985  771.869995  175.990005   \n",
            "2026-01-01  330.410004  124.910004  441.359985  733.039978  164.419998   \n",
            "\n",
            "            Close_ILMN  Close_IDXX  Close_ISRG  Close_ALGN  inflation_rate  \\\n",
            "Date                                                                         \n",
            "2015-02-01  190.136185   78.415001   55.555557   57.349998       -0.000870   \n",
            "2015-03-01  180.583664   77.239998   56.114445   53.790001       -0.000220   \n",
            "2015-04-01  179.231522   62.685001   55.108891   58.840000       -0.001040   \n",
            "2015-05-01  200.466919   67.800003   54.194443   60.669998        0.000350   \n",
            "2015-06-01  212.412445   64.139999   53.833332   62.709999        0.001796   \n",
            "...                ...         ...         ...         ...             ...   \n",
            "2025-09-01   94.970001  638.890015  447.230011  125.220001        0.030227   \n",
            "2025-10-01  123.540001  629.510010  534.280029  137.880005        0.027899   \n",
            "2025-11-01  131.449997  752.880005  573.479980  147.190002        0.027120   \n",
            "2025-12-01  131.160004  676.530029  566.359985  156.149994        0.026533   \n",
            "2026-01-01  141.649994  715.369995  535.000000  171.490005        0.021762   \n",
            "\n",
            "            m2_growth  m1_growth  bond_yield_spread       dxy  \\\n",
            "Date                                                            \n",
            "2015-02-01   0.009868   0.023276               1.21  105.5884   \n",
            "2015-03-01  -0.000160  -0.007965               1.37  105.5981   \n",
            "2015-04-01   0.002844   0.000500               1.32  107.0600   \n",
            "2015-05-01   0.002301  -0.008159               1.52  105.6382   \n",
            "2015-06-01   0.003371   0.012181               1.55  107.2238   \n",
            "...               ...        ...                ...       ...   \n",
            "2025-09-01   0.004698   0.004048                NaN       NaN   \n",
            "2025-10-01   0.003846   0.004816               0.57  120.5782   \n",
            "2025-11-01   0.001094   0.001136               0.51  121.7715   \n",
            "2025-12-01   0.000000   0.000000               0.55  121.3615   \n",
            "2026-01-01   0.000000   0.000000                NaN       NaN   \n",
            "\n",
            "            nonfarm_payrolls  unemployment_rate  vix_index  real_rate_10y  \\\n",
            "Date                                                                        \n",
            "2015-02-01          140827.0                5.5      20.97           0.03   \n",
            "2015-03-01          140923.0                5.4      13.34           0.17   \n",
            "2015-04-01          141196.0                5.4      15.11           0.07   \n",
            "2015-05-01          141538.0                5.6      12.70           0.18   \n",
            "2015-06-01          141709.0                5.3      13.97           0.39   \n",
            "...                      ...                ...        ...            ...   \n",
            "2025-09-01          159593.0                4.4      16.12            NaN   \n",
            "2025-10-01          159420.0                NaN      16.29           1.77   \n",
            "2025-11-01          159476.0                4.5      17.44           1.81   \n",
            "2025-12-01          159526.0                4.4      17.24           1.85   \n",
            "2026-01-01          159526.0                4.4        NaN            NaN   \n",
            "\n",
            "            ppi_inflation  \n",
            "Date                       \n",
            "2015-02-01      -0.070977  \n",
            "2015-03-01      -0.074879  \n",
            "2015-04-01      -0.083533  \n",
            "2015-05-01      -0.070192  \n",
            "2015-06-01      -0.064810  \n",
            "...                   ...  \n",
            "2025-09-01       0.036995  \n",
            "2025-10-01       0.030038  \n",
            "2025-11-01       0.032957  \n",
            "2025-12-01       0.032093  \n",
            "2026-01-01       0.016304  \n",
            "\n",
            "[132 rows x 19 columns]\n",
            "\n",
            "=== HEAD ===\n",
            "            Close_AMGN  Close_GILD  Close_VRTX  Close_REGN  Close_BIIB  \\\n",
            "Date                                                                     \n",
            "2015-02-01  157.720001  103.529999  119.430000  413.839996  409.589996   \n",
            "2015-03-01  159.850006   98.129997  117.970001  451.480011  422.239990   \n",
            "2015-04-01  157.910004  100.510002  123.279999  457.459991  373.929993   \n",
            "2015-05-01  156.259995  112.269997  128.289993  512.559998  396.989990   \n",
            "2015-06-01  153.520004  117.080002  123.480003  510.130005  403.940002   \n",
            "2015-07-01  176.589996  117.860001  135.000000  553.659973  318.779999   \n",
            "2015-08-01  151.779999  105.070000  127.519997  513.500000  297.299988   \n",
            "2015-09-01  138.320007   98.190002  104.139999  465.140015  291.809998   \n",
            "2015-10-01  158.179993  108.129997  124.739998  557.390015  290.510010   \n",
            "2015-11-01  161.100006  105.959999  129.360001  544.500000  286.859985   \n",
            "\n",
            "            Close_ILMN  Close_IDXX  Close_ISRG  Close_ALGN  inflation_rate  \\\n",
            "Date                                                                         \n",
            "2015-02-01  190.136185   78.415001   55.555557   57.349998       -0.000870   \n",
            "2015-03-01  180.583664   77.239998   56.114445   53.790001       -0.000220   \n",
            "2015-04-01  179.231522   62.685001   55.108891   58.840000       -0.001040   \n",
            "2015-05-01  200.466919   67.800003   54.194443   60.669998        0.000350   \n",
            "2015-06-01  212.412445   64.139999   53.833332   62.709999        0.001796   \n",
            "2015-07-01  213.326843   72.730003   59.241112   62.700001        0.002257   \n",
            "2015-08-01  192.227631   71.470001   56.772221   56.599998        0.002413   \n",
            "2015-09-01  171.031128   74.250000   51.064445   56.759998        0.000088   \n",
            "2015-10-01  139.377426   68.620003   55.177776   65.459999        0.001276   \n",
            "2015-11-01  178.891052   70.820000   57.779999   66.739998        0.004363   \n",
            "\n",
            "            m2_growth  m1_growth  bond_yield_spread       dxy  \\\n",
            "Date                                                            \n",
            "2015-02-01   0.009868   0.023276               1.21  105.5884   \n",
            "2015-03-01  -0.000160  -0.007965               1.37  105.5981   \n",
            "2015-04-01   0.002844   0.000500               1.32  107.0600   \n",
            "2015-05-01   0.002301  -0.008159               1.52  105.6382   \n",
            "2015-06-01   0.003371   0.012181               1.55  107.2238   \n",
            "2015-07-01   0.003634   0.006711               1.74  107.0101   \n",
            "2015-08-01   0.003711  -0.006877               1.53  108.7819   \n",
            "2015-09-01   0.005048   0.007832               1.47  110.4506   \n",
            "2015-10-01   0.004212  -0.006638               1.41  111.0439   \n",
            "2015-11-01   0.007452   0.018614               1.41  110.2079   \n",
            "\n",
            "            nonfarm_payrolls  unemployment_rate  vix_index  real_rate_10y  \\\n",
            "Date                                                                        \n",
            "2015-02-01          140827.0                5.5      20.97           0.03   \n",
            "2015-03-01          140923.0                5.4      13.34           0.17   \n",
            "2015-04-01          141196.0                5.4      15.11           0.07   \n",
            "2015-05-01          141538.0                5.6      12.70           0.18   \n",
            "2015-06-01          141709.0                5.3      13.97           0.39   \n",
            "2015-07-01          141991.0                5.2      16.09           0.54   \n",
            "2015-08-01          142125.0                5.1      12.12           0.46   \n",
            "2015-09-01          142275.0                5.0      31.40           0.60   \n",
            "2015-10-01          142579.0                5.0      22.55           0.59   \n",
            "2015-11-01          142808.0                5.1      15.07           0.63   \n",
            "\n",
            "            ppi_inflation  \n",
            "Date                       \n",
            "2015-02-01      -0.070977  \n",
            "2015-03-01      -0.074879  \n",
            "2015-04-01      -0.083533  \n",
            "2015-05-01      -0.070192  \n",
            "2015-06-01      -0.064810  \n",
            "2015-07-01      -0.067788  \n",
            "2015-08-01      -0.072947  \n",
            "2015-09-01      -0.083818  \n",
            "2015-10-01      -0.078171  \n",
            "2015-11-01      -0.075660  \n",
            "\n",
            "=== TAIL ===\n",
            "            Close_AMGN  Close_GILD  Close_VRTX  Close_REGN  Close_BIIB  \\\n",
            "Date                                                                     \n",
            "2025-04-01  290.920013  106.540001  509.500000  598.760010  121.080002   \n",
            "2025-05-01  288.179993  110.080002  442.049988  490.279999  129.789993   \n",
            "2025-06-01  279.209991  110.870003  445.200012  525.000000  125.589996   \n",
            "2025-07-01  295.100006  112.290001  456.869995  545.460022  128.000000   \n",
            "2025-08-01  287.709991  112.970001  391.019989  580.700012  132.220001   \n",
            "2025-09-01  282.200012  111.000000  391.640015  562.270020  140.080002   \n",
            "2025-10-01  298.429993  119.790001  425.570007  651.799988  154.270004   \n",
            "2025-11-01  345.459991  125.839996  433.609985  780.190002  182.089996   \n",
            "2025-12-01  327.309998  122.739998  453.359985  771.869995  175.990005   \n",
            "2026-01-01  330.410004  124.910004  441.359985  733.039978  164.419998   \n",
            "\n",
            "            Close_ILMN  Close_IDXX  Close_ISRG  Close_ALGN  inflation_rate  \\\n",
            "Date                                                                         \n",
            "2025-04-01   77.599998  432.649994  515.799988  173.300003        0.023337   \n",
            "2025-05-01   82.239998  513.359985  552.340027  180.940002        0.023759   \n",
            "2025-06-01   95.410004  536.340027  543.409973  189.330002        0.026727   \n",
            "2025-07-01  102.709999  534.309998  481.089996  129.009995        0.027318   \n",
            "2025-08-01   99.959999  647.090027  473.299988  141.960007        0.029392   \n",
            "2025-09-01   94.970001  638.890015  447.230011  125.220001        0.030227   \n",
            "2025-10-01  123.540001  629.510010  534.280029  137.880005        0.027899   \n",
            "2025-11-01  131.449997  752.880005  573.479980  147.190002        0.027120   \n",
            "2025-12-01  131.160004  676.530029  566.359985  156.149994        0.026533   \n",
            "2026-01-01  141.649994  715.369995  535.000000  171.490005        0.021762   \n",
            "\n",
            "            m2_growth  m1_growth  bond_yield_spread       dxy  \\\n",
            "Date                                                            \n",
            "2025-04-01   0.006169   0.006147               0.30  126.6783   \n",
            "2025-05-01   0.002610   0.001653               0.55  123.4811   \n",
            "2025-06-01   0.005255   0.005124               0.52  122.1112   \n",
            "2025-07-01   0.003921   0.002850               0.48  119.7678   \n",
            "2025-08-01   0.003607   0.001993               0.54  121.6148   \n",
            "2025-09-01   0.004698   0.004048                NaN       NaN   \n",
            "2025-10-01   0.003846   0.004816               0.57  120.5782   \n",
            "2025-11-01   0.001094   0.001136               0.51  121.7715   \n",
            "2025-12-01   0.000000   0.000000               0.55  121.3615   \n",
            "2026-01-01   0.000000   0.000000                NaN       NaN   \n",
            "\n",
            "            nonfarm_payrolls  unemployment_rate  vix_index  real_rate_10y  \\\n",
            "Date                                                                        \n",
            "2025-04-01          159433.0                4.2      21.77           1.84   \n",
            "2025-05-01          159452.0                4.3      24.60           2.00   \n",
            "2025-06-01          159439.0                4.1      18.57           2.07   \n",
            "2025-07-01          159511.0                4.3      16.83           1.97   \n",
            "2025-08-01          159485.0                4.3      20.38           1.90   \n",
            "2025-09-01          159593.0                4.4      16.12            NaN   \n",
            "2025-10-01          159420.0                NaN      16.29           1.77   \n",
            "2025-11-01          159476.0                4.5      17.44           1.81   \n",
            "2025-12-01          159526.0                4.4      17.24           1.85   \n",
            "2026-01-01          159526.0                4.4        NaN            NaN   \n",
            "\n",
            "            ppi_inflation  \n",
            "Date                       \n",
            "2025-04-01       0.005502  \n",
            "2025-05-01       0.013180  \n",
            "2025-06-01       0.017885  \n",
            "2025-07-01       0.019575  \n",
            "2025-08-01       0.026055  \n",
            "2025-09-01       0.036995  \n",
            "2025-10-01       0.030038  \n",
            "2025-11-01       0.032957  \n",
            "2025-12-01       0.032093  \n",
            "2026-01-01       0.016304  \n",
            "\n",
            "=== COLUMNS ===\n",
            "['Close_AMGN', 'Close_GILD', 'Close_VRTX', 'Close_REGN', 'Close_BIIB', 'Close_ILMN', 'Close_IDXX', 'Close_ISRG', 'Close_ALGN', 'inflation_rate', 'm2_growth', 'm1_growth', 'bond_yield_spread', 'dxy', 'nonfarm_payrolls', 'unemployment_rate', 'vix_index', 'real_rate_10y', 'ppi_inflation']\n",
            "\n",
            "=== NA COUNTS ===\n",
            "Close_AMGN            0\n",
            "Close_GILD            0\n",
            "Close_VRTX            0\n",
            "Close_REGN            0\n",
            "Close_BIIB            0\n",
            "Close_ILMN            0\n",
            "Close_IDXX            0\n",
            "Close_ISRG            0\n",
            "Close_ALGN            0\n",
            "inflation_rate        0\n",
            "m2_growth             0\n",
            "m1_growth             0\n",
            "bond_yield_spread    10\n",
            "dxy                  10\n",
            "nonfarm_payrolls      0\n",
            "unemployment_rate     1\n",
            "vix_index             9\n",
            "real_rate_10y        10\n",
            "ppi_inflation         0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2876661565.py:132: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
            "  df[\"inflation_rate\"] = cpi_aligned.pct_change(12)\n",
            "/tmp/ipython-input-2876661565.py:140: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
            "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
            "A typical example is when you are setting values in a column of a DataFrame, like:\n",
            "\n",
            "df[\"col\"][row_indexer] = value\n",
            "\n",
            "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "  df[\"m2_growth\"].iloc[0] = 0.0\n",
            "/tmp/ipython-input-2876661565.py:144: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
            "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
            "A typical example is when you are setting values in a column of a DataFrame, like:\n",
            "\n",
            "df[\"col\"][row_indexer] = value\n",
            "\n",
            "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "  df[\"m1_growth\"].iloc[0] = 0.0\n"
          ]
        }
      ],
      "source": [
        "# ================== Setup ==================\n",
        "# pip install yfinance fredapi pandas pandas-datareader\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from fredapi import Fred\n",
        "from datetime import date\n",
        "\n",
        "# ----- Parameters -----\n",
        "START = \"2013-01-01\"\n",
        "END   = date.today().isoformat()         # ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ\n",
        "FRED_API_KEY = \"c948956426006ca126a2dd3bd1f07cee\"  # ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏¢‡πà‡∏≤ hardcode key ‡∏à‡∏£‡∏¥‡∏á‡∏•‡∏á‡∏á‡∏≤‡∏ô/‡∏Ç‡∏∂‡πâ‡∏ô GitHub\n",
        "\n",
        "# FRED client (‡∏Å‡∏±‡∏ô‡∏≠‡∏¥‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡πÄ‡∏ô‡πá‡∏ï‡∏•‡πà‡∏°)\n",
        "try:\n",
        "    fred = Fred(api_key=FRED_API_KEY)\n",
        "except Exception:\n",
        "    fred = None\n",
        "\n",
        "# ================== Helper Functions ==================\n",
        "def get_fred_series(series_id: str, rename_to: str = None) -> pd.Series:\n",
        "    \"\"\"‡∏î‡∏∂‡∏á‡∏ã‡∏µ‡∏£‡∏µ‡∏™‡πå‡∏à‡∏≤‡∏Å FRED\"\"\"\n",
        "    if fred is None:\n",
        "        return pd.Series(dtype=\"float64\", name=rename_to or series_id)\n",
        "    s = fred.get_series(series_id)\n",
        "    s.name = rename_to or series_id\n",
        "    s.index = pd.to_datetime(s.index)\n",
        "    return s.sort_index()\n",
        "\n",
        "def expand_period_to_target_index(target_index: pd.DatetimeIndex,\n",
        "                                  lowfreq_series: pd.Series,\n",
        "                                  freq: str) -> pd.Series:\n",
        "    \"\"\"‡∏Ç‡∏¢‡∏≤‡∏¢‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà‡∏ï‡πà‡∏≥‡πÑ‡∏õ‡∏ó‡∏µ‡πà target_index (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Ç‡∏≠‡∏á‡πÄ‡∏î‡∏¥‡∏°)\"\"\"\n",
        "    if lowfreq_series is None or lowfreq_series.empty:\n",
        "        return pd.Series(index=target_index, dtype=\"float64\", name=getattr(lowfreq_series, \"name\", None))\n",
        "    s = lowfreq_series.dropna().copy()\n",
        "    s.index = pd.PeriodIndex(s.index, freq=freq)\n",
        "    df = pd.DataFrame(index=target_index)\n",
        "    df[\"period\"] = df.index.to_period(freq)\n",
        "    out = df.join(s.rename(s.name), on=\"period\")[s.name]\n",
        "    out.name = s.name\n",
        "    return out\n",
        "\n",
        "# ================== 2) Macro: USA via FRED ==================\n",
        "# ‡∏Ñ‡∏∏‡∏ì‡∏≠‡∏¢‡∏≤‡∏Å‡πÑ‡∏î‡πâ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£:\n",
        "# [\"inflation_rate\"], [\"GDP\"], [\"m2_growth\"], [\"bond_yield_spread\"], [\"dxy\"],\n",
        "# [\"nonfarm_payrolls\"], [\"unemployment_rate\"], [\"vix_index\"], [\"ppi_inflation\"],\n",
        "# [\"real_rate_10y\"], [\"m1_growth\"]\n",
        "\n",
        "# ‡∏î‡∏∂‡∏á series (‡∏ö‡∏≤‡∏á‡∏≠‡∏±‡∏ô‡πÄ‡∏õ‡πá‡∏ô daily, monthly, quarterly)\n",
        "cpi_index = get_fred_series(\"CPIAUCSL\", \"CPI_Index\")     # monthly\n",
        "ppi_index = get_fred_series(\"PPIACO\", \"PPI_Index\")       # monthly\n",
        "\n",
        "\n",
        "m2_level  = get_fred_series(\"M2SL\", \"M2_Level\")          # weekly-ish\n",
        "m1_level  = get_fred_series(\"M1SL\", \"M1_Level\")          # weekly-ish\n",
        "\n",
        "bond_spread = get_fred_series(\"T10Y2Y\", \"bond_yield_spread\")  # daily\n",
        "dxy_index   = get_fred_series(\"DTWEXBGS\", \"dxy\")              # weekly-ish\n",
        "payems      = get_fred_series(\"PAYEMS\", \"nonfarm_payrolls\")   # monthly\n",
        "unrate      = get_fred_series(\"UNRATE\", \"unemployment_rate\")  # monthly\n",
        "vix         = get_fred_series(\"VIXCLS\", \"vix_index\")          # daily\n",
        "real10y     = get_fred_series(\"DFII10\", \"real_rate_10y\")      # daily\n",
        "\n",
        "# ================== 1) Stock Prices ==================\n",
        "SECTORS = {\n",
        "    \"Healthcare\": [\"AMGN\",\"GILD\",\"VRTX\",\"REGN\",\"BIIB\",\"ILMN\",\"IDXX\",\"ISRG\",\"ALGN\"]\n",
        "}\n",
        "\n",
        "df_stocks = pd.DataFrame()\n",
        "for sector, tickers in SECTORS.items():\n",
        "    for ticker in tickers:\n",
        "        try:\n",
        "            data = yf.download(ticker, start=START, end=END, interval=\"1mo\", auto_adjust=False, progress=False)['Close']\n",
        "            if isinstance(data, pd.Series):\n",
        "                df_stocks[f\"Close_{ticker}\"] = data\n",
        "            else:\n",
        "                df_stocks[f\"Close_{ticker}\"] = data[ticker]\n",
        "        except Exception:\n",
        "            df_stocks[f\"Close_{ticker}\"] = pd.Series(dtype=\"float64\")\n",
        "\n",
        "df_stocks = df_stocks.dropna(how=\"all\")\n",
        "\n",
        "# *** ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏î‡∏¥‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì: ‡πÉ‡∏ä‡πâ index ‡∏à‡∏≤‡∏Å df_stocks ‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏Å‡∏ô ***\n",
        "# (‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏î‡∏¥‡∏° quarterly_index ‡πÅ‡∏ï‡πà‡∏à‡∏£‡∏¥‡∏á ‡πÜ ‡πÄ‡∏õ‡πá‡∏ô monthly ‡∏à‡∏≤‡∏Å interval=\"1mo\")\n",
        "if not df_stocks.empty:\n",
        "    monthly_index = df_stocks.index\n",
        "else:\n",
        "    monthly_index = pd.date_range(start=pd.to_datetime(START), end=pd.to_datetime(END), freq=\"MS\")\n",
        "\n",
        "# ================== 2) Align Macro (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°) ==================\n",
        "# ‡∏ó‡∏≥ index ‡∏ã‡πâ‡∏≥‡∏ã‡πâ‡∏≠‡∏ô‡πÉ‡∏´‡πâ‡∏™‡∏∞‡∏≠‡∏≤‡∏î\n",
        "def _dedupe(s: pd.Series) -> pd.Series:\n",
        "    s = s.copy()\n",
        "    s = s[~pd.Index(s.index).duplicated(keep=\"last\")]\n",
        "    return s.sort_index()\n",
        "\n",
        "cpi_index  = _dedupe(cpi_index)\n",
        "ppi_index  = _dedupe(ppi_index)\n",
        "m2_level   = _dedupe(m2_level)\n",
        "m1_level   = _dedupe(m1_level)\n",
        "bond_spread= _dedupe(bond_spread)\n",
        "dxy_index  = _dedupe(dxy_index)\n",
        "payems     = _dedupe(payems)\n",
        "unrate     = _dedupe(unrate)\n",
        "vix        = _dedupe(vix)\n",
        "real10y    = _dedupe(real10y)\n",
        "\n",
        "# GDP ‡πÄ‡∏õ‡πá‡∏ô quarterly -> ‡∏Ç‡∏¢‡∏≤‡∏¢‡πÑ‡∏õ‡∏ï‡∏≤‡∏° index ‡∏Ç‡∏≠‡∏á‡∏´‡∏∏‡πâ‡∏ô (monthly) ‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏¥‡∏°\n",
        "\n",
        "\n",
        "# ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÉ‡∏ä‡πâ reindex ffill ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Ç‡∏≠‡∏á‡πÄ‡∏î‡∏¥‡∏°\n",
        "cpi_aligned   = cpi_index.reindex(monthly_index, method=\"ffill\")\n",
        "ppi_aligned   = ppi_index.reindex(monthly_index, method=\"ffill\")\n",
        "m2_aligned    = m2_level.reindex(monthly_index, method=\"ffill\")\n",
        "m1_aligned    = m1_level.reindex(monthly_index, method=\"ffill\")\n",
        "bond_aligned  = bond_spread.reindex(monthly_index, method=\"ffill\")\n",
        "dxy_aligned   = dxy_index.reindex(monthly_index, method=\"ffill\")\n",
        "payems_aligned= payems.reindex(monthly_index, method=\"ffill\")\n",
        "unrate_aligned= unrate.reindex(monthly_index, method=\"ffill\")\n",
        "vix_aligned   = vix.reindex(monthly_index, method=\"ffill\")\n",
        "real10y_aligned = real10y.reindex(monthly_index, method=\"ffill\")\n",
        "\n",
        "\n",
        "# ================== 4) Combine ‡∏´‡∏∏‡πâ‡∏ô + Macro (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°) ==================\n",
        "df = df_stocks.copy()\n",
        "if df.empty:\n",
        "    df = pd.DataFrame(index=monthly_index)\n",
        "\n",
        "# inflation_rate: YoY ‡∏à‡∏≤‡∏Å CPI index\n",
        "df[\"inflation_rate\"] = cpi_aligned.pct_change(12)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# m2_growth / m1_growth: ln(S_t / S_{t-1}) ‡πÅ‡∏•‡∏∞‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å‡πÄ‡∏õ‡πá‡∏ô 0\n",
        "df[\"m2_growth\"] = np.log(m2_aligned / m2_aligned.shift(1))\n",
        "if len(df[\"m2_growth\"]) > 0:\n",
        "    df[\"m2_growth\"].iloc[0] = 0.0\n",
        "\n",
        "df[\"m1_growth\"] = np.log(m1_aligned / m1_aligned.shift(1))\n",
        "if len(df[\"m1_growth\"]) > 0:\n",
        "    df[\"m1_growth\"].iloc[0] = 0.0\n",
        "\n",
        "# bond_yield_spread, dxy, labor, risk\n",
        "df[\"bond_yield_spread\"] = bond_aligned\n",
        "df[\"dxy\"]               = dxy_aligned\n",
        "df[\"nonfarm_payrolls\"]  = payems_aligned\n",
        "df[\"unemployment_rate\"] = unrate_aligned\n",
        "df[\"vix_index\"]         = vix_aligned\n",
        "df[\"real_rate_10y\"]     = real10y_aligned\n",
        "\n",
        "# ppi_inflation: YoY ‡∏à‡∏≤‡∏Å PPI index\n",
        "df[\"ppi_inflation\"] = ppi_aligned.pct_change(12)\n",
        "\n",
        "# ================== 5) ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°) ==================\n",
        "df = df.iloc[25:]  # ‡∏ï‡∏±‡∏î‡∏ä‡πà‡∏ß‡∏á‡∏ï‡πâ‡∏ô‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏° (‡∏Å‡∏±‡∏ô NaN ‡∏à‡∏≤‡∏Å YoY/shift)\n",
        "\n",
        "print(df)\n",
        "print(\"\\n=== HEAD ===\")\n",
        "print(df.head(10))\n",
        "print(\"\\n=== TAIL ===\")\n",
        "print(df.tail(10))\n",
        "print(\"\\n=== COLUMNS ===\")\n",
        "print(df.columns.tolist())\n",
        "print(\"\\n=== NA COUNTS ===\")\n",
        "print(df.isna().sum())\n",
        "\n",
        "# (Optional) Save to CSV\n",
        "# df.to_csv(\"us_healthcare_macro_2013_today_monthly_like_yours.csv\", encoding=\"utf-8-sig\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# üìä BLOCK 1.5 (USA): Chow-Lin Temporal Disaggregation (GDP Quarterly ‚Üí Monthly)\n",
        "#    Chow & Lin (1971) - Best Linear Unbiased Interpolation\n",
        "#    Use FRED: GDP (quarterly) + INDPRO (monthly indicator)\n",
        "# ============================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import linalg  # not strictly required, but ok to keep\n",
        "\n",
        "# ================== 1) Chow-Lin Function ==================\n",
        "def chow_lin_disaggregate(y_low: pd.Series, X_high: pd.DataFrame,\n",
        "                          agg_method: str = 'sum', rho: float = None) -> tuple:\n",
        "    \"\"\"\n",
        "    Chow-Lin temporal disaggregation: Low-frequency ‚Üí High-frequency\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    y_low : pd.Series\n",
        "        Low-frequency series (e.g., Quarterly GDP) with DatetimeIndex\n",
        "    X_high : pd.DataFrame\n",
        "        High-frequency indicator(s) (e.g., Monthly INDPRO) with DatetimeIndex\n",
        "    agg_method : str\n",
        "        'sum' for flow variables (GDP), 'mean' for stock/average variables\n",
        "    rho : float or None\n",
        "        AR(1) autocorrelation parameter. If None, estimate from data.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    (pd.Series, beta, rho)\n",
        "    \"\"\"\n",
        "\n",
        "    # 1) Align data\n",
        "    y_low = y_low.dropna().copy()\n",
        "    X_high = X_high.dropna().copy()\n",
        "\n",
        "    # Frequency ratio Q‚ÜíM = 3 months per quarter\n",
        "    n_high_per_low = 3\n",
        "\n",
        "    # Overlap period\n",
        "    quarters = y_low.index\n",
        "    months = X_high.index\n",
        "\n",
        "    min_date = max(quarters.min(), months.min().to_period('Q').to_timestamp())\n",
        "    max_date = min(quarters.max(), months.max().to_period('Q').to_timestamp())\n",
        "\n",
        "    y_low = y_low[(y_low.index >= min_date) & (y_low.index <= max_date)]\n",
        "\n",
        "    # monthly span covering the low-frequency period\n",
        "    month_start = y_low.index.min()\n",
        "    month_end = (y_low.index.max() + pd.offsets.QuarterEnd()).to_period('M').to_timestamp()\n",
        "\n",
        "    X_high = X_high[(X_high.index >= month_start) & (X_high.index <= month_end)]\n",
        "\n",
        "    n_low = len(y_low)\n",
        "    n_high = n_low * n_high_per_low\n",
        "\n",
        "    # Trim / pad X_high to exact size\n",
        "    X_high = X_high.iloc[:n_high]\n",
        "    if len(X_high) < n_high:\n",
        "        pad_size = n_high - len(X_high)\n",
        "        last_idx = X_high.index[-1]\n",
        "        new_idx = pd.date_range(start=last_idx + pd.offsets.MonthBegin(), periods=pad_size, freq='MS')\n",
        "        pad_df = pd.DataFrame(index=new_idx, columns=X_high.columns)\n",
        "        for col in X_high.columns:\n",
        "            pad_df[col] = X_high[col].iloc[-1]\n",
        "        X_high = pd.concat([X_high, pad_df])\n",
        "\n",
        "    # 3) Aggregation matrix C (n_low x n_high)\n",
        "    C = np.zeros((n_low, n_high))\n",
        "    for i in range(n_low):\n",
        "        start_col = i * n_high_per_low\n",
        "        end_col = start_col + n_high_per_low\n",
        "        if agg_method == 'sum':\n",
        "            C[i, start_col:end_col] = 1.0\n",
        "        elif agg_method == 'mean':\n",
        "            C[i, start_col:end_col] = 1.0 / n_high_per_low\n",
        "        else:  # 'last'\n",
        "            C[i, end_col - 1] = 1.0\n",
        "\n",
        "    # 4) X matrix (add constant)\n",
        "    X = X_high.values\n",
        "    if X.ndim == 1:\n",
        "        X = X.reshape(-1, 1)\n",
        "    X = np.column_stack([np.ones(n_high), X])  # intercept\n",
        "\n",
        "    # 5) Aggregate X to quarterly\n",
        "    X_low = C @ X\n",
        "    y = y_low.values.flatten()\n",
        "\n",
        "    # 6) OLS on aggregated data\n",
        "    beta_ols = np.linalg.lstsq(X_low, y, rcond=None)[0]\n",
        "    u_low = y - X_low @ beta_ols\n",
        "\n",
        "    # 7) Estimate rho if None\n",
        "    if rho is None:\n",
        "        if len(u_low) > 1:\n",
        "            rho = np.corrcoef(u_low[:-1], u_low[1:])[0, 1]\n",
        "            rho = float(np.clip(rho, -0.99, 0.99))\n",
        "        else:\n",
        "            rho = 0.0\n",
        "\n",
        "    # 8) Covariance matrix V (AR1)\n",
        "    V = np.fromfunction(lambda i, j: rho ** np.abs(i - j), (n_high, n_high), dtype=float)\n",
        "\n",
        "    # 9) GLS\n",
        "    V_low = C @ V @ C.T\n",
        "    try:\n",
        "        V_low_inv = np.linalg.inv(V_low)\n",
        "    except np.linalg.LinAlgError:\n",
        "        V_low_inv = np.linalg.pinv(V_low)\n",
        "\n",
        "    XVX = X_low.T @ V_low_inv @ X_low\n",
        "    XVy = X_low.T @ V_low_inv @ y\n",
        "    try:\n",
        "        beta_gls = np.linalg.solve(XVX, XVy)\n",
        "    except np.linalg.LinAlgError:\n",
        "        beta_gls = np.linalg.lstsq(XVX, XVy, rcond=None)[0]\n",
        "\n",
        "    # 10) Preliminary high-frequency estimate\n",
        "    p_high = X @ beta_gls\n",
        "\n",
        "    # 11) Distribute residuals\n",
        "    u_low_gls = y - X_low @ beta_gls\n",
        "    VCt = V @ C.T\n",
        "    try:\n",
        "        dist_matrix = VCt @ np.linalg.inv(V_low)\n",
        "    except np.linalg.LinAlgError:\n",
        "        dist_matrix = VCt @ np.linalg.pinv(V_low)\n",
        "\n",
        "    y_high = p_high + dist_matrix @ u_low_gls\n",
        "\n",
        "    # 12) Output series\n",
        "    result = pd.Series(y_high, index=X_high.index, name=y_low.name or 'GDP_Monthly')\n",
        "    return result, beta_gls, rho\n",
        "\n",
        "\n",
        "# ================== 2) Load US GDP Quarterly from FRED ==================\n",
        "print(\"=\"*60)\n",
        "print(\"üìä BLOCK 1.5 (USA): Chow-Lin Temporal Disaggregation\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nüì• Loading US GDP Quarterly from FRED...\")\n",
        "\n",
        "# GDP (US, quarterly, SAAR in billions of dollars in FRED)\n",
        "gdp_quarterly = get_fred_series(\"GDP\", \"GDP_US_Q\")\n",
        "\n",
        "# Make sure it's quarter-start indexed (optional but helps consistent resample)\n",
        "# FRED GDP usually timestamps quarter start already; still ok either way.\n",
        "gdp_quarterly = gdp_quarterly.sort_index()\n",
        "\n",
        "print(f\"‚úÖ US GDP Quarterly loaded: {len(gdp_quarterly)} quarters\")\n",
        "print(f\"   Period: {gdp_quarterly.index.min().strftime('%Y-%m')} to {gdp_quarterly.index.max().strftime('%Y-%m')}\")\n",
        "\n",
        "\n",
        "# ================== 3) Prepare Monthly Indicator (INDPRO) ==================\n",
        "print(\"\\nüì• Loading monthly indicator (INDPRO) from FRED...\")\n",
        "\n",
        "# INDPRO: Industrial Production Index (monthly)\n",
        "indpro = get_fred_series(\"INDPRO\", \"INDPRO\")\n",
        "indpro = indpro.sort_index()\n",
        "\n",
        "# Align to month-start index (optional; depends on your df index style)\n",
        "# If your main df uses month-start (YYYY-MM-01), this keeps it consistent:\n",
        "indpro_ms = indpro.resample(\"MS\").mean()  # monthly value placed on month-start\n",
        "indpro_ms.name = \"INDPRO\"\n",
        "\n",
        "print(f\"‚úÖ INDPRO Monthly loaded: {len(indpro_ms)} months\")\n",
        "print(f\"   Period: {indpro_ms.index.min().strftime('%Y-%m')} to {indpro_ms.index.max().strftime('%Y-%m')}\")\n",
        "\n",
        "X_indicator = pd.DataFrame({\"INDPRO\": indpro_ms})\n",
        "\n",
        "\n",
        "# ================== 4) Apply Chow-Lin (GDP Q ‚Üí GDP M) ==================\n",
        "print(\"\\nüîÑ Applying Chow-Lin disaggregation (US GDP Quarterly ‚Üí Monthly)...\")\n",
        "\n",
        "gdp_monthly, beta_chowlin, rho_chowlin = chow_lin_disaggregate(\n",
        "    y_low=gdp_quarterly,\n",
        "    X_high=X_indicator,\n",
        "    agg_method=\"sum\",   # GDP is a flow variable\n",
        "    rho=None\n",
        ")\n",
        "\n",
        "# Monthly GDP growth (log)\n",
        "gdp_growth_monthly = np.log(gdp_monthly / gdp_monthly.shift(1))\n",
        "gdp_growth_monthly.name = \"gdp_growth\"\n",
        "\n",
        "print(f\"\\n‚úÖ Chow-Lin completed!\")\n",
        "print(f\"   - Estimated AR(1) rho: {rho_chowlin:.4f}\")\n",
        "print(f\"   - Monthly GDP observations: {len(gdp_monthly)}\")\n",
        "\n",
        "\n",
        "# ================== 5) Validation (aggregate back to quarterly) ==================\n",
        "print(\"\\nüîç Validation: Aggregating monthly back to quarterly...\")\n",
        "\n",
        "gdp_monthly_to_q = gdp_monthly.resample(\"QS\").sum()\n",
        "\n",
        "validation = pd.DataFrame({\n",
        "    \"Original_Q\": gdp_quarterly,\n",
        "    \"ChowLin_Agg_Q\": gdp_monthly_to_q\n",
        "}).dropna()\n",
        "\n",
        "validation[\"Error_%\"] = (validation[\"ChowLin_Agg_Q\"] - validation[\"Original_Q\"]).abs() / validation[\"Original_Q\"] * 100\n",
        "print(f\"‚úÖ Mean Aggregation Error: {validation['Error_%'].mean():.6f}%\")\n",
        "print(\"   (Should be ~0% if Chow-Lin is working correctly)\")\n",
        "\n",
        "\n",
        "# ================== 6) Add to main df (if exists) ==================\n",
        "print(\"\\nüìå Adding GDP_Monthly and gdp_growth to main dataframe...\")\n",
        "\n",
        "if \"df\" in globals():\n",
        "    df[\"GDP_Monthly\"] = gdp_monthly.reindex(df.index)\n",
        "    df[\"gdp_growth\"]  = gdp_growth_monthly.reindex(df.index)\n",
        "\n",
        "    # Optional: forward-fill small gaps\n",
        "    df[\"GDP_Monthly\"] = df[\"GDP_Monthly\"].ffill()\n",
        "    df[\"gdp_growth\"]  = df[\"gdp_growth\"].ffill()\n",
        "\n",
        "    print(\"‚úÖ Added to df:\", [\"GDP_Monthly\", \"gdp_growth\"])\n",
        "    print(\"df shape:\", df.shape)\n",
        "    print(df[[\"GDP_Monthly\", \"gdp_growth\"]].dropna().tail(10))\n",
        "else:\n",
        "    gdp_output = pd.DataFrame({\n",
        "        \"GDP_Monthly\": gdp_monthly,\n",
        "        \"gdp_growth\": gdp_growth_monthly\n",
        "    })\n",
        "    print(gdp_output.tail(10))\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ BLOCK 1.5 (USA) COMPLETED\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\"\"\n",
        "Summary:\n",
        "- Input:  US GDP Quarterly (FRED: GDP) - {len(gdp_quarterly)} quarters\n",
        "- Output: US GDP Monthly - {len(gdp_monthly)} months\n",
        "- Indicator used: INDPRO (Industrial Production Index)\n",
        "- Method: Chow-Lin (1971) with AR(1) residual structure\n",
        "- Estimated rho: {rho_chowlin:.4f}\n",
        "\n",
        "New columns (if df exists):\n",
        "- 'GDP_Monthly': Monthly GDP level (derived)\n",
        "- 'gdp_growth' : Monthly GDP growth rate (log)\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSokRAAP4TTp",
        "outputId": "6158b64e-9e2e-4213-a6f9-feb4a6448d3a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "üìä BLOCK 1.5 (USA): Chow-Lin Temporal Disaggregation\n",
            "============================================================\n",
            "\n",
            "üì• Loading US GDP Quarterly from FRED...\n",
            "‚úÖ US GDP Quarterly loaded: 319 quarters\n",
            "   Period: 1946-01 to 2025-07\n",
            "\n",
            "üì• Loading monthly indicator (INDPRO) from FRED...\n",
            "‚úÖ INDPRO Monthly loaded: 1284 months\n",
            "   Period: 1919-01 to 2025-12\n",
            "\n",
            "üîÑ Applying Chow-Lin disaggregation (US GDP Quarterly ‚Üí Monthly)...\n",
            "\n",
            "‚úÖ Chow-Lin completed!\n",
            "   - Estimated AR(1) rho: 0.9900\n",
            "   - Monthly GDP observations: 945\n",
            "\n",
            "üîç Validation: Aggregating monthly back to quarterly...\n",
            "‚úÖ Mean Aggregation Error: 0.000000%\n",
            "   (Should be ~0% if Chow-Lin is working correctly)\n",
            "\n",
            "üìå Adding GDP_Monthly and gdp_growth to main dataframe...\n",
            "‚úÖ Added to df: ['GDP_Monthly', 'gdp_growth']\n",
            "df shape: (132, 21)\n",
            "             GDP_Monthly  gdp_growth\n",
            "Date                                \n",
            "2025-04-01  10097.755060    0.004790\n",
            "2025-05-01  10144.625466    0.004631\n",
            "2025-06-01  10243.348473    0.009685\n",
            "2025-07-01  10349.465335    0.010306\n",
            "2025-08-01  10370.101168    0.001992\n",
            "2025-09-01  10375.522497    0.000523\n",
            "2025-10-01  10375.522497    0.000523\n",
            "2025-11-01  10375.522497    0.000523\n",
            "2025-12-01  10375.522497    0.000523\n",
            "2026-01-01  10375.522497    0.000523\n",
            "\n",
            "============================================================\n",
            "‚úÖ BLOCK 1.5 (USA) COMPLETED\n",
            "============================================================\n",
            "\n",
            "Summary:\n",
            "- Input:  US GDP Quarterly (FRED: GDP) - 319 quarters\n",
            "- Output: US GDP Monthly - 945 months\n",
            "- Indicator used: INDPRO (Industrial Production Index)\n",
            "- Method: Chow-Lin (1971) with AR(1) residual structure\n",
            "- Estimated rho: 0.9900\n",
            "\n",
            "New columns (if df exists):\n",
            "- 'GDP_Monthly': Monthly GDP level (derived)\n",
            "- 'gdp_growth' : Monthly GDP growth rate (log)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kbl9fHdopGI_"
      },
      "source": [
        "**2 Data preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 831
        },
        "id": "ZXefL-WtoerI",
        "outputId": "b44837a2-a76e-487f-f1b6-2b5293304352"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Combined data shape: (118, 20)\n",
            "‚úÖ Stocks: 9 | Macros: 11\n",
            "‚úÖ Differenced data ready: (117, 38)\n",
            "\n",
            "=== Combined_dfs (Levels) ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "            Close_AMGN  Close_GILD  Close_VRTX  Close_REGN  Close_BIIB  \\\n",
              "Date                                                                     \n",
              "2016-04-01  158.300003   88.209999   84.339996  376.709991  274.989990   \n",
              "2016-05-01  157.949997   87.059998   93.150002  398.929993  289.730011   \n",
              "2016-06-01  152.149994   83.419998   86.019997  349.230011  241.820007   \n",
              "2016-07-01  172.029999   79.470001   97.000000  425.119995  289.929993   \n",
              "2016-08-01  170.059998   78.379997   94.510002  392.549988  305.630005   \n",
              "\n",
              "            Close_ILMN  Close_IDXX  Close_ISRG  Close_ALGN  inflation_rate  \\\n",
              "Date                                                                         \n",
              "2016-04-01  131.313232   84.349998   69.595558   72.190002        0.011726   \n",
              "2016-05-01  140.885208   87.570000   70.523331   78.830002        0.010785   \n",
              "2016-06-01  136.556427   92.860001   73.489998   80.550003        0.010793   \n",
              "2016-07-01  161.819061   93.790001   77.306664   89.150002        0.008684   \n",
              "2016-08-01  163.754868  112.680000   76.268890   92.900002        0.010553   \n",
              "\n",
              "            ...  gdp_growth  Logclose_AMGN  Logclose_GILD  Logclose_VRTX  \\\n",
              "Date        ...                                                            \n",
              "2016-04-01  ...    0.008352       5.064492       4.479720       4.434856   \n",
              "2016-05-01  ...    0.001967       5.062279       4.466598       4.534211   \n",
              "2016-06-01  ...    0.007107       5.024867       4.423888       4.454580   \n",
              "2016-07-01  ...    0.002690       5.147669       4.375380       4.574711   \n",
              "2016-08-01  ...    0.001123       5.136151       4.361569       4.548706   \n",
              "\n",
              "            Logclose_REGN  Logclose_BIIB  Logclose_ILMN  Logclose_IDXX  \\\n",
              "Date                                                                     \n",
              "2016-04-01       5.931476       5.616735       4.877586       4.434975   \n",
              "2016-05-01       5.988786       5.668949       4.947945       4.472438   \n",
              "2016-06-01       5.855731       5.488194       4.916738       4.531093   \n",
              "2016-07-01       6.052371       5.669639       5.086479       4.541058   \n",
              "2016-08-01       5.972664       5.722375       5.098371       4.724552   \n",
              "\n",
              "            Logclose_ISRG  Logclose_ALGN  \n",
              "Date                                      \n",
              "2016-04-01       4.242701       4.279302  \n",
              "2016-05-01       4.255944       4.367294  \n",
              "2016-06-01       4.297149       4.388878  \n",
              "2016-07-01       4.347780       4.490320  \n",
              "2016-08-01       4.334265       4.531524  \n",
              "\n",
              "[5 rows x 29 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fcfbb92a-bf94-498f-a0e1-32b61859b4ad\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Close_AMGN</th>\n",
              "      <th>Close_GILD</th>\n",
              "      <th>Close_VRTX</th>\n",
              "      <th>Close_REGN</th>\n",
              "      <th>Close_BIIB</th>\n",
              "      <th>Close_ILMN</th>\n",
              "      <th>Close_IDXX</th>\n",
              "      <th>Close_ISRG</th>\n",
              "      <th>Close_ALGN</th>\n",
              "      <th>inflation_rate</th>\n",
              "      <th>...</th>\n",
              "      <th>gdp_growth</th>\n",
              "      <th>Logclose_AMGN</th>\n",
              "      <th>Logclose_GILD</th>\n",
              "      <th>Logclose_VRTX</th>\n",
              "      <th>Logclose_REGN</th>\n",
              "      <th>Logclose_BIIB</th>\n",
              "      <th>Logclose_ILMN</th>\n",
              "      <th>Logclose_IDXX</th>\n",
              "      <th>Logclose_ISRG</th>\n",
              "      <th>Logclose_ALGN</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2016-04-01</th>\n",
              "      <td>158.300003</td>\n",
              "      <td>88.209999</td>\n",
              "      <td>84.339996</td>\n",
              "      <td>376.709991</td>\n",
              "      <td>274.989990</td>\n",
              "      <td>131.313232</td>\n",
              "      <td>84.349998</td>\n",
              "      <td>69.595558</td>\n",
              "      <td>72.190002</td>\n",
              "      <td>0.011726</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008352</td>\n",
              "      <td>5.064492</td>\n",
              "      <td>4.479720</td>\n",
              "      <td>4.434856</td>\n",
              "      <td>5.931476</td>\n",
              "      <td>5.616735</td>\n",
              "      <td>4.877586</td>\n",
              "      <td>4.434975</td>\n",
              "      <td>4.242701</td>\n",
              "      <td>4.279302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-05-01</th>\n",
              "      <td>157.949997</td>\n",
              "      <td>87.059998</td>\n",
              "      <td>93.150002</td>\n",
              "      <td>398.929993</td>\n",
              "      <td>289.730011</td>\n",
              "      <td>140.885208</td>\n",
              "      <td>87.570000</td>\n",
              "      <td>70.523331</td>\n",
              "      <td>78.830002</td>\n",
              "      <td>0.010785</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001967</td>\n",
              "      <td>5.062279</td>\n",
              "      <td>4.466598</td>\n",
              "      <td>4.534211</td>\n",
              "      <td>5.988786</td>\n",
              "      <td>5.668949</td>\n",
              "      <td>4.947945</td>\n",
              "      <td>4.472438</td>\n",
              "      <td>4.255944</td>\n",
              "      <td>4.367294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-06-01</th>\n",
              "      <td>152.149994</td>\n",
              "      <td>83.419998</td>\n",
              "      <td>86.019997</td>\n",
              "      <td>349.230011</td>\n",
              "      <td>241.820007</td>\n",
              "      <td>136.556427</td>\n",
              "      <td>92.860001</td>\n",
              "      <td>73.489998</td>\n",
              "      <td>80.550003</td>\n",
              "      <td>0.010793</td>\n",
              "      <td>...</td>\n",
              "      <td>0.007107</td>\n",
              "      <td>5.024867</td>\n",
              "      <td>4.423888</td>\n",
              "      <td>4.454580</td>\n",
              "      <td>5.855731</td>\n",
              "      <td>5.488194</td>\n",
              "      <td>4.916738</td>\n",
              "      <td>4.531093</td>\n",
              "      <td>4.297149</td>\n",
              "      <td>4.388878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-07-01</th>\n",
              "      <td>172.029999</td>\n",
              "      <td>79.470001</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>425.119995</td>\n",
              "      <td>289.929993</td>\n",
              "      <td>161.819061</td>\n",
              "      <td>93.790001</td>\n",
              "      <td>77.306664</td>\n",
              "      <td>89.150002</td>\n",
              "      <td>0.008684</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002690</td>\n",
              "      <td>5.147669</td>\n",
              "      <td>4.375380</td>\n",
              "      <td>4.574711</td>\n",
              "      <td>6.052371</td>\n",
              "      <td>5.669639</td>\n",
              "      <td>5.086479</td>\n",
              "      <td>4.541058</td>\n",
              "      <td>4.347780</td>\n",
              "      <td>4.490320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-08-01</th>\n",
              "      <td>170.059998</td>\n",
              "      <td>78.379997</td>\n",
              "      <td>94.510002</td>\n",
              "      <td>392.549988</td>\n",
              "      <td>305.630005</td>\n",
              "      <td>163.754868</td>\n",
              "      <td>112.680000</td>\n",
              "      <td>76.268890</td>\n",
              "      <td>92.900002</td>\n",
              "      <td>0.010553</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001123</td>\n",
              "      <td>5.136151</td>\n",
              "      <td>4.361569</td>\n",
              "      <td>4.548706</td>\n",
              "      <td>5.972664</td>\n",
              "      <td>5.722375</td>\n",
              "      <td>5.098371</td>\n",
              "      <td>4.724552</td>\n",
              "      <td>4.334265</td>\n",
              "      <td>4.531524</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 29 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fcfbb92a-bf94-498f-a0e1-32b61859b4ad')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fcfbb92a-bf94-498f-a0e1-32b61859b4ad button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fcfbb92a-bf94-498f-a0e1-32b61859b4ad');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Combined_dfs_diff (Differenced) ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "            Close_AMGN  Close_GILD  Close_VRTX  Close_REGN  Close_BIIB  \\\n",
              "Date                                                                     \n",
              "2016-05-01  157.949997   87.059998   93.150002  398.929993  289.730011   \n",
              "2016-06-01  152.149994   83.419998   86.019997  349.230011  241.820007   \n",
              "2016-07-01  172.029999   79.470001   97.000000  425.119995  289.929993   \n",
              "2016-08-01  170.059998   78.379997   94.510002  392.549988  305.630005   \n",
              "2016-09-01  166.809998   79.120003   87.209999  402.019989  313.029999   \n",
              "\n",
              "            Close_ILMN  Close_IDXX  Close_ISRG  Close_ALGN  inflation_rate  \\\n",
              "Date                                                                         \n",
              "2016-05-01  140.885208   87.570000   70.523331   78.830002        0.010785   \n",
              "2016-06-01  136.556427   92.860001   73.489998   80.550003        0.010793   \n",
              "2016-07-01  161.819061   93.790001   77.306664   89.150002        0.008684   \n",
              "2016-08-01  163.754868  112.680000   76.268890   92.900002        0.010553   \n",
              "2016-09-01  176.712067  112.730003   80.536667   93.750000        0.015486   \n",
              "\n",
              "            ...  Logclose_ALGN  D_Logclose_AMGN  D_Logclose_GILD  \\\n",
              "Date        ...                                                    \n",
              "2016-05-01  ...       4.367294        -0.002213        -0.013123   \n",
              "2016-06-01  ...       4.388878        -0.037412        -0.042709   \n",
              "2016-07-01  ...       4.490320         0.122802        -0.048508   \n",
              "2016-08-01  ...       4.531524        -0.011518        -0.013811   \n",
              "2016-09-01  ...       4.540632        -0.019296         0.009397   \n",
              "\n",
              "            D_Logclose_VRTX  D_Logclose_REGN  D_Logclose_BIIB  \\\n",
              "Date                                                            \n",
              "2016-05-01         0.099355         0.057310         0.052215   \n",
              "2016-06-01        -0.079631        -0.133055        -0.180756   \n",
              "2016-07-01         0.120131         0.196641         0.181446   \n",
              "2016-08-01        -0.026005        -0.079708         0.052736   \n",
              "2016-09-01        -0.080387         0.023838         0.023924   \n",
              "\n",
              "            D_Logclose_ILMN  D_Logclose_IDXX  D_Logclose_ISRG  D_Logclose_ALGN  \n",
              "Date                                                                            \n",
              "2016-05-01         0.070360         0.037464         0.013243         0.087992  \n",
              "2016-06-01        -0.031208         0.058655         0.041206         0.021584  \n",
              "2016-07-01         0.169741         0.009965         0.050631         0.101442  \n",
              "2016-08-01         0.011892         0.183494        -0.013515         0.041203  \n",
              "2016-09-01         0.076151         0.000444         0.054447         0.009108  \n",
              "\n",
              "[5 rows x 38 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-33a807ab-2c7e-405e-b09e-3c6cc37103cf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Close_AMGN</th>\n",
              "      <th>Close_GILD</th>\n",
              "      <th>Close_VRTX</th>\n",
              "      <th>Close_REGN</th>\n",
              "      <th>Close_BIIB</th>\n",
              "      <th>Close_ILMN</th>\n",
              "      <th>Close_IDXX</th>\n",
              "      <th>Close_ISRG</th>\n",
              "      <th>Close_ALGN</th>\n",
              "      <th>inflation_rate</th>\n",
              "      <th>...</th>\n",
              "      <th>Logclose_ALGN</th>\n",
              "      <th>D_Logclose_AMGN</th>\n",
              "      <th>D_Logclose_GILD</th>\n",
              "      <th>D_Logclose_VRTX</th>\n",
              "      <th>D_Logclose_REGN</th>\n",
              "      <th>D_Logclose_BIIB</th>\n",
              "      <th>D_Logclose_ILMN</th>\n",
              "      <th>D_Logclose_IDXX</th>\n",
              "      <th>D_Logclose_ISRG</th>\n",
              "      <th>D_Logclose_ALGN</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2016-05-01</th>\n",
              "      <td>157.949997</td>\n",
              "      <td>87.059998</td>\n",
              "      <td>93.150002</td>\n",
              "      <td>398.929993</td>\n",
              "      <td>289.730011</td>\n",
              "      <td>140.885208</td>\n",
              "      <td>87.570000</td>\n",
              "      <td>70.523331</td>\n",
              "      <td>78.830002</td>\n",
              "      <td>0.010785</td>\n",
              "      <td>...</td>\n",
              "      <td>4.367294</td>\n",
              "      <td>-0.002213</td>\n",
              "      <td>-0.013123</td>\n",
              "      <td>0.099355</td>\n",
              "      <td>0.057310</td>\n",
              "      <td>0.052215</td>\n",
              "      <td>0.070360</td>\n",
              "      <td>0.037464</td>\n",
              "      <td>0.013243</td>\n",
              "      <td>0.087992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-06-01</th>\n",
              "      <td>152.149994</td>\n",
              "      <td>83.419998</td>\n",
              "      <td>86.019997</td>\n",
              "      <td>349.230011</td>\n",
              "      <td>241.820007</td>\n",
              "      <td>136.556427</td>\n",
              "      <td>92.860001</td>\n",
              "      <td>73.489998</td>\n",
              "      <td>80.550003</td>\n",
              "      <td>0.010793</td>\n",
              "      <td>...</td>\n",
              "      <td>4.388878</td>\n",
              "      <td>-0.037412</td>\n",
              "      <td>-0.042709</td>\n",
              "      <td>-0.079631</td>\n",
              "      <td>-0.133055</td>\n",
              "      <td>-0.180756</td>\n",
              "      <td>-0.031208</td>\n",
              "      <td>0.058655</td>\n",
              "      <td>0.041206</td>\n",
              "      <td>0.021584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-07-01</th>\n",
              "      <td>172.029999</td>\n",
              "      <td>79.470001</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>425.119995</td>\n",
              "      <td>289.929993</td>\n",
              "      <td>161.819061</td>\n",
              "      <td>93.790001</td>\n",
              "      <td>77.306664</td>\n",
              "      <td>89.150002</td>\n",
              "      <td>0.008684</td>\n",
              "      <td>...</td>\n",
              "      <td>4.490320</td>\n",
              "      <td>0.122802</td>\n",
              "      <td>-0.048508</td>\n",
              "      <td>0.120131</td>\n",
              "      <td>0.196641</td>\n",
              "      <td>0.181446</td>\n",
              "      <td>0.169741</td>\n",
              "      <td>0.009965</td>\n",
              "      <td>0.050631</td>\n",
              "      <td>0.101442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-08-01</th>\n",
              "      <td>170.059998</td>\n",
              "      <td>78.379997</td>\n",
              "      <td>94.510002</td>\n",
              "      <td>392.549988</td>\n",
              "      <td>305.630005</td>\n",
              "      <td>163.754868</td>\n",
              "      <td>112.680000</td>\n",
              "      <td>76.268890</td>\n",
              "      <td>92.900002</td>\n",
              "      <td>0.010553</td>\n",
              "      <td>...</td>\n",
              "      <td>4.531524</td>\n",
              "      <td>-0.011518</td>\n",
              "      <td>-0.013811</td>\n",
              "      <td>-0.026005</td>\n",
              "      <td>-0.079708</td>\n",
              "      <td>0.052736</td>\n",
              "      <td>0.011892</td>\n",
              "      <td>0.183494</td>\n",
              "      <td>-0.013515</td>\n",
              "      <td>0.041203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-09-01</th>\n",
              "      <td>166.809998</td>\n",
              "      <td>79.120003</td>\n",
              "      <td>87.209999</td>\n",
              "      <td>402.019989</td>\n",
              "      <td>313.029999</td>\n",
              "      <td>176.712067</td>\n",
              "      <td>112.730003</td>\n",
              "      <td>80.536667</td>\n",
              "      <td>93.750000</td>\n",
              "      <td>0.015486</td>\n",
              "      <td>...</td>\n",
              "      <td>4.540632</td>\n",
              "      <td>-0.019296</td>\n",
              "      <td>0.009397</td>\n",
              "      <td>-0.080387</td>\n",
              "      <td>0.023838</td>\n",
              "      <td>0.023924</td>\n",
              "      <td>0.076151</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.054447</td>\n",
              "      <td>0.009108</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 38 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33a807ab-2c7e-405e-b09e-3c6cc37103cf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-33a807ab-2c7e-405e-b09e-3c6cc37103cf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-33a807ab-2c7e-405e-b09e-3c6cc37103cf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# =====================================================\n",
        "# ‚öôÔ∏è BLOCK 2: Prepare Combined Data (No PCA, No LASSO)\n",
        "# =====================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ======== 1) Filter & split ========\n",
        "df_filtered = df.iloc[14:].copy()  # ‡∏ï‡∏±‡∏î‡∏ä‡πà‡∏ß‡∏á‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà NA ‡πÄ‡∏¢‡∏≠‡∏∞\n",
        "\n",
        "# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏∏‡πâ‡∏ô (‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 8 ‡∏ï‡∏±‡∏ß‡πÅ‡∏£‡∏Å)\n",
        "stock_columns = [c for c in df_filtered.columns if c.startswith(\"Close_\")]\n",
        "selected_stock_data = df_filtered[stock_columns]\n",
        "\n",
        "# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ macro ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á\n",
        "\n",
        "macro_columns = [\n",
        "    \"inflation_rate\",\n",
        "    \"ppi_inflation\",\n",
        "    \"m2_growth\",\n",
        "    \"m1_growth\",\n",
        "    \"bond_yield_spread\",\n",
        "    \"dxy\",\n",
        "    \"nonfarm_payrolls\",\n",
        "    \"unemployment_rate\",\n",
        "    \"vix_index\",\n",
        "    \"real_rate_10y\",\n",
        "    \"gdp_growth\"\n",
        "]\n",
        "macro_columns = [c for c in macro_columns if c in df_filtered.columns]\n",
        "selected_macro_data = df_filtered[macro_columns]\n",
        "\n",
        "# ======== 2) Combine + clean ========\n",
        "combined_df = pd.concat([selected_stock_data, selected_macro_data], axis=1)\n",
        "combined_df = combined_df.ffill().replace([np.inf, -np.inf], np.nan).dropna(how=\"any\")\n",
        "\n",
        "print(\"‚úÖ Combined data shape:\", combined_df.shape)\n",
        "print(\"‚úÖ Stocks:\", len(stock_columns), \"| Macros:\", len(macro_columns))\n",
        "\n",
        "# ======== 3) Log-transform ‡∏´‡∏∏‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á Œîlog ========\n",
        "combined_dfs = combined_df.copy()\n",
        "for c in stock_columns:\n",
        "    combined_dfs[f\"Logclose_{c.replace('Close_','')}\"] = np.log(combined_df[c])\n",
        "\n",
        "combined_dfs_diff = combined_dfs.copy()\n",
        "for c in stock_columns:\n",
        "    stock_name = c.replace(\"Close_\",\"\")\n",
        "    combined_dfs_diff[f\"D_Logclose_{stock_name}\"] = combined_dfs[f\"Logclose_{stock_name}\"].diff()\n",
        "\n",
        "# ======== 4) Drop ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å‡∏Ç‡∏≠‡∏á differenced ========\n",
        "combined_dfs_diff = combined_dfs_diff.dropna()\n",
        "\n",
        "print(\"‚úÖ Differenced data ready:\", combined_dfs_diff.shape)\n",
        "\n",
        "# ======== 5) ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå ========\n",
        "print(\"\\n=== Combined_dfs (Levels) ===\")\n",
        "display(combined_dfs.head())\n",
        "\n",
        "print(\"\\n=== Combined_dfs_diff (Differenced) ===\")\n",
        "display(combined_dfs_diff.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "mSL8-kKqouv3",
        "outputId": "15a9812f-e4fd-4fb7-c5c5-3a24337927e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Combined data for sector: Healthcare\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "            Logclose_AMGN  Logclose_GILD  Logclose_VRTX  Logclose_REGN  \\\n",
              "Date                                                                     \n",
              "2015-02-01       5.060821       4.639861       4.782730       6.025479   \n",
              "2015-03-01       5.074236       4.586293       4.770430       6.112531   \n",
              "2015-04-01       5.062025       4.610257       4.814458       6.125689   \n",
              "2015-05-01       5.051521       4.720907       4.854293       6.239418   \n",
              "2015-06-01       5.033831       4.762857       4.816079       6.234666   \n",
              "\n",
              "            Logclose_BIIB  Logclose_ILMN  Logclose_IDXX  Logclose_ISRG  \\\n",
              "Date                                                                     \n",
              "2015-02-01       6.015157       5.247741       4.362015       4.017384   \n",
              "2015-03-01       6.045574       5.196194       4.346917       4.027393   \n",
              "2015-04-01       5.924069       5.188678       4.138122       4.009311   \n",
              "2015-05-01       5.983911       5.300649       4.216562       3.992578   \n",
              "2015-06-01       6.001266       5.358530       4.161068       3.985893   \n",
              "\n",
              "            Logclose_ALGN  inflation_rate  ppi_inflation  m2_growth  \\\n",
              "Date                                                                  \n",
              "2015-02-01       4.049173       -0.000870      -0.070977   0.009868   \n",
              "2015-03-01       3.985088       -0.000220      -0.074879  -0.000160   \n",
              "2015-04-01       4.074822       -0.001040      -0.083533   0.002844   \n",
              "2015-05-01       4.105449        0.000350      -0.070192   0.002301   \n",
              "2015-06-01       4.138521        0.001796      -0.064810   0.003371   \n",
              "\n",
              "            m1_growth  bond_yield_spread       dxy  nonfarm_payrolls  \\\n",
              "Date                                                                   \n",
              "2015-02-01   0.023276               1.21  105.5884          140827.0   \n",
              "2015-03-01  -0.007965               1.37  105.5981          140923.0   \n",
              "2015-04-01   0.000500               1.32  107.0600          141196.0   \n",
              "2015-05-01  -0.008159               1.52  105.6382          141538.0   \n",
              "2015-06-01   0.012181               1.55  107.2238          141709.0   \n",
              "\n",
              "            unemployment_rate  vix_index  real_rate_10y  gdp_growth  \n",
              "Date                                                                 \n",
              "2015-02-01                5.5      20.97           0.03    0.002258  \n",
              "2015-03-01                5.4      13.34           0.17    0.006301  \n",
              "2015-04-01                5.4      15.11           0.07    0.005281  \n",
              "2015-05-01                5.6      12.70           0.18    0.002519  \n",
              "2015-06-01                5.3      13.97           0.39   -0.000021  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f23de549-61b4-4bbb-8a01-cfd136d436d3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Logclose_AMGN</th>\n",
              "      <th>Logclose_GILD</th>\n",
              "      <th>Logclose_VRTX</th>\n",
              "      <th>Logclose_REGN</th>\n",
              "      <th>Logclose_BIIB</th>\n",
              "      <th>Logclose_ILMN</th>\n",
              "      <th>Logclose_IDXX</th>\n",
              "      <th>Logclose_ISRG</th>\n",
              "      <th>Logclose_ALGN</th>\n",
              "      <th>inflation_rate</th>\n",
              "      <th>ppi_inflation</th>\n",
              "      <th>m2_growth</th>\n",
              "      <th>m1_growth</th>\n",
              "      <th>bond_yield_spread</th>\n",
              "      <th>dxy</th>\n",
              "      <th>nonfarm_payrolls</th>\n",
              "      <th>unemployment_rate</th>\n",
              "      <th>vix_index</th>\n",
              "      <th>real_rate_10y</th>\n",
              "      <th>gdp_growth</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2015-02-01</th>\n",
              "      <td>5.060821</td>\n",
              "      <td>4.639861</td>\n",
              "      <td>4.782730</td>\n",
              "      <td>6.025479</td>\n",
              "      <td>6.015157</td>\n",
              "      <td>5.247741</td>\n",
              "      <td>4.362015</td>\n",
              "      <td>4.017384</td>\n",
              "      <td>4.049173</td>\n",
              "      <td>-0.000870</td>\n",
              "      <td>-0.070977</td>\n",
              "      <td>0.009868</td>\n",
              "      <td>0.023276</td>\n",
              "      <td>1.21</td>\n",
              "      <td>105.5884</td>\n",
              "      <td>140827.0</td>\n",
              "      <td>5.5</td>\n",
              "      <td>20.97</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.002258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-03-01</th>\n",
              "      <td>5.074236</td>\n",
              "      <td>4.586293</td>\n",
              "      <td>4.770430</td>\n",
              "      <td>6.112531</td>\n",
              "      <td>6.045574</td>\n",
              "      <td>5.196194</td>\n",
              "      <td>4.346917</td>\n",
              "      <td>4.027393</td>\n",
              "      <td>3.985088</td>\n",
              "      <td>-0.000220</td>\n",
              "      <td>-0.074879</td>\n",
              "      <td>-0.000160</td>\n",
              "      <td>-0.007965</td>\n",
              "      <td>1.37</td>\n",
              "      <td>105.5981</td>\n",
              "      <td>140923.0</td>\n",
              "      <td>5.4</td>\n",
              "      <td>13.34</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.006301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-04-01</th>\n",
              "      <td>5.062025</td>\n",
              "      <td>4.610257</td>\n",
              "      <td>4.814458</td>\n",
              "      <td>6.125689</td>\n",
              "      <td>5.924069</td>\n",
              "      <td>5.188678</td>\n",
              "      <td>4.138122</td>\n",
              "      <td>4.009311</td>\n",
              "      <td>4.074822</td>\n",
              "      <td>-0.001040</td>\n",
              "      <td>-0.083533</td>\n",
              "      <td>0.002844</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>1.32</td>\n",
              "      <td>107.0600</td>\n",
              "      <td>141196.0</td>\n",
              "      <td>5.4</td>\n",
              "      <td>15.11</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.005281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-05-01</th>\n",
              "      <td>5.051521</td>\n",
              "      <td>4.720907</td>\n",
              "      <td>4.854293</td>\n",
              "      <td>6.239418</td>\n",
              "      <td>5.983911</td>\n",
              "      <td>5.300649</td>\n",
              "      <td>4.216562</td>\n",
              "      <td>3.992578</td>\n",
              "      <td>4.105449</td>\n",
              "      <td>0.000350</td>\n",
              "      <td>-0.070192</td>\n",
              "      <td>0.002301</td>\n",
              "      <td>-0.008159</td>\n",
              "      <td>1.52</td>\n",
              "      <td>105.6382</td>\n",
              "      <td>141538.0</td>\n",
              "      <td>5.6</td>\n",
              "      <td>12.70</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.002519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-06-01</th>\n",
              "      <td>5.033831</td>\n",
              "      <td>4.762857</td>\n",
              "      <td>4.816079</td>\n",
              "      <td>6.234666</td>\n",
              "      <td>6.001266</td>\n",
              "      <td>5.358530</td>\n",
              "      <td>4.161068</td>\n",
              "      <td>3.985893</td>\n",
              "      <td>4.138521</td>\n",
              "      <td>0.001796</td>\n",
              "      <td>-0.064810</td>\n",
              "      <td>0.003371</td>\n",
              "      <td>0.012181</td>\n",
              "      <td>1.55</td>\n",
              "      <td>107.2238</td>\n",
              "      <td>141709.0</td>\n",
              "      <td>5.3</td>\n",
              "      <td>13.97</td>\n",
              "      <td>0.39</td>\n",
              "      <td>-0.000021</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f23de549-61b4-4bbb-8a01-cfd136d436d3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f23de549-61b4-4bbb-8a01-cfd136d436d3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f23de549-61b4-4bbb-8a01-cfd136d436d3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    display(combined_df[cols_to_show_present]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2015-02-01 00:00:00\",\n        \"max\": \"2015-06-01 00:00:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2015-03-01 00:00:00\",\n          \"2015-06-01 00:00:00\",\n          \"2015-04-01 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_AMGN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.015020329289093127,\n        \"min\": 5.0338308795294395,\n        \"max\": 5.074235913688619,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          5.074235913688619,\n          5.0338308795294395,\n          5.062025273669669\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_GILD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07503412368562229,\n        \"min\": 4.586293102229183,\n        \"max\": 4.762857477463031,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4.586293102229183,\n          4.762857477463031,\n          4.6102572462905576\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_VRTX\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03278441360604778,\n        \"min\": 4.770430365201324,\n        \"max\": 4.854293273927728,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4.770430365201324,\n          4.816079226820009,\n          4.814458181109986\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_REGN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0903247629057373,\n        \"min\": 6.0254794168461645,\n        \"max\": 6.239417772567604,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          6.112531099421456,\n          6.234665604768873,\n          6.125689430520155\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_BIIB\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04514546963719572,\n        \"min\": 5.924068594534292,\n        \"max\": 6.045573849626876,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          6.045573849626876,\n          6.001266358124225,\n          5.924068594534292\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_ILMN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07185971221848969,\n        \"min\": 5.1886783868936,\n        \"max\": 5.358529880251867,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          5.196194182519713,\n          5.358529880251867,\n          5.1886783868936\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_IDXX\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1041103133217468,\n        \"min\": 4.138122206475797,\n        \"max\": 4.362015247261799,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4.3469174299032645,\n          4.161068184749082,\n          4.138122206475797\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_ISRG\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.017185376018296866,\n        \"min\": 3.9858928303741847,\n        \"max\": 4.027393261251588,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4.027393261251588,\n          3.9858928303741847,\n          4.009311055837066\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_ALGN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05834604589259097,\n        \"min\": 3.9850875933055514,\n        \"max\": 4.138520909955546,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3.9850875933055514,\n          4.138520909955546,\n          4.074821898326505\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"inflation_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0011440629815190962,\n        \"min\": -0.0010403098939391064,\n        \"max\": 0.001795718097550525,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.00022031284423873476,\n          0.001795718097550525,\n          -0.0010403098939391064\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ppi_inflation\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.006954396949497267,\n        \"min\": -0.08353336533845412,\n        \"max\": -0.06481036965914544,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.0748792270531401,\n          -0.06481036965914544,\n          -0.08353336533845412\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"m2_growth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0037324780825662117,\n        \"min\": -0.0001596135674921475,\n        \"max\": 0.009868181800301376,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.0001596135674921475,\n          0.0033710522227870135,\n          0.002844021296578305\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"m1_growth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.013617325412087534,\n        \"min\": -0.008159215972096198,\n        \"max\": 0.023275529067381978,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.007964996310300758,\n          0.012180825048328278,\n          0.0004996752215092272\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bond_yield_spread\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14152738250953417,\n        \"min\": 1.21,\n        \"max\": 1.55,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.37,\n          1.55,\n          1.32\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dxy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8422246434295317,\n        \"min\": 105.5884,\n        \"max\": 107.2238,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          105.5981,\n          107.2238,\n          107.06\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nonfarm_payrolls\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 381.36242604640535,\n        \"min\": 140827.0,\n        \"max\": 141709.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          140923.0,\n          141709.0,\n          141196.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"unemployment_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11401754250991367,\n        \"min\": 5.3,\n        \"max\": 5.6,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          5.4,\n          5.3,\n          5.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vix_index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.336235902930127,\n        \"min\": 12.7,\n        \"max\": 20.97,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          13.34,\n          13.97,\n          15.11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"real_rate_10y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13971399357258385,\n        \"min\": 0.03,\n        \"max\": 0.39,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.17,\n          0.39,\n          0.07\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gdp_growth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0025322460882108815,\n        \"min\": -2.101329711539847e-05,\n        \"max\": 0.006300654943472094,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.006300654943472094,\n          -2.101329711539847e-05,\n          0.005281184497541299\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ======== Filter sector log-prices + macro variables ========\n",
        "\n",
        "# Macro columns ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏ô Excel + yfinance\n",
        "macro_columns = [\n",
        "    \"inflation_rate\",\n",
        "    \"ppi_inflation\",\n",
        "    \"m2_growth\",\n",
        "    \"m1_growth\",\n",
        "    \"bond_yield_spread\",\n",
        "    \"dxy\",\n",
        "    \"nonfarm_payrolls\",\n",
        "    \"unemployment_rate\",\n",
        "    \"vix_index\",\n",
        "    \"real_rate_10y\",\n",
        "    \"gdp_growth\"\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "# ======== ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ df ‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏≤‡∏Å Block ‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤ ========\n",
        "if 'df' not in globals():\n",
        "    raise RuntimeError(\"‚ùå Variable 'df' not found. Please run the data-preparation block first.\")\n",
        "\n",
        "df_filtered_macro = df\n",
        "\n",
        "# ‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÅ‡∏¢‡∏Å sector\n",
        "combined_dfs = {}\n",
        "\n",
        "for sector, tickers_list in SECTORS.items():\n",
        "    sector_frames = []\n",
        "\n",
        "    for ticker in tickers_list:\n",
        "        colname = f\"Close_{ticker}\"\n",
        "        if colname not in df.columns:\n",
        "            print(f\"‚ö†Ô∏è {colname} not found in df. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        # ‚úÖ ‡πÉ‡∏ä‡πâ Logclose ‡πÅ‡∏ó‡∏ô log-return\n",
        "        tmp = df[[colname]].copy()\n",
        "        tmp[f\"Logclose_{ticker}\"] = np.log(tmp[colname])\n",
        "        tmp = tmp[[f\"Logclose_{ticker}\"]]\n",
        "\n",
        "        # align index ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö macro\n",
        "        tmp = tmp.loc[df_filtered_macro.index]\n",
        "        sector_frames.append(tmp)\n",
        "\n",
        "    if len(sector_frames) == 0:\n",
        "        continue\n",
        "\n",
        "    # ‡∏£‡∏ß‡∏° Logclose ‡∏Ç‡∏≠‡∏á‡∏´‡∏∏‡πâ‡∏ô‡∏ó‡∏∏‡∏Å‡∏ï‡∏±‡∏ß‡πÉ‡∏ô sector\n",
        "    sector_data = pd.concat(sector_frames, axis=1)\n",
        "\n",
        "    # ‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ö macro\n",
        "    combined_df = pd.concat([sector_data, df_filtered_macro], axis=1).ffill()\n",
        "\n",
        "    # ‡∏ï‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏µ 2025 (‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô incomplete data)\n",
        "    combined_df = combined_df[combined_df.index.year != 2025]\n",
        "\n",
        "    combined_dfs[sector] = combined_df\n",
        "\n",
        "# ======== ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå ========\n",
        "for sector, combined_df in combined_dfs.items():\n",
        "    print(f\"\\nüìä Combined data for sector: {sector}\")\n",
        "    cols_to_show = [c for c in combined_df.columns if c.startswith(\"Logclose_\")] + macro_columns\n",
        "    cols_to_show_present = [col for col in cols_to_show if col in combined_df.columns]\n",
        "    display(combined_df[cols_to_show_present].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "JiapIQVQrUOF",
        "outputId": "e4a98b4a-6fe0-4a60-d28b-4f151a64bcf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Displaying head of combined dataframes for each sector:\n",
            "\n",
            "--- Combined dataframe for Healthcare ---\n",
            "Columns in the combined dataframe for Healthcare:\n",
            "Index(['Logclose_AMGN', 'Logclose_GILD', 'Logclose_VRTX', 'Logclose_REGN',\n",
            "       'Logclose_BIIB', 'Logclose_ILMN', 'Logclose_IDXX', 'Logclose_ISRG',\n",
            "       'Logclose_ALGN', 'Close_AMGN', 'Close_GILD', 'Close_VRTX', 'Close_REGN',\n",
            "       'Close_BIIB', 'Close_ILMN', 'Close_IDXX', 'Close_ISRG', 'Close_ALGN',\n",
            "       'inflation_rate', 'm2_growth', 'm1_growth', 'bond_yield_spread', 'dxy',\n",
            "       'nonfarm_payrolls', 'unemployment_rate', 'vix_index', 'real_rate_10y',\n",
            "       'ppi_inflation', 'GDP_Monthly', 'gdp_growth'],\n",
            "      dtype='object')\n",
            "\n",
            "Head of the combined dataframe for Healthcare:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "            Logclose_AMGN  Logclose_GILD  Logclose_VRTX  Logclose_REGN  \\\n",
              "Date                                                                     \n",
              "2015-02-01       5.060821       4.639861       4.782730       6.025479   \n",
              "2015-03-01       5.074236       4.586293       4.770430       6.112531   \n",
              "2015-04-01       5.062025       4.610257       4.814458       6.125689   \n",
              "2015-05-01       5.051521       4.720907       4.854293       6.239418   \n",
              "2015-06-01       5.033831       4.762857       4.816079       6.234666   \n",
              "\n",
              "            Logclose_BIIB  Logclose_ILMN  Logclose_IDXX  Logclose_ISRG  \\\n",
              "Date                                                                     \n",
              "2015-02-01       6.015157       5.247741       4.362015       4.017384   \n",
              "2015-03-01       6.045574       5.196194       4.346917       4.027393   \n",
              "2015-04-01       5.924069       5.188678       4.138122       4.009311   \n",
              "2015-05-01       5.983911       5.300649       4.216562       3.992578   \n",
              "2015-06-01       6.001266       5.358530       4.161068       3.985893   \n",
              "\n",
              "            Logclose_ALGN  Close_AMGN  ...  m1_growth  bond_yield_spread  \\\n",
              "Date                                   ...                                 \n",
              "2015-02-01       4.049173  157.720001  ...   0.023276               1.21   \n",
              "2015-03-01       3.985088  159.850006  ...  -0.007965               1.37   \n",
              "2015-04-01       4.074822  157.910004  ...   0.000500               1.32   \n",
              "2015-05-01       4.105449  156.259995  ...  -0.008159               1.52   \n",
              "2015-06-01       4.138521  153.520004  ...   0.012181               1.55   \n",
              "\n",
              "                 dxy  nonfarm_payrolls  unemployment_rate  vix_index  \\\n",
              "Date                                                                   \n",
              "2015-02-01  105.5884          140827.0                5.5      20.97   \n",
              "2015-03-01  105.5981          140923.0                5.4      13.34   \n",
              "2015-04-01  107.0600          141196.0                5.4      15.11   \n",
              "2015-05-01  105.6382          141538.0                5.6      12.70   \n",
              "2015-06-01  107.2238          141709.0                5.3      13.97   \n",
              "\n",
              "            real_rate_10y  ppi_inflation  GDP_Monthly  gdp_growth  \n",
              "Date                                                               \n",
              "2015-02-01           0.03      -0.070977  6013.027543    0.002258  \n",
              "2015-03-01           0.17      -0.074879  6051.033159    0.006301  \n",
              "2015-04-01           0.07      -0.083533  6083.074315    0.005281  \n",
              "2015-05-01           0.18      -0.070192  6098.418916    0.002519  \n",
              "2015-06-01           0.39      -0.064810  6098.290769   -0.000021  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7909cd3c-64d4-4f06-b729-4b2858844e9d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Logclose_AMGN</th>\n",
              "      <th>Logclose_GILD</th>\n",
              "      <th>Logclose_VRTX</th>\n",
              "      <th>Logclose_REGN</th>\n",
              "      <th>Logclose_BIIB</th>\n",
              "      <th>Logclose_ILMN</th>\n",
              "      <th>Logclose_IDXX</th>\n",
              "      <th>Logclose_ISRG</th>\n",
              "      <th>Logclose_ALGN</th>\n",
              "      <th>Close_AMGN</th>\n",
              "      <th>...</th>\n",
              "      <th>m1_growth</th>\n",
              "      <th>bond_yield_spread</th>\n",
              "      <th>dxy</th>\n",
              "      <th>nonfarm_payrolls</th>\n",
              "      <th>unemployment_rate</th>\n",
              "      <th>vix_index</th>\n",
              "      <th>real_rate_10y</th>\n",
              "      <th>ppi_inflation</th>\n",
              "      <th>GDP_Monthly</th>\n",
              "      <th>gdp_growth</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2015-02-01</th>\n",
              "      <td>5.060821</td>\n",
              "      <td>4.639861</td>\n",
              "      <td>4.782730</td>\n",
              "      <td>6.025479</td>\n",
              "      <td>6.015157</td>\n",
              "      <td>5.247741</td>\n",
              "      <td>4.362015</td>\n",
              "      <td>4.017384</td>\n",
              "      <td>4.049173</td>\n",
              "      <td>157.720001</td>\n",
              "      <td>...</td>\n",
              "      <td>0.023276</td>\n",
              "      <td>1.21</td>\n",
              "      <td>105.5884</td>\n",
              "      <td>140827.0</td>\n",
              "      <td>5.5</td>\n",
              "      <td>20.97</td>\n",
              "      <td>0.03</td>\n",
              "      <td>-0.070977</td>\n",
              "      <td>6013.027543</td>\n",
              "      <td>0.002258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-03-01</th>\n",
              "      <td>5.074236</td>\n",
              "      <td>4.586293</td>\n",
              "      <td>4.770430</td>\n",
              "      <td>6.112531</td>\n",
              "      <td>6.045574</td>\n",
              "      <td>5.196194</td>\n",
              "      <td>4.346917</td>\n",
              "      <td>4.027393</td>\n",
              "      <td>3.985088</td>\n",
              "      <td>159.850006</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.007965</td>\n",
              "      <td>1.37</td>\n",
              "      <td>105.5981</td>\n",
              "      <td>140923.0</td>\n",
              "      <td>5.4</td>\n",
              "      <td>13.34</td>\n",
              "      <td>0.17</td>\n",
              "      <td>-0.074879</td>\n",
              "      <td>6051.033159</td>\n",
              "      <td>0.006301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-04-01</th>\n",
              "      <td>5.062025</td>\n",
              "      <td>4.610257</td>\n",
              "      <td>4.814458</td>\n",
              "      <td>6.125689</td>\n",
              "      <td>5.924069</td>\n",
              "      <td>5.188678</td>\n",
              "      <td>4.138122</td>\n",
              "      <td>4.009311</td>\n",
              "      <td>4.074822</td>\n",
              "      <td>157.910004</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>1.32</td>\n",
              "      <td>107.0600</td>\n",
              "      <td>141196.0</td>\n",
              "      <td>5.4</td>\n",
              "      <td>15.11</td>\n",
              "      <td>0.07</td>\n",
              "      <td>-0.083533</td>\n",
              "      <td>6083.074315</td>\n",
              "      <td>0.005281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-05-01</th>\n",
              "      <td>5.051521</td>\n",
              "      <td>4.720907</td>\n",
              "      <td>4.854293</td>\n",
              "      <td>6.239418</td>\n",
              "      <td>5.983911</td>\n",
              "      <td>5.300649</td>\n",
              "      <td>4.216562</td>\n",
              "      <td>3.992578</td>\n",
              "      <td>4.105449</td>\n",
              "      <td>156.259995</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.008159</td>\n",
              "      <td>1.52</td>\n",
              "      <td>105.6382</td>\n",
              "      <td>141538.0</td>\n",
              "      <td>5.6</td>\n",
              "      <td>12.70</td>\n",
              "      <td>0.18</td>\n",
              "      <td>-0.070192</td>\n",
              "      <td>6098.418916</td>\n",
              "      <td>0.002519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-06-01</th>\n",
              "      <td>5.033831</td>\n",
              "      <td>4.762857</td>\n",
              "      <td>4.816079</td>\n",
              "      <td>6.234666</td>\n",
              "      <td>6.001266</td>\n",
              "      <td>5.358530</td>\n",
              "      <td>4.161068</td>\n",
              "      <td>3.985893</td>\n",
              "      <td>4.138521</td>\n",
              "      <td>153.520004</td>\n",
              "      <td>...</td>\n",
              "      <td>0.012181</td>\n",
              "      <td>1.55</td>\n",
              "      <td>107.2238</td>\n",
              "      <td>141709.0</td>\n",
              "      <td>5.3</td>\n",
              "      <td>13.97</td>\n",
              "      <td>0.39</td>\n",
              "      <td>-0.064810</td>\n",
              "      <td>6098.290769</td>\n",
              "      <td>-0.000021</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 30 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7909cd3c-64d4-4f06-b729-4b2858844e9d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7909cd3c-64d4-4f06-b729-4b2858844e9d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7909cd3c-64d4-4f06-b729-4b2858844e9d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Select the dataframe for the first stock (e.g., 'BBL') from the combined_dfs dictionary\n",
        "# This cell is intended to display example dataframes from combined_dfs,\n",
        "# which are structured by sector, not individual tickers.\n",
        "# Iterate through the combined_dfs dictionary using sector names as keys.\n",
        "\n",
        "if 'combined_dfs' in globals() and combined_dfs:\n",
        "    print(\"Displaying head of combined dataframes for each sector:\")\n",
        "    for sector, combined_df_example in combined_dfs.items():\n",
        "        print(f\"\\n--- Combined dataframe for {sector} ---\")\n",
        "        # Display the columns of the example combined dataframe\n",
        "        print(f\"Columns in the combined dataframe for {sector}:\")\n",
        "        print(combined_df_example.columns)\n",
        "\n",
        "        # Display the head of the example combined dataframe\n",
        "        print(f\"\\nHead of the combined dataframe for {sector}:\")\n",
        "        display(combined_df_example.head())\n",
        "else:\n",
        "    print(\"The 'combined_dfs' dictionary is not available or is empty. Please run the data processing cell first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKCrzkPXBDzD"
      },
      "source": [
        "** 3 Econometric **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        },
        "id": "eb8545b7",
        "outputId": "fcffedcf-6c7e-4b36-d3f8-f7a530a837b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ‚úÖ Logclose columns collected ===\n",
            "Total: 9 stocks\n",
            "\n",
            "üìÖ First available data per stock:\n",
            "Logclose_AMGN            : 2015-02-01 00:00:00\n",
            "Logclose_GILD            : 2015-02-01 00:00:00\n",
            "Logclose_VRTX            : 2015-02-01 00:00:00\n",
            "Logclose_REGN            : 2015-02-01 00:00:00\n",
            "Logclose_BIIB            : 2015-02-01 00:00:00\n",
            "Logclose_ILMN            : 2015-02-01 00:00:00\n",
            "Logclose_IDXX            : 2015-02-01 00:00:00\n",
            "Logclose_ISRG            : 2015-02-01 00:00:00\n",
            "Logclose_ALGN            : 2015-02-01 00:00:00\n",
            "\n",
            "‚úÖ Dynamic Panel Ready: shape=(132, 9)\n",
            "üïê Date range: 2015-02-01 ‚Üí 2026-01-01\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "            Logclose_AMGN  Logclose_GILD  Logclose_VRTX  Logclose_REGN  \\\n",
              "Date                                                                     \n",
              "2015-02-01       5.060821       4.639861       4.782730       6.025479   \n",
              "2015-03-01       5.074236       4.586293       4.770430       6.112531   \n",
              "2015-04-01       5.062025       4.610257       4.814458       6.125689   \n",
              "2015-05-01       5.051521       4.720907       4.854293       6.239418   \n",
              "2015-06-01       5.033831       4.762857       4.816079       6.234666   \n",
              "2015-07-01       5.173831       4.769497       4.905275       6.316551   \n",
              "2015-08-01       5.022432       4.654627       4.848273       6.241250   \n",
              "2015-09-01       4.929570       4.586904       4.645736       6.142338   \n",
              "2015-10-01       5.063734       4.683334       4.826232       6.323265   \n",
              "2015-11-01       5.082025       4.663062       4.862599       6.299868   \n",
              "\n",
              "            Logclose_BIIB  Logclose_ILMN  \n",
              "Date                                      \n",
              "2015-02-01       6.015157       5.247741  \n",
              "2015-03-01       6.045574       5.196194  \n",
              "2015-04-01       5.924069       5.188678  \n",
              "2015-05-01       5.983911       5.300649  \n",
              "2015-06-01       6.001266       5.358530  \n",
              "2015-07-01       5.764501       5.362825  \n",
              "2015-08-01       5.694742       5.258680  \n",
              "2015-09-01       5.676103       5.141846  \n",
              "2015-10-01       5.671638       4.937186  \n",
              "2015-11-01       5.658994       5.186777  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2fa004df-fa5c-4d14-98e2-6d4c2f9d13f3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Logclose_AMGN</th>\n",
              "      <th>Logclose_GILD</th>\n",
              "      <th>Logclose_VRTX</th>\n",
              "      <th>Logclose_REGN</th>\n",
              "      <th>Logclose_BIIB</th>\n",
              "      <th>Logclose_ILMN</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2015-02-01</th>\n",
              "      <td>5.060821</td>\n",
              "      <td>4.639861</td>\n",
              "      <td>4.782730</td>\n",
              "      <td>6.025479</td>\n",
              "      <td>6.015157</td>\n",
              "      <td>5.247741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-03-01</th>\n",
              "      <td>5.074236</td>\n",
              "      <td>4.586293</td>\n",
              "      <td>4.770430</td>\n",
              "      <td>6.112531</td>\n",
              "      <td>6.045574</td>\n",
              "      <td>5.196194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-04-01</th>\n",
              "      <td>5.062025</td>\n",
              "      <td>4.610257</td>\n",
              "      <td>4.814458</td>\n",
              "      <td>6.125689</td>\n",
              "      <td>5.924069</td>\n",
              "      <td>5.188678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-05-01</th>\n",
              "      <td>5.051521</td>\n",
              "      <td>4.720907</td>\n",
              "      <td>4.854293</td>\n",
              "      <td>6.239418</td>\n",
              "      <td>5.983911</td>\n",
              "      <td>5.300649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-06-01</th>\n",
              "      <td>5.033831</td>\n",
              "      <td>4.762857</td>\n",
              "      <td>4.816079</td>\n",
              "      <td>6.234666</td>\n",
              "      <td>6.001266</td>\n",
              "      <td>5.358530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-07-01</th>\n",
              "      <td>5.173831</td>\n",
              "      <td>4.769497</td>\n",
              "      <td>4.905275</td>\n",
              "      <td>6.316551</td>\n",
              "      <td>5.764501</td>\n",
              "      <td>5.362825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-08-01</th>\n",
              "      <td>5.022432</td>\n",
              "      <td>4.654627</td>\n",
              "      <td>4.848273</td>\n",
              "      <td>6.241250</td>\n",
              "      <td>5.694742</td>\n",
              "      <td>5.258680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-09-01</th>\n",
              "      <td>4.929570</td>\n",
              "      <td>4.586904</td>\n",
              "      <td>4.645736</td>\n",
              "      <td>6.142338</td>\n",
              "      <td>5.676103</td>\n",
              "      <td>5.141846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-10-01</th>\n",
              "      <td>5.063734</td>\n",
              "      <td>4.683334</td>\n",
              "      <td>4.826232</td>\n",
              "      <td>6.323265</td>\n",
              "      <td>5.671638</td>\n",
              "      <td>4.937186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-11-01</th>\n",
              "      <td>5.082025</td>\n",
              "      <td>4.663062</td>\n",
              "      <td>4.862599</td>\n",
              "      <td>6.299868</td>\n",
              "      <td>5.658994</td>\n",
              "      <td>5.186777</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2fa004df-fa5c-4d14-98e2-6d4c2f9d13f3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2fa004df-fa5c-4d14-98e2-6d4c2f9d13f3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2fa004df-fa5c-4d14-98e2-6d4c2f9d13f3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2015-02-01 00:00:00\",\n        \"max\": \"2015-11-01 00:00:00\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"2015-10-01 00:00:00\",\n          \"2015-03-01 00:00:00\",\n          \"2015-07-01 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_AMGN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.060215003323401795,\n        \"min\": 4.929569894326297,\n        \"max\": 5.173830640687112,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          5.063733578788206,\n          5.074235913688619,\n          5.173830640687112\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_GILD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0665958828793572,\n        \"min\": 4.586293102229183,\n        \"max\": 4.769497484588382,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          4.683334181556705,\n          4.586293102229183,\n          4.769497484588382\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_VRTX\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07056504847457148,\n        \"min\": 4.645736141873877,\n        \"max\": 4.90527477843843,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          4.826231553972511,\n          4.770430365201324,\n          4.90527477843843\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_REGN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09988404073138377,\n        \"min\": 6.0254794168461645,\n        \"max\": 6.323265200729579,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          6.323265200729579,\n          6.112531099421456,\n          6.316550731428154\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_BIIB\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1637637494411986,\n        \"min\": 5.658994240801304,\n        \"max\": 6.045573849626876,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          5.671638032722863,\n          6.045573849626876,\n          5.7645012058616105\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_ILMN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12340522414088871,\n        \"min\": 4.93718554939892,\n        \"max\": 5.36282546501215,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          4.93718554939892,\n          5.196194182519713,\n          5.36282546501215\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ============================================================\n",
        "# üß† MULTI-STOCK PIPELINE (Logclose + Dynamic Alignment)\n",
        "# ============================================================\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# --- Safety check ---\n",
        "if 'combined_dfs' not in globals() or not isinstance(combined_dfs, dict) or not combined_dfs:\n",
        "    raise RuntimeError(\"‚ùå combined_dfs not found or empty. Run previous macro/stock preparation cells first.\")\n",
        "\n",
        "if 'SECTORS' not in globals():\n",
        "    raise RuntimeError(\"‚ùå SECTORS not defined. Make sure the sector mapping dict is loaded.\")\n",
        "\n",
        "# ============================================================\n",
        "# 1Ô∏è‚É£ Helper functions\n",
        "# ============================================================\n",
        "def _norm(s: str) -> str:\n",
        "    return re.sub(r'[^a-z0-9]+', '', str(s).lower())\n",
        "\n",
        "PRICE_TOKENS = (\"logclose\",\"close\",\"adjclose\",\"price\",\"px\",\"pxlast\",\"last\")\n",
        "\n",
        "def _find_price_like_col(df_one: pd.DataFrame, ticker: str) -> str | None:\n",
        "    \"\"\"‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏£‡∏≤‡∏Ñ‡∏≤‡∏´‡∏£‡∏∑‡∏≠ logclose ‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏∏‡πâ‡∏ô\"\"\"\n",
        "    if df_one is None or df_one.empty:\n",
        "        return None\n",
        "    exacts = [\n",
        "        f\"Logclose_{ticker}\",\n",
        "        f\"Close_{ticker}\",\n",
        "        f\"close_{ticker}\",\n",
        "        f\"AdjClose_{ticker}\",\n",
        "        f\"Adj_Close_{ticker}\"\n",
        "    ]\n",
        "    for c in exacts:\n",
        "        if c in df_one.columns:\n",
        "            return c\n",
        "    generics = [\"Logclose\", \"Close\", \"Adj Close\", \"Price\", \"PX\", \"PX_LAST\", \"Last\"]\n",
        "    for c in generics:\n",
        "        if c in df_one.columns:\n",
        "            return c\n",
        "    numeric_cols = [c for c in df_one.columns if pd.api.types.is_numeric_dtype(df_one[c])]\n",
        "    want = {_norm(t)+_norm(ticker) for t in PRICE_TOKENS}\n",
        "    best, best_nn = None, -1\n",
        "    for c in numeric_cols:\n",
        "        nc = _norm(c)\n",
        "        if any(tok in nc for tok in want) or any(t in nc for t in PRICE_TOKENS):\n",
        "            nn = df_one[c].notna().sum()\n",
        "            if nn > best_nn:\n",
        "                best, best_nn = c, nn\n",
        "    return best\n",
        "\n",
        "def _align(s: pd.Series, idx: pd.Index) -> pd.Series:\n",
        "    if s is None:\n",
        "        return None\n",
        "    s = s.copy()\n",
        "    s.index = pd.to_datetime(s.index)\n",
        "    return s.reindex(idx)\n",
        "\n",
        "# ============================================================\n",
        "# 2Ô∏è‚É£ Build base index (union of all sectors)\n",
        "# ============================================================\n",
        "union_idx = None\n",
        "for d in combined_dfs.values():\n",
        "    idx = pd.to_datetime(d.index)\n",
        "    union_idx = idx if union_idx is None else union_idx.union(idx)\n",
        "if 'df' in globals() and isinstance(df, pd.DataFrame) and not df.empty:\n",
        "    union_idx = (pd.to_datetime(df.index) if union_idx is None else union_idx.union(pd.to_datetime(df.index)))\n",
        "if union_idx is None:\n",
        "    raise RuntimeError(\"‚ùå No index found to build panel.\")\n",
        "union_idx = union_idx.sort_values()\n",
        "\n",
        "# Base DataFrame\n",
        "df_master = (df.reindex(union_idx).copy()\n",
        "             if 'df' in globals() and isinstance(df, pd.DataFrame)\n",
        "             else pd.DataFrame(index=union_idx))\n",
        "\n",
        "# ============================================================\n",
        "# 3Ô∏è‚É£ Collect Logclose per ticker\n",
        "# ============================================================\n",
        "TARGET_TICKERS = [ticker for tickers in SECTORS.values() for ticker in tickers]\n",
        "source_used, missing = {}, []\n",
        "\n",
        "for ticker in TARGET_TICKERS:\n",
        "    dsec = None\n",
        "    for sec, d in combined_dfs.items():\n",
        "        if f\"Logclose_{ticker}\" in d.columns or f\"Close_{ticker}\" in d.columns:\n",
        "            dsec = d\n",
        "            break\n",
        "\n",
        "    price, src, col_used = None, None, None\n",
        "    if dsec is not None:\n",
        "        pcol = _find_price_like_col(dsec, ticker)\n",
        "        if pcol is not None:\n",
        "            price = _align(pd.to_numeric(dsec[pcol], errors='coerce'), union_idx)\n",
        "            src, col_used = 'combined', pcol\n",
        "\n",
        "    if price is None and 'df' in globals() and isinstance(df, pd.DataFrame):\n",
        "        pcol_g = _find_price_like_col(df, ticker)\n",
        "        if pcol_g is not None:\n",
        "            price = _align(pd.to_numeric(df[pcol_g], errors='coerce'), union_idx)\n",
        "            src, col_used = 'global', pcol_g\n",
        "\n",
        "    if price is None:\n",
        "        missing.append(ticker)\n",
        "        source_used[ticker] = None\n",
        "        continue\n",
        "\n",
        "    logc = f\"Logclose_{ticker}\"\n",
        "    df_master[logc] = price.astype(float)\n",
        "    source_used[ticker] = (src, col_used)\n",
        "\n",
        "print(\"=== ‚úÖ Logclose columns collected ===\")\n",
        "print(f\"Total: {len([c for c in df_master.columns if 'Logclose_' in c])} stocks\")\n",
        "\n",
        "# ============================================================\n",
        "# 4Ô∏è‚É£ Dynamic Start Date per Ticker\n",
        "# ============================================================\n",
        "logclose_cols = [f\"Logclose_{t}\" for t in TARGET_TICKERS if f\"Logclose_{t}\" in df_master.columns]\n",
        "\n",
        "first_valid_dates = {}\n",
        "for c in logclose_cols:\n",
        "    valid = df_master[c].first_valid_index()\n",
        "    first_valid_dates[c] = valid\n",
        "\n",
        "print(\"\\nüìÖ First available data per stock:\")\n",
        "for k, v in first_valid_dates.items():\n",
        "    print(f\"{k:25s}: {v}\")\n",
        "\n",
        "# --- ‡∏™‡∏£‡πâ‡∏≤‡∏á Dynamic Panel ---\n",
        "df_dynamic = pd.DataFrame(index=df_master.index)\n",
        "for c in logclose_cols:\n",
        "    start_date = first_valid_dates[c]\n",
        "    if start_date is not None:\n",
        "        tmp = df_master.loc[start_date:, c]\n",
        "        df_dynamic[c] = tmp\n",
        "\n",
        "# --- ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡πà‡∏≤‡∏´‡∏•‡∏±‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢ ffill 1 step (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢) ---\n",
        "df_dynamic = df_dynamic.sort_index().ffill(limit=1)\n",
        "\n",
        "# ============================================================\n",
        "# 5Ô∏è‚É£ Final Panel\n",
        "# ============================================================\n",
        "df = df_dynamic.copy()\n",
        "\n",
        "print(f\"\\n‚úÖ Dynamic Panel Ready: shape={df.shape}\")\n",
        "print(f\"üïê Date range: {df.index.min().date()} ‚Üí {df.index.max().date()}\")\n",
        "if missing:\n",
        "    print(f\"\\n‚ö†Ô∏è Missing Logclose for: {missing}\")\n",
        "\n",
        "# --- Preview ---\n",
        "try:\n",
        "    from IPython.display import display\n",
        "    display(df.iloc[:10, :6])\n",
        "except Exception:\n",
        "    print(df.iloc[:10, :6])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zejkXEGI1i7n",
        "outputId": "a37647eb-4599-496f-845b-ae2cf79c812a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting arch\n",
            "  Downloading arch-8.0.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from arch) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from arch) (2.2.2)\n",
            "Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.12/dist-packages (from arch) (1.16.3)\n",
            "Requirement already satisfied: statsmodels>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from arch) (0.14.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from arch) (25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4.0->arch) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4.0->arch) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4.0->arch) (2025.3)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.13.0->arch) (1.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->arch) (1.17.0)\n",
            "Downloading arch-8.0.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (981 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m981.3/981.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: arch\n",
            "Successfully installed arch-8.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install arch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03ddfc94",
        "outputId": "f054f535-fc77-40aa-ba38-1e64527bac55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Integration Order Detected ===\n",
            "inflation_rate            ‚Üí I(1)\n",
            "ppi_inflation             ‚Üí I(1)\n",
            "m2_growth                 ‚Üí I(0)\n",
            "m1_growth                 ‚Üí I(0)\n",
            "bond_yield_spread         ‚Üí I(1)\n",
            "dxy                       ‚Üí I(1)\n",
            "nonfarm_payrolls          ‚Üí I(1)\n",
            "unemployment_rate         ‚Üí I(0)\n",
            "vix_index                 ‚Üí I(0)\n",
            "real_rate_10y             ‚Üí I(1)\n",
            "gdp_growth                ‚Üí I(0)\n",
            "\n",
            "‚úÖ Built 'combined_dfs_selective_diff' successfully.\n",
            "Diffed Macros (I(1)): ['inflation_rate', 'ppi_inflation', 'bond_yield_spread', 'dxy', 'nonfarm_payrolls', 'real_rate_10y']\n",
            "Kept in Levels (I(0)): ['m2_growth', 'm1_growth', 'unemployment_rate', 'vix_index', 'gdp_growth']\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# ‚öôÔ∏è Build Selectively-Differenced Panel (Diff only I(1))\n",
        "# ============================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "# --- Check availability ---\n",
        "if 'combined_dfs' not in globals() or not isinstance(combined_dfs, dict) or not combined_dfs:\n",
        "    raise RuntimeError(\"‚ùå combined_dfs not found or empty. Please run previous block first.\")\n",
        "\n",
        "# --- Helper function: classify I(0) vs I(1) ---\n",
        "def classify_order(series, signif=0.05):\n",
        "    series = series.dropna()\n",
        "    if len(series) < 10:\n",
        "        return None\n",
        "    try:\n",
        "        adf_result = adfuller(series, autolag='AIC')\n",
        "        pval = adf_result[1]\n",
        "        return \"I(0)\" if pval < signif else \"I(1)\"\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "# --- Detect integration order for all macros ---\n",
        "macro_candidates = [\n",
        "    \"inflation_rate\",\n",
        "    \"ppi_inflation\",\n",
        "    \"m2_growth\",\n",
        "    \"m1_growth\",\n",
        "    \"bond_yield_spread\",\n",
        "    \"dxy\",\n",
        "    \"nonfarm_payrolls\",\n",
        "    \"unemployment_rate\",\n",
        "    \"vix_index\",\n",
        "    \"real_rate_10y\",\n",
        "    \"gdp_growth\"\n",
        "]\n",
        "\n",
        "macro_orders = {}\n",
        "for sector, df_sec in combined_dfs.items():\n",
        "    for m in macro_candidates:\n",
        "        if m in df_sec.columns and m not in macro_orders:\n",
        "            order = classify_order(df_sec[m])\n",
        "            if order:\n",
        "                macro_orders[m] = order\n",
        "\n",
        "print(\"=== Integration Order Detected ===\")\n",
        "for k, v in macro_orders.items():\n",
        "    print(f\"{k:25s} ‚Üí {v}\")\n",
        "\n",
        "# --- Build differenced dataset selectively ---\n",
        "combined_dfs_selective_diff = {}\n",
        "\n",
        "for sector, df_sec in combined_dfs.items():\n",
        "    df_sec = df_sec.copy()\n",
        "    out = pd.DataFrame(index=df_sec.index)\n",
        "\n",
        "    # 1Ô∏è‚É£ ‡∏´‡∏∏‡πâ‡∏ô: ‡πÉ‡∏ä‡πâ Œîlog ‡πÄ‡∏™‡∏°‡∏≠\n",
        "    for col in df_sec.columns:\n",
        "        if col.startswith(\"Logclose_\"):\n",
        "            out[col] = df_sec[col].diff()\n",
        "\n",
        "    # 2Ô∏è‚É£ Macro: diff ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ I(1)\n",
        "    for m in macro_candidates:\n",
        "        if m not in df_sec.columns:\n",
        "            continue\n",
        "        if macro_orders.get(m, \"I(1)\") == \"I(1)\":\n",
        "            out[m] = df_sec[m].diff()\n",
        "        else:  # I(0)\n",
        "            out[m] = df_sec[m]\n",
        "\n",
        "    # 3Ô∏è‚É£ Drop NA\n",
        "    combined_dfs_selective_diff[sector] = out.dropna(how='all')\n",
        "\n",
        "print(\"\\n‚úÖ Built 'combined_dfs_selective_diff' successfully.\")\n",
        "print(\"Diffed Macros (I(1)):\", [k for k, v in macro_orders.items() if v == \"I(1)\"])\n",
        "print(\"Kept in Levels (I(0)):\", [k for k, v in macro_orders.items() if v == \"I(0)\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 868
        },
        "id": "ge8JSCNOi2m_",
        "outputId": "d7c70032-8ba9-414f-f94b-4ac1a6fd5836"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Checking macro variable presence in combined_dfs_selective_diff ===\n",
            "\n",
            "üìÇ Sector: Healthcare\n",
            "  ‚Ä¢ Stocks found: 9 (Logclose_AMGN, Logclose_GILD, Logclose_VRTX, Logclose_REGN, Logclose_BIIB...)\n",
            "  ‚Ä¢ Macros present (11): ['inflation_rate', 'ppi_inflation', 'm2_growth', 'm1_growth', 'bond_yield_spread', 'dxy', 'nonfarm_payrolls', 'unemployment_rate', 'vix_index', 'real_rate_10y', 'gdp_growth']\n",
            "  ‚Ä¢ Macros missing (0): []\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "=== Summary of Macro Coverage per Sector ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       Sector  N_stocks  Macros_present  Macros_missing Missing_list\n",
              "0  Healthcare         9              11               0             "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-beafe069-27d9-4453-afab-30427a1bc7da\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sector</th>\n",
              "      <th>N_stocks</th>\n",
              "      <th>Macros_present</th>\n",
              "      <th>Macros_missing</th>\n",
              "      <th>Missing_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-beafe069-27d9-4453-afab-30427a1bc7da')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-beafe069-27d9-4453-afab-30427a1bc7da button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-beafe069-27d9-4453-afab-30427a1bc7da');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_43f9904e-3735-4e9f-be21-d147f6ba0a15\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_summary')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_43f9904e-3735-4e9f-be21-d147f6ba0a15 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_summary');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_summary",
              "summary": "{\n  \"name\": \"df_summary\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Sector\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Healthcare\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"N_stocks\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 9,\n        \"max\": 9,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Macros_present\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 11,\n        \"max\": 11,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Macros_missing\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Missing_list\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Removed first NaN row and cleaned selective-diff dataframes successfully.\n",
            "\n",
            "=== Example after cleaning: 'Healthcare' ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "            Logclose_AMGN  Logclose_GILD  Logclose_VRTX  Logclose_REGN  \\\n",
              "Date                                                                     \n",
              "2015-03-01       0.013415      -0.053568      -0.012300       0.087052   \n",
              "2015-04-01      -0.012211       0.023964       0.044028       0.013158   \n",
              "2015-05-01      -0.010504       0.110649       0.039835       0.113728   \n",
              "2015-06-01      -0.017690       0.041951      -0.038214      -0.004752   \n",
              "2015-07-01       0.140000       0.006640       0.089196       0.081885   \n",
              "2015-08-01      -0.151399      -0.114871      -0.057002      -0.075301   \n",
              "2015-09-01      -0.092862      -0.067722      -0.202537      -0.098912   \n",
              "2015-10-01       0.134164       0.096430       0.180495       0.180927   \n",
              "2015-11-01       0.018292      -0.020273       0.036368      -0.023397   \n",
              "2015-12-01       0.007606      -0.046062      -0.027667      -0.002998   \n",
              "\n",
              "            Logclose_BIIB  Logclose_ILMN  Logclose_IDXX  Logclose_ISRG  \\\n",
              "Date                                                                     \n",
              "2015-03-01       0.030417      -0.051546      -0.015098       0.010010   \n",
              "2015-04-01      -0.121505      -0.007516      -0.208795      -0.018082   \n",
              "2015-05-01       0.059842       0.111971       0.078440      -0.016733   \n",
              "2015-06-01       0.017355       0.057881      -0.055494      -0.006686   \n",
              "2015-07-01      -0.236765       0.004296       0.125686       0.095723   \n",
              "2015-08-01      -0.069760      -0.104145      -0.017476      -0.042569   \n",
              "2015-09-01      -0.018639      -0.116835       0.038160      -0.105959   \n",
              "2015-10-01      -0.004465      -0.204660      -0.078854       0.077472   \n",
              "2015-11-01      -0.012644       0.249591       0.031557       0.046082   \n",
              "2015-12-01       0.065734       0.042843       0.029221       0.049045   \n",
              "\n",
              "            Logclose_ALGN  inflation_rate  ppi_inflation  m2_growth  \\\n",
              "Date                                                                  \n",
              "2015-03-01      -0.064085        0.000650      -0.003902  -0.000160   \n",
              "2015-04-01       0.089734       -0.000820      -0.008654   0.002844   \n",
              "2015-05-01       0.030627        0.001391       0.013341   0.002301   \n",
              "2015-06-01       0.033072        0.001445       0.005382   0.003371   \n",
              "2015-07-01      -0.000159        0.000461      -0.002978   0.003634   \n",
              "2015-08-01      -0.102353        0.000156      -0.005158   0.003711   \n",
              "2015-09-01       0.002823       -0.002325      -0.010871   0.005048   \n",
              "2015-10-01       0.142607        0.001188       0.005647   0.004212   \n",
              "2015-11-01       0.019365        0.003087       0.002512   0.007452   \n",
              "2015-12-01      -0.013425        0.002024       0.007132   0.005781   \n",
              "\n",
              "            m1_growth  bond_yield_spread     dxy  nonfarm_payrolls  \\\n",
              "Date                                                                 \n",
              "2015-03-01  -0.007965               0.16  0.0097              96.0   \n",
              "2015-04-01   0.000500              -0.05  1.4619             273.0   \n",
              "2015-05-01  -0.008159               0.20 -1.4218             342.0   \n",
              "2015-06-01   0.012181               0.03  1.5856             171.0   \n",
              "2015-07-01   0.006711               0.19 -0.2137             282.0   \n",
              "2015-08-01  -0.006877              -0.21  1.7718             134.0   \n",
              "2015-09-01   0.007832              -0.06  1.6687             150.0   \n",
              "2015-10-01  -0.006638              -0.06  0.5933             304.0   \n",
              "2015-11-01   0.018614               0.00 -0.8360             229.0   \n",
              "2015-12-01   0.010257              -0.17  1.9055             269.0   \n",
              "\n",
              "            unemployment_rate  vix_index  real_rate_10y  gdp_growth  \n",
              "Date                                                                 \n",
              "2015-03-01                5.4      13.34           0.14    0.006301  \n",
              "2015-04-01                5.4      15.11          -0.10    0.005281  \n",
              "2015-05-01                5.6      12.70           0.11    0.002519  \n",
              "2015-06-01                5.3      13.97           0.21   -0.000021  \n",
              "2015-07-01                5.2      16.09           0.15    0.005345  \n",
              "2015-08-01                5.1      12.12          -0.08   -0.000053  \n",
              "2015-09-01                5.0      31.40           0.14    0.001525  \n",
              "2015-10-01                5.0      22.55          -0.01    0.002076  \n",
              "2015-11-01                5.1      15.07           0.04   -0.001593  \n",
              "2015-12-01                5.0      14.67          -0.05   -0.000581  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f526d183-439b-49d3-a8b7-54bd06b3e552\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Logclose_AMGN</th>\n",
              "      <th>Logclose_GILD</th>\n",
              "      <th>Logclose_VRTX</th>\n",
              "      <th>Logclose_REGN</th>\n",
              "      <th>Logclose_BIIB</th>\n",
              "      <th>Logclose_ILMN</th>\n",
              "      <th>Logclose_IDXX</th>\n",
              "      <th>Logclose_ISRG</th>\n",
              "      <th>Logclose_ALGN</th>\n",
              "      <th>inflation_rate</th>\n",
              "      <th>ppi_inflation</th>\n",
              "      <th>m2_growth</th>\n",
              "      <th>m1_growth</th>\n",
              "      <th>bond_yield_spread</th>\n",
              "      <th>dxy</th>\n",
              "      <th>nonfarm_payrolls</th>\n",
              "      <th>unemployment_rate</th>\n",
              "      <th>vix_index</th>\n",
              "      <th>real_rate_10y</th>\n",
              "      <th>gdp_growth</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2015-03-01</th>\n",
              "      <td>0.013415</td>\n",
              "      <td>-0.053568</td>\n",
              "      <td>-0.012300</td>\n",
              "      <td>0.087052</td>\n",
              "      <td>0.030417</td>\n",
              "      <td>-0.051546</td>\n",
              "      <td>-0.015098</td>\n",
              "      <td>0.010010</td>\n",
              "      <td>-0.064085</td>\n",
              "      <td>0.000650</td>\n",
              "      <td>-0.003902</td>\n",
              "      <td>-0.000160</td>\n",
              "      <td>-0.007965</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.0097</td>\n",
              "      <td>96.0</td>\n",
              "      <td>5.4</td>\n",
              "      <td>13.34</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.006301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-04-01</th>\n",
              "      <td>-0.012211</td>\n",
              "      <td>0.023964</td>\n",
              "      <td>0.044028</td>\n",
              "      <td>0.013158</td>\n",
              "      <td>-0.121505</td>\n",
              "      <td>-0.007516</td>\n",
              "      <td>-0.208795</td>\n",
              "      <td>-0.018082</td>\n",
              "      <td>0.089734</td>\n",
              "      <td>-0.000820</td>\n",
              "      <td>-0.008654</td>\n",
              "      <td>0.002844</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>1.4619</td>\n",
              "      <td>273.0</td>\n",
              "      <td>5.4</td>\n",
              "      <td>15.11</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>0.005281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-05-01</th>\n",
              "      <td>-0.010504</td>\n",
              "      <td>0.110649</td>\n",
              "      <td>0.039835</td>\n",
              "      <td>0.113728</td>\n",
              "      <td>0.059842</td>\n",
              "      <td>0.111971</td>\n",
              "      <td>0.078440</td>\n",
              "      <td>-0.016733</td>\n",
              "      <td>0.030627</td>\n",
              "      <td>0.001391</td>\n",
              "      <td>0.013341</td>\n",
              "      <td>0.002301</td>\n",
              "      <td>-0.008159</td>\n",
              "      <td>0.20</td>\n",
              "      <td>-1.4218</td>\n",
              "      <td>342.0</td>\n",
              "      <td>5.6</td>\n",
              "      <td>12.70</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.002519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-06-01</th>\n",
              "      <td>-0.017690</td>\n",
              "      <td>0.041951</td>\n",
              "      <td>-0.038214</td>\n",
              "      <td>-0.004752</td>\n",
              "      <td>0.017355</td>\n",
              "      <td>0.057881</td>\n",
              "      <td>-0.055494</td>\n",
              "      <td>-0.006686</td>\n",
              "      <td>0.033072</td>\n",
              "      <td>0.001445</td>\n",
              "      <td>0.005382</td>\n",
              "      <td>0.003371</td>\n",
              "      <td>0.012181</td>\n",
              "      <td>0.03</td>\n",
              "      <td>1.5856</td>\n",
              "      <td>171.0</td>\n",
              "      <td>5.3</td>\n",
              "      <td>13.97</td>\n",
              "      <td>0.21</td>\n",
              "      <td>-0.000021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-07-01</th>\n",
              "      <td>0.140000</td>\n",
              "      <td>0.006640</td>\n",
              "      <td>0.089196</td>\n",
              "      <td>0.081885</td>\n",
              "      <td>-0.236765</td>\n",
              "      <td>0.004296</td>\n",
              "      <td>0.125686</td>\n",
              "      <td>0.095723</td>\n",
              "      <td>-0.000159</td>\n",
              "      <td>0.000461</td>\n",
              "      <td>-0.002978</td>\n",
              "      <td>0.003634</td>\n",
              "      <td>0.006711</td>\n",
              "      <td>0.19</td>\n",
              "      <td>-0.2137</td>\n",
              "      <td>282.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>16.09</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.005345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-08-01</th>\n",
              "      <td>-0.151399</td>\n",
              "      <td>-0.114871</td>\n",
              "      <td>-0.057002</td>\n",
              "      <td>-0.075301</td>\n",
              "      <td>-0.069760</td>\n",
              "      <td>-0.104145</td>\n",
              "      <td>-0.017476</td>\n",
              "      <td>-0.042569</td>\n",
              "      <td>-0.102353</td>\n",
              "      <td>0.000156</td>\n",
              "      <td>-0.005158</td>\n",
              "      <td>0.003711</td>\n",
              "      <td>-0.006877</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>1.7718</td>\n",
              "      <td>134.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>12.12</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.000053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-09-01</th>\n",
              "      <td>-0.092862</td>\n",
              "      <td>-0.067722</td>\n",
              "      <td>-0.202537</td>\n",
              "      <td>-0.098912</td>\n",
              "      <td>-0.018639</td>\n",
              "      <td>-0.116835</td>\n",
              "      <td>0.038160</td>\n",
              "      <td>-0.105959</td>\n",
              "      <td>0.002823</td>\n",
              "      <td>-0.002325</td>\n",
              "      <td>-0.010871</td>\n",
              "      <td>0.005048</td>\n",
              "      <td>0.007832</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>1.6687</td>\n",
              "      <td>150.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>31.40</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.001525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-10-01</th>\n",
              "      <td>0.134164</td>\n",
              "      <td>0.096430</td>\n",
              "      <td>0.180495</td>\n",
              "      <td>0.180927</td>\n",
              "      <td>-0.004465</td>\n",
              "      <td>-0.204660</td>\n",
              "      <td>-0.078854</td>\n",
              "      <td>0.077472</td>\n",
              "      <td>0.142607</td>\n",
              "      <td>0.001188</td>\n",
              "      <td>0.005647</td>\n",
              "      <td>0.004212</td>\n",
              "      <td>-0.006638</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.5933</td>\n",
              "      <td>304.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>22.55</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.002076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-11-01</th>\n",
              "      <td>0.018292</td>\n",
              "      <td>-0.020273</td>\n",
              "      <td>0.036368</td>\n",
              "      <td>-0.023397</td>\n",
              "      <td>-0.012644</td>\n",
              "      <td>0.249591</td>\n",
              "      <td>0.031557</td>\n",
              "      <td>0.046082</td>\n",
              "      <td>0.019365</td>\n",
              "      <td>0.003087</td>\n",
              "      <td>0.002512</td>\n",
              "      <td>0.007452</td>\n",
              "      <td>0.018614</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.8360</td>\n",
              "      <td>229.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>15.07</td>\n",
              "      <td>0.04</td>\n",
              "      <td>-0.001593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-12-01</th>\n",
              "      <td>0.007606</td>\n",
              "      <td>-0.046062</td>\n",
              "      <td>-0.027667</td>\n",
              "      <td>-0.002998</td>\n",
              "      <td>0.065734</td>\n",
              "      <td>0.042843</td>\n",
              "      <td>0.029221</td>\n",
              "      <td>0.049045</td>\n",
              "      <td>-0.013425</td>\n",
              "      <td>0.002024</td>\n",
              "      <td>0.007132</td>\n",
              "      <td>0.005781</td>\n",
              "      <td>0.010257</td>\n",
              "      <td>-0.17</td>\n",
              "      <td>1.9055</td>\n",
              "      <td>269.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>14.67</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>-0.000581</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f526d183-439b-49d3-a8b7-54bd06b3e552')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f526d183-439b-49d3-a8b7-54bd06b3e552 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f526d183-439b-49d3-a8b7-54bd06b3e552');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(combined_dfs_selective_diff[sector_to_inspect]\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2015-03-01 00:00:00\",\n        \"max\": \"2015-12-01 00:00:00\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"2015-11-01 00:00:00\",\n          \"2015-04-01 00:00:00\",\n          \"2015-08-01 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_AMGN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08832170210977164,\n        \"min\": -0.15139854475392767,\n        \"max\": 0.13999976115767243,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.018291749281225123,\n          -0.012210640018949448,\n          -0.15139854475392767\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_GILD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07230474694251708,\n        \"min\": -0.11487069279219764,\n        \"max\": 0.11064940827959013,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          -0.02027252579314709,\n          0.023964144061374704,\n          -0.11487069279219764\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_VRTX\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10097159094283195,\n        \"min\": -0.20253704684326568,\n        \"max\": 0.18049541209863396,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.036367666014580635,\n          0.04402781590866223,\n          -0.05700158972128655\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_REGN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08742765139867945,\n        \"min\": -0.0989115623339698,\n        \"max\": 0.1809267336949354,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          -0.02339725835656381,\n          0.01315833109869935,\n          -0.07530070205954065\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_BIIB\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09244126624001026,\n        \"min\": -0.2367651522626142,\n        \"max\": 0.06573401829370074,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          -0.012643791921559178,\n          -0.12150525509258348,\n          -0.06975951691720006\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_ILMN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12871175742009258,\n        \"min\": -0.20466002521397364,\n        \"max\": 0.24959142447139104,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.24959142447139104,\n          -0.007515795626113153,\n          -0.10414521910374042\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_IDXX\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09318689505017408,\n        \"min\": -0.20879522342746704,\n        \"max\": 0.12568581557347258,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.03155736491831007,\n          -0.20879522342746704,\n          -0.01747620201073019\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_ISRG\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06028187380273325,\n        \"min\": -0.10595866017605093,\n        \"max\": 0.09572292582046904,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.04608240429104171,\n          -0.018082205414522434,\n          -0.04256862384304316\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_ALGN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06964750511512104,\n        \"min\": -0.10235250155682252,\n        \"max\": 0.14260743236643147,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.019365186228003317,\n          0.08973430502095336,\n          -0.10235250155682252\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"inflation_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0015102898622144476,\n        \"min\": -0.002324608369003167,\n        \"max\": 0.003087016562480116,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.003087016562480116,\n          -0.0008199970497003717,\n          0.00015617687493540977\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ppi_inflation\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007740076662955738,\n        \"min\": -0.010870969553982812,\n        \"max\": 0.01334105764614646,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.002511559339902547,\n          -0.008654138285314028,\n          -0.005158398364920047\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"m2_growth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0020560864706567544,\n        \"min\": -0.0001596135674921475,\n        \"max\": 0.0074523352756581725,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.0074523352756581725,\n          0.002844021296578305,\n          0.0037114708696857224\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"m1_growth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009764210727902307,\n        \"min\": -0.008159215972096198,\n        \"max\": 0.018613586225841586,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.018613586225841586,\n          0.0004996752215092272,\n          -0.006876742145847476\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bond_yield_spread\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14345343805182534,\n        \"min\": -0.20999999999999996,\n        \"max\": 0.19999999999999996,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.0,\n          -0.050000000000000044,\n          -0.20999999999999996\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dxy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.2049278244866886,\n        \"min\": -1.4218000000000046,\n        \"max\": 1.9055000000000035,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          -0.8359999999999985,\n          1.4619,\n          1.771799999999999\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nonfarm_payrolls\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 82.2584004490997,\n        \"min\": 96.0,\n        \"max\": 342.0,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          229.0,\n          273.0,\n          134.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"unemployment_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.20789954839350236,\n        \"min\": 5.0,\n        \"max\": 5.6,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          5.4,\n          5.6,\n          5.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vix_index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.922737355123708,\n        \"min\": 12.12,\n        \"max\": 31.4,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          15.07,\n          15.11,\n          12.12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"real_rate_10y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10967122584241402,\n        \"min\": -0.1,\n        \"max\": 0.21000000000000002,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.040000000000000036,\n          -0.1,\n          -0.08000000000000002\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gdp_growth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0027639957999693538,\n        \"min\": -0.0015929637519117002,\n        \"max\": 0.006300654943472094,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          -0.0015929637519117002,\n          0.005281184497541299,\n          -5.290285921281841e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ============================================================\n",
        "# üîç CHECK DATA CONSISTENCY BEFORE ARDL (Selective Diff Version)\n",
        "# ============================================================\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "print(\"=== Checking macro variable presence in combined_dfs_selective_diff ===\\n\")\n",
        "\n",
        "# List ‡∏Ç‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ó‡∏µ‡πà ARDL ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ (‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö macro_vars ‡∏à‡∏£‡∏¥‡∏á)\n",
        "macro_vars = [\n",
        "    \"inflation_rate\",\n",
        "    \"ppi_inflation\",\n",
        "    \"m2_growth\",\n",
        "    \"m1_growth\",\n",
        "    \"bond_yield_spread\",\n",
        "    \"dxy\",\n",
        "    \"nonfarm_payrolls\",\n",
        "    \"unemployment_rate\",\n",
        "    \"vix_index\",\n",
        "    \"real_rate_10y\",\n",
        "    \"gdp_growth\"\n",
        "]\n",
        "\n",
        "summary_records = []\n",
        "\n",
        "for sector, df_sec in combined_dfs_selective_diff.items():\n",
        "    present = [m for m in macro_vars if m in df_sec.columns]\n",
        "    missing = [m for m in macro_vars if m not in df_sec.columns]\n",
        "    logclose_cols = [c for c in df_sec.columns if c.startswith(\"Logclose_\")]\n",
        "\n",
        "    print(f\"üìÇ Sector: {sector}\")\n",
        "    print(f\"  ‚Ä¢ Stocks found: {len(logclose_cols)} ({', '.join(logclose_cols[:5])}{'...' if len(logclose_cols)>5 else ''})\")\n",
        "    print(f\"  ‚Ä¢ Macros present ({len(present)}): {present}\")\n",
        "    print(f\"  ‚Ä¢ Macros missing ({len(missing)}): {missing}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    summary_records.append({\n",
        "        \"Sector\": sector,\n",
        "        \"N_stocks\": len(logclose_cols),\n",
        "        \"Macros_present\": len(present),\n",
        "        \"Macros_missing\": len(missing),\n",
        "        \"Missing_list\": \", \".join(missing)\n",
        "    })\n",
        "\n",
        "# ‡∏£‡∏ß‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°\n",
        "df_summary = pd.DataFrame(summary_records)\n",
        "print(\"\\n=== Summary of Macro Coverage per Sector ===\")\n",
        "display(df_summary)\n",
        "\n",
        "# # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á dataframe ‡∏à‡∏£‡∏¥‡∏á\n",
        "# sector_to_inspect = list(combined_dfs_selective_diff.keys())[0]\n",
        "# print(f\"\\n\\n=== Example: head() of combined_dfs_selective_diff['{sector_to_inspect}'] ===\")\n",
        "# display(combined_dfs_selective_diff[sector_to_inspect].head(10))\n",
        "\n",
        "# ============================================================\n",
        "# üßπ CLEAN: Drop first NaN row from all selective-diff dataframes\n",
        "# ============================================================\n",
        "\n",
        "for sector in combined_dfs_selective_diff:\n",
        "    df_tmp = combined_dfs_selective_diff[sector].copy()\n",
        "\n",
        "    # ‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô NaN ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n",
        "    df_tmp = df_tmp.dropna(how=\"all\")\n",
        "\n",
        "    # ‡∏•‡∏ö NaN ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏´‡∏•‡∏±‡∏Å (‡∏ñ‡πâ‡∏≤‡∏ö‡∏≤‡∏á macro ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ä‡πâ‡∏≤)\n",
        "    df_tmp = df_tmp.dropna(thresh=int(0.8 * len(df_tmp.columns)))  # ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 80% ‡∏ï‡πâ‡∏≠‡∏á‡πÑ‡∏°‡πà NA\n",
        "\n",
        "    combined_dfs_selective_diff[sector] = df_tmp\n",
        "\n",
        "print(\"‚úÖ Removed first NaN row and cleaned selective-diff dataframes successfully.\\n\")\n",
        "\n",
        "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏´‡∏•‡∏±‡∏á clean\n",
        "sector_to_inspect = list(combined_dfs_selective_diff.keys())[0]\n",
        "print(f\"=== Example after cleaning: '{sector_to_inspect}' ===\")\n",
        "display(combined_dfs_selective_diff[sector_to_inspect].head(10))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TX-tHo1AHRqs"
      },
      "source": [
        "# ARDL + ECM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cqmP28-XHTYE",
        "outputId": "d2f5d821-341d-443e-8232-288d334acd60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== üìÇ Sector: Healthcare | stocks=9 | macros=11 =====\n",
            "‚úÖ Healthcare-AMGN [FIXED] RMSE: ECM=1.217195 | AR=0.076331 | RW=0.075389\n",
            "‚úÖ Healthcare-AMGN [ACF] RMSE: ECM=0.112139 | AR=0.076743 | RW=0.075389\n",
            "‚úÖ Healthcare-AMGN [AIC] RMSE: ECM=0.087483 | AR=0.076743 | RW=0.075389\n",
            "‚úÖ Healthcare-GILD [FIXED] RMSE: ECM=0.733808 | AR=0.079856 | RW=0.078396\n",
            "‚úÖ Healthcare-GILD [ACF] RMSE: ECM=0.129017 | AR=0.079192 | RW=0.078396\n",
            "‚úÖ Healthcare-GILD [AIC] RMSE: ECM=0.109582 | AR=0.079192 | RW=0.078396\n",
            "‚úÖ Healthcare-VRTX [FIXED] RMSE: ECM=0.421544 | AR=0.069209 | RW=0.069014\n",
            "‚úÖ Healthcare-VRTX [ACF] RMSE: ECM=0.116594 | AR=0.069567 | RW=0.069014\n",
            "‚úÖ Healthcare-VRTX [AIC] RMSE: ECM=0.123825 | AR=0.069209 | RW=0.069014\n",
            "‚úÖ Healthcare-REGN [FIXED] RMSE: ECM=0.459000 | AR=0.083155 | RW=0.078029\n",
            "‚úÖ Healthcare-REGN [ACF] RMSE: ECM=0.168521 | AR=0.082501 | RW=0.078029\n",
            "‚úÖ Healthcare-REGN [AIC] RMSE: ECM=0.157405 | AR=0.083155 | RW=0.078029\n",
            "‚úÖ Healthcare-BIIB [FIXED] RMSE: ECM=0.818798 | AR=0.095318 | RW=0.088650\n",
            "‚úÖ Healthcare-BIIB [ACF] RMSE: ECM=0.166303 | AR=0.094011 | RW=0.088650\n",
            "‚úÖ Healthcare-BIIB [AIC] RMSE: ECM=0.113610 | AR=0.094011 | RW=0.088650\n",
            "‚úÖ Healthcare-ILMN [FIXED] RMSE: ECM=0.638736 | AR=0.121030 | RW=0.118999\n",
            "‚úÖ Healthcare-ILMN [ACF] RMSE: ECM=0.162377 | AR=0.120406 | RW=0.118999\n",
            "‚úÖ Healthcare-ILMN [AIC] RMSE: ECM=0.176588 | AR=0.120406 | RW=0.118999\n",
            "‚úÖ Healthcare-IDXX [FIXED] RMSE: ECM=0.584978 | AR=0.131504 | RW=0.129996\n",
            "‚úÖ Healthcare-IDXX [ACF] RMSE: ECM=0.161619 | AR=0.131400 | RW=0.129996\n",
            "‚úÖ Healthcare-IDXX [AIC] RMSE: ECM=0.166011 | AR=0.131400 | RW=0.129996\n",
            "‚úÖ Healthcare-ISRG [FIXED] RMSE: ECM=0.358611 | AR=0.102944 | RW=0.101925\n",
            "‚úÖ Healthcare-ISRG [ACF] RMSE: ECM=0.143188 | AR=0.102360 | RW=0.101925\n",
            "‚úÖ Healthcare-ISRG [AIC] RMSE: ECM=0.139043 | AR=0.102360 | RW=0.101925\n",
            "‚úÖ Healthcare-ALGN [FIXED] RMSE: ECM=0.752485 | AR=0.152970 | RW=0.153004\n",
            "‚úÖ Healthcare-ALGN [ACF] RMSE: ECM=0.247929 | AR=0.153541 | RW=0.153004\n",
            "‚úÖ Healthcare-ALGN [AIC] RMSE: ECM=0.258614 | AR=0.153541 | RW=0.153004\n",
            "\n",
            "‚úÖ Exported ‚Üí ALL_SECTORS_3MODELS_ECM_vs_AR_vs_RW.xlsx\n",
            "\n",
            "=== DONE ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        sector  model ticker  p  q_max          AIC   ECM_MAE  ECM_RMSE  \\\n",
              "0   Healthcare    ACF   ALGN  1      4   -59.085005  0.195675  0.247929   \n",
              "1   Healthcare    AIC   ALGN  1      2   -81.434354  0.209231  0.258614   \n",
              "2   Healthcare  FIXED   ALGN  2      6 -2634.073782  0.594141  0.752485   \n",
              "3   Healthcare    ACF   AMGN  1      4  -151.624879  0.086536  0.112139   \n",
              "4   Healthcare    AIC   AMGN  1      1  -175.983374  0.069783  0.087483   \n",
              "5   Healthcare  FIXED   AMGN  2      6 -2683.730245  0.556055  1.217195   \n",
              "6   Healthcare    ACF   BIIB  1      4   -98.667722  0.129600  0.166303   \n",
              "7   Healthcare    AIC   BIIB  1      1  -124.044249  0.084316  0.113610   \n",
              "8   Healthcare  FIXED   BIIB  2      6 -2578.683342  0.568414  0.818798   \n",
              "9   Healthcare    ACF   GILD  1      4  -155.620333  0.097202  0.129017   \n",
              "10  Healthcare    AIC   GILD  1      1  -180.473755  0.089802  0.109582   \n",
              "11  Healthcare  FIXED   GILD  2      6 -2651.142579  0.480193  0.733808   \n",
              "12  Healthcare    ACF   IDXX  1      4  -151.873955  0.127908  0.161619   \n",
              "13  Healthcare    AIC   IDXX  1      2  -160.550096  0.124128  0.166011   \n",
              "14  Healthcare  FIXED   IDXX  2      6 -2474.028296  0.425813  0.584978   \n",
              "15  Healthcare    ACF   ILMN  1      4   -85.619004  0.128574  0.162377   \n",
              "16  Healthcare    AIC   ILMN  1      2  -119.618474  0.133812  0.176588   \n",
              "17  Healthcare  FIXED   ILMN  2      6 -2568.823921  0.454171  0.638736   \n",
              "18  Healthcare    ACF   ISRG  1      4  -168.487858  0.114114  0.143188   \n",
              "19  Healthcare    AIC   ISRG  1      1  -195.567344  0.109702  0.139043   \n",
              "20  Healthcare  FIXED   ISRG  2      6 -2766.716966  0.287225  0.358611   \n",
              "21  Healthcare    ACF   REGN  1      4  -109.957518  0.118968  0.168521   \n",
              "22  Healthcare    AIC   REGN  2      2  -129.757678  0.122625  0.157405   \n",
              "23  Healthcare  FIXED   REGN  2      6 -2628.318626  0.329545  0.459000   \n",
              "24  Healthcare    ACF   VRTX  1      4   -99.112917  0.089026  0.116594   \n",
              "25  Healthcare    AIC   VRTX  2      2  -137.563423  0.094977  0.123825   \n",
              "26  Healthcare  FIXED   VRTX  2      6 -2509.567307  0.326412  0.421544   \n",
              "\n",
              "    ECM_MAPE(%)  ECM_n_test  ...  q_ppi_inflation  q_m2_growth  q_m1_growth  \\\n",
              "0      3.405712          49  ...                2            4            2   \n",
              "1      3.662961          49  ...                1            1            0   \n",
              "2     10.350089          49  ...                6            6            6   \n",
              "3      1.567685          49  ...                2            4            2   \n",
              "4      1.255004          49  ...                0            0            0   \n",
              "5     10.150618          49  ...                6            6            6   \n",
              "6      2.348226          49  ...                2            4            2   \n",
              "7      1.529134          49  ...                0            0            1   \n",
              "8     10.280378          49  ...                6            6            6   \n",
              "9      2.243645          49  ...                2            4            2   \n",
              "10     2.079441          49  ...                0            0            0   \n",
              "11    11.355572          49  ...                6            6            6   \n",
              "12     2.062869          49  ...                2            4            2   \n",
              "13     2.005382          49  ...                0            0            0   \n",
              "14     6.933922          49  ...                6            6            6   \n",
              "15     2.443334          49  ...                2            4            2   \n",
              "16     2.546577          49  ...                0            0            1   \n",
              "17     8.405567          49  ...                6            6            6   \n",
              "18     2.009493          49  ...                2            4            2   \n",
              "19     1.934478          49  ...                0            0            0   \n",
              "20     5.012893          49  ...                6            6            6   \n",
              "21     1.836056          49  ...                2            4            2   \n",
              "22     1.883405          49  ...                0            0            0   \n",
              "23     5.068751          49  ...                6            6            6   \n",
              "24     1.560539          49  ...                2            4            2   \n",
              "25     1.660668          49  ...                0            0            1   \n",
              "26     5.855042          49  ...                6            6            6   \n",
              "\n",
              "    q_bond_yield_spread  q_dxy  q_nonfarm_payrolls  q_unemployment_rate  \\\n",
              "0                     0      0                   0                    0   \n",
              "1                     2      0                   0                    0   \n",
              "2                     6      6                   6                    6   \n",
              "3                     0      0                   0                    0   \n",
              "4                     0      1                   1                    0   \n",
              "5                     6      6                   6                    6   \n",
              "6                     0      0                   0                    0   \n",
              "7                     0      1                   0                    0   \n",
              "8                     6      6                   6                    6   \n",
              "9                     0      0                   0                    0   \n",
              "10                    1      1                   0                    0   \n",
              "11                    6      6                   6                    6   \n",
              "12                    0      0                   0                    0   \n",
              "13                    0      0                   0                    2   \n",
              "14                    6      6                   6                    6   \n",
              "15                    0      0                   0                    0   \n",
              "16                    0      0                   0                    0   \n",
              "17                    6      6                   6                    6   \n",
              "18                    0      0                   0                    0   \n",
              "19                    0      0                   0                    0   \n",
              "20                    6      6                   6                    6   \n",
              "21                    0      0                   0                    0   \n",
              "22                    2      2                   2                    0   \n",
              "23                    6      6                   6                    6   \n",
              "24                    0      0                   0                    0   \n",
              "25                    2      2                   0                    0   \n",
              "26                    6      6                   6                    6   \n",
              "\n",
              "    q_vix_index  q_real_rate_10y  q_gdp_growth  \n",
              "0             0                0             3  \n",
              "1             2                0             0  \n",
              "2             6                6             6  \n",
              "3             0                0             3  \n",
              "4             0                0             0  \n",
              "5             6                6             6  \n",
              "6             0                0             3  \n",
              "7             0                0             0  \n",
              "8             6                6             6  \n",
              "9             0                0             3  \n",
              "10            0                0             1  \n",
              "11            6                6             6  \n",
              "12            0                0             3  \n",
              "13            0                2             0  \n",
              "14            6                6             6  \n",
              "15            0                0             3  \n",
              "16            2                2             1  \n",
              "17            6                6             6  \n",
              "18            0                0             3  \n",
              "19            0                0             1  \n",
              "20            6                6             6  \n",
              "21            0                0             3  \n",
              "22            1                2             1  \n",
              "23            6                6             6  \n",
              "24            0                0             3  \n",
              "25            2                2             2  \n",
              "26            6                6             6  \n",
              "\n",
              "[27 rows x 33 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-752144e0-c542-4e0b-9518-cfc53e3dcc7c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sector</th>\n",
              "      <th>model</th>\n",
              "      <th>ticker</th>\n",
              "      <th>p</th>\n",
              "      <th>q_max</th>\n",
              "      <th>AIC</th>\n",
              "      <th>ECM_MAE</th>\n",
              "      <th>ECM_RMSE</th>\n",
              "      <th>ECM_MAPE(%)</th>\n",
              "      <th>ECM_n_test</th>\n",
              "      <th>...</th>\n",
              "      <th>q_ppi_inflation</th>\n",
              "      <th>q_m2_growth</th>\n",
              "      <th>q_m1_growth</th>\n",
              "      <th>q_bond_yield_spread</th>\n",
              "      <th>q_dxy</th>\n",
              "      <th>q_nonfarm_payrolls</th>\n",
              "      <th>q_unemployment_rate</th>\n",
              "      <th>q_vix_index</th>\n",
              "      <th>q_real_rate_10y</th>\n",
              "      <th>q_gdp_growth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>ACF</td>\n",
              "      <td>ALGN</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-59.085005</td>\n",
              "      <td>0.195675</td>\n",
              "      <td>0.247929</td>\n",
              "      <td>3.405712</td>\n",
              "      <td>49</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AIC</td>\n",
              "      <td>ALGN</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-81.434354</td>\n",
              "      <td>0.209231</td>\n",
              "      <td>0.258614</td>\n",
              "      <td>3.662961</td>\n",
              "      <td>49</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>ALGN</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>-2634.073782</td>\n",
              "      <td>0.594141</td>\n",
              "      <td>0.752485</td>\n",
              "      <td>10.350089</td>\n",
              "      <td>49</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>ACF</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-151.624879</td>\n",
              "      <td>0.086536</td>\n",
              "      <td>0.112139</td>\n",
              "      <td>1.567685</td>\n",
              "      <td>49</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AIC</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-175.983374</td>\n",
              "      <td>0.069783</td>\n",
              "      <td>0.087483</td>\n",
              "      <td>1.255004</td>\n",
              "      <td>49</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>-2683.730245</td>\n",
              "      <td>0.556055</td>\n",
              "      <td>1.217195</td>\n",
              "      <td>10.150618</td>\n",
              "      <td>49</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>ACF</td>\n",
              "      <td>BIIB</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-98.667722</td>\n",
              "      <td>0.129600</td>\n",
              "      <td>0.166303</td>\n",
              "      <td>2.348226</td>\n",
              "      <td>49</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AIC</td>\n",
              "      <td>BIIB</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-124.044249</td>\n",
              "      <td>0.084316</td>\n",
              "      <td>0.113610</td>\n",
              "      <td>1.529134</td>\n",
              "      <td>49</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>BIIB</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>-2578.683342</td>\n",
              "      <td>0.568414</td>\n",
              "      <td>0.818798</td>\n",
              "      <td>10.280378</td>\n",
              "      <td>49</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>ACF</td>\n",
              "      <td>GILD</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-155.620333</td>\n",
              "      <td>0.097202</td>\n",
              "      <td>0.129017</td>\n",
              "      <td>2.243645</td>\n",
              "      <td>49</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AIC</td>\n",
              "      <td>GILD</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-180.473755</td>\n",
              "      <td>0.089802</td>\n",
              "      <td>0.109582</td>\n",
              "      <td>2.079441</td>\n",
              "      <td>49</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>GILD</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>-2651.142579</td>\n",
              "      <td>0.480193</td>\n",
              "      <td>0.733808</td>\n",
              "      <td>11.355572</td>\n",
              "      <td>49</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>ACF</td>\n",
              "      <td>IDXX</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-151.873955</td>\n",
              "      <td>0.127908</td>\n",
              "      <td>0.161619</td>\n",
              "      <td>2.062869</td>\n",
              "      <td>49</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AIC</td>\n",
              "      <td>IDXX</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-160.550096</td>\n",
              "      <td>0.124128</td>\n",
              "      <td>0.166011</td>\n",
              "      <td>2.005382</td>\n",
              "      <td>49</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>IDXX</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>-2474.028296</td>\n",
              "      <td>0.425813</td>\n",
              "      <td>0.584978</td>\n",
              "      <td>6.933922</td>\n",
              "      <td>49</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>ACF</td>\n",
              "      <td>ILMN</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-85.619004</td>\n",
              "      <td>0.128574</td>\n",
              "      <td>0.162377</td>\n",
              "      <td>2.443334</td>\n",
              "      <td>49</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AIC</td>\n",
              "      <td>ILMN</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-119.618474</td>\n",
              "      <td>0.133812</td>\n",
              "      <td>0.176588</td>\n",
              "      <td>2.546577</td>\n",
              "      <td>49</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>ILMN</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>-2568.823921</td>\n",
              "      <td>0.454171</td>\n",
              "      <td>0.638736</td>\n",
              "      <td>8.405567</td>\n",
              "      <td>49</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>ACF</td>\n",
              "      <td>ISRG</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-168.487858</td>\n",
              "      <td>0.114114</td>\n",
              "      <td>0.143188</td>\n",
              "      <td>2.009493</td>\n",
              "      <td>49</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AIC</td>\n",
              "      <td>ISRG</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-195.567344</td>\n",
              "      <td>0.109702</td>\n",
              "      <td>0.139043</td>\n",
              "      <td>1.934478</td>\n",
              "      <td>49</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>ISRG</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>-2766.716966</td>\n",
              "      <td>0.287225</td>\n",
              "      <td>0.358611</td>\n",
              "      <td>5.012893</td>\n",
              "      <td>49</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>ACF</td>\n",
              "      <td>REGN</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-109.957518</td>\n",
              "      <td>0.118968</td>\n",
              "      <td>0.168521</td>\n",
              "      <td>1.836056</td>\n",
              "      <td>49</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AIC</td>\n",
              "      <td>REGN</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>-129.757678</td>\n",
              "      <td>0.122625</td>\n",
              "      <td>0.157405</td>\n",
              "      <td>1.883405</td>\n",
              "      <td>49</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>REGN</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>-2628.318626</td>\n",
              "      <td>0.329545</td>\n",
              "      <td>0.459000</td>\n",
              "      <td>5.068751</td>\n",
              "      <td>49</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>ACF</td>\n",
              "      <td>VRTX</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-99.112917</td>\n",
              "      <td>0.089026</td>\n",
              "      <td>0.116594</td>\n",
              "      <td>1.560539</td>\n",
              "      <td>49</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AIC</td>\n",
              "      <td>VRTX</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>-137.563423</td>\n",
              "      <td>0.094977</td>\n",
              "      <td>0.123825</td>\n",
              "      <td>1.660668</td>\n",
              "      <td>49</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>VRTX</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>-2509.567307</td>\n",
              "      <td>0.326412</td>\n",
              "      <td>0.421544</td>\n",
              "      <td>5.855042</td>\n",
              "      <td>49</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>27 rows √ó 33 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-752144e0-c542-4e0b-9518-cfc53e3dcc7c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-752144e0-c542-4e0b-9518-cfc53e3dcc7c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-752144e0-c542-4e0b-9518-cfc53e3dcc7c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        sector ticker  model  p  q_max          AIC  q_inflation_rate  \\\n",
              "0   Healthcare   AMGN  FIXED  2      6 -2683.730245                 6   \n",
              "1   Healthcare   AMGN    ACF  1      4  -151.624879                 4   \n",
              "2   Healthcare   AMGN    AIC  1      1  -175.983374                 0   \n",
              "3   Healthcare   GILD  FIXED  2      6 -2651.142579                 6   \n",
              "4   Healthcare   GILD    ACF  1      4  -155.620333                 4   \n",
              "5   Healthcare   GILD    AIC  1      1  -180.473755                 1   \n",
              "6   Healthcare   VRTX  FIXED  2      6 -2509.567307                 6   \n",
              "7   Healthcare   VRTX    ACF  1      4   -99.112917                 4   \n",
              "8   Healthcare   VRTX    AIC  2      2  -137.563423                 1   \n",
              "9   Healthcare   REGN  FIXED  2      6 -2628.318626                 6   \n",
              "10  Healthcare   REGN    ACF  1      4  -109.957518                 4   \n",
              "11  Healthcare   REGN    AIC  2      2  -129.757678                 1   \n",
              "12  Healthcare   BIIB  FIXED  2      6 -2578.683342                 6   \n",
              "13  Healthcare   BIIB    ACF  1      4   -98.667722                 4   \n",
              "14  Healthcare   BIIB    AIC  1      1  -124.044249                 1   \n",
              "15  Healthcare   ILMN  FIXED  2      6 -2568.823921                 6   \n",
              "16  Healthcare   ILMN    ACF  1      4   -85.619004                 4   \n",
              "17  Healthcare   ILMN    AIC  1      2  -119.618474                 0   \n",
              "18  Healthcare   IDXX  FIXED  2      6 -2474.028296                 6   \n",
              "19  Healthcare   IDXX    ACF  1      4  -151.873955                 4   \n",
              "20  Healthcare   IDXX    AIC  1      2  -160.550096                 0   \n",
              "21  Healthcare   ISRG  FIXED  2      6 -2766.716966                 6   \n",
              "22  Healthcare   ISRG    ACF  1      4  -168.487858                 4   \n",
              "23  Healthcare   ISRG    AIC  1      1  -195.567344                 0   \n",
              "24  Healthcare   ALGN  FIXED  2      6 -2634.073782                 6   \n",
              "25  Healthcare   ALGN    ACF  1      4   -59.085005                 4   \n",
              "26  Healthcare   ALGN    AIC  1      2   -81.434354                 2   \n",
              "\n",
              "    q_ppi_inflation  q_m2_growth  q_m1_growth  q_bond_yield_spread  q_dxy  \\\n",
              "0                 6            6            6                    6      6   \n",
              "1                 2            4            2                    0      0   \n",
              "2                 0            0            0                    0      1   \n",
              "3                 6            6            6                    6      6   \n",
              "4                 2            4            2                    0      0   \n",
              "5                 0            0            0                    1      1   \n",
              "6                 6            6            6                    6      6   \n",
              "7                 2            4            2                    0      0   \n",
              "8                 0            0            1                    2      2   \n",
              "9                 6            6            6                    6      6   \n",
              "10                2            4            2                    0      0   \n",
              "11                0            0            0                    2      2   \n",
              "12                6            6            6                    6      6   \n",
              "13                2            4            2                    0      0   \n",
              "14                0            0            1                    0      1   \n",
              "15                6            6            6                    6      6   \n",
              "16                2            4            2                    0      0   \n",
              "17                0            0            1                    0      0   \n",
              "18                6            6            6                    6      6   \n",
              "19                2            4            2                    0      0   \n",
              "20                0            0            0                    0      0   \n",
              "21                6            6            6                    6      6   \n",
              "22                2            4            2                    0      0   \n",
              "23                0            0            0                    0      0   \n",
              "24                6            6            6                    6      6   \n",
              "25                2            4            2                    0      0   \n",
              "26                1            1            0                    2      0   \n",
              "\n",
              "    q_nonfarm_payrolls  q_unemployment_rate  q_vix_index  q_real_rate_10y  \\\n",
              "0                    6                    6            6                6   \n",
              "1                    0                    0            0                0   \n",
              "2                    1                    0            0                0   \n",
              "3                    6                    6            6                6   \n",
              "4                    0                    0            0                0   \n",
              "5                    0                    0            0                0   \n",
              "6                    6                    6            6                6   \n",
              "7                    0                    0            0                0   \n",
              "8                    0                    0            2                2   \n",
              "9                    6                    6            6                6   \n",
              "10                   0                    0            0                0   \n",
              "11                   2                    0            1                2   \n",
              "12                   6                    6            6                6   \n",
              "13                   0                    0            0                0   \n",
              "14                   0                    0            0                0   \n",
              "15                   6                    6            6                6   \n",
              "16                   0                    0            0                0   \n",
              "17                   0                    0            2                2   \n",
              "18                   6                    6            6                6   \n",
              "19                   0                    0            0                0   \n",
              "20                   0                    2            0                2   \n",
              "21                   6                    6            6                6   \n",
              "22                   0                    0            0                0   \n",
              "23                   0                    0            0                0   \n",
              "24                   6                    6            6                6   \n",
              "25                   0                    0            0                0   \n",
              "26                   0                    0            2                0   \n",
              "\n",
              "    q_gdp_growth  \n",
              "0              6  \n",
              "1              3  \n",
              "2              0  \n",
              "3              6  \n",
              "4              3  \n",
              "5              1  \n",
              "6              6  \n",
              "7              3  \n",
              "8              2  \n",
              "9              6  \n",
              "10             3  \n",
              "11             1  \n",
              "12             6  \n",
              "13             3  \n",
              "14             0  \n",
              "15             6  \n",
              "16             3  \n",
              "17             1  \n",
              "18             6  \n",
              "19             3  \n",
              "20             0  \n",
              "21             6  \n",
              "22             3  \n",
              "23             1  \n",
              "24             6  \n",
              "25             3  \n",
              "26             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e41fa67c-32be-41d8-87f1-5c7351e5d52f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sector</th>\n",
              "      <th>ticker</th>\n",
              "      <th>model</th>\n",
              "      <th>p</th>\n",
              "      <th>q_max</th>\n",
              "      <th>AIC</th>\n",
              "      <th>q_inflation_rate</th>\n",
              "      <th>q_ppi_inflation</th>\n",
              "      <th>q_m2_growth</th>\n",
              "      <th>q_m1_growth</th>\n",
              "      <th>q_bond_yield_spread</th>\n",
              "      <th>q_dxy</th>\n",
              "      <th>q_nonfarm_payrolls</th>\n",
              "      <th>q_unemployment_rate</th>\n",
              "      <th>q_vix_index</th>\n",
              "      <th>q_real_rate_10y</th>\n",
              "      <th>q_gdp_growth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>-2683.730245</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>ACF</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-151.624879</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>AIC</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-175.983374</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>GILD</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>-2651.142579</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>GILD</td>\n",
              "      <td>ACF</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-155.620333</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>GILD</td>\n",
              "      <td>AIC</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-180.473755</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>VRTX</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>-2509.567307</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>VRTX</td>\n",
              "      <td>ACF</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-99.112917</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>VRTX</td>\n",
              "      <td>AIC</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>-137.563423</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>REGN</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>-2628.318626</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>REGN</td>\n",
              "      <td>ACF</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-109.957518</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>REGN</td>\n",
              "      <td>AIC</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>-129.757678</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>BIIB</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>-2578.683342</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>BIIB</td>\n",
              "      <td>ACF</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-98.667722</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>BIIB</td>\n",
              "      <td>AIC</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-124.044249</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>ILMN</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>-2568.823921</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>ILMN</td>\n",
              "      <td>ACF</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-85.619004</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>ILMN</td>\n",
              "      <td>AIC</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-119.618474</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>IDXX</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>-2474.028296</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>IDXX</td>\n",
              "      <td>ACF</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-151.873955</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>IDXX</td>\n",
              "      <td>AIC</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-160.550096</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>ISRG</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>-2766.716966</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>ISRG</td>\n",
              "      <td>ACF</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-168.487858</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>ISRG</td>\n",
              "      <td>AIC</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-195.567344</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>ALGN</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>-2634.073782</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>ALGN</td>\n",
              "      <td>ACF</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-59.085005</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>ALGN</td>\n",
              "      <td>AIC</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-81.434354</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e41fa67c-32be-41d8-87f1-5c7351e5d52f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e41fa67c-32be-41d8-87f1-5c7351e5d52f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e41fa67c-32be-41d8-87f1-5c7351e5d52f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df_gamma\",\n  \"rows\": 27,\n  \"fields\": [\n    {\n      \"column\": \"sector\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Healthcare\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ticker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"ISRG\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"FIXED\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"q_max\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 6,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AIC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1191.8534543534038,\n        \"min\": -2766.7169656406827,\n        \"max\": -59.08500530225837,\n        \"num_unique_values\": 27,\n        \"samples\": [\n          -137.563423004504\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"q_inflation_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"q_ppi_inflation\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"q_m2_growth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"q_m1_growth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"q_bond_yield_spread\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"q_dxy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"q_nonfarm_payrolls\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"q_unemployment_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"q_vix_index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"q_real_rate_10y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"q_gdp_growth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       Sector Stock  Model     Alpha  Alpha_pval\n",
              "0  Healthcare  AMGN  FIXED  1.508777         NaN\n",
              "1  Healthcare  AMGN    ACF -0.408052    0.001937\n",
              "2  Healthcare  AMGN    AIC -0.411776    0.000271\n",
              "3  Healthcare  GILD  FIXED  0.324813         NaN\n",
              "4  Healthcare  GILD    ACF -0.381129    0.025036\n",
              "5  Healthcare  GILD    AIC -0.561746    0.000203\n",
              "6  Healthcare  VRTX  FIXED -0.684523         NaN\n",
              "7  Healthcare  VRTX    ACF -0.135407    0.107369\n",
              "8  Healthcare  VRTX    AIC -0.174369    0.018949\n",
              "9  Healthcare  REGN  FIXED  0.421292         NaN"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7209b27d-6a77-4735-a14e-ec2acc6b6d3b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sector</th>\n",
              "      <th>Stock</th>\n",
              "      <th>Model</th>\n",
              "      <th>Alpha</th>\n",
              "      <th>Alpha_pval</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>1.508777</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>ACF</td>\n",
              "      <td>-0.408052</td>\n",
              "      <td>0.001937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>AIC</td>\n",
              "      <td>-0.411776</td>\n",
              "      <td>0.000271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>GILD</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>0.324813</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>GILD</td>\n",
              "      <td>ACF</td>\n",
              "      <td>-0.381129</td>\n",
              "      <td>0.025036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>GILD</td>\n",
              "      <td>AIC</td>\n",
              "      <td>-0.561746</td>\n",
              "      <td>0.000203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>VRTX</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>-0.684523</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>VRTX</td>\n",
              "      <td>ACF</td>\n",
              "      <td>-0.135407</td>\n",
              "      <td>0.107369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>VRTX</td>\n",
              "      <td>AIC</td>\n",
              "      <td>-0.174369</td>\n",
              "      <td>0.018949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>REGN</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>0.421292</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7209b27d-6a77-4735-a14e-ec2acc6b6d3b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7209b27d-6a77-4735-a14e-ec2acc6b6d3b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7209b27d-6a77-4735-a14e-ec2acc6b6d3b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df_gamma\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Sector\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Healthcare\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Stock\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"GILD\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"FIXED\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Alpha\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6539096448556279,\n        \"min\": -0.6845230017867218,\n        \"max\": 1.5087767900569464,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          -0.17436874010857362\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Alpha_pval\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.041418008384530525,\n        \"min\": 0.00020262009428832287,\n        \"max\": 0.10736925843864774,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.0019370170748150835\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       Sector Stock  Model           Variable      coef\n",
              "0  Healthcare  AMGN  FIXED              const -0.815545\n",
              "1  Healthcare  AMGN  FIXED     inflation_rate  0.579385\n",
              "2  Healthcare  AMGN  FIXED      ppi_inflation -2.639006\n",
              "3  Healthcare  AMGN  FIXED          m2_growth -1.232555\n",
              "4  Healthcare  AMGN  FIXED          m1_growth  0.724349\n",
              "5  Healthcare  AMGN  FIXED  bond_yield_spread -0.511343\n",
              "6  Healthcare  AMGN  FIXED                dxy  0.002979\n",
              "7  Healthcare  AMGN  FIXED   nonfarm_payrolls  0.000037\n",
              "8  Healthcare  AMGN  FIXED  unemployment_rate  0.232235\n",
              "9  Healthcare  AMGN  FIXED          vix_index -0.024238"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-03ae1e3a-c90f-46c5-a838-6ca929b36b48\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sector</th>\n",
              "      <th>Stock</th>\n",
              "      <th>Model</th>\n",
              "      <th>Variable</th>\n",
              "      <th>coef</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>const</td>\n",
              "      <td>-0.815545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>inflation_rate</td>\n",
              "      <td>0.579385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>ppi_inflation</td>\n",
              "      <td>-2.639006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>m2_growth</td>\n",
              "      <td>-1.232555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>m1_growth</td>\n",
              "      <td>0.724349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>bond_yield_spread</td>\n",
              "      <td>-0.511343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>dxy</td>\n",
              "      <td>0.002979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>nonfarm_payrolls</td>\n",
              "      <td>0.000037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>unemployment_rate</td>\n",
              "      <td>0.232235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>vix_index</td>\n",
              "      <td>-0.024238</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-03ae1e3a-c90f-46c5-a838-6ca929b36b48')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-03ae1e3a-c90f-46c5-a838-6ca929b36b48 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-03ae1e3a-c90f-46c5-a838-6ca929b36b48');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df_gamma\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Sector\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Healthcare\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Stock\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"AMGN\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"FIXED\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Variable\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"unemployment_rate\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"coef\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9982239836536795,\n        \"min\": -2.6390059246942883,\n        \"max\": 0.7243489925486093,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.2322354830364256\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       Sector Stock  Model             Variable      Coef  pval\n",
              "0  Healthcare  AMGN  FIXED   D.L1.Logclose_AMGN -1.729835   NaN\n",
              "1  Healthcare  AMGN  FIXED     D.inflation_rate  2.407794   NaN\n",
              "2  Healthcare  AMGN  FIXED  D.L1.inflation_rate -6.902358   NaN\n",
              "3  Healthcare  AMGN  FIXED  D.L2.inflation_rate  5.390904   NaN\n",
              "4  Healthcare  AMGN  FIXED  D.L3.inflation_rate -2.062771   NaN\n",
              "5  Healthcare  AMGN  FIXED  D.L4.inflation_rate -0.262685   NaN\n",
              "6  Healthcare  AMGN  FIXED  D.L5.inflation_rate -1.261027   NaN\n",
              "7  Healthcare  AMGN  FIXED      D.ppi_inflation  3.036915   NaN\n",
              "8  Healthcare  AMGN  FIXED   D.L1.ppi_inflation -3.213948   NaN\n",
              "9  Healthcare  AMGN  FIXED   D.L2.ppi_inflation  1.387178   NaN"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ddabe165-1426-4ac1-9ac1-ba12b2efcbcc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sector</th>\n",
              "      <th>Stock</th>\n",
              "      <th>Model</th>\n",
              "      <th>Variable</th>\n",
              "      <th>Coef</th>\n",
              "      <th>pval</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>D.L1.Logclose_AMGN</td>\n",
              "      <td>-1.729835</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>D.inflation_rate</td>\n",
              "      <td>2.407794</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>D.L1.inflation_rate</td>\n",
              "      <td>-6.902358</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>D.L2.inflation_rate</td>\n",
              "      <td>5.390904</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>D.L3.inflation_rate</td>\n",
              "      <td>-2.062771</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>D.L4.inflation_rate</td>\n",
              "      <td>-0.262685</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>D.L5.inflation_rate</td>\n",
              "      <td>-1.261027</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>D.ppi_inflation</td>\n",
              "      <td>3.036915</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>D.L1.ppi_inflation</td>\n",
              "      <td>-3.213948</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>D.L2.ppi_inflation</td>\n",
              "      <td>1.387178</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ddabe165-1426-4ac1-9ac1-ba12b2efcbcc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ddabe165-1426-4ac1-9ac1-ba12b2efcbcc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ddabe165-1426-4ac1-9ac1-ba12b2efcbcc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df_gamma\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Sector\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Healthcare\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Stock\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"AMGN\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"FIXED\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Variable\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"D.L1.ppi_inflation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Coef\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.525379219145489,\n        \"min\": -6.902358211080499,\n        \"max\": 5.390903823749907,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          -3.2139483036523977\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pval\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ============================================================\n",
        "# ‚úÖ RUN 3 ARDL-ECM LAG REGIMES FOR *ALL STOCKS* (ALL SECTORS)\n",
        "#    FIXED / ACF-PACF / AIC-greedy\n",
        "#    Walk-forward: ECM vs AR(p) vs RW + DM tests\n",
        "#    + BUILD df_alpha / df_beta / df_gamma FOR DOWNSTREAM FORECAST\n",
        "#    Export Excel\n",
        "# ============================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tsa.ar_model import AutoReg\n",
        "from scipy import stats\n",
        "from statsmodels.tsa.stattools import acf, pacf\n",
        "\n",
        "# -----------------------------\n",
        "# 0) SAFETY: which dataset?\n",
        "# -----------------------------\n",
        "USE_DATA = \"combined_dfs\"  # or \"combined_dfs_selective_diff\"\n",
        "\n",
        "if USE_DATA not in globals() or not isinstance(globals()[USE_DATA], dict) or not globals()[USE_DATA]:\n",
        "    raise RuntimeError(f\"‚ùå {USE_DATA} not found or empty.\")\n",
        "sector_dfs = globals()[USE_DATA]\n",
        "\n",
        "# -----------------------------\n",
        "# CONFIG\n",
        "# -----------------------------\n",
        "macro_vars = [\n",
        "    \"inflation_rate\",\"ppi_inflation\",\"m2_growth\",\"m1_growth\",\"bond_yield_spread\",\"dxy\",\n",
        "    \"nonfarm_payrolls\",\"unemployment_rate\",\"vix_index\",\"real_rate_10y\",\"gdp_growth\"\n",
        "]\n",
        "\n",
        "# AIC search bounds (fast)\n",
        "CRITERION = \"AIC\"     # \"AIC\" or \"BIC\"\n",
        "P_MIN, P_MAX = 1, 2\n",
        "Q_MAX_AIC = 2\n",
        "\n",
        "# FIXED lag regime\n",
        "P_FIXED = 2\n",
        "Q_FIXED = 6\n",
        "Q_CAP   = 6          # cap for ACF/PACF q selection too\n",
        "\n",
        "# Walk-forward evaluation\n",
        "TRAIN_END = \"2020-12-01\"\n",
        "TEST_END  = None\n",
        "MIN_TRAIN = 60\n",
        "REFIT_EVERY = 6\n",
        "MAX_TEST_POINTS = 120\n",
        "\n",
        "EXPORT_PATH = \"ALL_SECTORS_3MODELS_ECM_vs_AR_vs_RW.xlsx\"\n",
        "\n",
        "# ============================================================\n",
        "# 1) Utilities (columns + metrics + DM)\n",
        "# ============================================================\n",
        "def clean_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    d = df.copy()\n",
        "    d.columns = d.columns.astype(str).str.strip()\n",
        "    return d\n",
        "\n",
        "def _safe_mape(y_true, y_pred, eps=1e-8):\n",
        "    denom = np.maximum(np.abs(y_true), eps)\n",
        "    return np.mean(np.abs((y_true - y_pred) / denom)) * 100.0\n",
        "\n",
        "def metrics(y_true, y_pred) -> dict:\n",
        "    err = y_true - y_pred\n",
        "    return {\n",
        "        \"MAE\": float(np.mean(np.abs(err))),\n",
        "        \"RMSE\": float(np.sqrt(np.mean(err**2))),\n",
        "        \"MAPE(%)\": float(_safe_mape(y_true, y_pred)),\n",
        "        \"n_test\": int(len(y_true))\n",
        "    }\n",
        "\n",
        "def dm_test(e1: np.ndarray, e2: np.ndarray, power: int = 2):\n",
        "    e1 = np.asarray(e1); e2 = np.asarray(e2)\n",
        "    if power == 1:\n",
        "        d = np.abs(e1) - np.abs(e2)\n",
        "    else:\n",
        "        d = (e1**2) - (e2**2)\n",
        "    d = d[~np.isnan(d)]\n",
        "    T = len(d)\n",
        "    if T < 10:\n",
        "        return np.nan, np.nan\n",
        "    mean_d = d.mean()\n",
        "    var_d = d.var(ddof=1)\n",
        "    if var_d <= 1e-12:\n",
        "        return np.nan, np.nan\n",
        "    dm_stat = mean_d / np.sqrt(var_d / T)\n",
        "    pval = 2 * (1 - stats.t.cdf(np.abs(dm_stat), df=T-1))\n",
        "    return float(dm_stat), float(pval)\n",
        "\n",
        "# ============================================================\n",
        "# 2) ECM (manual OLS)\n",
        "# ============================================================\n",
        "def build_ecm_ols(y: pd.Series, X: pd.DataFrame, p: int, q_dict: dict, add_const: bool = True):\n",
        "    y = y.astype(float)\n",
        "    X = X.astype(float)\n",
        "\n",
        "    dy = y.diff()\n",
        "    Z = pd.DataFrame(index=y.index)\n",
        "\n",
        "    if add_const:\n",
        "        Z[\"const\"] = 1.0\n",
        "\n",
        "    # levels (t-1)\n",
        "    Z[f\"L1.{y.name}\"] = y.shift(1)\n",
        "    for m in X.columns:\n",
        "        Z[f\"L1.{m}\"] = X[m].shift(1)\n",
        "\n",
        "    # Œîy lags 1..p-1\n",
        "    for i in range(1, max(p, 1)):\n",
        "        if i <= p - 1:\n",
        "            Z[f\"D.L{i}.{y.name}\"] = dy.shift(i)\n",
        "\n",
        "    # Œîx lags 0..q_m-1\n",
        "    for m in X.columns:\n",
        "        q_m = int(q_dict.get(m, 0))\n",
        "        dx = X[m].diff()\n",
        "        for k in range(0, q_m):\n",
        "            Z[f\"D.{m}\" if k == 0 else f\"D.L{k}.{m}\"] = dx.shift(k)\n",
        "\n",
        "    df_all = pd.concat([dy.rename(\"D.y\"), Z], axis=1).dropna()\n",
        "    if df_all.shape[0] < 30:\n",
        "        raise ValueError(\"Too few observations after alignment.\")\n",
        "\n",
        "    y_dep = df_all[\"D.y\"]\n",
        "    X_reg = df_all.drop(columns=[\"D.y\"])\n",
        "    res = sm.OLS(y_dep, X_reg).fit()\n",
        "    return res, X_reg\n",
        "\n",
        "def get_ic(res, criterion=\"AIC\"):\n",
        "    return res.aic if str(criterion).upper() == \"AIC\" else res.bic\n",
        "\n",
        "# ============================================================\n",
        "# 3) AIC Greedy selector (fast)\n",
        "# ============================================================\n",
        "def greedy_select_q_AIC(y, X, p, q_max=2, add_const=True, criterion=\"AIC\"):\n",
        "    q_dict = {m: 0 for m in X.columns}\n",
        "    best_res, _ = build_ecm_ols(y, X, p=p, q_dict=q_dict, add_const=add_const)\n",
        "    best_ic = get_ic(best_res, criterion=criterion)\n",
        "\n",
        "    for _ in range(2):\n",
        "        improved = False\n",
        "        for m in X.columns:\n",
        "            cur_q = q_dict[m]\n",
        "            best_local_q = cur_q\n",
        "            best_local_ic = best_ic\n",
        "            best_local_res = best_res\n",
        "\n",
        "            for q_try in range(0, q_max + 1):\n",
        "                if q_try == cur_q:\n",
        "                    continue\n",
        "                q_tmp = dict(q_dict); q_tmp[m] = q_try\n",
        "                try:\n",
        "                    res_try, _ = build_ecm_ols(y, X, p=p, q_dict=q_tmp, add_const=add_const)\n",
        "                    ic_try = get_ic(res_try, criterion=criterion)\n",
        "                    if ic_try < best_local_ic - 1e-9:\n",
        "                        best_local_ic = ic_try\n",
        "                        best_local_q = q_try\n",
        "                        best_local_res = res_try\n",
        "                except Exception:\n",
        "                    continue\n",
        "\n",
        "            if best_local_q != cur_q:\n",
        "                q_dict[m] = best_local_q\n",
        "                best_ic = best_local_ic\n",
        "                best_res = best_local_res\n",
        "                improved = True\n",
        "\n",
        "        if not improved:\n",
        "            break\n",
        "\n",
        "    return q_dict, best_res, best_ic\n",
        "\n",
        "def select_pq_AIC_fast(y, X, p_min=1, p_max=2, q_max=2, add_const=True, criterion=\"AIC\"):\n",
        "    best = None\n",
        "    for p in range(p_min, p_max + 1):\n",
        "        try:\n",
        "            q_dict, res, ic = greedy_select_q_AIC(y, X, p=p, q_max=q_max, add_const=add_const, criterion=criterion)\n",
        "            if (best is None) or (ic < best[\"ic\"]):\n",
        "                best = {\"p\": p, \"q_dict\": q_dict, \"res\": res, \"ic\": ic}\n",
        "        except Exception:\n",
        "            continue\n",
        "    if best is None:\n",
        "        raise ValueError(\"cannot select ARDL order by AIC\")\n",
        "    return best[\"p\"], best[\"q_dict\"], best[\"res\"], best[\"ic\"]\n",
        "\n",
        "# ============================================================\n",
        "# 4) ACF/PACF selector\n",
        "# ============================================================\n",
        "def _sig_lags_from_acf(series: pd.Series, max_lag: int, alpha: float = 0.05):\n",
        "    s = pd.to_numeric(series, errors=\"coerce\").dropna()\n",
        "    if len(s) < max(30, max_lag + 5):\n",
        "        return []\n",
        "    acf_vals, confint = acf(s, nlags=max_lag, alpha=alpha, fft=True)\n",
        "    sig = []\n",
        "    for k in range(1, max_lag + 1):\n",
        "        lo, hi = confint[k]\n",
        "        if not (lo <= 0 <= hi):\n",
        "            sig.append(k)\n",
        "    return sig\n",
        "\n",
        "def _choose_p_from_pacf_dy(y: pd.Series, p_min: int, p_max: int, alpha: float = 0.05):\n",
        "    dy = pd.to_numeric(y, errors=\"coerce\").diff().dropna()\n",
        "    if len(dy) < max(30, p_max + 5):\n",
        "        return p_min\n",
        "    pacf_vals, confint = pacf(dy, nlags=p_max, alpha=alpha, method=\"ywm\")\n",
        "    sig_lags = []\n",
        "    for k in range(1, p_max + 1):\n",
        "        lo, hi = confint[k]\n",
        "        if not (lo <= 0 <= hi):\n",
        "            sig_lags.append(k)\n",
        "    p = (max(sig_lags) + 1) if sig_lags else p_min\n",
        "    return int(np.clip(p, p_min, p_max))\n",
        "\n",
        "def _choose_q_from_acf_dx(x: pd.Series, q_cap: int, alpha: float = 0.05):\n",
        "    dx = pd.to_numeric(x, errors=\"coerce\").diff()\n",
        "    sig_lags = _sig_lags_from_acf(dx, max_lag=q_cap, alpha=alpha)\n",
        "    if not sig_lags:\n",
        "        return 0\n",
        "    q = max(sig_lags) + 1\n",
        "    return int(np.clip(q, 0, q_cap))\n",
        "\n",
        "def select_pq_ACF(y: pd.Series, X: pd.DataFrame, p_min=1, p_max=2, q_cap=6, alpha=0.05, add_const=True, criterion=\"AIC\"):\n",
        "    p_sel = _choose_p_from_pacf_dy(y, p_min, p_max, alpha=alpha)\n",
        "    q_dict = {m: _choose_q_from_acf_dx(X[m], q_cap=q_cap, alpha=alpha) for m in X.columns}\n",
        "    res, _ = build_ecm_ols(y, X, p=p_sel, q_dict=q_dict, add_const=add_const)\n",
        "    ic = get_ic(res, criterion=criterion)\n",
        "    return p_sel, q_dict, res, ic\n",
        "\n",
        "# ============================================================\n",
        "# 5) FIXED selector\n",
        "# ============================================================\n",
        "def select_pq_FIXED(y: pd.Series, X: pd.DataFrame, p_fixed=2, q_fixed=6, add_const=True, criterion=\"AIC\"):\n",
        "    q_dict = {m: int(q_fixed) for m in X.columns}\n",
        "    res, _ = build_ecm_ols(y, X, p=p_fixed, q_dict=q_dict, add_const=add_const)\n",
        "    ic = get_ic(res, criterion=criterion)\n",
        "    return int(p_fixed), q_dict, res, ic\n",
        "\n",
        "# ============================================================\n",
        "# 6) Walk-forward eval\n",
        "# ============================================================\n",
        "def fit_ecm_from_train(df_train: pd.DataFrame, y_col: str, x_cols: list, p: int, q_dict: dict):\n",
        "    y = df_train[y_col].copy(); y.name = y_col\n",
        "    X = df_train[x_cols].copy()\n",
        "    res, _ = build_ecm_ols(y, X, p=p, q_dict=q_dict, add_const=True)\n",
        "    return res\n",
        "\n",
        "def ar_one_step_forecast(y_train: pd.Series, y_all: pd.Series, i: int, p: int):\n",
        "    ytr = y_train.dropna()\n",
        "    if len(ytr) < max(p + 5, 20):\n",
        "        return float(y_all.shift(1).iloc[i])\n",
        "    fit = AutoReg(ytr, lags=p, old_names=False).fit()\n",
        "    fc = fit.predict(start=len(ytr), end=len(ytr))\n",
        "    return float(fc.iloc[0])\n",
        "\n",
        "def rw_one_step_forecast(y_all: pd.Series, i: int):\n",
        "    return float(y_all.shift(1).iloc[i])\n",
        "\n",
        "def ecm_one_step_forecast_from_params(df_all: pd.DataFrame, i: int, y_col: str, x_cols: list, p: int, q_dict: dict, ecm_fit):\n",
        "    params = ecm_fit.params\n",
        "    row = {}\n",
        "\n",
        "    if \"const\" in params.index:\n",
        "        row[\"const\"] = 1.0\n",
        "\n",
        "    row[f\"L1.{y_col}\"] = df_all[y_col].shift(1).iloc[i]\n",
        "    for m in x_cols:\n",
        "        row[f\"L1.{m}\"] = df_all[m].shift(1).iloc[i]\n",
        "\n",
        "    dy = df_all[y_col].diff()\n",
        "    for j in range(1, max(p, 1)):\n",
        "        if j <= p - 1:\n",
        "            nm = f\"D.L{j}.{y_col}\"\n",
        "            if nm in params.index:\n",
        "                row[nm] = dy.shift(j).iloc[i]\n",
        "\n",
        "    for m in x_cols:\n",
        "        q = int(q_dict.get(m, 0))\n",
        "        if q <= 0:\n",
        "            continue\n",
        "        dx = df_all[m].diff()\n",
        "        for k in range(0, q):\n",
        "            nm = f\"D.{m}\" if k == 0 else f\"D.L{k}.{m}\"\n",
        "            if nm in params.index:\n",
        "                row[nm] = dx.shift(k).iloc[i]\n",
        "\n",
        "    exog_names = list(params.index)\n",
        "    x_vec = np.array([row.get(n, 0.0) for n in exog_names], dtype=float)\n",
        "    dy_hat = float(np.dot(x_vec, params.values))\n",
        "    y_prev = df_all[y_col].shift(1).iloc[i]\n",
        "    return float(y_prev + dy_hat)\n",
        "\n",
        "def evaluate_ticker(df: pd.DataFrame,\n",
        "                    ticker: str,\n",
        "                    y_col: str,\n",
        "                    x_cols: list,\n",
        "                    p: int,\n",
        "                    q_dict: dict,\n",
        "                    train_end: str,\n",
        "                    test_end: str = None,\n",
        "                    min_train: int = 60,\n",
        "                    refit_every: int = 6,\n",
        "                    max_test_points: int = 120):\n",
        "\n",
        "    d = df.copy().sort_index()\n",
        "    if test_end is not None:\n",
        "        d = d.loc[:pd.to_datetime(test_end)]\n",
        "\n",
        "    train_end_dt = pd.to_datetime(train_end)\n",
        "    d_train0 = d.loc[d.index <= train_end_dt]\n",
        "    d_test   = d.loc[d.index >  train_end_dt]\n",
        "\n",
        "    if len(d_train0) < min_train:\n",
        "        raise ValueError(f\"{ticker}: not enough train data ({len(d_train0)})\")\n",
        "\n",
        "    all_idx = d.index.tolist()\n",
        "    test_indices = [i for i, dt in enumerate(all_idx) if dt in d_test.index]\n",
        "    if max_test_points is not None:\n",
        "        test_indices = test_indices[:max_test_points]\n",
        "\n",
        "    y_true, yhat_ecm, yhat_ar, yhat_rw = [], [], [], []\n",
        "    ecm_fit = None\n",
        "\n",
        "    for step, i in enumerate(test_indices):\n",
        "        d_train = d.iloc[:i].copy()\n",
        "        if len(d_train) < min_train:\n",
        "            continue\n",
        "\n",
        "        if (ecm_fit is None) or (step % refit_every == 0):\n",
        "            ecm_fit = fit_ecm_from_train(d_train, y_col, x_cols, p, q_dict)\n",
        "\n",
        "        y_pred_ecm = ecm_one_step_forecast_from_params(d, i, y_col, x_cols, p, q_dict, ecm_fit)\n",
        "\n",
        "        y_series_train = d_train[y_col]\n",
        "        y_series_all   = d[y_col]\n",
        "        y_pred_ar = ar_one_step_forecast(y_series_train, y_series_all, i, p=max(1, p))\n",
        "        y_pred_rw = rw_one_step_forecast(y_series_all, i)\n",
        "\n",
        "        y_true.append(float(d[y_col].iloc[i]))\n",
        "        yhat_ecm.append(y_pred_ecm)\n",
        "        yhat_ar.append(y_pred_ar)\n",
        "        yhat_rw.append(y_pred_rw)\n",
        "\n",
        "    y_true = np.array(y_true, dtype=float)\n",
        "    yhat_ecm = np.array(yhat_ecm, dtype=float)\n",
        "    yhat_ar  = np.array(yhat_ar, dtype=float)\n",
        "    yhat_rw  = np.array(yhat_rw, dtype=float)\n",
        "\n",
        "    out = {\"ticker\": ticker, \"p\": int(p), \"q_max\": int(max(q_dict.values()) if q_dict else 0)}\n",
        "    out.update({f\"ECM_{k}\": v for k, v in metrics(y_true, yhat_ecm).items()})\n",
        "    out.update({f\"AR_{k}\":  v for k, v in metrics(y_true, yhat_ar).items()})\n",
        "    out.update({f\"RW_{k}\":  v for k, v in metrics(y_true, yhat_rw).items()})\n",
        "\n",
        "    e_ecm = y_true - yhat_ecm\n",
        "    e_ar  = y_true - yhat_ar\n",
        "    e_rw  = y_true - yhat_rw\n",
        "\n",
        "    dm_ecm_ar, p_ecm_ar = dm_test(e_ecm, e_ar, power=2)\n",
        "    dm_ecm_rw, p_ecm_rw = dm_test(e_ecm, e_rw, power=2)\n",
        "\n",
        "    out[\"DM(ECM-AR)\"] = dm_ecm_ar\n",
        "    out[\"pval(ECM-AR)\"] = p_ecm_ar\n",
        "    out[\"DM(ECM-RW)\"] = dm_ecm_rw\n",
        "    out[\"pval(ECM-RW)\"] = p_ecm_rw\n",
        "    return out\n",
        "\n",
        "# ============================================================\n",
        "# 7) ‚úÖ NEW: convert ECM fit -> df_alpha / df_beta / df_gamma rows\n",
        "# ============================================================\n",
        "def ecm_to_tables(ecm_fit, y_col, x_cols, model_name, sector, ticker):\n",
        "    params = ecm_fit.params\n",
        "    pvals  = ecm_fit.pvalues\n",
        "\n",
        "    # alpha\n",
        "    alpha_key = f\"L1.{y_col}\"\n",
        "    alpha = float(params.get(alpha_key, np.nan))\n",
        "    alpha_p = float(pvals.get(alpha_key, np.nan))\n",
        "\n",
        "    alpha_row = {\n",
        "        \"Sector\": sector,\n",
        "        \"Stock\": ticker,\n",
        "        \"Model\": model_name,\n",
        "        \"Alpha\": alpha,\n",
        "        \"Alpha_pval\": alpha_p\n",
        "    }\n",
        "\n",
        "    # beta long-run: -L1.x / alpha , const included\n",
        "    beta_rows = []\n",
        "    if np.isfinite(alpha) and alpha != 0:\n",
        "        if \"const\" in params.index:\n",
        "            beta_rows.append({\n",
        "                \"Sector\": sector, \"Stock\": ticker, \"Model\": model_name,\n",
        "                \"Variable\": \"const\", \"coef\": float(-params[\"const\"] / alpha)\n",
        "            })\n",
        "        for m in x_cols:\n",
        "            k = f\"L1.{m}\"\n",
        "            if k in params.index:\n",
        "                beta_rows.append({\n",
        "                    \"Sector\": sector, \"Stock\": ticker, \"Model\": model_name,\n",
        "                    \"Variable\": m, \"coef\": float(-params[k] / alpha)\n",
        "                })\n",
        "\n",
        "    # gamma short-run: keep ONLY D.* terms (forecast expects D.Lk.)\n",
        "    gamma_rows = []\n",
        "    for name in params.index:\n",
        "        if name.startswith(\"D.\"):\n",
        "            gamma_rows.append({\n",
        "                \"Sector\": sector, \"Stock\": ticker, \"Model\": model_name,\n",
        "                \"Variable\": name,\n",
        "                \"Coef\": float(params[name]),\n",
        "                \"pval\": float(pvals.get(name, np.nan))\n",
        "            })\n",
        "\n",
        "    return alpha_row, beta_rows, gamma_rows\n",
        "\n",
        "# ============================================================\n",
        "# 8) MAIN runner (produces res_df, orders_df, df_alpha/beta/gamma)\n",
        "# ============================================================\n",
        "def run_all_sectors_3models(sector_dfs: dict,\n",
        "                            macro_vars: list,\n",
        "                            train_end: str,\n",
        "                            test_end: str = None,\n",
        "                            export_path: str = None,\n",
        "                            verbose: bool = True):\n",
        "\n",
        "    all_rows = []\n",
        "    orders_dump = []\n",
        "\n",
        "    alpha_list = []\n",
        "    beta_list  = []\n",
        "    gamma_list = []\n",
        "\n",
        "    for sector, df_sec in sector_dfs.items():\n",
        "        d = clean_columns(df_sec)\n",
        "        stock_cols = [c for c in d.columns if str(c).startswith(\"Logclose_\")]\n",
        "        if not stock_cols:\n",
        "            if verbose: print(f\"‚ö†Ô∏è {sector}: no Logclose_ columns\")\n",
        "            continue\n",
        "\n",
        "        X_cols = [m for m in macro_vars if m in d.columns]\n",
        "        if not X_cols:\n",
        "            if verbose: print(f\"‚ö†Ô∏è {sector}: no macro columns found\")\n",
        "            continue\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"\\n===== üìÇ Sector: {sector} | stocks={len(stock_cols)} | macros={len(X_cols)} =====\")\n",
        "\n",
        "        d_train0 = d.loc[d.index <= pd.to_datetime(train_end)].copy()\n",
        "        if len(d_train0) < MIN_TRAIN:\n",
        "            if verbose: print(f\"‚ö†Ô∏è {sector}: not enough train rows ({len(d_train0)})\")\n",
        "            continue\n",
        "\n",
        "        for y_col in stock_cols:\n",
        "            ticker = y_col.replace(\"Logclose_\", \"\")\n",
        "            try:\n",
        "                y_train = d_train0[y_col].copy(); y_train.name = y_col\n",
        "                X_train = d_train0[X_cols].copy()\n",
        "\n",
        "                # 3 lag regimes (chosen on TRAIN only)\n",
        "                p_fix, q_fix, res_fix, ic_fix = select_pq_FIXED(\n",
        "                    y_train, X_train, p_fixed=P_FIXED, q_fixed=Q_FIXED,\n",
        "                    add_const=True, criterion=CRITERION\n",
        "                )\n",
        "                p_acf, q_acf, res_acf, ic_acf = select_pq_ACF(\n",
        "                    y_train, X_train, p_min=P_MIN, p_max=P_MAX, q_cap=Q_CAP,\n",
        "                    alpha=0.05, add_const=True, criterion=CRITERION\n",
        "                )\n",
        "                p_aic, q_aic, res_aic, ic_aic = select_pq_AIC_fast(\n",
        "                    y_train, X_train, p_min=P_MIN, p_max=P_MAX, q_max=Q_MAX_AIC,\n",
        "                    add_const=True, criterion=CRITERION\n",
        "                )\n",
        "\n",
        "                model_orders = [\n",
        "                    (\"FIXED\", p_fix, q_fix, res_fix, ic_fix),\n",
        "                    (\"ACF\",   p_acf, q_acf, res_acf, ic_acf),\n",
        "                    (\"AIC\",   p_aic, q_aic, res_aic, ic_aic),\n",
        "                ]\n",
        "\n",
        "                for model_name, p_sel, q_dict, res_train_fit, ic in model_orders:\n",
        "                    # ---------------------------\n",
        "                    # ‚úÖ 1) store alpha/beta/gamma from TRAIN fit\n",
        "                    # ---------------------------\n",
        "                    a_row, b_rows, g_rows = ecm_to_tables(\n",
        "                        ecm_fit=res_train_fit, y_col=y_col, x_cols=X_cols,\n",
        "                        model_name=model_name, sector=sector, ticker=ticker\n",
        "                    )\n",
        "                    alpha_list.append(a_row)\n",
        "                    beta_list.extend(b_rows)\n",
        "                    gamma_list.extend(g_rows)\n",
        "\n",
        "                    # ---------------------------\n",
        "                    # ‚úÖ 2) evaluate walk-forward\n",
        "                    # ---------------------------\n",
        "                    row = evaluate_ticker(\n",
        "                        df=d, ticker=ticker, y_col=y_col, x_cols=X_cols,\n",
        "                        p=p_sel, q_dict=q_dict,\n",
        "                        train_end=train_end, test_end=test_end,\n",
        "                        min_train=MIN_TRAIN,\n",
        "                        refit_every=REFIT_EVERY,\n",
        "                        max_test_points=MAX_TEST_POINTS\n",
        "                    )\n",
        "\n",
        "                    row[\"sector\"] = sector\n",
        "                    row[\"model\"] = model_name\n",
        "                    row[\"ticker\"] = ticker\n",
        "                    row[CRITERION] = float(ic)\n",
        "                    for m in X_cols:\n",
        "                        row[f\"q_{m}\"] = int(q_dict.get(m, 0))\n",
        "\n",
        "                    all_rows.append(row)\n",
        "\n",
        "                    orders_dump.append({\n",
        "                        \"sector\": sector, \"ticker\": ticker, \"model\": model_name,\n",
        "                        \"p\": int(p_sel),\n",
        "                        \"q_max\": int(max(q_dict.values()) if q_dict else 0),\n",
        "                        CRITERION: float(ic),\n",
        "                        **{f\"q_{m}\": int(q_dict.get(m, 0)) for m in X_cols}\n",
        "                    })\n",
        "\n",
        "                    if verbose:\n",
        "                        print(f\"‚úÖ {sector}-{ticker} [{model_name}] \"\n",
        "                              f\"RMSE: ECM={row['ECM_RMSE']:.6f} | AR={row['AR_RMSE']:.6f} | RW={row['RW_RMSE']:.6f}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                if verbose:\n",
        "                    print(f\"‚ö†Ô∏è {sector}-{ticker} failed: {e}\")\n",
        "                continue\n",
        "\n",
        "    if not all_rows:\n",
        "        raise RuntimeError(\"‚ùå No results produced (all failed).\")\n",
        "\n",
        "    res_df = pd.DataFrame(all_rows)\n",
        "    orders_df = pd.DataFrame(orders_dump)\n",
        "\n",
        "    df_alpha = pd.DataFrame(alpha_list)\n",
        "    df_beta  = pd.DataFrame(beta_list)\n",
        "    df_gamma = pd.DataFrame(gamma_list)\n",
        "\n",
        "    # nice ordering\n",
        "    front = [\"sector\",\"model\",\"ticker\",\"p\",\"q_max\",CRITERION,\n",
        "             \"ECM_MAE\",\"ECM_RMSE\",\"ECM_MAPE(%)\",\"ECM_n_test\",\n",
        "             \"AR_MAE\",\"AR_RMSE\",\"AR_MAPE(%)\",\"AR_n_test\",\n",
        "             \"RW_MAE\",\"RW_RMSE\",\"RW_MAPE(%)\",\"RW_n_test\",\n",
        "             \"DM(ECM-AR)\",\"pval(ECM-AR)\",\"DM(ECM-RW)\",\"pval(ECM-RW)\"]\n",
        "    cols = [c for c in front if c in res_df.columns] + [c for c in res_df.columns if c not in front]\n",
        "    res_df = res_df[cols].sort_values(by=[\"sector\",\"ticker\",\"model\",\"ECM_RMSE\"]).reset_index(drop=True)\n",
        "\n",
        "    if export_path:\n",
        "        with pd.ExcelWriter(export_path, engine=\"openpyxl\") as writer:\n",
        "            res_df.to_excel(writer, sheet_name=\"Results_All\", index=False)\n",
        "            orders_df.to_excel(writer, sheet_name=\"Chosen_Lags\", index=False)\n",
        "            df_alpha.to_excel(writer, sheet_name=\"Alpha\", index=False)\n",
        "            df_beta.to_excel(writer, sheet_name=\"Beta_LongRun\", index=False)\n",
        "            df_gamma.to_excel(writer, sheet_name=\"Gamma_ShortRun\", index=False)\n",
        "\n",
        "            for sector in sorted(res_df[\"sector\"].unique()):\n",
        "                tmp = res_df[res_df[\"sector\"] == sector].copy()\n",
        "                tmp.to_excel(writer, sheet_name=str(sector)[:31], index=False)\n",
        "\n",
        "        print(f\"\\n‚úÖ Exported ‚Üí {export_path}\")\n",
        "\n",
        "    return res_df, orders_df, df_alpha, df_beta, df_gamma\n",
        "\n",
        "# -----------------------------\n",
        "# RUN\n",
        "# -----------------------------\n",
        "res_all, lags_all, df_alpha, df_beta, df_gamma = run_all_sectors_3models(\n",
        "    sector_dfs=sector_dfs,\n",
        "    macro_vars=macro_vars,\n",
        "    train_end=TRAIN_END,\n",
        "    test_end=TEST_END,\n",
        "    export_path=EXPORT_PATH,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"\\n=== DONE ===\")\n",
        "display(res_all.head(30))\n",
        "display(lags_all.head(30))\n",
        "display(df_alpha.head(10))\n",
        "display(df_beta.head(10))\n",
        "display(df_gamma.head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpH9jpf15N6x"
      },
      "source": [
        "# Forecast Return from ARDL + ECM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "YDAjcIDp5NbX",
        "outputId": "2d851339-d968-4d90-84d5-c6e065006e47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ AMGN     | Sector=Healthcare           | Model=AIC   | Œî≈∂=-0.67152\n",
            "‚úÖ GILD     | Sector=Healthcare           | Model=AIC   | Œî≈∂=+3.06900\n",
            "‚úÖ VRTX     | Sector=Healthcare           | Model=AIC   | Œî≈∂=-7.09608\n",
            "‚úÖ REGN     | Sector=Healthcare           | Model=AIC   | Œî≈∂=-5.28529\n",
            "‚úÖ BIIB     | Sector=Healthcare           | Model=AIC   | Œî≈∂=+4.57720\n",
            "‚úÖ ILMN     | Sector=Healthcare           | Model=AIC   | Œî≈∂=+0.76058\n",
            "‚úÖ IDXX     | Sector=Healthcare           | Model=AIC   | Œî≈∂=-1.31541\n",
            "‚úÖ ISRG     | Sector=Healthcare           | Model=AIC   | Œî≈∂=+0.01916\n",
            "‚úÖ ALGN     | Sector=Healthcare           | Model=AIC   | Œî≈∂=-5.52500\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Stock      Sector Model  Pred_dLogclose  Expected_Return_% Signal\n",
              "0  AMGN  Healthcare   AIC       -0.671515         -67.151535   SELL\n",
              "1  GILD  Healthcare   AIC        3.068997         306.899657    BUY\n",
              "2  VRTX  Healthcare   AIC       -7.096076        -709.607629   SELL\n",
              "3  REGN  Healthcare   AIC       -5.285292        -528.529209   SELL\n",
              "4  BIIB  Healthcare   AIC        4.577202         457.720173    BUY\n",
              "5  ILMN  Healthcare   AIC        0.760578          76.057802    BUY\n",
              "6  IDXX  Healthcare   AIC       -1.315413        -131.541329   SELL\n",
              "7  ISRG  Healthcare   AIC        0.019159           1.915859    BUY\n",
              "8  ALGN  Healthcare   AIC       -5.525002        -552.500198   SELL"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a73b96aa-7445-4b6d-bbf4-654dcf748b29\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Stock</th>\n",
              "      <th>Sector</th>\n",
              "      <th>Model</th>\n",
              "      <th>Pred_dLogclose</th>\n",
              "      <th>Expected_Return_%</th>\n",
              "      <th>Signal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AMGN</td>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AIC</td>\n",
              "      <td>-0.671515</td>\n",
              "      <td>-67.151535</td>\n",
              "      <td>SELL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GILD</td>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AIC</td>\n",
              "      <td>3.068997</td>\n",
              "      <td>306.899657</td>\n",
              "      <td>BUY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>VRTX</td>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AIC</td>\n",
              "      <td>-7.096076</td>\n",
              "      <td>-709.607629</td>\n",
              "      <td>SELL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>REGN</td>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AIC</td>\n",
              "      <td>-5.285292</td>\n",
              "      <td>-528.529209</td>\n",
              "      <td>SELL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BIIB</td>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AIC</td>\n",
              "      <td>4.577202</td>\n",
              "      <td>457.720173</td>\n",
              "      <td>BUY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ILMN</td>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AIC</td>\n",
              "      <td>0.760578</td>\n",
              "      <td>76.057802</td>\n",
              "      <td>BUY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>IDXX</td>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AIC</td>\n",
              "      <td>-1.315413</td>\n",
              "      <td>-131.541329</td>\n",
              "      <td>SELL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ISRG</td>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AIC</td>\n",
              "      <td>0.019159</td>\n",
              "      <td>1.915859</td>\n",
              "      <td>BUY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ALGN</td>\n",
              "      <td>Healthcare</td>\n",
              "      <td>AIC</td>\n",
              "      <td>-5.525002</td>\n",
              "      <td>-552.500198</td>\n",
              "      <td>SELL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a73b96aa-7445-4b6d-bbf4-654dcf748b29')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a73b96aa-7445-4b6d-bbf4-654dcf748b29 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a73b96aa-7445-4b6d-bbf4-654dcf748b29');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_b228e57b-1bd6-4f93-ac9a-7c3336a7f017\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_forecast_summary')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b228e57b-1bd6-4f93-ac9a-7c3336a7f017 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_forecast_summary');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_forecast_summary",
              "summary": "{\n  \"name\": \"df_forecast_summary\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"Stock\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"ISRG\",\n          \"GILD\",\n          \"ILMN\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sector\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Healthcare\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"AIC\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pred_dLogclose\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.9895598894442017,\n        \"min\": -7.096076294444573,\n        \"max\": 4.577201731779127,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.019158587251811868\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Expected_Return_%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 398.95598894442014,\n        \"min\": -709.6076294444573,\n        \"max\": 457.72017317791267,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          1.9158587251811867\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Signal\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"BUY\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Exported ‚Üí Forecast_ARDL_ECM_NextMonth_Clean_AIC.xlsx\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# ============================================================\n",
        "# ‚úÖ Forecast next-month ŒîLogclose (ECM Full, Simplified)\n",
        "#   - ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ lagged Œî (D.Lk.) + ECT\n",
        "#   - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö df_alpha/df_beta/df_gamma ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Model\n",
        "#   - ‡πÑ‡∏°‡πà‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì/‡πÑ‡∏°‡πà‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ Logclose_next ‡πÅ‡∏•‡∏∞ Close_next\n",
        "# ============================================================\n",
        "\n",
        "def forecast_next_month_full(\n",
        "    stock_name, sector_name,\n",
        "    df_macro_levels,      # df ‡∏£‡∏∞‡∏î‡∏±‡∏ö (levels) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö X ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì ŒîX lag ‡πÅ‡∏•‡∏∞ ECT\n",
        "    df_gamma, df_alpha, df_beta,\n",
        "    combined_dfs_selective_diff,  # ‡πÉ‡∏ä‡πâ‡∏î‡∏∂‡∏á Logclose(series) ‡∏Ç‡∏≠‡∏á‡∏´‡∏∏‡πâ‡∏ô (‡∏£‡∏∞‡∏î‡∏±‡∏ö log)\n",
        "    model_name=\"AIC\",             # ‚úÖ NEW: \"AIC\" / \"ACF\" / \"FIXED\"\n",
        "    use_sector_filter=False       # ‚úÖ optional: ‡∏ñ‡πâ‡∏≤‡∏ä‡∏∑‡πà‡∏≠ ticker ‡∏ã‡πâ‡∏≥‡∏Ç‡πâ‡∏≤‡∏° sector ‡∏Ñ‡πà‡∏≠‡∏¢‡πÄ‡∏õ‡∏¥‡∏î True\n",
        "):\n",
        "    # -------------------------\n",
        "    # 0) Filter parameter tables\n",
        "    # -------------------------\n",
        "    if use_sector_filter and (\"Sector\" in df_gamma.columns) and (\"Sector\" in df_alpha.columns) and (\"Sector\" in df_beta.columns):\n",
        "        gtab = df_gamma[(df_gamma[\"Stock\"] == stock_name) & (df_gamma[\"Model\"] == model_name) & (df_gamma[\"Sector\"] == sector_name)].copy()\n",
        "        atab = df_alpha[(df_alpha[\"Stock\"] == stock_name) & (df_alpha[\"Model\"] == model_name) & (df_alpha[\"Sector\"] == sector_name)]\n",
        "        btab = df_beta[(df_beta[\"Stock\"] == stock_name) & (df_beta[\"Model\"] == model_name) & (df_beta[\"Sector\"] == sector_name)]\n",
        "    else:\n",
        "        gtab = df_gamma[(df_gamma[\"Stock\"] == stock_name) & (df_gamma[\"Model\"] == model_name)].copy()\n",
        "        atab = df_alpha[(df_alpha[\"Stock\"] == stock_name) & (df_alpha[\"Model\"] == model_name)]\n",
        "        btab = df_beta[(df_beta[\"Stock\"] == stock_name) & (df_beta[\"Model\"] == model_name)]\n",
        "\n",
        "    if gtab.empty or atab.empty or btab.empty:\n",
        "        return None\n",
        "\n",
        "    # -------------------------\n",
        "    # 1) Keep only lagged Œî terms + add ECT\n",
        "    # -------------------------\n",
        "    # ‚úÖ ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°: ‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞ D.Lk. (‡πÑ‡∏°‡πà‡πÄ‡∏≠‡∏≤ D.<macro> lag0)\n",
        "    gtab = gtab[gtab[\"Variable\"].astype(str).str.contains(r\"D\\.L\\d+\\.\", regex=True, na=False)].copy()\n",
        "\n",
        "    # ‚úÖ Add ECT_lag1 = alpha\n",
        "    alpha_val = float(atab[\"Alpha\"].iloc[0])\n",
        "    gtab = pd.concat(\n",
        "        [gtab, pd.DataFrame([{\"Variable\": \"ECT_lag1\", \"Coef\": alpha_val}])],\n",
        "        ignore_index=True\n",
        "    )\n",
        "\n",
        "    # -------------------------\n",
        "    # 2) Prepare stock log series\n",
        "    # -------------------------\n",
        "    df_stock = combined_dfs_selective_diff[sector_name][[f\"Logclose_{stock_name}\"]].copy()\n",
        "    df_stock.columns = [\"Logclose\"]\n",
        "\n",
        "    # -------------------------\n",
        "    # 3) Align macro levels to stock index\n",
        "    # -------------------------\n",
        "    df_macro_aligned = df_macro_levels.reindex(df_stock.index).ffill().copy()\n",
        "\n",
        "    # -------------------------\n",
        "    # 4) Long-run coefficients for ECT\n",
        "    # -------------------------\n",
        "    lr_params = btab.drop_duplicates(subset=\"Variable\").set_index(\"Variable\")[\"coef\"]\n",
        "\n",
        "    # ‡πÉ‡∏ä‡πâ 3 ‡πÅ‡∏ñ‡∏ß‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Œî ‡πÅ‡∏•‡∏∞ lag (‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö L1 / L2)\n",
        "    last_row = df_macro_aligned.tail(3).copy()\n",
        "    deltas = {}\n",
        "\n",
        "    # -------------------------\n",
        "    # 5) Compute Œî lag and ECT\n",
        "    # -------------------------\n",
        "    for var in gtab[\"Variable\"].astype(str).tolist():\n",
        "        if var == \"ECT_lag1\":\n",
        "            const = float(lr_params.get(\"const\", 0.0))\n",
        "            X_lag = {\n",
        "                k: float(last_row[k].iloc[-2])\n",
        "                for k in lr_params.index\n",
        "                if k != \"const\" and k in last_row.columns\n",
        "            }\n",
        "            Y_lag = float(df_stock[\"Logclose\"].iloc[-2])\n",
        "            ect_val = Y_lag - (const + sum(float(lr_params[k]) * X_lag[k] for k in X_lag))\n",
        "            deltas[var] = float(ect_val)\n",
        "            continue\n",
        "\n",
        "        # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠: \"D.L1.inflation_rate\" ‡∏´‡∏£‡∏∑‡∏≠ \"D.L1.Logclose_XYZ\"\n",
        "        parts = var.split(\".\")\n",
        "        if len(parts) < 3:\n",
        "            continue\n",
        "        lag = int(parts[1].replace(\"L\", \"\"))   # L1 -> 1\n",
        "        base = parts[2]\n",
        "\n",
        "        # ŒîY lag (Logclose)\n",
        "        if base.startswith(\"Logclose_\"):\n",
        "            stock_base = base.replace(\"Logclose_\", \"\")\n",
        "            if stock_base != stock_name:\n",
        "                continue\n",
        "\n",
        "            # ŒîY_{t-lag} = logY_{t-lag} - logY_{t-lag-1}\n",
        "            if len(df_stock) > lag + 1:\n",
        "                dy = float(df_stock[\"Logclose\"].iloc[-lag]) - float(df_stock[\"Logclose\"].iloc[-(lag + 1)])\n",
        "            else:\n",
        "                dy = 0.0\n",
        "            deltas[var] = dy\n",
        "\n",
        "        # ŒîX lag (macro levels)\n",
        "        else:\n",
        "            if base in df_macro_aligned.columns and len(last_row) > lag + 1:\n",
        "                dx = float(last_row[base].iloc[-lag]) - float(last_row[base].iloc[-(lag + 1)])\n",
        "            else:\n",
        "                dx = 0.0\n",
        "            deltas[var] = dx\n",
        "\n",
        "    # -------------------------\n",
        "    # 6) Sum contributions -> Pred Œîlogclose\n",
        "    # -------------------------\n",
        "    df_pred = pd.DataFrame(list(deltas.items()), columns=[\"Variable\", \"Value\"])\n",
        "    merged = pd.merge(gtab[[\"Variable\", \"Coef\"]], df_pred, on=\"Variable\", how=\"left\")\n",
        "    merged[\"Value\"] = merged[\"Value\"].fillna(0.0)\n",
        "    merged[\"Contribution\"] = merged[\"Coef\"].astype(float) * merged[\"Value\"].astype(float)\n",
        "\n",
        "    pred_dy = float(merged[\"Contribution\"].sum())\n",
        "\n",
        "    return {\n",
        "        \"Stock\": stock_name,\n",
        "        \"Sector\": sector_name,\n",
        "        \"Model\": model_name,\n",
        "        \"Pred_dLogclose\": pred_dy,\n",
        "        \"Details\": merged\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# üöÄ Run for ALL stocks (Clean Output)\n",
        "#   ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏° model_name ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏≤‡∏Å‡πÉ‡∏ä‡πâ\n",
        "# ============================================================\n",
        "\n",
        "MODEL_TO_FORECAST = \"AIC\"   # \"AIC\" / \"ACF\" / \"FIXED\"\n",
        "USE_SECTOR_FILTER = False  # ‡∏ñ‡πâ‡∏≤ ticker ‡∏ã‡πâ‡∏≥‡∏Ç‡πâ‡∏≤‡∏° sector ‡∏Ñ‡πà‡∏≠‡∏¢‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô True\n",
        "\n",
        "forecast_results = []\n",
        "\n",
        "for sector_name, df_sec in combined_dfs_selective_diff.items():\n",
        "    for col in df_sec.columns:\n",
        "        if not str(col).startswith(\"Logclose_\"):\n",
        "            continue\n",
        "\n",
        "        stock_name = col.replace(\"Logclose_\", \"\")\n",
        "\n",
        "        try:\n",
        "            res = forecast_next_month_full(\n",
        "                stock_name=stock_name,\n",
        "                sector_name=sector_name,\n",
        "                df_macro_levels=df,  # levels macro\n",
        "                df_gamma=df_gamma, df_alpha=df_alpha, df_beta=df_beta,\n",
        "                combined_dfs_selective_diff=combined_dfs_selective_diff,\n",
        "                model_name=MODEL_TO_FORECAST,\n",
        "                use_sector_filter=USE_SECTOR_FILTER\n",
        "            )\n",
        "            if res is not None:\n",
        "                forecast_results.append({\n",
        "                    \"Stock\": res[\"Stock\"],\n",
        "                    \"Sector\": res[\"Sector\"],\n",
        "                    \"Model\": res[\"Model\"],\n",
        "                    \"Pred_dLogclose\": res[\"Pred_dLogclose\"],\n",
        "                })\n",
        "                print(f\"‚úÖ {stock_name:<8} | Sector={sector_name:<20} | Model={MODEL_TO_FORECAST:<5} | Œî≈∂={res['Pred_dLogclose']:+.5f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è {stock_name} failed: {e}\")\n",
        "\n",
        "df_forecast_summary = pd.DataFrame(forecast_results)\n",
        "if not df_forecast_summary.empty:\n",
        "    df_forecast_summary[\"Expected_Return_%\"] = df_forecast_summary[\"Pred_dLogclose\"] * 100.0\n",
        "    df_forecast_summary[\"Signal\"] = np.where(df_forecast_summary[\"Pred_dLogclose\"] > 0, \"BUY\", \"SELL\")\n",
        "\n",
        "display(df_forecast_summary)\n",
        "\n",
        "OUT_NAME = f\"Forecast_ARDL_ECM_NextMonth_Clean_{MODEL_TO_FORECAST}.xlsx\"\n",
        "df_forecast_summary.to_excel(OUT_NAME, index=False)\n",
        "print(f\"\\n‚úÖ Exported ‚Üí {OUT_NAME}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzlO7rCf_-Q9"
      },
      "source": [
        "# Technical Indicators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1C8fkZTfC9iA",
        "outputId": "5282af1e-de56-4a5c-8e89-d98d55462657"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ta\n",
            "  Downloading ta-0.11.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from ta) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from ta) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->ta) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->ta) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->ta) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->ta) (1.17.0)\n",
            "Building wheels for collected packages: ta\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta: filename=ta-0.11.0-py3-none-any.whl size=29412 sha256=1a7953cb45856b92f68d4cb3d18a9f5a7bd7b1444d6d561ccdda181fe54e921c\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/a1/5f/c6b85a7d9452057be4ce68a8e45d77ba34234a6d46581777c6\n",
            "Successfully built ta\n",
            "Installing collected packages: ta\n",
            "Successfully installed ta-0.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install ta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6yzCB4C_-X8",
        "outputId": "2fba1943-f947-4f79-e442-c1ac2207aa66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "üìä BLOCK 2 ENHANCED: Advanced Technical Features\n",
            "======================================================================\n",
            "\n",
            "    Features:\n",
            "    1. Market Regime Detector (Bull/Bear/Sideways)\n",
            "    2. Volatility Regime (High/Normal/Low)\n",
            "    3. Pattern Detection (20 Patterns)\n",
            "    4. Sector Rotation Score\n",
            "    5. Proxy Sentiment (Fear/Greed Index)\n",
            "\n",
            "    NO LLM / NO FinBERT - Pure Technical Analysis\n",
            "    \n",
            "======================================================================\n",
            "\n",
            "üè¢ Processing Sector: Healthcare\n",
            "--------------------------------------------------\n",
            "   üì• Downloading AMGN ...\n",
            "   ‚úÖ AMGN processed: 2765 rows\n",
            "   üì• Downloading GILD ...\n",
            "   ‚úÖ GILD processed: 2765 rows\n",
            "   üì• Downloading VRTX ...\n",
            "   ‚úÖ VRTX processed: 2765 rows\n",
            "   üì• Downloading REGN ...\n",
            "   ‚úÖ REGN processed: 2765 rows\n",
            "   üì• Downloading BIIB ...\n",
            "   ‚úÖ BIIB processed: 2765 rows\n",
            "   üì• Downloading ILMN ...\n",
            "   ‚úÖ ILMN processed: 2765 rows\n",
            "   üì• Downloading IDXX ...\n",
            "   ‚úÖ IDXX processed: 2765 rows\n",
            "   üì• Downloading ISRG ...\n",
            "   ‚úÖ ISRG processed: 2765 rows\n",
            "   üì• Downloading ALGN ...\n",
            "   ‚úÖ ALGN processed: 2765 rows\n",
            "\n",
            "üìä Calculating Sector Features...\n",
            "\n",
            "======================================================================\n",
            "üìä SUMMARY\n",
            "======================================================================\n",
            "‚úÖ Total Stocks: 9\n",
            "‚úÖ Total Sectors: 1\n",
            "‚úÖ Total Rows: 24,885\n",
            "‚úÖ Date Range: 2015-01-02 00:00:00 to 2025-12-30 00:00:00\n",
            "\n",
            "üíæ Saved to: Block2_Enhanced_Features.xlsx\n",
            "\n",
            "üìà Sample Output (Last 5 rows of AMGN):\n",
            "      Date      Close Market_Regime  Regime_Score Volatility_Regime         Pattern_Type  Pattern_Confidence  Fear_Greed_Index Fear_Greed_Label  Sector_Momentum\n",
            "2025-12-23 331.489990      Sideways           1.0            Normal           Double_Top            0.564751         57.240738            Greed         0.077042\n",
            "2025-12-24 333.959991      Sideways           1.0            Normal           Double_Top            0.564751         57.577751            Greed         0.068281\n",
            "2025-12-26 332.929993      Sideways           1.0            Normal Symmetrical_Triangle            1.000000         57.709157            Greed         0.061182\n",
            "2025-12-29 329.630005      Sideways           1.0            Normal Symmetrical_Triangle            1.000000         58.084288            Greed         0.051494\n",
            "2025-12-30 328.690002          Bull           2.0            Normal Symmetrical_Triangle            1.000000         62.019817            Greed         0.043319\n",
            "\n",
            "üìã All Columns:\n",
            "['Date', 'Close', 'High', 'Low', 'Open', 'Volume', 'Stock', 'Sector', 'Market_Regime', 'Regime_Score', 'ADX', 'Volatility_Regime', 'Volatility_Score', 'Historical_Volatility', 'ATR', 'Pattern_Type', 'Pattern_Confidence', 'Pattern_Signal', 'Volume_Sentiment', 'Momentum_Sentiment', 'Fear_Greed_Index', 'Fear_Greed_Label', 'RSI', 'MACD', 'MACD_Signal', 'EMA_12', 'EMA_26', 'SMA_50', 'SMA_200', 'BB_Upper', 'BB_Lower', 'BB_Width', 'Sector_Momentum']\n",
            "\n",
            "======================================================================\n",
            "‚úÖ BLOCK 2 ENHANCED COMPLETED!\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# üìä BLOCK 2 ENHANCED: Advanced Technical Features\n",
        "#    Features:\n",
        "#    1. Market Regime Detector (Bull/Bear/Sideways)\n",
        "#    2. Volatility Regime (High/Normal/Low)\n",
        "#    3. Pattern Detection (20 Patterns from TradingView)\n",
        "#    4. Sector Rotation Score\n",
        "#    5. Proxy Sentiment (Foreign Flow, Market Breadth)\n",
        "#\n",
        "#    NO LLM / NO FinBERT - Pure Technical Analysis\n",
        "# ============================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from scipy.signal import argrelextrema\n",
        "from scipy.stats import linregress\n",
        "import ta\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ============================================================\n",
        "# 1. CONFIGURATION\n",
        "# ============================================================\n",
        "\n",
        "SECTORS = {\n",
        "    \"Healthcare\": [\"AMGN\",\"GILD\",\"VRTX\",\"REGN\",\"BIIB\",\"ILMN\",\"IDXX\",\"ISRG\",\"ALGN\"]\n",
        "}\n",
        "\n",
        "\n",
        "ALL_STOCKS = [stock for stocks in SECTORS.values() for stock in stocks]\n",
        "\n",
        "START_DATE = \"2015-01-01\"\n",
        "END_DATE = \"2025-12-31\"\n",
        "\n",
        "# ============================================================\n",
        "# 2. MARKET REGIME DETECTOR\n",
        "# ============================================================\n",
        "\n",
        "class MarketRegimeDetector:\n",
        "    \"\"\"\n",
        "    Detect Market Regime: Bull / Bear / Sideways\n",
        "\n",
        "    Methods:\n",
        "    - SMA Crossover (50/200)\n",
        "    - ADX Trend Strength\n",
        "    - Price vs Moving Average\n",
        "    - Higher Highs / Lower Lows\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def detect_regime_sma(close, short_window=50, long_window=200):\n",
        "        \"\"\"\n",
        "        SMA Crossover Method\n",
        "        - Bull: SMA50 > SMA200\n",
        "        - Bear: SMA50 < SMA200\n",
        "        \"\"\"\n",
        "        sma_short = close.rolling(window=short_window).mean()\n",
        "        sma_long = close.rolling(window=long_window).mean()\n",
        "\n",
        "        regime = pd.Series(index=close.index, dtype='object')\n",
        "        regime[sma_short > sma_long] = 'Bull'\n",
        "        regime[sma_short < sma_long] = 'Bear'\n",
        "        regime[sma_short == sma_long] = 'Sideways'\n",
        "\n",
        "        return regime\n",
        "\n",
        "    @staticmethod\n",
        "    def detect_regime_adx(high, low, close, window=14, trend_threshold=25):\n",
        "        \"\"\"\n",
        "        ADX Method\n",
        "        - Trending (Bull/Bear): ADX > 25\n",
        "        - Sideways: ADX < 25\n",
        "        \"\"\"\n",
        "        adx = ta.trend.adx(high, low, close, window=window)\n",
        "        plus_di = ta.trend.adx_pos(high, low, close, window=window)\n",
        "        minus_di = ta.trend.adx_neg(high, low, close, window=window)\n",
        "\n",
        "        regime = pd.Series(index=close.index, dtype='object')\n",
        "\n",
        "        # Trending\n",
        "        trending = adx > trend_threshold\n",
        "        regime[trending & (plus_di > minus_di)] = 'Bull'\n",
        "        regime[trending & (plus_di < minus_di)] = 'Bear'\n",
        "\n",
        "        # Sideways\n",
        "        regime[adx <= trend_threshold] = 'Sideways'\n",
        "\n",
        "        return regime, adx\n",
        "\n",
        "    @staticmethod\n",
        "    def detect_regime_combined(high, low, close, volume):\n",
        "        \"\"\"\n",
        "        Combined Method (Most Robust)\n",
        "        - Uses multiple signals for confirmation\n",
        "        \"\"\"\n",
        "        # Method 1: SMA\n",
        "        regime_sma = MarketRegimeDetector.detect_regime_sma(close)\n",
        "\n",
        "        # Method 2: ADX\n",
        "        regime_adx, adx = MarketRegimeDetector.detect_regime_adx(high, low, close)\n",
        "\n",
        "        # Method 3: Price vs SMA200\n",
        "        sma200 = close.rolling(200).mean()\n",
        "        price_above_sma = close > sma200\n",
        "\n",
        "        # Method 4: Trend Strength (linear regression slope)\n",
        "        def calc_slope(series, window=20):\n",
        "            slopes = pd.Series(index=series.index, dtype=float)\n",
        "            for i in range(window, len(series)):\n",
        "                y = series.iloc[i-window:i].values\n",
        "                x = np.arange(window)\n",
        "                slope, _, _, _, _ = linregress(x, y)\n",
        "                slopes.iloc[i] = slope\n",
        "            return slopes\n",
        "\n",
        "        price_slope = calc_slope(close, 20)\n",
        "        price_slope_normalized = price_slope / close * 100  # Normalize by price\n",
        "\n",
        "        # Combine signals\n",
        "        regime_combined = pd.Series(index=close.index, dtype='object')\n",
        "        regime_score = pd.Series(index=close.index, dtype=float)\n",
        "\n",
        "        for i in range(len(close)):\n",
        "            score = 0\n",
        "\n",
        "            # SMA signal\n",
        "            if regime_sma.iloc[i] == 'Bull':\n",
        "                score += 1\n",
        "            elif regime_sma.iloc[i] == 'Bear':\n",
        "                score -= 1\n",
        "\n",
        "            # ADX signal\n",
        "            if regime_adx.iloc[i] == 'Bull':\n",
        "                score += 1\n",
        "            elif regime_adx.iloc[i] == 'Bear':\n",
        "                score -= 1\n",
        "\n",
        "            # Price vs SMA200\n",
        "            if i >= 200:\n",
        "                if price_above_sma.iloc[i]:\n",
        "                    score += 1\n",
        "                else:\n",
        "                    score -= 1\n",
        "\n",
        "            # Slope signal\n",
        "            if pd.notna(price_slope_normalized.iloc[i]):\n",
        "                if price_slope_normalized.iloc[i] > 0.1:\n",
        "                    score += 1\n",
        "                elif price_slope_normalized.iloc[i] < -0.1:\n",
        "                    score -= 1\n",
        "\n",
        "            regime_score.iloc[i] = score\n",
        "\n",
        "            # Determine regime\n",
        "            if score >= 2:\n",
        "                regime_combined.iloc[i] = 'Bull'\n",
        "            elif score <= -2:\n",
        "                regime_combined.iloc[i] = 'Bear'\n",
        "            else:\n",
        "                regime_combined.iloc[i] = 'Sideways'\n",
        "\n",
        "        return regime_combined, regime_score, adx\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 3. VOLATILITY REGIME DETECTOR\n",
        "# ============================================================\n",
        "\n",
        "class VolatilityRegimeDetector:\n",
        "    \"\"\"\n",
        "    Detect Volatility Regime: High / Normal / Low\n",
        "\n",
        "    Methods:\n",
        "    - Historical Volatility (Rolling Std)\n",
        "    - ATR Percentile\n",
        "    - Bollinger Band Width\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_historical_volatility(close, window=20):\n",
        "        \"\"\"Calculate annualized historical volatility\"\"\"\n",
        "        returns = np.log(close / close.shift(1))\n",
        "        vol = returns.rolling(window=window).std() * np.sqrt(252)\n",
        "        return vol\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_atr_percentile(high, low, close, window=14, lookback=252):\n",
        "        \"\"\"Calculate ATR and its percentile ranking\"\"\"\n",
        "        atr = ta.volatility.average_true_range(high, low, close, window=window)\n",
        "\n",
        "        # Percentile rank over lookback period\n",
        "        atr_percentile = atr.rolling(window=lookback).apply(\n",
        "            lambda x: pd.Series(x).rank(pct=True).iloc[-1] * 100\n",
        "        )\n",
        "\n",
        "        return atr, atr_percentile\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_bb_width(close, window=20, std_dev=2):\n",
        "        \"\"\"Calculate Bollinger Band Width\"\"\"\n",
        "        bb = ta.volatility.BollingerBands(close, window=window, window_dev=std_dev)\n",
        "        bb_width = (bb.bollinger_hband() - bb.bollinger_lband()) / bb.bollinger_mavg()\n",
        "        return bb_width\n",
        "\n",
        "    @staticmethod\n",
        "    def detect_volatility_regime(high, low, close,\n",
        "                                  low_threshold=30, high_threshold=70):\n",
        "        \"\"\"\n",
        "        Detect Volatility Regime\n",
        "\n",
        "        Returns:\n",
        "        - regime: 'High', 'Normal', 'Low'\n",
        "        - vol_score: 0-100 percentile\n",
        "        \"\"\"\n",
        "        # Calculate metrics\n",
        "        hist_vol = VolatilityRegimeDetector.calculate_historical_volatility(close)\n",
        "        atr, atr_pct = VolatilityRegimeDetector.calculate_atr_percentile(high, low, close)\n",
        "        bb_width = VolatilityRegimeDetector.calculate_bb_width(close)\n",
        "\n",
        "        # Normalize BB Width to percentile\n",
        "        bb_pct = bb_width.rolling(window=252).apply(\n",
        "            lambda x: pd.Series(x).rank(pct=True).iloc[-1] * 100\n",
        "        )\n",
        "\n",
        "        # Combine scores (average of percentiles)\n",
        "        vol_score = (atr_pct.fillna(50) + bb_pct.fillna(50)) / 2\n",
        "\n",
        "        # Determine regime\n",
        "        regime = pd.Series(index=close.index, dtype='object')\n",
        "        regime[vol_score >= high_threshold] = 'High'\n",
        "        regime[vol_score <= low_threshold] = 'Low'\n",
        "        regime[(vol_score > low_threshold) & (vol_score < high_threshold)] = 'Normal'\n",
        "\n",
        "        return regime, vol_score, hist_vol, atr\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 4. PATTERN DETECTOR (20 Patterns)\n",
        "# ============================================================\n",
        "\n",
        "class PatternDetector:\n",
        "    \"\"\"\n",
        "    Detect 20 Trading Patterns from TradingView Cheat Sheet\n",
        "\n",
        "    Categories:\n",
        "    - CONTINUATION: Pennant, Megaphone, Bearish Flag, Bullish Flag, Channel\n",
        "    - NEUTRAL: Symmetrical Triangle, Descending Triangle, Ascending Triangle\n",
        "    - REVERSAL: Diamond, Double Top, Double Bottom, Head & Shoulders,\n",
        "                Inverse H&S, Cup and Handle\n",
        "    - SPECIAL: Descending Wedge, Ascending Wedge, Gartley, Cypher\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, lookback=60, order=5):\n",
        "        self.lookback = lookback\n",
        "        self.order = order  # For finding local extrema\n",
        "\n",
        "    def find_pivots(self, high, low, close):\n",
        "        \"\"\"Find pivot highs and lows\"\"\"\n",
        "        pivot_highs = argrelextrema(high.values, np.greater, order=self.order)[0]\n",
        "        pivot_lows = argrelextrema(low.values, np.less, order=self.order)[0]\n",
        "        return pivot_highs, pivot_lows\n",
        "\n",
        "    def detect_double_top(self, high, close, pivot_highs, tolerance=0.02):\n",
        "        \"\"\"\n",
        "        Double Top Pattern (Reversal - Bearish)\n",
        "        - Two peaks at similar levels\n",
        "        - Valley between peaks\n",
        "        \"\"\"\n",
        "        if len(pivot_highs) < 2:\n",
        "            return 0.0, None\n",
        "\n",
        "        # Get last two peaks\n",
        "        peak1_idx = pivot_highs[-2]\n",
        "        peak2_idx = pivot_highs[-1]\n",
        "        peak1_val = high.iloc[peak1_idx]\n",
        "        peak2_val = high.iloc[peak2_idx]\n",
        "\n",
        "        # Check if peaks are at similar levels\n",
        "        diff = abs(peak1_val - peak2_val) / peak1_val\n",
        "\n",
        "        if diff <= tolerance:\n",
        "            confidence = 1 - diff / tolerance\n",
        "            return confidence, {'type': 'Double_Top', 'signal': 'Bearish'}\n",
        "\n",
        "        return 0.0, None\n",
        "\n",
        "    def detect_double_bottom(self, low, close, pivot_lows, tolerance=0.02):\n",
        "        \"\"\"\n",
        "        Double Bottom Pattern (Reversal - Bullish)\n",
        "        - Two troughs at similar levels\n",
        "        - Peak between troughs\n",
        "        \"\"\"\n",
        "        if len(pivot_lows) < 2:\n",
        "            return 0.0, None\n",
        "\n",
        "        # Get last two troughs\n",
        "        trough1_idx = pivot_lows[-2]\n",
        "        trough2_idx = pivot_lows[-1]\n",
        "        trough1_val = low.iloc[trough1_idx]\n",
        "        trough2_val = low.iloc[trough2_idx]\n",
        "\n",
        "        # Check if troughs are at similar levels\n",
        "        diff = abs(trough1_val - trough2_val) / trough1_val\n",
        "\n",
        "        if diff <= tolerance:\n",
        "            confidence = 1 - diff / tolerance\n",
        "            return confidence, {'type': 'Double_Bottom', 'signal': 'Bullish'}\n",
        "\n",
        "        return 0.0, None\n",
        "\n",
        "    def detect_head_and_shoulders(self, high, pivot_highs, tolerance=0.03):\n",
        "        \"\"\"\n",
        "        Head and Shoulders Pattern (Reversal - Bearish)\n",
        "        - Three peaks: middle (head) higher than two sides (shoulders)\n",
        "        - Shoulders at similar levels\n",
        "        \"\"\"\n",
        "        if len(pivot_highs) < 3:\n",
        "            return 0.0, None\n",
        "\n",
        "        # Get last three peaks\n",
        "        left_idx = pivot_highs[-3]\n",
        "        head_idx = pivot_highs[-2]\n",
        "        right_idx = pivot_highs[-1]\n",
        "\n",
        "        left_val = high.iloc[left_idx]\n",
        "        head_val = high.iloc[head_idx]\n",
        "        right_val = high.iloc[right_idx]\n",
        "\n",
        "        # Check pattern conditions\n",
        "        # Head should be higher than shoulders\n",
        "        if head_val > left_val and head_val > right_val:\n",
        "            # Shoulders should be at similar levels\n",
        "            shoulder_diff = abs(left_val - right_val) / left_val\n",
        "\n",
        "            if shoulder_diff <= tolerance:\n",
        "                head_prominence = (head_val - max(left_val, right_val)) / head_val\n",
        "                confidence = min(1.0, head_prominence * 10) * (1 - shoulder_diff / tolerance)\n",
        "                return confidence, {'type': 'Head_Shoulders', 'signal': 'Bearish'}\n",
        "\n",
        "        return 0.0, None\n",
        "\n",
        "    def detect_inverse_head_and_shoulders(self, low, pivot_lows, tolerance=0.03):\n",
        "        \"\"\"\n",
        "        Inverse Head and Shoulders Pattern (Reversal - Bullish)\n",
        "        \"\"\"\n",
        "        if len(pivot_lows) < 3:\n",
        "            return 0.0, None\n",
        "\n",
        "        left_idx = pivot_lows[-3]\n",
        "        head_idx = pivot_lows[-2]\n",
        "        right_idx = pivot_lows[-1]\n",
        "\n",
        "        left_val = low.iloc[left_idx]\n",
        "        head_val = low.iloc[head_idx]\n",
        "        right_val = low.iloc[right_idx]\n",
        "\n",
        "        if head_val < left_val and head_val < right_val:\n",
        "            shoulder_diff = abs(left_val - right_val) / left_val\n",
        "\n",
        "            if shoulder_diff <= tolerance:\n",
        "                head_prominence = (min(left_val, right_val) - head_val) / head_val\n",
        "                confidence = min(1.0, head_prominence * 10) * (1 - shoulder_diff / tolerance)\n",
        "                return confidence, {'type': 'Inverse_Head_Shoulders', 'signal': 'Bullish'}\n",
        "\n",
        "        return 0.0, None\n",
        "\n",
        "    def detect_triangle(self, high, low, pivot_highs, pivot_lows, window=20):\n",
        "        \"\"\"\n",
        "        Triangle Patterns (Neutral - wait for breakout)\n",
        "        - Symmetrical: converging trendlines\n",
        "        - Ascending: flat top, rising bottom\n",
        "        - Descending: falling top, flat bottom\n",
        "        \"\"\"\n",
        "        if len(pivot_highs) < 2 or len(pivot_lows) < 2:\n",
        "            return 0.0, None, None\n",
        "\n",
        "        # Get recent pivots\n",
        "        recent_highs = pivot_highs[-3:] if len(pivot_highs) >= 3 else pivot_highs\n",
        "        recent_lows = pivot_lows[-3:] if len(pivot_lows) >= 3 else pivot_lows\n",
        "\n",
        "        # Calculate slopes of trendlines\n",
        "        if len(recent_highs) >= 2:\n",
        "            high_vals = [high.iloc[i] for i in recent_highs]\n",
        "            high_slope = (high_vals[-1] - high_vals[0]) / (recent_highs[-1] - recent_highs[0] + 1)\n",
        "        else:\n",
        "            high_slope = 0\n",
        "\n",
        "        if len(recent_lows) >= 2:\n",
        "            low_vals = [low.iloc[i] for i in recent_lows]\n",
        "            low_slope = (low_vals[-1] - low_vals[0]) / (recent_lows[-1] - recent_lows[0] + 1)\n",
        "        else:\n",
        "            low_slope = 0\n",
        "\n",
        "        # Normalize slopes\n",
        "        avg_price = (high.iloc[-1] + low.iloc[-1]) / 2\n",
        "        high_slope_norm = high_slope / avg_price * 100\n",
        "        low_slope_norm = low_slope / avg_price * 100\n",
        "\n",
        "        # Detect triangle type\n",
        "        if high_slope_norm < -0.01 and low_slope_norm > 0.01:\n",
        "            # Symmetrical Triangle\n",
        "            convergence = abs(high_slope_norm) + abs(low_slope_norm)\n",
        "            confidence = min(1.0, convergence * 10)\n",
        "            return confidence, 'Symmetrical_Triangle', 'Neutral'\n",
        "\n",
        "        elif abs(high_slope_norm) < 0.01 and low_slope_norm > 0.01:\n",
        "            # Ascending Triangle (Bullish)\n",
        "            confidence = min(1.0, abs(low_slope_norm) * 20)\n",
        "            return confidence, 'Ascending_Triangle', 'Bullish'\n",
        "\n",
        "        elif high_slope_norm < -0.01 and abs(low_slope_norm) < 0.01:\n",
        "            # Descending Triangle (Bearish)\n",
        "            confidence = min(1.0, abs(high_slope_norm) * 20)\n",
        "            return confidence, 'Descending_Triangle', 'Bearish'\n",
        "\n",
        "        return 0.0, None, None\n",
        "\n",
        "    def detect_flag(self, high, low, close, pivot_highs, pivot_lows, window=30):\n",
        "        \"\"\"\n",
        "        Flag Patterns (Continuation)\n",
        "        - Bullish Flag: Strong up move, then small downward channel\n",
        "        - Bearish Flag: Strong down move, then small upward channel\n",
        "        \"\"\"\n",
        "        if len(close) < window:\n",
        "            return 0.0, None\n",
        "\n",
        "        # Check for prior strong move (pole)\n",
        "        pole_period = close.iloc[-window:-window//2]\n",
        "        flag_period = close.iloc[-window//2:]\n",
        "\n",
        "        pole_return = (pole_period.iloc[-1] - pole_period.iloc[0]) / pole_period.iloc[0]\n",
        "        flag_return = (flag_period.iloc[-1] - flag_period.iloc[0]) / flag_period.iloc[0]\n",
        "\n",
        "        # Bullish Flag: Strong up pole, slight down flag\n",
        "        if pole_return > 0.05 and -0.03 < flag_return < 0:\n",
        "            confidence = min(1.0, pole_return * 5)\n",
        "            return confidence, {'type': 'Bullish_Flag', 'signal': 'Bullish'}\n",
        "\n",
        "        # Bearish Flag: Strong down pole, slight up flag\n",
        "        if pole_return < -0.05 and 0 < flag_return < 0.03:\n",
        "            confidence = min(1.0, abs(pole_return) * 5)\n",
        "            return confidence, {'type': 'Bearish_Flag', 'signal': 'Bearish'}\n",
        "\n",
        "        return 0.0, None\n",
        "\n",
        "    def detect_wedge(self, high, low, pivot_highs, pivot_lows):\n",
        "        \"\"\"\n",
        "        Wedge Patterns (Special)\n",
        "        - Rising Wedge: Both trendlines rising, converging (Bearish)\n",
        "        - Falling Wedge: Both trendlines falling, converging (Bullish)\n",
        "        \"\"\"\n",
        "        if len(pivot_highs) < 2 or len(pivot_lows) < 2:\n",
        "            return 0.0, None\n",
        "\n",
        "        # Calculate slopes\n",
        "        high_vals = [high.iloc[i] for i in pivot_highs[-3:]]\n",
        "        low_vals = [low.iloc[i] for i in pivot_lows[-3:]]\n",
        "\n",
        "        if len(high_vals) >= 2 and len(low_vals) >= 2:\n",
        "            high_slope = high_vals[-1] - high_vals[0]\n",
        "            low_slope = low_vals[-1] - low_vals[0]\n",
        "\n",
        "            # Rising Wedge (Bearish)\n",
        "            if high_slope > 0 and low_slope > 0 and high_slope < low_slope:\n",
        "                confidence = min(1.0, (low_slope - high_slope) / abs(high_slope + 0.001) * 2)\n",
        "                return confidence, {'type': 'Rising_Wedge', 'signal': 'Bearish'}\n",
        "\n",
        "            # Falling Wedge (Bullish)\n",
        "            if high_slope < 0 and low_slope < 0 and high_slope > low_slope:\n",
        "                confidence = min(1.0, (high_slope - low_slope) / abs(low_slope + 0.001) * 2)\n",
        "                return confidence, {'type': 'Falling_Wedge', 'signal': 'Bullish'}\n",
        "\n",
        "        return 0.0, None\n",
        "\n",
        "    def detect_channel(self, high, low, pivot_highs, pivot_lows, tolerance=0.02):\n",
        "        \"\"\"\n",
        "        Channel Pattern (Continuation)\n",
        "        - Parallel trendlines\n",
        "        \"\"\"\n",
        "        if len(pivot_highs) < 2 or len(pivot_lows) < 2:\n",
        "            return 0.0, None\n",
        "\n",
        "        # Calculate slopes\n",
        "        high_indices = pivot_highs[-3:]\n",
        "        low_indices = pivot_lows[-3:]\n",
        "\n",
        "        high_vals = [high.iloc[i] for i in high_indices]\n",
        "        low_vals = [low.iloc[i] for i in low_indices]\n",
        "\n",
        "        if len(high_vals) >= 2 and len(low_vals) >= 2:\n",
        "            # Linear regression for trendlines\n",
        "            high_slope, high_intercept, _, _, _ = linregress(high_indices, high_vals)\n",
        "            low_slope, low_intercept, _, _, _ = linregress(low_indices, low_vals)\n",
        "\n",
        "            # Check if parallel (similar slopes)\n",
        "            slope_diff = abs(high_slope - low_slope) / (abs(high_slope) + 0.001)\n",
        "\n",
        "            if slope_diff < tolerance:\n",
        "                if high_slope > 0:\n",
        "                    return 1 - slope_diff, {'type': 'Ascending_Channel', 'signal': 'Bullish'}\n",
        "                elif high_slope < 0:\n",
        "                    return 1 - slope_diff, {'type': 'Descending_Channel', 'signal': 'Bearish'}\n",
        "                else:\n",
        "                    return 1 - slope_diff, {'type': 'Horizontal_Channel', 'signal': 'Neutral'}\n",
        "\n",
        "        return 0.0, None\n",
        "\n",
        "    def detect_cup_and_handle(self, close, window=60):\n",
        "        \"\"\"\n",
        "        Cup and Handle Pattern (Reversal - Bullish)\n",
        "        - U-shaped cup followed by small pullback (handle)\n",
        "        \"\"\"\n",
        "        if len(close) < window:\n",
        "            return 0.0, None\n",
        "\n",
        "        cup = close.iloc[-window:-window//4]\n",
        "        handle = close.iloc[-window//4:]\n",
        "\n",
        "        # Check for U-shape (cup)\n",
        "        cup_min_idx = cup.argmin()\n",
        "        cup_start = cup.iloc[0]\n",
        "        cup_end = cup.iloc[-1]\n",
        "        cup_min = cup.min()\n",
        "\n",
        "        # Cup should have similar start and end, with lower middle\n",
        "        start_end_diff = abs(cup_start - cup_end) / cup_start\n",
        "        cup_depth = (cup_start - cup_min) / cup_start\n",
        "\n",
        "        if start_end_diff < 0.05 and cup_depth > 0.05:\n",
        "            # Check handle (small pullback)\n",
        "            handle_return = (handle.iloc[-1] - handle.iloc[0]) / handle.iloc[0]\n",
        "\n",
        "            if -0.05 < handle_return < 0.02:\n",
        "                confidence = min(1.0, cup_depth * 5 * (1 - start_end_diff))\n",
        "                return confidence, {'type': 'Cup_Handle', 'signal': 'Bullish'}\n",
        "\n",
        "        return 0.0, None\n",
        "\n",
        "    def detect_all_patterns(self, high, low, close):\n",
        "        \"\"\"\n",
        "        Detect all patterns and return the most prominent one\n",
        "        \"\"\"\n",
        "        pivot_highs, pivot_lows = self.find_pivots(high, low, close)\n",
        "\n",
        "        patterns = {}\n",
        "\n",
        "        # Double patterns\n",
        "        conf, pattern = self.detect_double_top(high, close, pivot_highs)\n",
        "        if conf > 0:\n",
        "            patterns['Double_Top'] = (conf, pattern)\n",
        "\n",
        "        conf, pattern = self.detect_double_bottom(low, close, pivot_lows)\n",
        "        if conf > 0:\n",
        "            patterns['Double_Bottom'] = (conf, pattern)\n",
        "\n",
        "        # Head and Shoulders\n",
        "        conf, pattern = self.detect_head_and_shoulders(high, pivot_highs)\n",
        "        if conf > 0:\n",
        "            patterns['Head_Shoulders'] = (conf, pattern)\n",
        "\n",
        "        conf, pattern = self.detect_inverse_head_and_shoulders(low, pivot_lows)\n",
        "        if conf > 0:\n",
        "            patterns['Inverse_HS'] = (conf, pattern)\n",
        "\n",
        "        # Triangles\n",
        "        conf, pattern_type, signal = self.detect_triangle(high, low, pivot_highs, pivot_lows)\n",
        "        if conf > 0:\n",
        "            patterns[pattern_type] = (conf, {'type': pattern_type, 'signal': signal})\n",
        "\n",
        "        # Flags\n",
        "        conf, pattern = self.detect_flag(high, low, close, pivot_highs, pivot_lows)\n",
        "        if conf > 0:\n",
        "            patterns[pattern['type']] = (conf, pattern)\n",
        "\n",
        "        # Wedges\n",
        "        conf, pattern = self.detect_wedge(high, low, pivot_highs, pivot_lows)\n",
        "        if conf > 0:\n",
        "            patterns[pattern['type']] = (conf, pattern)\n",
        "\n",
        "        # Channels\n",
        "        conf, pattern = self.detect_channel(high, low, pivot_highs, pivot_lows)\n",
        "        if conf > 0:\n",
        "            patterns[pattern['type']] = (conf, pattern)\n",
        "\n",
        "        # Cup and Handle\n",
        "        conf, pattern = self.detect_cup_and_handle(close)\n",
        "        if conf > 0:\n",
        "            patterns['Cup_Handle'] = (conf, pattern)\n",
        "\n",
        "        # Find best pattern\n",
        "        if patterns:\n",
        "            best_pattern = max(patterns.items(), key=lambda x: x[1][0])\n",
        "            return best_pattern[0], best_pattern[1][0], best_pattern[1][1]\n",
        "\n",
        "        return None, 0.0, None\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 5. SECTOR ROTATION ANALYZER\n",
        "# ============================================================\n",
        "\n",
        "class SectorRotationAnalyzer:\n",
        "    \"\"\"\n",
        "    Analyze Sector Rotation\n",
        "\n",
        "    Methods:\n",
        "    - Relative Strength vs SET Index\n",
        "    - Sector Momentum\n",
        "    - Sector Ranking\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_relative_strength(sector_prices, benchmark_prices, window=20):\n",
        "        \"\"\"\n",
        "        Calculate Relative Strength\n",
        "        RS = Sector Return / Benchmark Return\n",
        "        \"\"\"\n",
        "        sector_return = sector_prices.pct_change(window)\n",
        "        benchmark_return = benchmark_prices.pct_change(window)\n",
        "\n",
        "        rs = sector_return / (benchmark_return + 0.0001)  # Avoid division by zero\n",
        "        return rs\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_sector_momentum(sector_prices, windows=[5, 10, 20, 60]):\n",
        "        \"\"\"\n",
        "        Calculate Sector Momentum across multiple timeframes\n",
        "        \"\"\"\n",
        "        momentum = pd.DataFrame(index=sector_prices.index)\n",
        "\n",
        "        for w in windows:\n",
        "            momentum[f'Mom_{w}'] = sector_prices.pct_change(w)\n",
        "\n",
        "        # Composite momentum score\n",
        "        momentum['Momentum_Score'] = momentum.mean(axis=1)\n",
        "\n",
        "        return momentum['Momentum_Score']\n",
        "\n",
        "    @staticmethod\n",
        "    def rank_sectors(sector_data, metric='Momentum_Score'):\n",
        "        \"\"\"\n",
        "        Rank sectors by a given metric\n",
        "        1 = Best, N = Worst\n",
        "        \"\"\"\n",
        "        return sector_data.rank(ascending=False)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 6. PROXY SENTIMENT INDICATORS\n",
        "# ============================================================\n",
        "\n",
        "class ProxySentimentCalculator:\n",
        "    \"\"\"\n",
        "    Calculate Proxy Sentiment (without LLM/News)\n",
        "\n",
        "    Indicators:\n",
        "    - Market Breadth (Advance/Decline)\n",
        "    - Volume Sentiment\n",
        "    - Price Momentum Breadth\n",
        "    - Put/Call Proxy (Volatility-based)\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_volume_sentiment(close, volume, window=20):\n",
        "        \"\"\"\n",
        "        Volume Sentiment\n",
        "        - Up volume vs Down volume\n",
        "        \"\"\"\n",
        "        price_change = close.diff()\n",
        "\n",
        "        up_volume = volume.where(price_change > 0, 0)\n",
        "        down_volume = volume.where(price_change < 0, 0)\n",
        "\n",
        "        up_vol_ma = up_volume.rolling(window).sum()\n",
        "        down_vol_ma = down_volume.rolling(window).sum()\n",
        "\n",
        "        # Volume Ratio (-1 to +1)\n",
        "        vol_sentiment = (up_vol_ma - down_vol_ma) / (up_vol_ma + down_vol_ma + 1)\n",
        "\n",
        "        return vol_sentiment\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_price_momentum_sentiment(close, window=20):\n",
        "        \"\"\"\n",
        "        Price Momentum Sentiment\n",
        "        - Based on rate of change percentile\n",
        "        \"\"\"\n",
        "        roc = close.pct_change(window)\n",
        "\n",
        "        # Percentile rank\n",
        "        roc_percentile = roc.rolling(252).apply(\n",
        "            lambda x: pd.Series(x).rank(pct=True).iloc[-1]\n",
        "        )\n",
        "\n",
        "        # Convert to -1 to +1 scale\n",
        "        sentiment = (roc_percentile - 0.5) * 2\n",
        "\n",
        "        return sentiment\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_fear_greed_proxy(high, low, close, volume, window=20):\n",
        "        \"\"\"\n",
        "        Fear & Greed Proxy Index\n",
        "\n",
        "        Components:\n",
        "        - Price Momentum\n",
        "        - Volatility (inverse)\n",
        "        - Volume Trend\n",
        "        - Price vs MA\n",
        "        \"\"\"\n",
        "        # 1. Price Momentum (0 to 100)\n",
        "        roc = close.pct_change(window)\n",
        "        mom_score = roc.rolling(252).apply(\n",
        "            lambda x: pd.Series(x).rank(pct=True).iloc[-1]\n",
        "        ) * 100\n",
        "\n",
        "        # 2. Volatility (inverse - low vol = greed, high vol = fear)\n",
        "        atr = ta.volatility.average_true_range(high, low, close, window=14)\n",
        "        atr_pct = atr.rolling(252).apply(\n",
        "            lambda x: pd.Series(x).rank(pct=True).iloc[-1]\n",
        "        )\n",
        "        vol_score = (1 - atr_pct) * 100\n",
        "\n",
        "        # 3. Volume Trend\n",
        "        vol_ma = volume.rolling(window).mean()\n",
        "        vol_ma_long = volume.rolling(window * 3).mean()\n",
        "        vol_score_2 = (vol_ma / vol_ma_long).clip(0.5, 1.5)\n",
        "        vol_score_2 = ((vol_score_2 - 0.5) / 1.0) * 100\n",
        "\n",
        "        # 4. Price vs 200 MA\n",
        "        ma200 = close.rolling(200).mean()\n",
        "        price_vs_ma = ((close / ma200) - 1).clip(-0.2, 0.2)\n",
        "        ma_score = ((price_vs_ma + 0.2) / 0.4) * 100\n",
        "\n",
        "        # Combine (equal weight)\n",
        "        fear_greed = (mom_score.fillna(50) + vol_score.fillna(50) +\n",
        "                      vol_score_2.fillna(50) + ma_score.fillna(50)) / 4\n",
        "\n",
        "        return fear_greed\n",
        "\n",
        "    @staticmethod\n",
        "    def interpret_fear_greed(score):\n",
        "        \"\"\"\n",
        "        Interpret Fear & Greed Score\n",
        "        \"\"\"\n",
        "        if score >= 75:\n",
        "            return 'Extreme_Greed'\n",
        "        elif score >= 55:\n",
        "            return 'Greed'\n",
        "        elif score >= 45:\n",
        "            return 'Neutral'\n",
        "        elif score >= 25:\n",
        "            return 'Fear'\n",
        "        else:\n",
        "            return 'Extreme_Fear'\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 7. MAIN PROCESSING\n",
        "# ============================================================\n",
        "\n",
        "def process_stock(stock, sector, start_date, end_date):\n",
        "    \"\"\"Process single stock with all enhanced features\"\"\"\n",
        "\n",
        "    print(f\"   üì• Downloading {stock} ...\")\n",
        "\n",
        "    try:\n",
        "        df = yf.download(stock, start=start_date, end=end_date, progress=False)\n",
        "\n",
        "        if df.empty or len(df) < 252:\n",
        "            print(f\"   ‚ö†Ô∏è Insufficient data for {stock}\")\n",
        "            return None\n",
        "\n",
        "        # Flatten MultiIndex if needed\n",
        "        if isinstance(df.columns, pd.MultiIndex):\n",
        "            df.columns = df.columns.get_level_values(0)\n",
        "\n",
        "        df = df.reset_index()\n",
        "        df['Stock'] = stock\n",
        "        df['Sector'] = sector\n",
        "\n",
        "        # Extract OHLCV\n",
        "        high = df['High']\n",
        "        low = df['Low']\n",
        "        close = df['Close']\n",
        "        volume = df['Volume']\n",
        "\n",
        "        # ----- 1. Market Regime -----\n",
        "        regime, regime_score, adx = MarketRegimeDetector.detect_regime_combined(\n",
        "            high, low, close, volume\n",
        "        )\n",
        "        df['Market_Regime'] = regime\n",
        "        df['Regime_Score'] = regime_score\n",
        "        df['ADX'] = adx\n",
        "\n",
        "        # ----- 2. Volatility Regime -----\n",
        "        vol_regime, vol_score, hist_vol, atr = VolatilityRegimeDetector.detect_volatility_regime(\n",
        "            high, low, close\n",
        "        )\n",
        "        df['Volatility_Regime'] = vol_regime\n",
        "        df['Volatility_Score'] = vol_score\n",
        "        df['Historical_Volatility'] = hist_vol\n",
        "        df['ATR'] = atr\n",
        "\n",
        "        # ----- 3. Pattern Detection -----\n",
        "        detector = PatternDetector(lookback=60, order=5)\n",
        "\n",
        "        pattern_types = []\n",
        "        pattern_confidences = []\n",
        "        pattern_signals = []\n",
        "\n",
        "        for i in range(len(df)):\n",
        "            if i < 60:\n",
        "                pattern_types.append(None)\n",
        "                pattern_confidences.append(0.0)\n",
        "                pattern_signals.append(None)\n",
        "                continue\n",
        "\n",
        "            h = high.iloc[:i+1]\n",
        "            l = low.iloc[:i+1]\n",
        "            c = close.iloc[:i+1]\n",
        "\n",
        "            pattern_type, confidence, pattern_info = detector.detect_all_patterns(h, l, c)\n",
        "\n",
        "            pattern_types.append(pattern_type)\n",
        "            pattern_confidences.append(confidence)\n",
        "            if pattern_info:\n",
        "                pattern_signals.append(pattern_info.get('signal'))\n",
        "            else:\n",
        "                pattern_signals.append(None)\n",
        "\n",
        "        df['Pattern_Type'] = pattern_types\n",
        "        df['Pattern_Confidence'] = pattern_confidences\n",
        "        df['Pattern_Signal'] = pattern_signals\n",
        "\n",
        "        # ----- 4. Proxy Sentiment -----\n",
        "        df['Volume_Sentiment'] = ProxySentimentCalculator.calculate_volume_sentiment(\n",
        "            close, volume\n",
        "        )\n",
        "        df['Momentum_Sentiment'] = ProxySentimentCalculator.calculate_price_momentum_sentiment(\n",
        "            close\n",
        "        )\n",
        "        df['Fear_Greed_Index'] = ProxySentimentCalculator.calculate_fear_greed_proxy(\n",
        "            high, low, close, volume\n",
        "        )\n",
        "        df['Fear_Greed_Label'] = df['Fear_Greed_Index'].apply(\n",
        "            ProxySentimentCalculator.interpret_fear_greed\n",
        "        )\n",
        "\n",
        "        # ----- 5. Basic Technical Indicators -----\n",
        "        df['RSI'] = ta.momentum.rsi(close, window=14)\n",
        "        df['MACD'] = ta.trend.macd(close)\n",
        "        df['MACD_Signal'] = ta.trend.macd_signal(close)\n",
        "        df['EMA_12'] = ta.trend.ema_indicator(close, window=12)\n",
        "        df['EMA_26'] = ta.trend.ema_indicator(close, window=26)\n",
        "        df['SMA_50'] = close.rolling(50).mean()\n",
        "        df['SMA_200'] = close.rolling(200).mean()\n",
        "\n",
        "        # Bollinger Bands\n",
        "        bb = ta.volatility.BollingerBands(close, window=20, window_dev=2)\n",
        "        df['BB_Upper'] = bb.bollinger_hband()\n",
        "        df['BB_Lower'] = bb.bollinger_lband()\n",
        "        df['BB_Width'] = (df['BB_Upper'] - df['BB_Lower']) / bb.bollinger_mavg()\n",
        "\n",
        "        print(f\"   ‚úÖ {stock} processed: {len(df)} rows\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ùå Error processing {stock}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def calculate_sector_features(all_data, sectors):\n",
        "    \"\"\"Calculate sector-level features\"\"\"\n",
        "\n",
        "    print(\"\\nüìä Calculating Sector Features...\")\n",
        "\n",
        "    # Calculate sector average prices\n",
        "    sector_prices = {}\n",
        "\n",
        "    for sector, stocks in sectors.items():\n",
        "        sector_df = all_data[all_data['Sector'] == sector]\n",
        "\n",
        "        if sector_df.empty:\n",
        "            continue\n",
        "\n",
        "        # Average close price for sector\n",
        "        sector_avg = sector_df.groupby('Date')['Close'].mean()\n",
        "        sector_prices[sector] = sector_avg\n",
        "\n",
        "        # Calculate sector momentum\n",
        "        sector_momentum = SectorRotationAnalyzer.calculate_sector_momentum(sector_avg)\n",
        "\n",
        "        # Add to individual stock data\n",
        "        for idx in all_data[all_data['Sector'] == sector].index:\n",
        "            date = all_data.loc[idx, 'Date']\n",
        "            if date in sector_momentum.index:\n",
        "                all_data.loc[idx, 'Sector_Momentum'] = sector_momentum.loc[date]\n",
        "\n",
        "    # Calculate sector rankings per date\n",
        "    dates = all_data['Date'].unique()\n",
        "\n",
        "    for date in dates:\n",
        "        daily_data = all_data[all_data['Date'] == date]\n",
        "\n",
        "        if daily_data.empty:\n",
        "            continue\n",
        "\n",
        "        # Get sector momentums for this date\n",
        "        sector_moms = daily_data.groupby('Sector')['Sector_Momentum'].first()\n",
        "\n",
        "        if len(sector_moms) > 1:\n",
        "            ranks = sector_moms.rank(ascending=False)\n",
        "\n",
        "            for sector, rank in ranks.items():\n",
        "                mask = (all_data['Date'] == date) & (all_data['Sector'] == sector)\n",
        "                all_data.loc[mask, 'Sector_Rank'] = rank\n",
        "\n",
        "    return all_data\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 8. MAIN EXECUTION\n",
        "# ============================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    print(\"=\" * 70)\n",
        "    print(\"üìä BLOCK 2 ENHANCED: Advanced Technical Features\")\n",
        "    print(\"=\" * 70)\n",
        "    print(\"\"\"\n",
        "    Features:\n",
        "    1. Market Regime Detector (Bull/Bear/Sideways)\n",
        "    2. Volatility Regime (High/Normal/Low)\n",
        "    3. Pattern Detection (20 Patterns)\n",
        "    4. Sector Rotation Score\n",
        "    5. Proxy Sentiment (Fear/Greed Index)\n",
        "\n",
        "    NO LLM / NO FinBERT - Pure Technical Analysis\n",
        "    \"\"\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Process all stocks\n",
        "    all_results = []\n",
        "\n",
        "    for sector, stocks in SECTORS.items():\n",
        "        print(f\"\\nüè¢ Processing Sector: {sector}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        for stock in stocks:\n",
        "            result = process_stock(stock, sector, START_DATE, END_DATE)\n",
        "            if result is not None:\n",
        "                all_results.append(result)\n",
        "\n",
        "    # Combine all data\n",
        "    if all_results:\n",
        "        df_all = pd.concat(all_results, ignore_index=True)\n",
        "\n",
        "        # Calculate sector features\n",
        "        df_all = calculate_sector_features(df_all, SECTORS)\n",
        "\n",
        "        # Sort\n",
        "        df_all = df_all.sort_values(['Sector', 'Stock', 'Date']).reset_index(drop=True)\n",
        "\n",
        "        # Export\n",
        "        output_file = \"Block2_Enhanced_Features.xlsx\"\n",
        "        df_all.to_excel(output_file, index=False)\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        print(\"üìä SUMMARY\")\n",
        "        print(\"=\" * 70)\n",
        "        print(f\"‚úÖ Total Stocks: {df_all['Stock'].nunique()}\")\n",
        "        print(f\"‚úÖ Total Sectors: {df_all['Sector'].nunique()}\")\n",
        "        print(f\"‚úÖ Total Rows: {len(df_all):,}\")\n",
        "        print(f\"‚úÖ Date Range: {df_all['Date'].min()} to {df_all['Date'].max()}\")\n",
        "        print(f\"\\nüíæ Saved to: {output_file}\")\n",
        "\n",
        "        print(\"\\nüìà Sample Output (Last 5 rows of AMGN):\")\n",
        "        sample = df_all[df_all['Stock'] == 'AMGN'].tail(5)[\n",
        "            ['Date', 'Close', 'Market_Regime', 'Regime_Score', 'Volatility_Regime',\n",
        "            'Pattern_Type', 'Pattern_Confidence', 'Fear_Greed_Index', 'Fear_Greed_Label',\n",
        "            'Sector_Momentum']   # ‚ùå ‡∏•‡∏ö Sector_Rank ‡∏≠‡∏≠‡∏Å\n",
        "        ]\n",
        "\n",
        "        print(sample.to_string(index=False))\n",
        "\n",
        "        # Show columns\n",
        "        print(\"\\nüìã All Columns:\")\n",
        "        print(df_all.columns.tolist())\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"‚úÖ BLOCK 2 ENHANCED COMPLETED!\")\n",
        "    print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìä ‡∏™‡∏£‡∏∏‡∏õ DL Structure ‡∏Ç‡∏≠‡∏á Block 5.5\n",
        "Component‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏îInputClose Price ‚Üí Kalman Filter ‚Üí MinMaxScaler ‚Üí Shape (60, 1)Model2 ‡πÇ‡∏°‡πÄ‡∏î‡∏•: CNN-LSTM ‡πÅ‡∏•‡∏∞ CNN-GRULayers7 layers: Conv1D ‚Üí BN ‚Üí MaxPool ‚Üí LSTM/GRU ‚Üí BN ‚Üí Dropout ‚Üí DenseOutputProbability [0,1] ‡∏ß‡πà‡∏≤‡∏£‡∏≤‡∏Ñ‡∏≤‡∏à‡∏∞‡∏Ç‡∏∂‡πâ‡∏ôEnsemble(LSTM + GRU) / 2OptimizerAdam (lr=0.001)LossBinary Crossentropy\n",
        "\n",
        "üî¨ Activation Functions\n",
        "LayerActivation‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•Conv1DReLU‡πÄ‡∏£‡πá‡∏ß, ‡πÑ‡∏°‡πà‡∏°‡∏µ vanishing gradient, ‡∏î‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö feature extractionLSTM/GRUtanh + sigmoidBuilt-in ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö gates ‡πÅ‡∏•‡∏∞ cell stateDense (Output)SigmoidBinary classification ‚Üí output ‡πÄ‡∏õ‡πá‡∏ô probability [0,1]"
      ],
      "metadata": {
        "id": "bDPx4_oMDZt_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß† Bidirectional + Attention ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£ ‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÑ‡∏á\n",
        "\n",
        "1. Bidirectional LSTM/GRU ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?\n",
        "‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô (Unidirectional):\n",
        "Past ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ> Future\n",
        " t-60   t-59   t-58   ...   t-2   t-1   t\n",
        "  ‚Üí      ‚Üí      ‚Üí      ‚Üí     ‚Üí     ‚Üí    [Output]\n",
        "‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å ‡∏ã‡πâ‡∏≤‡∏¢‡πÑ‡∏õ‡∏Ç‡∏ß‡∏≤ ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß (‡∏≠‡∏î‡∏µ‡∏ï ‚Üí ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô)\n",
        "Bidirectional:\n",
        "Forward:   t-60 ‚Üí t-59 ‚Üí t-58 ‚Üí ... ‚Üí t-1 ‚Üí t\n",
        "                                            ‚Üò\n",
        "                                             [Concat] ‚Üí Output\n",
        "                                            ‚Üó\n",
        "Backward:  t-60 ‚Üê t-59 ‚Üê t-58 ‚Üê ... ‚Üê t-1 ‚Üê t\n",
        "‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á ‡πÅ‡∏•‡πâ‡∏ß‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ô\n",
        "‡∏Ç‡πâ‡∏≠‡∏î‡∏µ:\n",
        "\n",
        "‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à Context ‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô (‡∏£‡∏π‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏≠‡∏î‡∏µ‡∏ï‡πÅ‡∏•‡∏∞‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏à‡∏∏‡∏î)\n",
        "‡∏à‡∏±‡∏ö Pattern ‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤\n",
        "\n",
        "\n",
        "2. Attention Mechanism ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?\n",
        "‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Ç‡∏≠‡∏á LSTM ‡∏õ‡∏Å‡∏ï‡∏¥:\n",
        "\n",
        "Output ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏ï‡πâ‡∏≠‡∏á \"‡∏à‡∏≥\" ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á 60 ‡∏ß‡∏±‡∏ô‡πÑ‡∏ß‡πâ‡πÉ‡∏ô hidden state ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß\n",
        "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡πÜ ‡∏≠‡∏≤‡∏à‡∏ñ‡∏π‡∏Å‡∏•‡∏∑‡∏° (vanishing information)\n",
        "\n",
        "Attention ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ô‡∏µ‡πâ:\n",
        "Input: [t-60, t-59, t-58, ..., t-2, t-1, t]\n",
        "         ‚Üì     ‚Üì     ‚Üì          ‚Üì    ‚Üì   ‚Üì\n",
        "       [h1,   h2,   h3,   ..., h58, h59, h60]  ‚Üê Hidden states ‡∏ó‡∏∏‡∏Å timestep\n",
        "         ‚Üì     ‚Üì     ‚Üì          ‚Üì    ‚Üì   ‚Üì\n",
        "       [0.01, 0.02, 0.05, ..., 0.15, 0.30, 0.40]  ‚Üê Attention weights\n",
        "         ‚Üì     ‚Üì     ‚Üì          ‚Üì    ‚Üì   ‚Üì\n",
        "       ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Weighted Sum ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "                        ‚Üì\n",
        "                   Context Vector\n",
        "                        ‚Üì\n",
        "                     Output\n",
        "‡∏Ç‡πâ‡∏≠‡∏î‡∏µ:\n",
        "\n",
        "‡πÇ‡∏°‡πÄ‡∏î‡∏• \"‡πÄ‡∏•‡∏∑‡∏≠‡∏Å\" ‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Å‡∏±‡∏ö‡∏ß‡∏±‡∏ô‡πÑ‡∏´‡∏ô‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤\n",
        "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç (‡πÄ‡∏ä‡πà‡∏ô ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ pattern breakout) ‡∏à‡∏∞‡πÑ‡∏î‡πâ weight ‡∏™‡∏π‡∏á\n",
        "Interpretable: ‡∏î‡∏π‡πÑ‡∏î‡πâ‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏ô‡πÉ‡∏à‡∏ß‡∏±‡∏ô‡πÑ‡∏´‡∏ô\n",
        "\n",
        "\n",
        "3. ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏™‡∏ô‡∏≠\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ                  üèóÔ∏è UPGRADED MODEL: BiLSTM + Attention           ‚îÇ\n",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "‚îÇ                                                                 ‚îÇ\n",
        "‚îÇ  Input (60, 1)                                                  ‚îÇ\n",
        "‚îÇ       ‚Üì                                                         ‚îÇ\n",
        "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ\n",
        "‚îÇ  ‚îÇ Conv1D (64 filters, kernel=3, ReLU)                      ‚îÇ   ‚îÇ\n",
        "‚îÇ  ‚îÇ BatchNormalization                                       ‚îÇ   ‚îÇ\n",
        "‚îÇ  ‚îÇ MaxPooling1D (pool=2)                                    ‚îÇ   ‚îÇ\n",
        "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\n",
        "‚îÇ       ‚Üì                                                         ‚îÇ\n",
        "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ\n",
        "‚îÇ  ‚îÇ üÜï Bidirectional LSTM (50 units, return_sequences=True)  ‚îÇ   ‚îÇ\n",
        "‚îÇ  ‚îÇ    Output: (timesteps, 100)  ‚Üê 50*2 ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ bi-directional ‚îÇ   ‚îÇ\n",
        "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\n",
        "‚îÇ       ‚Üì                                                         ‚îÇ\n",
        "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ\n",
        "‚îÇ  ‚îÇ üÜï Attention Layer                                       ‚îÇ   ‚îÇ\n",
        "‚îÇ  ‚îÇ    - Compute attention weights for each timestep         ‚îÇ   ‚îÇ\n",
        "‚îÇ  ‚îÇ    - Weighted sum ‚Üí Context vector (100,)                ‚îÇ   ‚îÇ\n",
        "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\n",
        "‚îÇ       ‚Üì                                                         ‚îÇ\n",
        "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ\n",
        "‚îÇ  ‚îÇ BatchNormalization                                       ‚îÇ   ‚îÇ\n",
        "‚îÇ  ‚îÇ Dropout (0.3)                                            ‚îÇ   ‚îÇ\n",
        "‚îÇ  ‚îÇ Dense (1, sigmoid)                                       ‚îÇ   ‚îÇ\n",
        "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\n",
        "‚îÇ       ‚Üì                                                         ‚îÇ\n",
        "‚îÇ  Output: P(price UP) ‚àà [0, 1]                                   ‚îÇ\n",
        "‚îÇ                                                                 ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "\n",
        "4. ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö ‡πÄ‡∏î‡∏¥‡∏° vs ‡πÉ‡∏´‡∏°‡πà\n",
        "Component‡πÄ‡∏î‡∏¥‡∏° (Block 5.5)‡πÉ‡∏´‡∏°‡πà (Upgraded)LSTM/GRUUnidirectionalBidirectionalreturn_sequencesFalseTrue (‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏∏‡∏Å timestep)Attention‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‚úÖ ‡∏°‡∏µOutput dimension50100 (50√ó2)Interpretability‡∏ï‡πà‡∏≥‡∏™‡∏π‡∏á (‡∏î‡∏π attention weights ‡πÑ‡∏î‡πâ)\n",
        "\n",
        "5. ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏£‡∏∞‡∏ß‡∏±‡∏á\n",
        "‡∏Ç‡πâ‡∏≠‡∏î‡∏µ‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢‡∏à‡∏±‡∏ö pattern ‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ôParameters ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô ~2xInterpretable (attention weights)Train ‡∏ô‡∏≤‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô‡∏•‡∏î information loss‡∏≠‡∏≤‡∏à overfit ‡∏ñ‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡πâ‡∏≠‡∏¢"
      ],
      "metadata": {
        "id": "muOqS_uzDdnK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "czUyyAvCABB1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        },
        "outputId": "08fd1535-a5d3-41e5-cc77-5a596f7fb403"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "üß† BLOCK 5.5: Deep Learning Signal (UPGRADED + ROLLING WINDOW)\n",
            "======================================================================\n",
            "\n",
            "üì¶ Model Architecture:\n",
            "   - Model 1: CNN + Bidirectional LSTM + Attention\n",
            "   - Model 2: CNN + Bidirectional GRU + Attention\n",
            "   - Model 3: Stacked Bidirectional LSTM + Attention\n",
            "\n",
            "üîÑ Rolling Window Configuration:\n",
            "   - Window 1: Train [2015-2018] ‚Üí Test [2019]\n",
            "   - Window 2: Train [2016-2019] ‚Üí Test [2020]\n",
            "   - Window 3: Train [2017-2020] ‚Üí Test [2021]\n",
            "   - Window 4: Train [2018-2021] ‚Üí Test [2022]\n",
            "   - Window 5: Train [2019-2022] ‚Üí Test [2023]\n",
            "   - Window 6: Train [2020-2023] ‚Üí Test [2024]\n",
            "   - Window 7: Train [2021-2024] ‚Üí Test [2025]\n",
            "\n",
            "‚öôÔ∏è Configuration:\n",
            "   - Lookback: 60 days\n",
            "   - Epochs: 20 (with EarlyStopping)\n",
            "   - Batch Size: 32\n",
            "   - Ensemble: Average of 3 models\n",
            "\n",
            "======================================================================\n",
            "\n",
            "==================================================\n",
            "üîπ Processing: AMGN\n",
            "==================================================\n",
            "   üìÖ Data range: 2015-01-02 to 2025-12-30\n",
            "   üìä Total rows: 2765\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-256330251.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0;31m# ===== 3. Train with Rolling Window =====\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         predictions, metrics = train_with_rolling_window(\n\u001b[0m\u001b[1;32m    420\u001b[0m             \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mlook_back\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLOOK_BACK\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-256330251.py\u001b[0m in \u001b[0;36mtrain_with_rolling_window\u001b[0;34m(df, scaled_data, look_back, epochs, batch_size)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;31m# Train Model 3: Stacked BiLSTM-Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0mmodel3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_stacked_bilstm_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m         model3.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n\u001b[0m\u001b[1;32m    310\u001b[0m                    callbacks=[early_stop], verbose=0)\n\u001b[1;32m    311\u001b[0m         \u001b[0mpred3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/callbacks/callback_list.py\u001b[0m in \u001b[0;36mon_train_batch_begin\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# üß† BLOCK 5.5: Deep Learning Signal (UPGRADED + ROLLING WINDOW)\n",
        "#    Config: Kalman -> CNN -> BN -> Bidirectional LSTM/GRU -> Attention -> Dropout\n",
        "#    Features:\n",
        "#    - Bidirectional LSTM/GRU (capture both past and future context)\n",
        "#    - Attention Mechanism (focus on important timesteps)\n",
        "#    - Rolling Window / Walk-Forward Validation\n",
        "#    - Improved Ensemble (3 models)\n",
        "# ============================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Dense, LSTM, GRU, Conv1D, MaxPooling1D, Input, Dropout,\n",
        "    BatchNormalization, Bidirectional, Layer\n",
        ")\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import warnings\n",
        "import os\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "# ============================================================\n",
        "# 1. TARGET STOCKS\n",
        "# ============================================================\n",
        "\n",
        "# [\n",
        "#     \"AAV\", \"AEONTS\", \"AOT\", \"BA\", \"BBL\", \"BCH\", \"BDMS\", \"BEM\", \"BH\", \"BTS\",\n",
        "#     \"CHG\", \"JMT\", \"KBANK\", \"KKP\", \"KTB\", \"KTC\", \"PR9\", \"PRM\", \"RCL\", \"SAWAD\",\n",
        "#     \"TCAP\", \"TISCO\", \"TTB\"\n",
        "# ]\n",
        "\n",
        "target_stocks = [\"AMGN\",\"GILD\",\"VRTX\",\"REGN\",\"BIIB\",\"ILMN\",\"IDXX\",\"ISRG\",\"ALGN\"]\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 2. ROLLING WINDOW CONFIGURATION\n",
        "# ============================================================\n",
        "# Walk-Forward Validation Windows\n",
        "# Format: (train_start, train_end, test_year)\n",
        "ROLLING_WINDOWS = [\n",
        "    (\"2015-01-01\", \"2018-12-31\", 2019),\n",
        "    (\"2016-01-01\", \"2019-12-31\", 2020),\n",
        "    (\"2017-01-01\", \"2020-12-31\", 2021),\n",
        "    (\"2018-01-01\", \"2021-12-31\", 2022),\n",
        "    (\"2019-01-01\", \"2022-12-31\", 2023),\n",
        "    (\"2020-01-01\", \"2023-12-31\", 2024),\n",
        "    (\"2021-01-01\", \"2024-12-31\", 2025),\n",
        "]\n",
        "\n",
        "# ============================================================\n",
        "# 3. KALMAN FILTER (Noise Reduction)\n",
        "# ============================================================\n",
        "class KalmanFilter1D:\n",
        "    \"\"\"1D Kalman Filter for smoothing price data\"\"\"\n",
        "    def __init__(self, process_noise=1e-5, measurement_noise=1e-3, estimated_error=1.0):\n",
        "        self.Q = process_noise\n",
        "        self.R = measurement_noise\n",
        "        self.P = estimated_error\n",
        "        self.X = 0\n",
        "\n",
        "    def update(self, measurement):\n",
        "        self.P = self.P + self.Q\n",
        "        K = self.P / (self.P + self.R)\n",
        "        self.X = self.X + K * (measurement - self.X)\n",
        "        self.P = (1 - K) * self.P\n",
        "        return self.X\n",
        "\n",
        "    def smooth(self, data):\n",
        "        self.X = data[0]\n",
        "        result = []\n",
        "        for measurement in data:\n",
        "            result.append(self.update(measurement))\n",
        "        return np.array(result)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 4. ATTENTION LAYER (Custom Implementation)\n",
        "# ============================================================\n",
        "class AttentionLayer(Layer):\n",
        "    \"\"\"\n",
        "    Attention Mechanism for Time Series\n",
        "    \"\"\"\n",
        "    def __init__(self, return_attention=False, **kwargs):\n",
        "        self.return_attention = return_attention\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W = self.add_weight(\n",
        "            name='attention_weight',\n",
        "            shape=(input_shape[-1], input_shape[-1]),\n",
        "            initializer='glorot_uniform',\n",
        "            trainable=True\n",
        "        )\n",
        "        self.b = self.add_weight(\n",
        "            name='attention_bias',\n",
        "            shape=(input_shape[-1],),\n",
        "            initializer='zeros',\n",
        "            trainable=True\n",
        "        )\n",
        "        self.u = self.add_weight(\n",
        "            name='attention_context',\n",
        "            shape=(input_shape[-1], 1),\n",
        "            initializer='glorot_uniform',\n",
        "            trainable=True\n",
        "        )\n",
        "        super(AttentionLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        uit = tf.nn.tanh(tf.tensordot(x, self.W, axes=1) + self.b)\n",
        "        ait = tf.tensordot(uit, self.u, axes=1)\n",
        "        ait = tf.squeeze(ait, axis=-1)\n",
        "        ait = tf.nn.softmax(ait, axis=1)\n",
        "        ait_expanded = tf.expand_dims(ait, axis=-1)\n",
        "        weighted_input = x * ait_expanded\n",
        "        output = tf.reduce_sum(weighted_input, axis=1)\n",
        "\n",
        "        if self.return_attention:\n",
        "            return output, ait\n",
        "        return output\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], input_shape[-1])\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(AttentionLayer, self).get_config()\n",
        "        config.update({'return_attention': self.return_attention})\n",
        "        return config\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 5. MODEL ARCHITECTURES\n",
        "# ============================================================\n",
        "\n",
        "def build_cnn_bilstm_attention(input_shape):\n",
        "    \"\"\"Model 1: CNN + Bidirectional LSTM + Attention\"\"\"\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    x = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling1D(pool_size=2)(x)\n",
        "\n",
        "    x = Bidirectional(LSTM(50, return_sequences=True))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = AttentionLayer(return_attention=False)(x)\n",
        "\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Dense(32, activation='relu')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "def build_cnn_bigru_attention(input_shape):\n",
        "    \"\"\"Model 2: CNN + Bidirectional GRU + Attention\"\"\"\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    x = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling1D(pool_size=2)(x)\n",
        "\n",
        "    x = Bidirectional(GRU(50, return_sequences=True))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = AttentionLayer(return_attention=False)(x)\n",
        "\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Dense(32, activation='relu')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "def build_stacked_bilstm_attention(input_shape):\n",
        "    \"\"\"Model 3: Stacked Bidirectional LSTM + Attention\"\"\"\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    x = Bidirectional(LSTM(64, return_sequences=True))(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    x = Bidirectional(LSTM(32, return_sequences=True))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = AttentionLayer(return_attention=False)(x)\n",
        "\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Dense(32, activation='relu')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 6. DATA PREPARATION\n",
        "# ============================================================\n",
        "\n",
        "def create_dataset(data, look_back=60):\n",
        "    \"\"\"Create sequences for time series prediction\"\"\"\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - look_back - 1):\n",
        "        X.append(data[i:(i + look_back), 0])\n",
        "        y.append(1 if data[i + look_back, 0] > data[i + look_back - 1, 0] else 0)\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "\n",
        "def create_dataset_with_dates(df, scaled_data, look_back=60):\n",
        "    \"\"\"Create sequences with corresponding dates\"\"\"\n",
        "    X, y, dates = [], [], []\n",
        "    for i in range(len(scaled_data) - look_back - 1):\n",
        "        X.append(scaled_data[i:(i + look_back), 0])\n",
        "        y.append(1 if scaled_data[i + look_back, 0] > scaled_data[i + look_back - 1, 0] else 0)\n",
        "        dates.append(df.index[i + look_back])\n",
        "    return np.array(X), np.array(y), dates\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 7. ROLLING WINDOW TRAINING FUNCTION\n",
        "# ============================================================\n",
        "\n",
        "def train_with_rolling_window(df, scaled_data, look_back=60, epochs=20, batch_size=32):\n",
        "    \"\"\"\n",
        "    Train models using Rolling Window / Walk-Forward Validation\n",
        "\n",
        "    Returns:\n",
        "        all_predictions: List of predictions for each window\n",
        "        all_metrics: Performance metrics for each window\n",
        "    \"\"\"\n",
        "\n",
        "    # Create dataset with dates\n",
        "    X, y, dates = create_dataset_with_dates(df, scaled_data, look_back)\n",
        "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
        "\n",
        "    # Convert dates to DataFrame for easier filtering\n",
        "    dates_df = pd.DataFrame({'date': dates, 'idx': range(len(dates))})\n",
        "    dates_df['year'] = pd.to_datetime(dates_df['date']).dt.year\n",
        "\n",
        "    all_predictions = []\n",
        "    all_metrics = []\n",
        "\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor='loss',\n",
        "        patience=5,\n",
        "        restore_best_weights=True,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    for train_start, train_end, test_year in ROLLING_WINDOWS:\n",
        "        # Get indices for train and test\n",
        "        train_mask = (dates_df['date'] >= train_start) & (dates_df['date'] <= train_end)\n",
        "        test_mask = (dates_df['year'] == test_year)\n",
        "\n",
        "        train_idx = dates_df[train_mask]['idx'].values\n",
        "        test_idx = dates_df[test_mask]['idx'].values\n",
        "\n",
        "        if len(train_idx) < 100 or len(test_idx) < 10:\n",
        "            continue\n",
        "\n",
        "        X_train, y_train = X[train_idx], y[train_idx]\n",
        "        X_test, y_test = X[test_idx], y[test_idx]\n",
        "        test_dates = [dates[i] for i in test_idx]\n",
        "\n",
        "        input_shape = (look_back, 1)\n",
        "\n",
        "        # Train Model 1: CNN-BiLSTM-Attention\n",
        "        model1 = build_cnn_bilstm_attention(input_shape)\n",
        "        model1.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                   callbacks=[early_stop], verbose=0)\n",
        "        pred1 = model1.predict(X_test, verbose=0)\n",
        "\n",
        "        # Train Model 2: CNN-BiGRU-Attention\n",
        "        model2 = build_cnn_bigru_attention(input_shape)\n",
        "        model2.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                   callbacks=[early_stop], verbose=0)\n",
        "        pred2 = model2.predict(X_test, verbose=0)\n",
        "\n",
        "        # Train Model 3: Stacked BiLSTM-Attention\n",
        "        model3 = build_stacked_bilstm_attention(input_shape)\n",
        "        model3.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                   callbacks=[early_stop], verbose=0)\n",
        "        pred3 = model3.predict(X_test, verbose=0)\n",
        "\n",
        "        # Ensemble\n",
        "        ensemble_pred = (pred1 + pred2 + pred3) / 3.0\n",
        "        ensemble_binary = (ensemble_pred > 0.5).astype(int).flatten()\n",
        "\n",
        "        # Evaluate\n",
        "        accuracy = accuracy_score(y_test, ensemble_binary)\n",
        "        precision = precision_score(y_test, ensemble_binary, zero_division=0)\n",
        "        recall = recall_score(y_test, ensemble_binary, zero_division=0)\n",
        "        f1 = f1_score(y_test, ensemble_binary, zero_division=0)\n",
        "\n",
        "        all_metrics.append({\n",
        "            'Train_Period': f\"{train_start[:4]}-{train_end[:4]}\",\n",
        "            'Test_Year': test_year,\n",
        "            'Accuracy': accuracy,\n",
        "            'Precision': precision,\n",
        "            'Recall': recall,\n",
        "            'F1_Score': f1,\n",
        "            'Train_Samples': len(y_train),\n",
        "            'Test_Samples': len(y_test)\n",
        "        })\n",
        "\n",
        "        # Store predictions\n",
        "        for i, date in enumerate(test_dates):\n",
        "            all_predictions.append({\n",
        "                'Date': date,\n",
        "                'Test_Year': test_year,\n",
        "                'DL_Signal': ensemble_pred[i, 0],\n",
        "                'DL_Signal_Binary': ensemble_binary[i],\n",
        "                'Actual': y_test[i]\n",
        "            })\n",
        "\n",
        "        # Clean up memory\n",
        "        del model1, model2, model3\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "    return all_predictions, all_metrics\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 8. MAIN TRAINING LOOP\n",
        "# ============================================================\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"üß† BLOCK 5.5: Deep Learning Signal (UPGRADED + ROLLING WINDOW)\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\"\"\n",
        "üì¶ Model Architecture:\n",
        "   - Model 1: CNN + Bidirectional LSTM + Attention\n",
        "   - Model 2: CNN + Bidirectional GRU + Attention\n",
        "   - Model 3: Stacked Bidirectional LSTM + Attention\n",
        "\n",
        "üîÑ Rolling Window Configuration:\n",
        "   - Window 1: Train [2015-2018] ‚Üí Test [2019]\n",
        "   - Window 2: Train [2016-2019] ‚Üí Test [2020]\n",
        "   - Window 3: Train [2017-2020] ‚Üí Test [2021]\n",
        "   - Window 4: Train [2018-2021] ‚Üí Test [2022]\n",
        "   - Window 5: Train [2019-2022] ‚Üí Test [2023]\n",
        "   - Window 6: Train [2020-2023] ‚Üí Test [2024]\n",
        "   - Window 7: Train [2021-2024] ‚Üí Test [2025]\n",
        "\n",
        "‚öôÔ∏è Configuration:\n",
        "   - Lookback: 60 days\n",
        "   - Epochs: 20 (with EarlyStopping)\n",
        "   - Batch Size: 32\n",
        "   - Ensemble: Average of 3 models\n",
        "\"\"\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Storage for results\n",
        "all_stock_predictions = []\n",
        "all_stock_metrics = []\n",
        "\n",
        "# Training parameters\n",
        "LOOK_BACK = 60\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "for stock in target_stocks:\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"üîπ Processing: {stock}\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "    try:\n",
        "        # ===== 1. Download Data =====\n",
        "        df = yf.download(stock, start=\"2015-01-01\", end=\"2025-12-31\", progress=False)\n",
        "\n",
        "        if len(df) < 500:\n",
        "            print(f\"‚ö†Ô∏è Skipped (insufficient data: {len(df)} rows)\")\n",
        "            continue\n",
        "\n",
        "        if isinstance(df.columns, pd.MultiIndex):\n",
        "            df.columns = df.columns.get_level_values(0)\n",
        "\n",
        "        data = df[['Close']].values\n",
        "\n",
        "        print(f\"   üìÖ Data range: {df.index.min().strftime('%Y-%m-%d')} to {df.index.max().strftime('%Y-%m-%d')}\")\n",
        "        print(f\"   üìä Total rows: {len(df)}\")\n",
        "\n",
        "        # ===== 2. Preprocessing =====\n",
        "        kf = KalmanFilter1D(process_noise=1e-5, measurement_noise=0.01)\n",
        "        smoothed_data = kf.smooth(data.flatten()).reshape(-1, 1)\n",
        "\n",
        "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "        scaled_data = scaler.fit_transform(smoothed_data)\n",
        "\n",
        "        # ===== 3. Train with Rolling Window =====\n",
        "        predictions, metrics = train_with_rolling_window(\n",
        "            df, scaled_data,\n",
        "            look_back=LOOK_BACK,\n",
        "            epochs=EPOCHS,\n",
        "            batch_size=BATCH_SIZE\n",
        "        )\n",
        "\n",
        "        # Add stock name to results\n",
        "        for pred in predictions:\n",
        "            pred['Stock'] = stock\n",
        "        for metric in metrics:\n",
        "            metric['Stock'] = stock\n",
        "\n",
        "        all_stock_predictions.extend(predictions)\n",
        "        all_stock_metrics.extend(metrics)\n",
        "\n",
        "        # Print window results\n",
        "        print(f\"\\n   üìä Rolling Window Results for {stock}:\")\n",
        "        print(f\"   {'Train Period':<15} {'Test Year':<10} {'Accuracy':<10} {'F1 Score':<10}\")\n",
        "        print(f\"   {'-'*45}\")\n",
        "        for m in metrics:\n",
        "            print(f\"   {m['Train_Period']:<15} {m['Test_Year']:<10} {m['Accuracy']:.2%}     {m['F1_Score']:.2%}\")\n",
        "\n",
        "        # Average performance\n",
        "        if metrics:\n",
        "            avg_acc = np.mean([m['Accuracy'] for m in metrics])\n",
        "            avg_f1 = np.mean([m['F1_Score'] for m in metrics])\n",
        "            print(f\"   {'-'*45}\")\n",
        "            print(f\"   {'AVERAGE':<15} {'':<10} {avg_acc:.2%}     {avg_f1:.2%}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {e}\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 9. SUMMARY & EXPORT\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"üìä OVERALL PERFORMANCE SUMMARY (All Stocks, All Windows)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "if all_stock_metrics:\n",
        "    df_metrics = pd.DataFrame(all_stock_metrics)\n",
        "\n",
        "    # Summary by Test Year\n",
        "    print(\"\\nüìÖ Performance by Test Year:\")\n",
        "    print(\"-\" * 50)\n",
        "    year_summary = df_metrics.groupby('Test_Year').agg({\n",
        "        'Accuracy': 'mean',\n",
        "        'Precision': 'mean',\n",
        "        'Recall': 'mean',\n",
        "        'F1_Score': 'mean',\n",
        "        'Test_Samples': 'sum'\n",
        "    }).round(4)\n",
        "    print(year_summary.to_string())\n",
        "\n",
        "    # Summary by Stock\n",
        "    print(\"\\nüìà Performance by Stock (Average across all windows):\")\n",
        "    print(\"-\" * 50)\n",
        "    stock_summary = df_metrics.groupby('Stock').agg({\n",
        "        'Accuracy': 'mean',\n",
        "        'Precision': 'mean',\n",
        "        'Recall': 'mean',\n",
        "        'F1_Score': 'mean'\n",
        "    }).round(4)\n",
        "    print(stock_summary.to_string())\n",
        "\n",
        "    # Overall Average\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"üéØ OVERALL AVERAGE PERFORMANCE\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"   ‚Ä¢ Accuracy:  {df_metrics['Accuracy'].mean():.2%}\")\n",
        "    print(f\"   ‚Ä¢ Precision: {df_metrics['Precision'].mean():.2%}\")\n",
        "    print(f\"   ‚Ä¢ Recall:    {df_metrics['Recall'].mean():.2%}\")\n",
        "    print(f\"   ‚Ä¢ F1 Score:  {df_metrics['F1_Score'].mean():.2%}\")\n",
        "    print(f\"   ‚Ä¢ Total Test Samples: {df_metrics['Test_Samples'].sum():,}\")\n",
        "\n",
        "# Export Results\n",
        "if all_stock_predictions:\n",
        "    df_predictions = pd.DataFrame(all_stock_predictions)\n",
        "\n",
        "    # Save predictions\n",
        "    outfile_signals = \"DeepLearning_Signal_BiLSTM_Attention_RollingWindow.xlsx\"\n",
        "    df_predictions.to_excel(outfile_signals, index=False)\n",
        "    print(f\"\\nüíæ Predictions saved to: {outfile_signals}\")\n",
        "\n",
        "    # Save metrics\n",
        "    outfile_metrics = \"DeepLearning_Metrics_BiLSTM_Attention_RollingWindow.xlsx\"\n",
        "    df_metrics.to_excel(outfile_metrics, index=False)\n",
        "    print(f\"üíæ Metrics saved to: {outfile_metrics}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"‚úÖ BLOCK 5.5 COMPLETED: BiLSTM/GRU + Attention + Rolling Window\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-u-fC_JSABEf"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# üîó BLOCK 6: Data Integration (Standard)\n",
        "# ============================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"‚è≥ Integrating Data with Advanced Technicals...\")\n",
        "\n",
        "# target_stocks = [\n",
        "#     \"AAV\", \"AEONTS\", \"AOT\", \"BA\", \"BBL\", \"BCH\", \"BDMS\", \"BEM\", \"BH\", \"BTS\",\n",
        "#     \"CHG\", \"JMT\", \"KBANK\", \"KKP\", \"KTB\", \"KTC\", \"PR9\", \"PRM\", \"RCL\", \"SAWAD\",\n",
        "#     \"TCAP\", \"TISCO\", \"TTB\"\n",
        "# ]\n",
        "\n",
        "target_stocks = [\"BBL\",\"KBANK\",\"KKP\",\"KTB\",\"TCAP\",\"TISCO\",\"TTB\"]\n",
        "\n",
        "def calculate_adx(df, window=14):\n",
        "    high = df['High']\n",
        "    low = df['Low']\n",
        "    close = df['Close']\n",
        "    plus_dm = high.diff()\n",
        "    minus_dm = low.diff()\n",
        "    plus_dm[plus_dm < 0] = 0\n",
        "    minus_dm[minus_dm > 0] = 0\n",
        "    tr1 = pd.DataFrame(high - low)\n",
        "    tr2 = pd.DataFrame(abs(high - close.shift(1)))\n",
        "    tr3 = pd.DataFrame(abs(low - close.shift(1)))\n",
        "    tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
        "    atr = tr.rolling(window).mean()\n",
        "    plus_di = 100 * (plus_dm.ewm(alpha=1/window).mean() / atr)\n",
        "    minus_di = 100 * (abs(minus_dm).ewm(alpha=1/window).mean() / atr)\n",
        "    dx = (abs(plus_di - minus_di) / abs(plus_di + minus_di)) * 100\n",
        "    return dx.rolling(window).mean()\n",
        "\n",
        "def add_technical_score(df):\n",
        "    df = df.copy()\n",
        "    df['EMA_200'] = df['Close'].ewm(span=200, adjust=False).mean()\n",
        "\n",
        "    delta = df['Close'].diff()\n",
        "    gain = (delta.where(delta > 0, 0)).rolling(14).mean()\n",
        "    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
        "    rs = gain / loss\n",
        "    df['RSI'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "    k = df['Close'].ewm(span=12, adjust=False).mean()\n",
        "    d = df['Close'].ewm(span=26, adjust=False).mean()\n",
        "    df['MACD'] = k - d\n",
        "    df['MACD_Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
        "\n",
        "    s_trend = np.where(df['Close'] > df['EMA_200'], 1, -1)\n",
        "    s_rsi = np.where(df['RSI'] < 30, 1, np.where(df['RSI'] > 70, -1, 0))\n",
        "    s_macd = np.where(df['MACD'] > df['MACD_Signal'], 1, -1)\n",
        "    df['Tech_Signal'] = (s_trend * 0.4) + (s_macd * 0.4) + (s_rsi * 0.2)\n",
        "    return df\n",
        "\n",
        "print(\"   üîπ Step 1: Loading Full Price Data...\")\n",
        "df_price = pd.DataFrame()\n",
        "for stock in target_stocks:\n",
        "    try:\n",
        "        data = yf.download(f\"{stock}.BK\", start=\"2018-01-01\", end=\"2025-12-31\", progress=False)\n",
        "        if isinstance(data.columns, pd.MultiIndex): data.columns = data.columns.get_level_values(0)\n",
        "        data = data.reset_index()\n",
        "        data['Stock'] = stock\n",
        "        data['ADX'] = calculate_adx(data)\n",
        "        data = add_technical_score(data)\n",
        "        df_price = pd.concat([df_price, data], ignore_index=True)\n",
        "    except: pass\n",
        "\n",
        "req_cols = ['Date', 'Stock', 'Close', 'Tech_Signal', 'ADX', 'RSI', 'MACD']\n",
        "df_rl = df_price[req_cols].dropna().sort_values(['Stock', 'Date']).reset_index(drop=True)\n",
        "\n",
        "print(\"   üîπ Step 2 & 3: Merging Signals...\")\n",
        "try:\n",
        "    df_macro = pd.read_excel(\"Forecast_ARDL_ECM_NextMonth_Clean.xlsx\")\n",
        "    sig_col = 'Pred_dLogclose' if 'Pred_dLogclose' in df_macro.columns else df_macro.select_dtypes(include=[np.number]).columns[0]\n",
        "    macro_map = df_macro.set_index('Stock')[sig_col].to_dict()\n",
        "    df_rl['Macro_Signal'] = df_rl['Stock'].map(macro_map).fillna(0)\n",
        "except: df_rl['Macro_Signal'] = 0\n",
        "\n",
        "try:\n",
        "    df_dl = pd.read_excel(\"DeepLearning_Signal_LSTM_GRU.xlsx\")\n",
        "    df_dl['Date'] = pd.to_datetime(df_dl['Date'])\n",
        "    df_rl = pd.merge(df_rl, df_dl[['Date', 'Stock', 'DL_Signal']], on=['Date', 'Stock'], how='left')\n",
        "    df_rl['DL_Signal'] = df_rl['DL_Signal'].fillna(0.5)\n",
        "except: df_rl['DL_Signal'] = 0.5\n",
        "\n",
        "df_rl.to_excel(\"Final_RL_Input_Ready.xlsx\", index=False)\n",
        "print(\"‚úÖ Data Integration Complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UieFy0V7HuYj"
      },
      "outputs": [],
      "source": [
        "!pip install stable_baselines3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìã 1. Constraint ‡∏ó‡∏µ‡πà‡∏î‡∏±‡∏î‡∏ô‡∏¥‡∏™‡∏±‡∏¢ RLConstraint‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏à‡∏∏‡∏î‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πåCooldown 2 Days‡∏´‡∏•‡∏±‡∏á Sell ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏≠ 2 ‡∏ß‡∏±‡∏ô‡∏ñ‡∏∂‡∏á‡∏à‡∏∞ Buy ‡πÑ‡∏î‡πâ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô OvertradingMomentum Rule (Buy)Buy ‡πÑ‡∏î‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠ ADX > 25 ‡πÅ‡∏•‡∏∞ RSI < 75 ‡∏´‡∏£‡∏∑‡∏≠ RSI < 45‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏ã‡∏∑‡πâ‡∏≠‡∏ï‡∏≤‡∏° TrendüÜï Volatility-based SizingPosition Size 30-70% ‡∏ï‡∏≤‡∏° Volatility‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ä‡πà‡∏ß‡∏á Vol ‡∏™‡∏π‡∏áüÜï Max Consecutive Losses‡∏Ç‡∏≤‡∏î‡∏ó‡∏∏‡∏ô 5 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ï‡∏¥‡∏î ‚Üí ‡∏´‡∏¢‡∏∏‡∏î 3 ‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î‡∏û‡∏±‡∏Å‡πÄ‡∏°‡∏∑‡πà‡∏≠ Strategy ‡πÑ‡∏°‡πà workRandom Initial Position50% ‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏°‡∏µ‡∏´‡∏∏‡πâ‡∏ô‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß‡∏ù‡∏∂‡∏Å‡πÉ‡∏´‡πâ‡∏£‡∏±‡∏ö‡∏°‡∏∑‡∏≠‡∏ó‡∏∏‡∏Å‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πåüõ°Ô∏è 2. Risk ManagementRuleTriggerAction‡∏à‡∏∏‡∏î‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πåHard Stop LossPnL ‚â§ -6%Force Sell‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡∏≤‡∏î‡∏ó‡∏∏‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏îTrailing StopPnL > +10% ‡πÅ‡∏•‡πâ‡∏ß‡∏ï‡∏Å > 4% ‡∏à‡∏≤‡∏Å PeakForce Sell‡∏•‡πá‡∏≠‡∏Ñ‡∏Å‡∏≥‡πÑ‡∏£üÜï Volatility Sizing‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà Buy‡∏õ‡∏£‡∏±‡∏ö Size 30-70%‡∏•‡∏î Position ‡∏ä‡πà‡∏ß‡∏á Vol ‡∏™‡∏π‡∏áüÜï Loss Pause‡∏Ç‡∏≤‡∏î‡∏ó‡∏∏‡∏ô 5 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ï‡∏¥‡∏î‡∏´‡∏¢‡∏∏‡∏î 3 ‡∏ß‡∏±‡∏ô‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô Drawdown ‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏áüéÅ 3. Reward Shaping‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πåReward‡∏à‡∏∏‡∏î‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πåBuy ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à+0.1‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÉ‡∏à Take ActionSell ‡∏à‡∏≤‡∏Å Trailing Stop+2.0‡∏£‡∏≤‡∏á‡∏ß‡∏±‡∏•‡πÉ‡∏´‡∏ç‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≥‡πÑ‡∏£‡πÄ‡∏¢‡∏≠‡∏∞Sell ‡∏à‡∏≤‡∏Å Stop Loss+0.1‡∏£‡∏≤‡∏á‡∏ß‡∏±‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö DisciplineSell ‡∏°‡∏µ‡∏Å‡∏≥‡πÑ‡∏£ (‡∏õ‡∏Å‡∏ï‡∏¥)+PnL √ó 10‡∏ï‡∏≤‡∏°‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏Å‡∏≥‡πÑ‡∏£Sell ‡∏Ç‡∏≤‡∏î‡∏ó‡∏∏‡∏ô (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà SL)-0.5‡∏•‡∏á‡πÇ‡∏ó‡∏© Sell ‡∏ú‡∏¥‡∏î‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏∞üÜï Trigger Loss Pause-1.5‡∏•‡∏á‡πÇ‡∏ó‡∏©‡∏´‡∏ô‡∏±‡∏Å‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ç‡∏≤‡∏î‡∏ó‡∏∏‡∏ô‡∏ï‡∏¥‡∏î 5 ‡∏Ñ‡∏£‡∏±‡πâ‡∏áüÜï ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á Pause-0.3 ‡∏ï‡πà‡∏≠‡∏ß‡∏±‡∏ô‡∏•‡∏á‡πÇ‡∏ó‡∏© Opportunity Cost‡∏ó‡∏∏‡∏Å Step+(ŒîNetWorth / NetWorth) √ó 100‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏° Portfolio Valueüìä 4. State Vector (11 Features)#FeatureOriginal/New1Macro_SignalOriginal2DL_SignalOriginal3Tech_SignalOriginal4ADX / 100Original5Balance / 1MOriginal6Holdings Value / 1MOriginal7RSI / 100Original8MACD / 10Original9Volatility MultiplierüÜï New10Consecutive Losses / 5üÜï New11Pause Counter / 3üÜï New"
      ],
      "metadata": {
        "id": "mW6OMFtKhumH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "                    ‚îÇ          RL Agent (PPO)             ‚îÇ\n",
        "                    ‚îÇ         ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Action                ‚îÇ\n",
        "                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                                    ‚îÇ\n",
        "                                    ‚ñº\n",
        "                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "                    ‚îÇ   üÜï CHECK: Loss Pause Active?      ‚îÇ\n",
        "                    ‚îÇ      (‡∏Ç‡∏≤‡∏î‡∏ó‡∏∏‡∏ô 5 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á ‚Üí ‡∏´‡∏¢‡∏∏‡∏î 3 ‡∏ß‡∏±‡∏ô)   ‚îÇ\n",
        "                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                                    ‚îÇ\n",
        "                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "                    ‚ñº                               ‚ñº\n",
        "              [Pause = YES]                   [Pause = NO]\n",
        "              Force HOLD                      Continue...\n",
        "              Reward -0.3                           ‚îÇ\n",
        "                    ‚îÇ                               ‚ñº\n",
        "                    ‚îÇ               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "                    ‚îÇ               ‚îÇ    CHECK: Risk Management       ‚îÇ\n",
        "                    ‚îÇ               ‚îÇ    ‚Ä¢ Stop Loss -6%?             ‚îÇ\n",
        "                    ‚îÇ               ‚îÇ    ‚Ä¢ Trailing Stop?             ‚îÇ\n",
        "                    ‚îÇ               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                    ‚îÇ                               ‚îÇ\n",
        "                    ‚îÇ               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "                    ‚îÇ               ‚ñº                               ‚ñº\n",
        "                    ‚îÇ         [Risk Trigger]                  [No Trigger]\n",
        "                    ‚îÇ         Force SELL                      Continue...\n",
        "                    ‚îÇ               ‚îÇ                               ‚îÇ\n",
        "                    ‚îÇ               ‚îÇ                               ‚ñº\n",
        "                    ‚îÇ               ‚îÇ               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "                    ‚îÇ               ‚îÇ               ‚îÇ    CHECK: Cooldown Active?      ‚îÇ\n",
        "                    ‚îÇ               ‚îÇ               ‚îÇ    (‡∏´‡∏•‡∏±‡∏á Sell ‡∏£‡∏≠ 2 ‡∏ß‡∏±‡∏ô)          ‚îÇ\n",
        "                    ‚îÇ               ‚îÇ               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                    ‚îÇ               ‚îÇ                               ‚îÇ\n",
        "                    ‚îÇ               ‚îÇ               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "                    ‚îÇ               ‚îÇ               ‚ñº                               ‚ñº\n",
        "                    ‚îÇ               ‚îÇ         [Cooldown = YES]               [Cooldown = NO]\n",
        "                    ‚îÇ               ‚îÇ         Block BUY                       Continue...\n",
        "                    ‚îÇ               ‚îÇ               ‚îÇ                               ‚îÇ\n",
        "                    ‚îÇ               ‚îÇ               ‚îÇ                               ‚ñº\n",
        "                    ‚îÇ               ‚îÇ               ‚îÇ               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "                    ‚îÇ               ‚îÇ               ‚îÇ               ‚îÇ      EXECUTE ACTION         ‚îÇ\n",
        "                    ‚îÇ               ‚îÇ               ‚îÇ               ‚îÇ  BUY / HOLD / SELL          ‚îÇ\n",
        "                    ‚îÇ               ‚îÇ               ‚îÇ               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                    ‚îÇ               ‚îÇ               ‚îÇ                               ‚îÇ\n",
        "                    ‚îÇ               ‚îÇ               ‚îÇ                               ‚ñº\n",
        "                    ‚îÇ               ‚îÇ               ‚îÇ               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "                    ‚îÇ               ‚îÇ               ‚îÇ               ‚îÇ  üÜï BUY: Volatility Sizing  ‚îÇ\n",
        "                    ‚îÇ               ‚îÇ               ‚îÇ               ‚îÇ     High Vol ‚Üí 30-50%       ‚îÇ\n",
        "                    ‚îÇ               ‚îÇ               ‚îÇ               ‚îÇ     Low Vol ‚Üí 50-70%        ‚îÇ\n",
        "                    ‚îÇ               ‚îÇ               ‚îÇ               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                    ‚îÇ               ‚îÇ               ‚îÇ                               ‚îÇ\n",
        "                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                                                    ‚îÇ\n",
        "                                                    ‚ñº\n",
        "                                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "                                    ‚îÇ  üÜï SELL: Track Consecutive     ‚îÇ\n",
        "                                    ‚îÇ     Losses (‡∏ñ‡πâ‡∏≤‡∏Ç‡∏≤‡∏î‡∏ó‡∏∏‡∏ô)          ‚îÇ\n",
        "                                    ‚îÇ     ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏£‡∏ö 5 ‚Üí Trigger Pause    ‚îÇ\n",
        "                                    ‚îÇ     Reward -1.5                 ‚îÇ\n",
        "                                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                                                    ‚îÇ\n",
        "                                                    ‚ñº\n",
        "                                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "                                    ‚îÇ      Calculate Reward           ‚îÇ\n",
        "                                    ‚îÇ      Update State               ‚îÇ\n",
        "                                    ‚îÇ      Learn                      ‚îÇ\n",
        "                                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò"
      ],
      "metadata": {
        "id": "-w1olGHwiMR2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7YRj6DfABKt"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# ü§ñ BLOCK 7: Train PPO (ELITE VERSION V3)\n",
        "#    Based on Academic \"Elite\" Checklist\n",
        "#\n",
        "#    üÜï CRITICAL FIXES:\n",
        "#    1. Risk-Adjusted Reward (Log Return - Volatility Penalty)\n",
        "#    2. Transaction Costs (0.16% commission)\n",
        "#    3. Normalized Observations (relative to initial balance)\n",
        "#\n",
        "#    Original Features:\n",
        "#    - Cooldown 2 Days after Sell\n",
        "#    - Stop Loss -6%\n",
        "#    - Trailing Stop (Trigger 10%, Drop 4%)\n",
        "#    - Volatility-based Position Sizing\n",
        "#    - Max Consecutive Losses (5 losses ‚Üí pause 3 days)\n",
        "# ============================================================\n",
        "import os\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "os.makedirs(\"trained_models\", exist_ok=True)\n",
        "\n",
        "# ============================================================\n",
        "# 1. CONFIGURATION\n",
        "# ============================================================\n",
        "\n",
        "# Target Stocks\n",
        "target_stocks = [\n",
        "    \"AAV\", \"AEONTS\", \"AOT\", \"BA\", \"BBL\", \"BCH\", \"BDMS\", \"BEM\", \"BH\", \"BTS\",\n",
        "    \"CHG\", \"JMT\", \"KBANK\", \"KKP\", \"KTB\", \"KTC\", \"PR9\", \"PRM\", \"RCL\", \"SAWAD\",\n",
        "    \"TCAP\", \"TISCO\", \"TTB\"\n",
        "]\n",
        "\n",
        "# Rolling Window Configuration\n",
        "ROLLING_WINDOWS = [\n",
        "    (2015, 2018, 2019),\n",
        "    (2016, 2019, 2020),\n",
        "    (2017, 2020, 2021),\n",
        "    (2018, 2021, 2022),\n",
        "    (2019, 2022, 2023),\n",
        "    (2020, 2023, 2024),\n",
        "    (2021, 2024, 2025),\n",
        "]\n",
        "\n",
        "# üÜï Transaction Costs (Thailand SET)\n",
        "COMMISSION_RATE = 0.0016  # 0.16% (includes VAT)\n",
        "\n",
        "# ============================================================\n",
        "# 2. LOAD DATA\n",
        "# ============================================================\n",
        "try:\n",
        "    df_rl_all = pd.read_excel(\"Final_RL_Input_Ready.xlsx\")\n",
        "    df_rl_all['Date'] = pd.to_datetime(df_rl_all['Date'])\n",
        "    df_rl_all['Year'] = df_rl_all['Date'].dt.year\n",
        "except:\n",
        "    raise RuntimeError(\"‚ùå Missing Data: Final_RL_Input_Ready.xlsx\")\n",
        "\n",
        "# ============================================================\n",
        "# 3. TRADING ENVIRONMENT (ELITE VERSION)\n",
        "# ============================================================\n",
        "class StockTradingEnvElite(gym.Env):\n",
        "    \"\"\"\n",
        "    Stock Trading Environment - ELITE VERSION\n",
        "\n",
        "    Based on Academic \"Elite\" Checklist:\n",
        "\n",
        "    ‚úÖ FIX 1: Risk-Adjusted Reward\n",
        "       - Use Log Returns (stationary, additive)\n",
        "       - Penalize volatility (approximate Sharpe Ratio)\n",
        "       - Remove arbitrary point rewards\n",
        "\n",
        "    ‚úÖ FIX 2: Transaction Costs\n",
        "       - Deduct 0.16% commission on Buy and Sell\n",
        "       - Prevents unrealistic high-frequency trading\n",
        "\n",
        "    ‚úÖ FIX 3: Normalized Observations\n",
        "       - Balance / Initial Balance (not raw 1,000,000)\n",
        "       - Position Value / Initial Balance\n",
        "       - All values bounded and stationary\n",
        "\n",
        "    Original Features (Kept):\n",
        "    - Cooldown mechanism (2 days after sell)\n",
        "    - Stop Loss (-6%)\n",
        "    - Trailing Stop (Trigger +10%, Drop -4%)\n",
        "    - Volatility-based Position Sizing\n",
        "    - Max Consecutive Losses (5 losses ‚Üí pause 3 days)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, df,\n",
        "                 initial_balance=1_000_000,\n",
        "                 commission_rate=COMMISSION_RATE,\n",
        "                 volatility_lookback=20,\n",
        "                 base_position_pct=0.5,\n",
        "                 max_consecutive_losses=5,\n",
        "                 loss_pause_days=3,\n",
        "                 risk_penalty_factor=100):\n",
        "\n",
        "        super(StockTradingEnvElite, self).__init__()\n",
        "\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.initial_balance = initial_balance\n",
        "        self.commission_rate = commission_rate  # üÜï Transaction Cost\n",
        "        self.risk_penalty_factor = risk_penalty_factor  # üÜï For Sharpe-like reward\n",
        "\n",
        "        # Action & Observation Space\n",
        "        self.action_space = spaces.Discrete(3)  # 0=Hold, 1=Buy, 2=Sell\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=-np.inf, high=np.inf, shape=(12,), dtype=np.float32\n",
        "        )\n",
        "\n",
        "        # Volatility-based Sizing Parameters\n",
        "        self.volatility_lookback = volatility_lookback\n",
        "        self.base_position_pct = base_position_pct\n",
        "\n",
        "        # Max Consecutive Losses Parameters\n",
        "        self.max_consecutive_losses = max_consecutive_losses\n",
        "        self.loss_pause_days = loss_pause_days\n",
        "\n",
        "        # Precompute volatility\n",
        "        self._precompute_volatility()\n",
        "\n",
        "        self.reset()\n",
        "\n",
        "    def _precompute_volatility(self):\n",
        "        \"\"\"Precompute rolling volatility for position sizing\"\"\"\n",
        "        prices = self.df['Close'].values\n",
        "        returns = np.diff(prices) / prices[:-1]\n",
        "        returns = np.insert(returns, 0, 0)\n",
        "\n",
        "        self.volatility = pd.Series(returns).rolling(\n",
        "            window=self.volatility_lookback,\n",
        "            min_periods=5\n",
        "        ).std().fillna(0.02).values\n",
        "\n",
        "        vol_mean = np.mean(self.volatility[self.volatility > 0])\n",
        "        vol_std = np.std(self.volatility[self.volatility > 0])\n",
        "\n",
        "        if vol_std > 0:\n",
        "            self.vol_multiplier = 1 - (self.volatility - vol_mean) / (2 * vol_std)\n",
        "            self.vol_multiplier = np.clip(self.vol_multiplier, 0.3, 1.0)\n",
        "        else:\n",
        "            self.vol_multiplier = np.ones(len(self.df)) * 0.5\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.current_step = 0\n",
        "\n",
        "        # Random initial position (50% chance)\n",
        "        if np.random.rand() < 0.5:\n",
        "            self.balance = self.initial_balance\n",
        "            self.shares_held = 0\n",
        "            self.avg_cost = 0.0\n",
        "            self.highest_price = 0.0\n",
        "        else:\n",
        "            start_price = self.df.iloc[0]['Close']\n",
        "            invest_pct = np.random.uniform(0.2, 0.8)\n",
        "            cash_invested = self.initial_balance * invest_pct\n",
        "            self.shares_held = int(cash_invested // start_price)\n",
        "            cost = self.shares_held * start_price\n",
        "            fee = cost * self.commission_rate  # üÜï Include fee in initial position\n",
        "            self.balance = self.initial_balance - cost - fee\n",
        "            self.avg_cost = start_price * (1 + self.commission_rate)  # üÜï Avg cost includes fee\n",
        "            self.highest_price = start_price\n",
        "\n",
        "        # Portfolio tracking\n",
        "        self.prev_portfolio_value = self._get_portfolio_value()\n",
        "\n",
        "        # Cooldown\n",
        "        self.cooldown = 0\n",
        "\n",
        "        # Consecutive Losses Tracking\n",
        "        self.consecutive_losses = 0\n",
        "        self.loss_pause_counter = 0\n",
        "\n",
        "        # Statistics\n",
        "        self.total_trades = 0\n",
        "        self.winning_trades = 0\n",
        "        self.losing_trades = 0\n",
        "        self.pause_triggered_count = 0\n",
        "        self.total_commission_paid = 0  # üÜï Track total fees\n",
        "\n",
        "        return self._next_observation(), {}\n",
        "\n",
        "    def _get_portfolio_value(self):\n",
        "        \"\"\"Calculate current portfolio value (Mark-to-Market)\"\"\"\n",
        "        current_price = self.df.iloc[self.current_step]['Close']\n",
        "        return self.balance + (self.shares_held * current_price)\n",
        "\n",
        "    def _get_current_volatility(self):\n",
        "        \"\"\"Get current volatility multiplier for position sizing\"\"\"\n",
        "        return self.vol_multiplier[min(self.current_step, len(self.vol_multiplier) - 1)]\n",
        "\n",
        "    def _next_observation(self):\n",
        "        \"\"\"\n",
        "        üÜï ELITE FIX 3: Normalized Observations\n",
        "\n",
        "        All values are normalized relative to initial balance\n",
        "        or bounded to reasonable ranges\n",
        "        \"\"\"\n",
        "        obs = self.df.iloc[self.current_step]\n",
        "        current_price = obs['Close']\n",
        "        current_vol = self._get_current_volatility()\n",
        "        portfolio_value = self._get_portfolio_value()\n",
        "\n",
        "        return np.array([\n",
        "            # Market Indicators (already normalized 0-1 or small range)\n",
        "            obs.get('Macro_Signal', 0),\n",
        "            obs.get('DL_Signal', 0.5),\n",
        "            obs.get('Tech_Signal', 0),\n",
        "            obs.get('ADX', 25) / 100.0,\n",
        "            obs.get('RSI', 50) / 100.0,\n",
        "            obs.get('MACD', 0) / 10.0,\n",
        "\n",
        "            # üÜï FIX 3: Normalized Portfolio State\n",
        "            self.balance / self.initial_balance,  # Cash ratio (0-1+)\n",
        "            (self.shares_held * current_price) / self.initial_balance,  # Position ratio\n",
        "            portfolio_value / self.initial_balance,  # Total portfolio ratio\n",
        "\n",
        "            # Risk Management State\n",
        "            current_vol,  # Volatility multiplier (0.3-1.0)\n",
        "            self.consecutive_losses / self.max_consecutive_losses,  # Loss streak (0-1)\n",
        "            self.loss_pause_counter / self.loss_pause_days  # Pause counter (0-1)\n",
        "        ], dtype=np.float32)\n",
        "\n",
        "    def _calculate_position_size(self):\n",
        "        \"\"\"Volatility-based Position Sizing\"\"\"\n",
        "        vol_mult = self._get_current_volatility()\n",
        "        position_pct = self.base_position_pct * vol_mult\n",
        "        return np.clip(position_pct, 0.15, 0.70)\n",
        "\n",
        "    def step(self, action):\n",
        "        current_price = self.df.iloc[self.current_step]['Close']\n",
        "        obs = self.df.iloc[self.current_step]\n",
        "\n",
        "        force_sell = False\n",
        "        reason = \"\"\n",
        "\n",
        "        # ============================================================\n",
        "        # CHECK: Max Consecutive Losses Pause\n",
        "        # ============================================================\n",
        "        if self.loss_pause_counter > 0:\n",
        "            self.loss_pause_counter -= 1\n",
        "            action = 0  # Force Hold\n",
        "            if self.loss_pause_counter == 0:\n",
        "                self.consecutive_losses = 0\n",
        "\n",
        "        # ============================================================\n",
        "        # CHECK: Risk Management (Stop Loss / Trailing Stop)\n",
        "        # ============================================================\n",
        "        if self.shares_held > 0:\n",
        "            if current_price > self.highest_price:\n",
        "                self.highest_price = current_price\n",
        "\n",
        "            # üÜï PnL calculation considers avg_cost (which includes fees)\n",
        "            pnl_pct = (current_price - self.avg_cost) / self.avg_cost if self.avg_cost > 0 else 0\n",
        "\n",
        "            # Hard Stop Loss (-6%)\n",
        "            if pnl_pct <= -0.06:\n",
        "                force_sell = True\n",
        "                reason = \"SL\"\n",
        "\n",
        "            # Trailing Stop (Trigger > +10%, Drop -4%)\n",
        "            if pnl_pct > 0.10:\n",
        "                drop = (self.highest_price - current_price) / self.highest_price\n",
        "                if drop > 0.04:\n",
        "                    force_sell = True\n",
        "                    reason = \"TRAIL\"\n",
        "\n",
        "        if force_sell:\n",
        "            action = 2\n",
        "\n",
        "        # ============================================================\n",
        "        # CHECK: Cooldown (after sell)\n",
        "        # ============================================================\n",
        "        if self.cooldown > 0:\n",
        "            if action == 1:\n",
        "                action = 0\n",
        "            self.cooldown -= 1\n",
        "\n",
        "        # ============================================================\n",
        "        # EXECUTE ACTION\n",
        "        # ============================================================\n",
        "\n",
        "        # ----- BUY -----\n",
        "        if action == 1 and self.loss_pause_counter == 0:\n",
        "            can_buy = False\n",
        "            rsi = obs.get('RSI', 50)\n",
        "            adx = obs.get('ADX', 0)\n",
        "\n",
        "            # Momentum Rule\n",
        "            if adx > 25 and rsi < 75:\n",
        "                can_buy = True\n",
        "            elif rsi < 45:\n",
        "                can_buy = True\n",
        "\n",
        "            if can_buy:\n",
        "                position_pct = self._calculate_position_size()\n",
        "                budget = self.balance * position_pct\n",
        "\n",
        "                # üÜï FIX 2: Calculate cost WITH commission\n",
        "                max_shares = int(budget // (current_price * (1 + self.commission_rate)))\n",
        "\n",
        "                if max_shares > 0:\n",
        "                    cost = max_shares * current_price\n",
        "                    fee = cost * self.commission_rate  # üÜï Commission\n",
        "                    total_cost = cost + fee\n",
        "\n",
        "                    if self.balance >= total_cost:\n",
        "                        # Update average cost (includes fee per share)\n",
        "                        new_total_shares = self.shares_held + max_shares\n",
        "                        new_total_cost = (self.shares_held * self.avg_cost) + total_cost\n",
        "                        self.avg_cost = new_total_cost / new_total_shares\n",
        "\n",
        "                        self.balance -= total_cost\n",
        "                        self.shares_held += max_shares\n",
        "                        self.highest_price = current_price\n",
        "                        self.total_trades += 1\n",
        "                        self.total_commission_paid += fee  # üÜï Track fees\n",
        "\n",
        "                        # üÜï FIX 1: NO arbitrary reward for buying\n",
        "                        # (reward is calculated based on portfolio change)\n",
        "\n",
        "        # ----- SELL -----\n",
        "        elif action == 2 and self.shares_held > 0:\n",
        "            revenue_gross = self.shares_held * current_price\n",
        "            fee = revenue_gross * self.commission_rate  # üÜï Commission\n",
        "            revenue_net = revenue_gross - fee\n",
        "\n",
        "            # Calculate actual PnL (after fees)\n",
        "            total_cost = self.shares_held * self.avg_cost\n",
        "            pnl = revenue_net - total_cost\n",
        "            pnl_pct = pnl / total_cost if total_cost > 0 else 0\n",
        "\n",
        "            self.balance += revenue_net  # üÜï Net of fees\n",
        "            self.shares_held = 0\n",
        "            self.avg_cost = 0\n",
        "            self.highest_price = 0\n",
        "            self.cooldown = 2\n",
        "            self.total_trades += 1\n",
        "            self.total_commission_paid += fee  # üÜï Track fees\n",
        "\n",
        "            # Track win/loss\n",
        "            if pnl > 0:\n",
        "                self.winning_trades += 1\n",
        "                self.consecutive_losses = 0\n",
        "            else:\n",
        "                self.losing_trades += 1\n",
        "                self.consecutive_losses += 1\n",
        "\n",
        "            # üÜï FIX 1: NO arbitrary rewards like +2.0 for trailing stop\n",
        "            # The portfolio return already captures the profit\n",
        "\n",
        "            # Check: Trigger Loss Pause\n",
        "            if self.consecutive_losses >= self.max_consecutive_losses:\n",
        "                self.loss_pause_counter = self.loss_pause_days\n",
        "                self.pause_triggered_count += 1\n",
        "\n",
        "        # ============================================================\n",
        "        # STEP FORWARD & CALCULATE REWARD\n",
        "        # ============================================================\n",
        "        self.current_step += 1\n",
        "        done = self.current_step >= len(self.df) - 1\n",
        "\n",
        "        # üÜï FIX 1: Risk-Adjusted Reward (Sharpe-like)\n",
        "        current_portfolio_value = self._get_portfolio_value()\n",
        "\n",
        "        # Use Log Return (stationary, additive)\n",
        "        if self.prev_portfolio_value > 0:\n",
        "            portfolio_return = np.log(current_portfolio_value / self.prev_portfolio_value)\n",
        "        else:\n",
        "            portfolio_return = 0\n",
        "\n",
        "        # Risk Penalty: Penalize volatility (large returns = high variance = bad)\n",
        "        # This approximates Sharpe Ratio optimization\n",
        "        risk_penalty = (portfolio_return ** 2) * self.risk_penalty_factor\n",
        "\n",
        "        # Base reward = return - volatility penalty\n",
        "        reward = portfolio_return - risk_penalty\n",
        "\n",
        "        # Small penalty for holding cash (encourage seeking alpha)\n",
        "        if self.shares_held == 0:\n",
        "            reward -= 0.0001\n",
        "\n",
        "        # Penalty for being in loss pause (reduced from 0.3)\n",
        "        if self.loss_pause_counter > 0:\n",
        "            reward -= 0.1\n",
        "\n",
        "        # Update for next step\n",
        "        self.prev_portfolio_value = current_portfolio_value\n",
        "\n",
        "        return self._next_observation(), reward, done, False, {}\n",
        "\n",
        "    def get_stats(self):\n",
        "        \"\"\"Return trading statistics\"\"\"\n",
        "        final_value = self._get_portfolio_value()\n",
        "        total_return = (final_value - self.initial_balance) / self.initial_balance\n",
        "\n",
        "        return {\n",
        "            'total_trades': self.total_trades,\n",
        "            'winning_trades': self.winning_trades,\n",
        "            'losing_trades': self.losing_trades,\n",
        "            'win_rate': self.winning_trades / max(1, self.total_trades),\n",
        "            'pause_triggered_count': self.pause_triggered_count,\n",
        "            'total_commission_paid': self.total_commission_paid,  # üÜï\n",
        "            'final_value': final_value,\n",
        "            'total_return': total_return\n",
        "        }\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 4. BACKTESTING FUNCTION\n",
        "# ============================================================\n",
        "def backtest_model(model, test_df):\n",
        "    \"\"\"Backtest trained model on test data\"\"\"\n",
        "    env = StockTradingEnvElite(test_df)\n",
        "    obs, _ = env.reset()\n",
        "\n",
        "    total_reward = 0\n",
        "    actions = []\n",
        "    net_worths = [env.initial_balance]\n",
        "    daily_returns = []\n",
        "\n",
        "    done = False\n",
        "    prev_value = env.initial_balance\n",
        "\n",
        "    while not done:\n",
        "        action, _ = model.predict(obs, deterministic=True)\n",
        "        obs, reward, done, _, _ = env.step(action)\n",
        "        total_reward += reward\n",
        "        actions.append(action)\n",
        "\n",
        "        current_value = env._get_portfolio_value()\n",
        "        net_worths.append(current_value)\n",
        "\n",
        "        # Track daily returns for Sharpe calculation\n",
        "        if prev_value > 0:\n",
        "            daily_return = (current_value - prev_value) / prev_value\n",
        "            daily_returns.append(daily_return)\n",
        "        prev_value = current_value\n",
        "\n",
        "    # Calculate metrics\n",
        "    final_value = net_worths[-1]\n",
        "    initial_value = env.initial_balance\n",
        "    total_return = (final_value - initial_value) / initial_value\n",
        "\n",
        "    # Maximum Drawdown\n",
        "    peak = net_worths[0]\n",
        "    max_drawdown = 0\n",
        "    for nw in net_worths:\n",
        "        if nw > peak:\n",
        "            peak = nw\n",
        "        drawdown = (peak - nw) / peak\n",
        "        if drawdown > max_drawdown:\n",
        "            max_drawdown = drawdown\n",
        "\n",
        "    # üÜï Sharpe Ratio (annualized)\n",
        "    if len(daily_returns) > 1:\n",
        "        avg_return = np.mean(daily_returns)\n",
        "        std_return = np.std(daily_returns)\n",
        "        if std_return > 0:\n",
        "            sharpe_ratio = (avg_return / std_return) * np.sqrt(252)\n",
        "        else:\n",
        "            sharpe_ratio = 0\n",
        "    else:\n",
        "        sharpe_ratio = 0\n",
        "\n",
        "    # üÜï Sortino Ratio (downside risk only)\n",
        "    downside_returns = [r for r in daily_returns if r < 0]\n",
        "    if len(downside_returns) > 1:\n",
        "        downside_std = np.std(downside_returns)\n",
        "        if downside_std > 0:\n",
        "            sortino_ratio = (np.mean(daily_returns) / downside_std) * np.sqrt(252)\n",
        "        else:\n",
        "            sortino_ratio = 0\n",
        "    else:\n",
        "        sortino_ratio = 0\n",
        "\n",
        "    # Get env stats\n",
        "    stats = env.get_stats()\n",
        "\n",
        "    return {\n",
        "        'Total_Return': total_return,\n",
        "        'Final_Value': final_value,\n",
        "        'Max_Drawdown': max_drawdown,\n",
        "        'Sharpe_Ratio': sharpe_ratio,  # üÜï\n",
        "        'Sortino_Ratio': sortino_ratio,  # üÜï\n",
        "        'Total_Reward': total_reward,\n",
        "        'N_Buys': sum(1 for a in actions if a == 1),\n",
        "        'N_Sells': sum(1 for a in actions if a == 2),\n",
        "        'N_Holds': sum(1 for a in actions if a == 0),\n",
        "        'N_Trades': stats['total_trades'],\n",
        "        'Win_Rate': stats['win_rate'],\n",
        "        'Pause_Triggered': stats['pause_triggered_count'],\n",
        "        'Total_Commission': stats['total_commission_paid']  # üÜï\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 5. MAIN TRAINING LOOP\n",
        "# ============================================================\n",
        "print(\"=\" * 70)\n",
        "print(\"ü§ñ BLOCK 7: PPO Training (ELITE VERSION V3)\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\"\"\n",
        "üÜï ELITE FIXES (Based on Academic Literature):\n",
        "\n",
        "   ‚úÖ FIX 1: Risk-Adjusted Reward\n",
        "      - Log Returns (stationary, additive)\n",
        "      - Volatility Penalty (approximates Sharpe Ratio)\n",
        "      - NO arbitrary point rewards (+2.0, +0.1)\n",
        "\n",
        "   ‚úÖ FIX 2: Transaction Costs\n",
        "      - 0.16% commission on Buy AND Sell\n",
        "      - Prevents unrealistic high-frequency trading\n",
        "\n",
        "   ‚úÖ FIX 3: Normalized Observations\n",
        "      - Balance / Initial_Balance (not raw 1,000,000)\n",
        "      - Position_Value / Initial_Balance\n",
        "      - All values bounded and stationary\n",
        "\n",
        "üîÑ Rolling Window Configuration:\n",
        "   - Window 1: Train [2015-2018] ‚Üí Test [2019]\n",
        "   - Window 2: Train [2016-2019] ‚Üí Test [2020]\n",
        "   - Window 3: Train [2017-2020] ‚Üí Test [2021]\n",
        "   - Window 4: Train [2018-2021] ‚Üí Test [2022]\n",
        "   - Window 5: Train [2019-2022] ‚Üí Test [2023]\n",
        "   - Window 6: Train [2020-2023] ‚Üí Test [2024]\n",
        "   - Window 7: Train [2021-2024] ‚Üí Test [2025]\n",
        "\n",
        "üõ°Ô∏è Risk Management:\n",
        "   - Stop Loss: -6%\n",
        "   - Trailing Stop: Trigger +10%, Drop -4%\n",
        "   - Cooldown: 2 days after sell\n",
        "   - Volatility-based Position Sizing (30-70%)\n",
        "   - Max Consecutive Losses: 5 ‚Üí Pause 3 days\n",
        "\n",
        "‚öôÔ∏è PPO Configuration:\n",
        "   - Learning Rate: 0.0003\n",
        "   - Entropy Coef: 0.01\n",
        "   - Batch Size: 64\n",
        "   - Timesteps: 50,000 per window (increased for better learning)\n",
        "\"\"\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Storage\n",
        "all_backtest_metrics = []\n",
        "\n",
        "for stock in target_stocks:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"üîπ Processing: {stock}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    stock_df = df_rl_all[df_rl_all['Stock'] == stock].copy()\n",
        "\n",
        "    if len(stock_df) < 200:\n",
        "        print(f\"‚ö†Ô∏è Skipped (insufficient data: {len(stock_df)} rows)\")\n",
        "        continue\n",
        "\n",
        "    stock_metrics = []\n",
        "\n",
        "    for train_start, train_end, test_year in ROLLING_WINDOWS:\n",
        "        train_df = stock_df[(stock_df['Year'] >= train_start) & (stock_df['Year'] <= train_end)].copy()\n",
        "        test_df = stock_df[stock_df['Year'] == test_year].copy()\n",
        "\n",
        "        if len(train_df) < 50:\n",
        "            print(f\"   ‚ö†Ô∏è Window {train_start}-{train_end} ‚Üí {test_year}: Insufficient train data\")\n",
        "            continue\n",
        "\n",
        "        if len(test_df) < 10:\n",
        "            print(f\"   ‚ö†Ô∏è Window {train_start}-{train_end} ‚Üí {test_year}: Insufficient test data\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # Create Elite environment\n",
        "            env = DummyVecEnv([lambda df=train_df: StockTradingEnvElite(\n",
        "                df,\n",
        "                commission_rate=COMMISSION_RATE,\n",
        "                volatility_lookback=20,\n",
        "                base_position_pct=0.5,\n",
        "                max_consecutive_losses=5,\n",
        "                loss_pause_days=3,\n",
        "                risk_penalty_factor=100\n",
        "            )])\n",
        "\n",
        "            model = PPO(\n",
        "                \"MlpPolicy\",\n",
        "                env,\n",
        "                verbose=0,\n",
        "                learning_rate=0.0003,\n",
        "                ent_coef=0.01,\n",
        "                batch_size=64,\n",
        "                n_steps=2048,  # üÜï Increased for better learning\n",
        "                gamma=0.99,\n",
        "                gae_lambda=0.95\n",
        "            )\n",
        "\n",
        "            # üÜï Increased timesteps for better convergence\n",
        "            model.learn(total_timesteps=50000)\n",
        "\n",
        "            # Save model\n",
        "            model_path = f\"trained_models/ppo_elite_{stock}_train{train_start}_{train_end}_test{test_year}\"\n",
        "            model.save(model_path)\n",
        "\n",
        "            # Backtest\n",
        "            metrics = backtest_model(model, test_df)\n",
        "            metrics['Stock'] = stock\n",
        "            metrics['Train_Period'] = f\"{train_start}-{train_end}\"\n",
        "            metrics['Test_Year'] = test_year\n",
        "            metrics['Train_Samples'] = len(train_df)\n",
        "            metrics['Test_Samples'] = len(test_df)\n",
        "\n",
        "            stock_metrics.append(metrics)\n",
        "            all_backtest_metrics.append(metrics)\n",
        "\n",
        "            print(f\"   ‚úÖ Window {train_start}-{train_end} ‚Üí {test_year}: \"\n",
        "                  f\"Return={metrics['Total_Return']:+.2%} | Sharpe={metrics['Sharpe_Ratio']:.2f} | \"\n",
        "                  f\"MDD={metrics['Max_Drawdown']:.2%} | Commission={metrics['Total_Commission']:,.0f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ùå Window {train_start}-{train_end} ‚Üí {test_year}: Error - {e}\")\n",
        "\n",
        "    # Summary for this stock\n",
        "    if stock_metrics:\n",
        "        avg_return = np.mean([m['Total_Return'] for m in stock_metrics])\n",
        "        avg_sharpe = np.mean([m['Sharpe_Ratio'] for m in stock_metrics])\n",
        "        avg_mdd = np.mean([m['Max_Drawdown'] for m in stock_metrics])\n",
        "        total_commission = sum([m['Total_Commission'] for m in stock_metrics])\n",
        "\n",
        "        print(f\"\\n   üìä {stock} Average: Return={avg_return:+.2%} | Sharpe={avg_sharpe:.2f} | \"\n",
        "              f\"MDD={avg_mdd:.2%} | Total Commission={total_commission:,.0f}\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 6. OVERALL SUMMARY\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"üìä OVERALL PERFORMANCE SUMMARY (ELITE V3)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "if all_backtest_metrics:\n",
        "    df_metrics = pd.DataFrame(all_backtest_metrics)\n",
        "\n",
        "    # Summary by Test Year\n",
        "    print(\"\\nüìÖ Performance by Test Year:\")\n",
        "    print(\"-\" * 80)\n",
        "    year_summary = df_metrics.groupby('Test_Year').agg({\n",
        "        'Total_Return': ['mean', 'std'],\n",
        "        'Sharpe_Ratio': 'mean',\n",
        "        'Max_Drawdown': 'mean',\n",
        "        'Win_Rate': 'mean',\n",
        "        'Total_Commission': 'sum'\n",
        "    }).round(4)\n",
        "    print(year_summary.to_string())\n",
        "\n",
        "    # Summary by Stock\n",
        "    print(\"\\nüìà Performance by Stock:\")\n",
        "    print(\"-\" * 80)\n",
        "    stock_summary = df_metrics.groupby('Stock').agg({\n",
        "        'Total_Return': 'mean',\n",
        "        'Sharpe_Ratio': 'mean',\n",
        "        'Max_Drawdown': 'mean',\n",
        "        'Win_Rate': 'mean',\n",
        "        'Total_Commission': 'sum'\n",
        "    }).round(4).sort_values('Sharpe_Ratio', ascending=False)  # üÜï Sort by Sharpe\n",
        "    print(stock_summary.to_string())\n",
        "\n",
        "    # Overall Average\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"üéØ OVERALL AVERAGE PERFORMANCE\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"\"\"\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ                        ELITE V3 RESULTS                                 ‚îÇ\n",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "‚îÇ   ‚Ä¢ Average Return:        {df_metrics['Total_Return'].mean():>+10.2%}                            ‚îÇ\n",
        "‚îÇ   ‚Ä¢ Std Dev Return:        {df_metrics['Total_Return'].std():>10.2%}                            ‚îÇ\n",
        "‚îÇ   ‚Ä¢ Average Sharpe Ratio:  {df_metrics['Sharpe_Ratio'].mean():>10.2f}                            ‚îÇ\n",
        "‚îÇ   ‚Ä¢ Average Sortino Ratio: {df_metrics['Sortino_Ratio'].mean():>10.2f}                            ‚îÇ\n",
        "‚îÇ   ‚Ä¢ Average Max Drawdown:  {df_metrics['Max_Drawdown'].mean():>10.2%}                            ‚îÇ\n",
        "‚îÇ   ‚Ä¢ Average Win Rate:      {df_metrics['Win_Rate'].mean():>10.1%}                            ‚îÇ\n",
        "‚îÇ   ‚Ä¢ Total Commission Paid: {df_metrics['Total_Commission'].sum():>10,.0f} THB                     ‚îÇ\n",
        "‚îÇ   ‚Ä¢ Win Rate (Return>0):   {(df_metrics['Total_Return'] > 0).mean():>10.1%}                            ‚îÇ\n",
        "‚îÇ   ‚Ä¢ Total Test Windows:    {len(df_metrics):>10d}                                   ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "\"\"\")\n",
        "\n",
        "    # Best and Worst (by Sharpe, not just Return)\n",
        "    best_sharpe = df_metrics.loc[df_metrics['Sharpe_Ratio'].idxmax()]\n",
        "    worst_sharpe = df_metrics.loc[df_metrics['Sharpe_Ratio'].idxmin()]\n",
        "    best_return = df_metrics.loc[df_metrics['Total_Return'].idxmax()]\n",
        "\n",
        "    print(f\"   üèÜ Best Sharpe:  {best_sharpe['Stock']} ({best_sharpe['Train_Period']} ‚Üí {best_sharpe['Test_Year']}): {best_sharpe['Sharpe_Ratio']:.2f}\")\n",
        "    print(f\"   üèÜ Best Return:  {best_return['Stock']} ({best_return['Train_Period']} ‚Üí {best_return['Test_Year']}): {best_return['Total_Return']:+.2%}\")\n",
        "    print(f\"   üíÄ Worst Sharpe: {worst_sharpe['Stock']} ({worst_sharpe['Train_Period']} ‚Üí {worst_sharpe['Test_Year']}): {worst_sharpe['Sharpe_Ratio']:.2f}\")\n",
        "\n",
        "    # Export\n",
        "    outfile = \"PPO_Backtest_Results_Elite_V3.xlsx\"\n",
        "    df_metrics.to_excel(outfile, index=False)\n",
        "    print(f\"\\nüíæ Results saved to: {outfile}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"‚úÖ BLOCK 7 COMPLETED: PPO Elite V3 (Risk-Adjusted + Transaction Costs)\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ============================================================\n",
        "# üìö LITERATURE-BASED REWARD (Approximated Sharpe)\n",
        "# Source: Moody & Saffell (2001) Logic\n",
        "# ============================================================\n",
        "\n",
        "# 1. Calculate Portfolio Value (Mark-to-Market)\n",
        "#    (Must include cash + shares * current_price)\n",
        "current_portfolio_value = self.balance + (self.shares_held * current_price)\n",
        "\n",
        "# 2. Calculate LOG RETURN (Stationary Input)\n",
        "#    We use Log Return because it handles compounding correctly.\n",
        "#    Formula: ln(Current_Value / Previous_Value)\n",
        "portfolio_return = np.log(current_portfolio_value / self.prev_net_worth)\n",
        "\n",
        "# 3. The \"Risk Penalty\" (The Magic Sauce)\n",
        "#    We penalize the SQUARE of the return.\n",
        "#    Why? Large swings (both up and down) increase variance.\n",
        "#    We want small, consistent gains, not huge spikes.\n",
        "risk_penalty = (portfolio_return ** 2) * 100  # 100 is a scaling factor (Lambda)\n",
        "\n",
        "# 4. Final Reward\n",
        "#    Reward = Return - (Risk * Lambda)\n",
        "reward = portfolio_return - risk_penalty\n",
        "\n",
        "# 5. (Optional) Small \"Existing Costs\"\n",
        "#    Keep your penalty for pausing, but keep it small relative to the return.\n",
        "if self.loss_pause_counter > 0:\n",
        "    reward -= 0.005 # Small drag, not a wall\n",
        "\n",
        "# Update for next step\n",
        "self.prev_net_worth = current_portfolio_value"
      ],
      "metadata": {
        "id": "I-Svj1D4FmU0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyqSl5NnABSu"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# üèÜ BLOCK 8: Evaluation & Prediction (UPGRADED)\n",
        "#    Features:\n",
        "#    - Star Rating System\n",
        "#    - üÜï Performance Metrics: Sharpe Ratio, Max Drawdown, Calmar Ratio\n",
        "#    - üÜï Benchmark Comparison vs Buy-and-Hold\n",
        "#    - üÜï Rolling Window Evaluation\n",
        "# ============================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "import os\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "from stable_baselines3 import PPO\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ============================================================\n",
        "# 1. CONFIGURATION\n",
        "# ============================================================\n",
        "\n",
        "# [\n",
        "#     \"AAV\", \"AEONTS\", \"AOT\", \"BA\", \"BBL\", \"BCH\", \"BDMS\", \"BEM\", \"BH\", \"BTS\",\n",
        "#     \"CHG\", \"JMT\", \"KBANK\", \"KKP\", \"KTB\", \"KTC\", \"PR9\", \"PRM\", \"RCL\", \"SAWAD\",\n",
        "#     \"TCAP\", \"TISCO\", \"TTB\"\n",
        "# ]\n",
        "\n",
        "stock_symbols = [\"BBL\",\"KBANK\",\"KKP\",\"KTB\",\"TCAP\",\"TISCO\",\"TTB\"]\n",
        "\n",
        "INITIAL_BALANCE = 1_000_000\n",
        "COMMISSION = 0.00157\n",
        "RISK_FREE_RATE = 0.02  # 2% annual risk-free rate (Thai government bond ~2%)\n",
        "TRADING_DAYS_PER_YEAR = 245  # Thai market\n",
        "\n",
        "# Rolling Window Configuration\n",
        "ROLLING_WINDOWS = [\n",
        "    (2015, 2018, 2019),\n",
        "    (2016, 2019, 2020),\n",
        "    (2017, 2020, 2021),\n",
        "    (2018, 2021, 2022),\n",
        "    (2019, 2022, 2023),\n",
        "    (2020, 2023, 2024),\n",
        "    (2021, 2024, 2025),\n",
        "]\n",
        "\n",
        "# ============================================================\n",
        "# 2. LOAD DATA\n",
        "# ============================================================\n",
        "try:\n",
        "    df_rl_all = pd.read_excel(\"Final_RL_Input_Ready.xlsx\")\n",
        "    df_rl_all['Date'] = pd.to_datetime(df_rl_all['Date'])\n",
        "    df_rl_all['Year'] = df_rl_all['Date'].dt.year\n",
        "except:\n",
        "    raise RuntimeError(\"‚ùå Missing Data: Final_RL_Input_Ready.xlsx\")\n",
        "\n",
        "# ============================================================\n",
        "# 3. TRADING ENVIRONMENT\n",
        "# ============================================================\n",
        "class StockTradingEnv(gym.Env):\n",
        "    \"\"\"Trading environment matching Block 7 V2\"\"\"\n",
        "    def __init__(self, df):\n",
        "        super().__init__()\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.balance = INITIAL_BALANCE\n",
        "        self.shares_held = 0\n",
        "        self.current_step = 0\n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(11,), dtype=np.float32)\n",
        "        self.action_space = spaces.Discrete(3)\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        self.current_step = 0\n",
        "        self.balance = INITIAL_BALANCE\n",
        "        self.shares_held = 0\n",
        "        return self._next_observation(), {}\n",
        "\n",
        "    def _next_observation(self):\n",
        "        if self.current_step >= len(self.df):\n",
        "            self.current_step = len(self.df) - 1\n",
        "        obs = self.df.iloc[self.current_step]\n",
        "        return np.array([\n",
        "            obs.get('Macro_Signal', 0),\n",
        "            obs.get('DL_Signal', 0.5),\n",
        "            obs.get('Tech_Signal', 0),\n",
        "            obs.get('ADX', 25) / 100.0,\n",
        "            self.balance / 1_000_000.0,\n",
        "            (self.shares_held * obs['Close']) / 1_000_000.0,\n",
        "            obs.get('RSI', 50) / 100.0,\n",
        "            obs.get('MACD', 0) / 10.0,\n",
        "            0.5,  # Volatility placeholder\n",
        "            0.0,  # Consecutive losses placeholder\n",
        "            0.0   # Pause counter placeholder\n",
        "        ], dtype=np.float32)\n",
        "\n",
        "    def step(self, action):\n",
        "        self.current_step += 1\n",
        "        done = self.current_step >= len(self.df) - 1\n",
        "        return self._next_observation(), 0, done, False, {}\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 4. PERFORMANCE METRICS CALCULATOR\n",
        "# ============================================================\n",
        "class PerformanceMetrics:\n",
        "    \"\"\"\n",
        "    Calculate comprehensive trading performance metrics\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_returns(equity_curve):\n",
        "        \"\"\"Calculate daily returns from equity curve\"\"\"\n",
        "        equity = np.array(equity_curve)\n",
        "        returns = np.diff(equity) / equity[:-1]\n",
        "        return returns\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_sharpe_ratio(returns, risk_free_rate=RISK_FREE_RATE,\n",
        "                                trading_days=TRADING_DAYS_PER_YEAR):\n",
        "        \"\"\"\n",
        "        Calculate annualized Sharpe Ratio\n",
        "\n",
        "        Formula: Sharpe = (Mean Return - Risk Free Rate) / Std Dev √ó ‚àö(Trading Days)\n",
        "        \"\"\"\n",
        "        if len(returns) < 2:\n",
        "            return 0.0\n",
        "\n",
        "        # Daily risk-free rate\n",
        "        daily_rf = risk_free_rate / trading_days\n",
        "\n",
        "        # Excess returns\n",
        "        excess_returns = returns - daily_rf\n",
        "\n",
        "        # Sharpe Ratio\n",
        "        if np.std(excess_returns) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        sharpe = np.mean(excess_returns) / np.std(excess_returns)\n",
        "\n",
        "        # Annualize\n",
        "        sharpe_annualized = sharpe * np.sqrt(trading_days)\n",
        "\n",
        "        return sharpe_annualized\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_sortino_ratio(returns, risk_free_rate=RISK_FREE_RATE,\n",
        "                                 trading_days=TRADING_DAYS_PER_YEAR):\n",
        "        \"\"\"\n",
        "        Calculate annualized Sortino Ratio (downside risk only)\n",
        "\n",
        "        Formula: Sortino = (Mean Return - Risk Free Rate) / Downside Std Dev √ó ‚àö(Trading Days)\n",
        "        \"\"\"\n",
        "        if len(returns) < 2:\n",
        "            return 0.0\n",
        "\n",
        "        daily_rf = risk_free_rate / trading_days\n",
        "        excess_returns = returns - daily_rf\n",
        "\n",
        "        # Downside returns only\n",
        "        downside_returns = excess_returns[excess_returns < 0]\n",
        "\n",
        "        if len(downside_returns) == 0 or np.std(downside_returns) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        sortino = np.mean(excess_returns) / np.std(downside_returns)\n",
        "        sortino_annualized = sortino * np.sqrt(trading_days)\n",
        "\n",
        "        return sortino_annualized\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_max_drawdown(equity_curve):\n",
        "        \"\"\"\n",
        "        Calculate Maximum Drawdown (MDD)\n",
        "\n",
        "        Formula: MDD = (Peak - Trough) / Peak\n",
        "        \"\"\"\n",
        "        equity = np.array(equity_curve)\n",
        "        peak = equity[0]\n",
        "        max_dd = 0.0\n",
        "\n",
        "        for value in equity:\n",
        "            if value > peak:\n",
        "                peak = value\n",
        "            drawdown = (peak - value) / peak\n",
        "            if drawdown > max_dd:\n",
        "                max_dd = drawdown\n",
        "\n",
        "        return max_dd\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_calmar_ratio(total_return, max_drawdown, years=1):\n",
        "        \"\"\"\n",
        "        Calculate Calmar Ratio\n",
        "\n",
        "        Formula: Calmar = Annualized Return / Max Drawdown\n",
        "        \"\"\"\n",
        "        if max_drawdown == 0:\n",
        "            return 0.0\n",
        "\n",
        "        annualized_return = total_return / years if years > 0 else total_return\n",
        "        calmar = annualized_return / max_drawdown\n",
        "\n",
        "        return calmar\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_win_rate(trades):\n",
        "        \"\"\"Calculate win rate from list of trade PnLs\"\"\"\n",
        "        if len(trades) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        wins = sum(1 for t in trades if t > 0)\n",
        "        return wins / len(trades)\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_profit_factor(trades):\n",
        "        \"\"\"\n",
        "        Calculate Profit Factor\n",
        "\n",
        "        Formula: Profit Factor = Sum(Winning Trades) / |Sum(Losing Trades)|\n",
        "        \"\"\"\n",
        "        if len(trades) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        gross_profit = sum(t for t in trades if t > 0)\n",
        "        gross_loss = abs(sum(t for t in trades if t < 0))\n",
        "\n",
        "        if gross_loss == 0:\n",
        "            return float('inf') if gross_profit > 0 else 0.0\n",
        "\n",
        "        return gross_profit / gross_loss\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_all_metrics(equity_curve, trade_pnls, years=1):\n",
        "        \"\"\"Calculate all metrics at once\"\"\"\n",
        "        returns = PerformanceMetrics.calculate_returns(equity_curve)\n",
        "\n",
        "        total_return = (equity_curve[-1] - equity_curve[0]) / equity_curve[0]\n",
        "        max_dd = PerformanceMetrics.calculate_max_drawdown(equity_curve)\n",
        "\n",
        "        return {\n",
        "            'Total_Return': total_return,\n",
        "            'Total_Return_Pct': total_return * 100,\n",
        "            'Annualized_Return': (total_return / years) * 100 if years > 0 else total_return * 100,\n",
        "            'Sharpe_Ratio': PerformanceMetrics.calculate_sharpe_ratio(returns),\n",
        "            'Sortino_Ratio': PerformanceMetrics.calculate_sortino_ratio(returns),\n",
        "            'Max_Drawdown': max_dd,\n",
        "            'Max_Drawdown_Pct': max_dd * 100,\n",
        "            'Calmar_Ratio': PerformanceMetrics.calculate_calmar_ratio(total_return, max_dd, years),\n",
        "            'Win_Rate': PerformanceMetrics.calculate_win_rate(trade_pnls),\n",
        "            'Win_Rate_Pct': PerformanceMetrics.calculate_win_rate(trade_pnls) * 100,\n",
        "            'Profit_Factor': PerformanceMetrics.calculate_profit_factor(trade_pnls),\n",
        "            'Total_Trades': len(trade_pnls),\n",
        "            'Final_Value': equity_curve[-1]\n",
        "        }\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 5. BACKTEST WITH DETAILED TRACKING\n",
        "# ============================================================\n",
        "def backtest_with_metrics(df_test, model_path):\n",
        "    \"\"\"\n",
        "    Backtest with detailed equity tracking for metrics calculation\n",
        "\n",
        "    Returns:\n",
        "        dict: All performance metrics + equity curve\n",
        "    \"\"\"\n",
        "    env = StockTradingEnv(df_test)\n",
        "    model = PPO.load(model_path)\n",
        "    prices = df_test['Close'].values\n",
        "    dates = df_test['Date'].values\n",
        "\n",
        "    cash = INITIAL_BALANCE\n",
        "    shares = 0\n",
        "    avg_cost = 0.0\n",
        "    highest_price = 0.0\n",
        "    cooldown = 0\n",
        "    consecutive_losses = 0\n",
        "    loss_pause_counter = 0\n",
        "\n",
        "    # Tracking\n",
        "    equity_curve = [INITIAL_BALANCE]\n",
        "    trade_pnls = []\n",
        "    actions_taken = []\n",
        "\n",
        "    obs, _ = env.reset()\n",
        "\n",
        "    for i in range(len(prices) - 1):\n",
        "        action, _ = model.predict(obs, deterministic=True)\n",
        "        curr_price = prices[i]\n",
        "\n",
        "        # Loss Pause Check\n",
        "        if loss_pause_counter > 0:\n",
        "            action = 0\n",
        "            loss_pause_counter -= 1\n",
        "            if loss_pause_counter == 0:\n",
        "                consecutive_losses = 0\n",
        "\n",
        "        # Risk Check\n",
        "        force_sell = False\n",
        "        reason = \"\"\n",
        "\n",
        "        if shares > 0:\n",
        "            if curr_price > highest_price:\n",
        "                highest_price = curr_price\n",
        "            pnl_pct = (curr_price - avg_cost) / avg_cost if avg_cost > 0 else 0\n",
        "\n",
        "            if pnl_pct <= -0.06:\n",
        "                force_sell = True\n",
        "                reason = \"SL\"\n",
        "            if pnl_pct > 0.10:\n",
        "                if (highest_price - curr_price) / highest_price > 0.04:\n",
        "                    force_sell = True\n",
        "                    reason = \"TRAIL\"\n",
        "\n",
        "        if force_sell:\n",
        "            action = 2\n",
        "\n",
        "        # Cooldown Check\n",
        "        if cooldown > 0:\n",
        "            if action == 1:\n",
        "                action = 0\n",
        "            cooldown -= 1\n",
        "\n",
        "        # Execute Action\n",
        "        if action == 1 and cash > curr_price and loss_pause_counter == 0:\n",
        "            row = df_test.iloc[i]\n",
        "            can_buy = False\n",
        "\n",
        "            if (row.get('ADX', 0) > 25 and row.get('RSI', 50) < 75) or row.get('RSI', 50) < 45:\n",
        "                can_buy = True\n",
        "\n",
        "            if can_buy:\n",
        "                # Volatility-based sizing (simplified)\n",
        "                position_pct = 0.5\n",
        "                budget = cash * position_pct\n",
        "                buy_amt = int(budget // (curr_price * (1 + COMMISSION)))\n",
        "\n",
        "                if buy_amt > 0:\n",
        "                    cost = buy_amt * curr_price * (1 + COMMISSION)\n",
        "                    total_shares = shares + buy_amt\n",
        "                    avg_cost = ((shares * avg_cost) + cost) / total_shares if total_shares > 0 else curr_price\n",
        "                    cash -= cost\n",
        "                    shares += buy_amt\n",
        "                    highest_price = curr_price\n",
        "                    actions_taken.append(('BUY', i, curr_price, buy_amt))\n",
        "\n",
        "        elif action == 2 and shares > 0:\n",
        "            revenue = shares * curr_price * (1 - COMMISSION)\n",
        "            pnl = revenue - (shares * avg_cost)\n",
        "            pnl_pct = pnl / (shares * avg_cost) if avg_cost > 0 else 0\n",
        "\n",
        "            trade_pnls.append(pnl)\n",
        "            actions_taken.append(('SELL', i, curr_price, shares, pnl))\n",
        "\n",
        "            cash += revenue\n",
        "            shares = 0\n",
        "            cooldown = 2\n",
        "\n",
        "            # Track consecutive losses\n",
        "            if pnl < 0:\n",
        "                consecutive_losses += 1\n",
        "                if consecutive_losses >= 5:\n",
        "                    loss_pause_counter = 3\n",
        "                    consecutive_losses = 0\n",
        "            else:\n",
        "                consecutive_losses = 0\n",
        "\n",
        "            avg_cost = 0\n",
        "            highest_price = 0\n",
        "\n",
        "        # Update equity curve\n",
        "        current_equity = cash + (shares * prices[i + 1])\n",
        "        equity_curve.append(current_equity)\n",
        "\n",
        "        obs, _, done, _, _ = env.step(action)\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    # Final value\n",
        "    final_value = cash + (shares * prices[-1])\n",
        "    if len(equity_curve) < len(prices):\n",
        "        equity_curve.append(final_value)\n",
        "\n",
        "    # Calculate years\n",
        "    days = len(df_test)\n",
        "    years = days / TRADING_DAYS_PER_YEAR\n",
        "\n",
        "    # Calculate all metrics\n",
        "    metrics = PerformanceMetrics.calculate_all_metrics(equity_curve, trade_pnls, years)\n",
        "    metrics['equity_curve'] = equity_curve\n",
        "    metrics['trade_pnls'] = trade_pnls\n",
        "    metrics['actions'] = actions_taken\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 6. BUY-AND-HOLD BENCHMARK\n",
        "# ============================================================\n",
        "def calculate_buy_and_hold(df_test):\n",
        "    \"\"\"\n",
        "    Calculate Buy-and-Hold benchmark performance\n",
        "\n",
        "    Strategy: Buy at first day, hold until last day\n",
        "    \"\"\"\n",
        "    prices = df_test['Close'].values\n",
        "\n",
        "    # Buy at first price\n",
        "    first_price = prices[0]\n",
        "    shares = int(INITIAL_BALANCE // (first_price * (1 + COMMISSION)))\n",
        "    cost = shares * first_price * (1 + COMMISSION)\n",
        "    remaining_cash = INITIAL_BALANCE - cost\n",
        "\n",
        "    # Build equity curve\n",
        "    equity_curve = []\n",
        "    for price in prices:\n",
        "        equity = remaining_cash + (shares * price)\n",
        "        equity_curve.append(equity)\n",
        "\n",
        "    # Final value (sell at last price)\n",
        "    final_value = remaining_cash + (shares * prices[-1] * (1 - COMMISSION))\n",
        "\n",
        "    # Calculate metrics\n",
        "    days = len(df_test)\n",
        "    years = days / TRADING_DAYS_PER_YEAR\n",
        "\n",
        "    # Simple trade PnL (one buy, one sell)\n",
        "    trade_pnl = final_value - INITIAL_BALANCE\n",
        "\n",
        "    metrics = PerformanceMetrics.calculate_all_metrics(equity_curve, [trade_pnl], years)\n",
        "    metrics['equity_curve'] = equity_curve\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 7. STAR RATING LOGIC\n",
        "# ============================================================\n",
        "def get_star_rating(action, tech_score, sharpe_ratio=0):\n",
        "    \"\"\"Enhanced star rating with Sharpe consideration\"\"\"\n",
        "    base_rating = 3\n",
        "\n",
        "    if action == 1:  # BUY\n",
        "        if tech_score > 0.2:\n",
        "            base_rating = 5  # Strong Buy\n",
        "        else:\n",
        "            base_rating = 4  # Buy\n",
        "    elif action == 0:  # HOLD\n",
        "        base_rating = 3\n",
        "    elif action == 2:  # SELL\n",
        "        if tech_score < -0.2:\n",
        "            base_rating = 1  # Strong Sell\n",
        "        else:\n",
        "            base_rating = 2  # Sell\n",
        "\n",
        "    # Adjust based on model performance (Sharpe)\n",
        "    if sharpe_ratio > 1.5:\n",
        "        base_rating = min(5, base_rating + 1)\n",
        "    elif sharpe_ratio < 0:\n",
        "        base_rating = max(1, base_rating - 1)\n",
        "\n",
        "    return \"‚≠ê\" * base_rating\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 8. MAIN EVALUATION\n",
        "# ============================================================\n",
        "print(\"=\" * 80)\n",
        "print(\"üèÜ BLOCK 8: Evaluation & Prediction (UPGRADED)\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\"\"\n",
        "üìä Performance Metrics:\n",
        "   - Total Return (%)\n",
        "   - Annualized Return (%)\n",
        "   - Sharpe Ratio\n",
        "   - Sortino Ratio\n",
        "   - Maximum Drawdown (%)\n",
        "   - Calmar Ratio\n",
        "   - Win Rate (%)\n",
        "   - Profit Factor\n",
        "\n",
        "üìà Benchmark: Buy-and-Hold Strategy\n",
        "\"\"\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Storage\n",
        "all_results = []\n",
        "all_comparisons = []\n",
        "forecasts = []\n",
        "\n",
        "# Process each stock\n",
        "for ticker in stock_symbols:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"üîπ Evaluating: {ticker}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    try:\n",
        "        stock_df = df_rl_all[df_rl_all['Stock'] == ticker].copy()\n",
        "\n",
        "        if len(stock_df) < 100:\n",
        "            print(f\"‚ö†Ô∏è Skipped (insufficient data: {len(stock_df)} rows)\")\n",
        "            continue\n",
        "\n",
        "        stock_results = []\n",
        "\n",
        "        # Evaluate each rolling window\n",
        "        for train_start, train_end, test_year in ROLLING_WINDOWS:\n",
        "            df_test = stock_df[stock_df['Year'] == test_year].copy()\n",
        "\n",
        "            if len(df_test) < 10:\n",
        "                continue\n",
        "\n",
        "            # Model path (from Block 7 rolling window)\n",
        "            model_path = f\"trained_models/ppo_{ticker}_train{train_start}_{train_end}_test{test_year}.zip\"\n",
        "\n",
        "            # Fallback to old model path\n",
        "            if not os.path.exists(model_path):\n",
        "                model_path = f\"trained_models/ppo_{ticker}.zip\"\n",
        "\n",
        "            if not os.path.exists(model_path):\n",
        "                continue\n",
        "\n",
        "            # Run backtest\n",
        "            ai_metrics = backtest_with_metrics(df_test, model_path)\n",
        "            bh_metrics = calculate_buy_and_hold(df_test)\n",
        "\n",
        "            # Comparison\n",
        "            result = {\n",
        "                'Stock': ticker,\n",
        "                'Test_Year': test_year,\n",
        "                'Train_Period': f\"{train_start}-{train_end}\",\n",
        "\n",
        "                # AI Strategy Metrics\n",
        "                'AI_Return_%': round(ai_metrics['Total_Return_Pct'], 2),\n",
        "                'AI_Sharpe': round(ai_metrics['Sharpe_Ratio'], 2),\n",
        "                'AI_Sortino': round(ai_metrics['Sortino_Ratio'], 2),\n",
        "                'AI_MDD_%': round(ai_metrics['Max_Drawdown_Pct'], 2),\n",
        "                'AI_Calmar': round(ai_metrics['Calmar_Ratio'], 2),\n",
        "                'AI_WinRate_%': round(ai_metrics['Win_Rate_Pct'], 1),\n",
        "                'AI_ProfitFactor': round(ai_metrics['Profit_Factor'], 2),\n",
        "                'AI_Trades': ai_metrics['Total_Trades'],\n",
        "\n",
        "                # Benchmark Metrics\n",
        "                'BH_Return_%': round(bh_metrics['Total_Return_Pct'], 2),\n",
        "                'BH_Sharpe': round(bh_metrics['Sharpe_Ratio'], 2),\n",
        "                'BH_MDD_%': round(bh_metrics['Max_Drawdown_Pct'], 2),\n",
        "\n",
        "                # Comparison\n",
        "                'Return_Diff_%': round(ai_metrics['Total_Return_Pct'] - bh_metrics['Total_Return_Pct'], 2),\n",
        "                'Sharpe_Diff': round(ai_metrics['Sharpe_Ratio'] - bh_metrics['Sharpe_Ratio'], 2),\n",
        "                'MDD_Diff_%': round(bh_metrics['Max_Drawdown_Pct'] - ai_metrics['Max_Drawdown_Pct'], 2),\n",
        "                'Beat_BH': ai_metrics['Total_Return_Pct'] > bh_metrics['Total_Return_Pct']\n",
        "            }\n",
        "\n",
        "            stock_results.append(result)\n",
        "            all_results.append(result)\n",
        "\n",
        "            # Print summary\n",
        "            status = \"‚úÖ WIN\" if result['Beat_BH'] else \"‚ùå LOSS\"\n",
        "            print(f\"   {test_year}: AI={result['AI_Return_%']:+.1f}% vs BH={result['BH_Return_%']:+.1f}% \"\n",
        "                  f\"| Sharpe={result['AI_Sharpe']:.2f} | MDD={result['AI_MDD_%']:.1f}% | {status}\")\n",
        "\n",
        "        # Stock Summary\n",
        "        if stock_results:\n",
        "            avg_ai_return = np.mean([r['AI_Return_%'] for r in stock_results])\n",
        "            avg_bh_return = np.mean([r['BH_Return_%'] for r in stock_results])\n",
        "            avg_sharpe = np.mean([r['AI_Sharpe'] for r in stock_results])\n",
        "            win_count = sum(1 for r in stock_results if r['Beat_BH'])\n",
        "\n",
        "            print(f\"\\n   üìä {ticker} Summary:\")\n",
        "            print(f\"      Avg AI Return: {avg_ai_return:+.2f}%\")\n",
        "            print(f\"      Avg BH Return: {avg_bh_return:+.2f}%\")\n",
        "            print(f\"      Avg Sharpe:    {avg_sharpe:.2f}\")\n",
        "            print(f\"      Beat BH:       {win_count}/{len(stock_results)} windows\")\n",
        "\n",
        "            # Generate forecast for latest data\n",
        "            latest_df = stock_df[stock_df['Year'] == stock_df['Year'].max()].copy()\n",
        "            if len(latest_df) > 0:\n",
        "                latest_model = f\"trained_models/ppo_{ticker}.zip\"\n",
        "                if os.path.exists(latest_model):\n",
        "                    env = StockTradingEnv(latest_df)\n",
        "                    obs, _ = env.reset()\n",
        "                    env.current_step = len(latest_df) - 1\n",
        "                    obs = env._next_observation()\n",
        "\n",
        "                    model = PPO.load(latest_model)\n",
        "                    action, _ = model.predict(obs, deterministic=True)\n",
        "\n",
        "                    last_close = latest_df.iloc[-1]['Close']\n",
        "                    tech_score = latest_df.iloc[-1].get('Tech_Signal', 0)\n",
        "                    rating = get_star_rating(action, tech_score, avg_sharpe)\n",
        "\n",
        "                    act_str = \"BUY\" if action == 1 else \"SELL\" if action == 2 else \"HOLD\"\n",
        "                    forecasts.append({\n",
        "                        'Stock': ticker,\n",
        "                        'Last_Price': round(last_close, 2),\n",
        "                        'AI_Action': act_str,\n",
        "                        'Tech_Score': round(tech_score, 2),\n",
        "                        'Avg_Sharpe': round(avg_sharpe, 2),\n",
        "                        'Rating': rating\n",
        "                    })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {e}\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 9. OVERALL SUMMARY\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üìä OVERALL PERFORMANCE SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "if all_results:\n",
        "    df_results = pd.DataFrame(all_results)\n",
        "\n",
        "    # Summary by Year\n",
        "    print(\"\\nüìÖ Performance by Test Year:\")\n",
        "    print(\"-\" * 80)\n",
        "    year_summary = df_results.groupby('Test_Year').agg({\n",
        "        'AI_Return_%': 'mean',\n",
        "        'BH_Return_%': 'mean',\n",
        "        'AI_Sharpe': 'mean',\n",
        "        'AI_MDD_%': 'mean',\n",
        "        'Beat_BH': 'mean'\n",
        "    }).round(2)\n",
        "    year_summary.columns = ['AI_Return', 'BH_Return', 'Sharpe', 'MDD', 'Win_Rate']\n",
        "    print(year_summary.to_string())\n",
        "\n",
        "    # Summary by Stock\n",
        "    print(\"\\nüìà Performance by Stock:\")\n",
        "    print(\"-\" * 80)\n",
        "    stock_summary = df_results.groupby('Stock').agg({\n",
        "        'AI_Return_%': 'mean',\n",
        "        'BH_Return_%': 'mean',\n",
        "        'AI_Sharpe': 'mean',\n",
        "        'AI_MDD_%': 'mean',\n",
        "        'Beat_BH': 'mean'\n",
        "    }).round(2).sort_values('AI_Return_%', ascending=False)\n",
        "    stock_summary.columns = ['AI_Return', 'BH_Return', 'Sharpe', 'MDD', 'Win_Rate']\n",
        "    print(stock_summary.to_string())\n",
        "\n",
        "    # Overall Statistics\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"üéØ OVERALL STATISTICS\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    print(f\"\"\"\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ                        AI STRATEGY vs BUY-AND-HOLD                      ‚îÇ\n",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "‚îÇ                            ‚îÇ     AI Strategy    ‚îÇ    Buy-and-Hold      ‚îÇ\n",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "‚îÇ Average Return             ‚îÇ  {df_results['AI_Return_%'].mean():>+10.2f}%     ‚îÇ  {df_results['BH_Return_%'].mean():>+10.2f}%      ‚îÇ\n",
        "‚îÇ Median Return              ‚îÇ  {df_results['AI_Return_%'].median():>+10.2f}%     ‚îÇ  {df_results['BH_Return_%'].median():>+10.2f}%      ‚îÇ\n",
        "‚îÇ Std Dev Return             ‚îÇ  {df_results['AI_Return_%'].std():>10.2f}%     ‚îÇ  {df_results['BH_Return_%'].std():>10.2f}%      ‚îÇ\n",
        "‚îÇ Average Sharpe Ratio       ‚îÇ  {df_results['AI_Sharpe'].mean():>10.2f}       ‚îÇ  {df_results['BH_Sharpe'].mean():>10.2f}        ‚îÇ\n",
        "‚îÇ Average Max Drawdown       ‚îÇ  {df_results['AI_MDD_%'].mean():>10.2f}%     ‚îÇ  {df_results['BH_MDD_%'].mean():>10.2f}%      ‚îÇ\n",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "‚îÇ Win Rate vs Benchmark      ‚îÇ  {df_results['Beat_BH'].mean()*100:>10.1f}%     ‚îÇ        -             ‚îÇ\n",
        "‚îÇ Total Test Windows         ‚îÇ  {len(df_results):>10d}         ‚îÇ        -             ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "\"\"\")\n",
        "\n",
        "    # Best and Worst Performers\n",
        "    best = df_results.loc[df_results['AI_Return_%'].idxmax()]\n",
        "    worst = df_results.loc[df_results['AI_Return_%'].idxmin()]\n",
        "    best_sharpe = df_results.loc[df_results['AI_Sharpe'].idxmax()]\n",
        "\n",
        "    print(f\"   üèÜ Best Return:  {best['Stock']} ({best['Test_Year']}): {best['AI_Return_%']:+.2f}%\")\n",
        "    print(f\"   üíÄ Worst Return: {worst['Stock']} ({worst['Test_Year']}): {worst['AI_Return_%']:+.2f}%\")\n",
        "    print(f\"   üìà Best Sharpe:  {best_sharpe['Stock']} ({best_sharpe['Test_Year']}): {best_sharpe['AI_Sharpe']:.2f}\")\n",
        "\n",
        "    # Export detailed results\n",
        "    outfile_detailed = \"Block8_Performance_Detailed.xlsx\"\n",
        "    df_results.to_excel(outfile_detailed, index=False)\n",
        "    print(f\"\\nüíæ Detailed results saved to: {outfile_detailed}\")\n",
        "\n",
        "# ============================================================\n",
        "# 10. FORECAST OUTPUT\n",
        "# ============================================================\n",
        "if forecasts:\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"üîÆ AI FORECAST FOR TOMORROW\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    df_forecast = pd.DataFrame(forecasts)\n",
        "\n",
        "    # Sort by rating (descending)\n",
        "    df_forecast['Rating_Num'] = df_forecast['Rating'].apply(len)\n",
        "    df_forecast = df_forecast.sort_values('Rating_Num', ascending=False)\n",
        "\n",
        "    print(f\"\\n{'Stock':<10} {'Price':<10} {'Action':<8} {'Tech':<8} {'Sharpe':<8} {'Rating':<12}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    for _, row in df_forecast.iterrows():\n",
        "        print(f\"{row['Stock']:<10} {row['Last_Price']:<10.2f} {row['AI_Action']:<8} \"\n",
        "              f\"{row['Tech_Score']:<8.2f} {row['Avg_Sharpe']:<8.2f} {row['Rating']:<12}\")\n",
        "\n",
        "    # Export\n",
        "    outfile_forecast = \"Block8_AI_Forecast.xlsx\"\n",
        "    df_forecast.drop(columns=['Rating_Num']).to_excel(outfile_forecast, index=False)\n",
        "    print(f\"\\nüíæ Forecast saved to: {outfile_forecast}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"‚úÖ BLOCK 8 COMPLETED: Evaluation with Sharpe, MDD & Benchmark Comparison\")\n",
        "print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8H5OC-DGuOlN"
      },
      "source": [
        "1) Change price frequentcy from day to hour\n",
        "2) Edit Technical Block ‚úÖ\n",
        "3) optimize DL signal using validation set ‡∏õ‡∏£‡∏±‡∏ö Block 5.5 (DL Signal)  ‡πÉ‡∏´‡πâ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏∂‡πâ‡∏ô ‚úÖ\n",
        "4) ‡πÄ‡∏û‡∏¥‡πà‡∏° Feature ‡πÉ‡∏´‡∏°‡πà‡πÜ ‡πÉ‡∏ô Block 6 (‡πÄ‡∏ä‡πà‡∏ô Volume Profile, Bid/Offer) => ‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏à‡∏≤‡∏Å ‡∏û‡∏µ‡πà AIQ\n",
        "5) ‡∏à‡∏π‡∏ô Hyperparameter ‡πÉ‡∏ô Block 7\n",
        "6) ‡πÅ‡∏Å‡πâ‡πÑ‡∏ü‡∏•‡πå Macro.xlsx ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏° Data ‡∏Ç‡∏≠‡∏á 2025 ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHMk7GPeACl-"
      },
      "source": [
        "## Excluded Part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lECT28HvgcpH"
      },
      "outputs": [],
      "source": [
        "# # ============================================================\n",
        "# # ü§ñ BLOCK 7: Train PPO (Hierarchy: Macro First, DL Fallback)\n",
        "# #    Concept: Trust Macro if aligned with Price Trend.\n",
        "# #             If Macro conflicts with Price, Trust DL.\n",
        "# # ============================================================\n",
        "# import os\n",
        "# import gymnasium as gym\n",
        "# from gymnasium import spaces\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# from stable_baselines3 import PPO\n",
        "# from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "# import warnings\n",
        "\n",
        "# warnings.filterwarnings(\"ignore\")\n",
        "# os.makedirs(\"trained_models\", exist_ok=True)\n",
        "\n",
        "# # 1. ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏∏‡πâ‡∏ô\n",
        "# target_stocks = [\n",
        "#     \"AAV\", \"AEONTS\", \"AOT\", \"BA\", \"BBL\", \"BCH\", \"BDMS\", \"BEM\", \"BH\", \"BTS\",\n",
        "#     \"CHG\", \"JMT\", \"KBANK\", \"KKP\", \"KTB\", \"KTC\", \"PR9\", \"PRM\", \"RCL\", \"SAWAD\",\n",
        "#     \"TCAP\", \"TISCO\", \"TTB\"\n",
        "# ]\n",
        "\n",
        "# # 2. ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
        "# try:\n",
        "#     df_rl_all = pd.read_excel(\"Final_RL_Input_Ready.xlsx\")\n",
        "#     df_rl_all['Date'] = pd.to_datetime(df_rl_all['Date'])\n",
        "#     print(f\"‚úÖ Loaded Training Data: {len(df_rl_all)} rows\")\n",
        "# except FileNotFoundError:\n",
        "#     raise RuntimeError(\"‚ùå ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡πÑ‡∏ü‡∏•‡πå Final_RL_Input_Ready.xlsx\")\n",
        "\n",
        "# # --- Environment Definition ---\n",
        "# class StockTradingEnv(gym.Env):\n",
        "#     def __init__(self, df, initial_balance=1_000_000):\n",
        "#         super(StockTradingEnv, self).__init__()\n",
        "#         self.df = df.reset_index(drop=True)\n",
        "#         self.initial_balance = initial_balance\n",
        "#         self.commission = 0.0 # Train 0%\n",
        "\n",
        "#         self.action_space = spaces.Discrete(3) # 0=Hold, 1=Buy, 2=Sell\n",
        "#         self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(6,), dtype=np.float32)\n",
        "\n",
        "#         self.reset()\n",
        "\n",
        "#     def reset(self, seed=None, options=None):\n",
        "#         super().reset(seed=seed)\n",
        "#         self.current_step = 0\n",
        "\n",
        "#         # MIXED INIT (‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏á‡∏¥‡∏ô‡∏™‡∏î 50% / ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏´‡∏∏‡πâ‡∏ô 50%)\n",
        "#         if np.random.rand() < 0.5:\n",
        "#             self.balance = self.initial_balance\n",
        "#             self.shares_held = 0\n",
        "#             self.avg_cost = 0.0\n",
        "#         else:\n",
        "#             start_price = self.df.iloc[0]['Close']\n",
        "#             invest_pct = np.random.uniform(0.2, 0.8)\n",
        "#             cash_invested = self.initial_balance * invest_pct\n",
        "#             self.shares_held = int(cash_invested // start_price)\n",
        "#             self.balance = self.initial_balance - (self.shares_held * start_price)\n",
        "#             self.avg_cost = start_price\n",
        "\n",
        "#         self.net_worth = self.initial_balance\n",
        "#         self.prev_net_worth = self.initial_balance\n",
        "#         self.days_since_trade = 0\n",
        "\n",
        "#         return self._next_observation(), {}\n",
        "\n",
        "#     def _next_observation(self):\n",
        "#         obs = self.df.iloc[self.current_step]\n",
        "#         # Manual Scaling\n",
        "#         return np.array([\n",
        "#             obs.get('Macro_Signal', 0),\n",
        "#             obs.get('DL_Signal', 0.5),\n",
        "#             self.balance / 1_000_000.0,\n",
        "#             (self.shares_held * obs['Close']) / 1_000_000.0,\n",
        "#             obs.get('RSI', 50) / 100.0,\n",
        "#             obs.get('MACD', 0) / 10.0\n",
        "#         ], dtype=np.float32)\n",
        "\n",
        "#     def step(self, action):\n",
        "#         current_price = self.df.iloc[self.current_step]['Close']\n",
        "\n",
        "#         # ‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏°‡∏≤‡πÄ‡∏ä‡πá‡∏Ñ Logic\n",
        "#         obs = self.df.iloc[self.current_step]\n",
        "#         macro_val = obs.get('Macro_Signal', 0) # -1 ‡∏ñ‡∏∂‡∏á 1\n",
        "#         dl_val = obs.get('DL_Signal', 0.5)     # 0 ‡∏ñ‡∏∂‡∏á 1\n",
        "#         macd_val = obs.get('MACD', 0)          # ‡πÉ‡∏ä‡πâ MACD ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÅ‡∏ó‡∏ô Trend ‡∏Å‡∏£‡∏≤‡∏ü‡∏£‡∏≤‡∏Ñ‡∏≤\n",
        "\n",
        "#         # --- üî• CORE LOGIC: MACRO PROTAGONIST w/ REALITY CHECK ---\n",
        "\n",
        "#         # 1. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏°‡∏∏‡∏°‡∏°‡∏≠‡∏á‡∏Ç‡∏≠‡∏á Macro\n",
        "#         macro_view = \"NEUTRAL\"\n",
        "#         if macro_val > 0.1: macro_view = \"BULL\"\n",
        "#         elif macro_val < -0.1: macro_view = \"BEAR\"\n",
        "\n",
        "#         # 2. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏°‡∏∏‡∏°‡∏°‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡∏à‡∏£‡∏¥‡∏á (Price Trend)\n",
        "#         # MACD > 0 ‡∏Ñ‡∏∑‡∏≠‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå‡∏Ç‡∏≤‡∏Ç‡∏∂‡πâ‡∏ô, MACD < 0 ‡∏Ñ‡∏∑‡∏≠‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå‡∏Ç‡∏≤‡∏•‡∏á\n",
        "#         price_trend = \"BULL\" if macd_val > 0 else \"BEAR\"\n",
        "\n",
        "#         # 3. ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à (Decision Making)\n",
        "#         market_state = \"NEUTRAL\"\n",
        "\n",
        "#         # ‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç: Macro ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏à‡∏£‡∏¥‡∏á‡πÑ‡∏´‡∏°?\n",
        "#         if (macro_view == \"BULL\" and price_trend == \"BULL\") or \\\n",
        "#            (macro_view == \"BEAR\" and price_trend == \"BEAR\"):\n",
        "#             # ‚úÖ Macro ‡πÅ‡∏°‡πà‡∏ô -> ‡πÄ‡∏ä‡∏∑‡πà‡∏≠ Macro (‡∏û‡∏£‡∏∞‡πÄ‡∏≠‡∏Å‡∏ó‡∏≥‡∏á‡∏≤‡∏ô)\n",
        "#             market_state = macro_view\n",
        "#         else:\n",
        "#             # ‚ùå Macro ‡∏°‡∏±‡πà‡∏ß (‡∏Ç‡∏±‡∏î‡πÅ‡∏¢‡πâ‡∏á‡∏Å‡∏±‡∏ö‡∏Å‡∏£‡∏≤‡∏ü) -> ‡πÄ‡∏ä‡∏∑‡πà‡∏≠ DL (‡∏û‡∏£‡∏∞‡∏£‡∏≠‡∏á‡∏°‡∏≤‡∏ä‡πà‡∏ß‡∏¢)\n",
        "#             if dl_val > 0.55: market_state = \"BULL\"\n",
        "#             elif dl_val < 0.45: market_state = \"BEAR\"\n",
        "#             # ‡∏ñ‡πâ‡∏≤ DL ‡∏Å‡πá‡πÑ‡∏°‡πà‡πÅ‡∏ô‡πà‡πÉ‡∏à ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô NEUTRAL\n",
        "\n",
        "#         # --- Reward Calculation ---\n",
        "#         reward = 0.0\n",
        "\n",
        "#         # Action Logic\n",
        "#         # BUY\n",
        "#         if action == 1 and self.balance > current_price:\n",
        "#             budget = self.balance * 0.5\n",
        "#             shares = int(budget // current_price)\n",
        "#             if shares > 0:\n",
        "#                 cost = shares * current_price\n",
        "#                 total_shares = self.shares_held + shares\n",
        "#                 total_cost = (self.shares_held * self.avg_cost) + cost\n",
        "#                 self.avg_cost = total_cost / total_shares\n",
        "\n",
        "#                 self.balance -= cost\n",
        "#                 self.shares_held += shares\n",
        "#                 self.days_since_trade = 0\n",
        "\n",
        "#                 # ‡πÉ‡∏´‡πâ‡∏£‡∏≤‡∏á‡∏ß‡∏±‡∏•‡∏ñ‡πâ‡∏≤‡∏ã‡∏∑‡πâ‡∏≠‡∏ñ‡∏π‡∏Å‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏∞\n",
        "#                 if market_state == \"BULL\": reward += 0.2\n",
        "#                 if market_state == \"BEAR\": reward -= 0.2\n",
        "\n",
        "#         # SELL\n",
        "#         elif action == 2 and self.shares_held > 0:\n",
        "#             revenue = self.shares_held * current_price\n",
        "#             profit_pct = (current_price - self.avg_cost) / self.avg_cost\n",
        "\n",
        "#             self.balance += revenue\n",
        "#             self.shares_held = 0\n",
        "#             self.avg_cost = 0\n",
        "#             self.days_since_trade = 0\n",
        "\n",
        "#             # Profit Bonus\n",
        "#             if profit_pct > 0:\n",
        "#                 reward += (profit_pct * 20.0)\n",
        "#             else:\n",
        "#                 # ‡∏ñ‡πâ‡∏≤‡∏ï‡∏•‡∏≤‡∏î‡πÅ‡∏¢‡πà ‡πÅ‡∏•‡πâ‡∏ß Cut Loss ‡πÑ‡∏î‡πâ -> ‡∏ä‡∏°‡πÄ‡∏ä‡∏¢\n",
        "#                 if market_state == \"BEAR\": reward += 0.1\n",
        "#                 else: reward -= 0.1\n",
        "\n",
        "#         # HOLD\n",
        "#         elif action == 0:\n",
        "#             self.days_since_trade += 1\n",
        "#             if self.days_since_trade > 3: # Inactivity Penalty\n",
        "#                 reward -= 0.1 * (self.days_since_trade - 3)\n",
        "\n",
        "#         # Step Update\n",
        "#         self.current_step += 1\n",
        "#         done = self.current_step >= len(self.df) - 1\n",
        "\n",
        "#         # PnL Reward\n",
        "#         next_price = self.df.iloc[self.current_step]['Close']\n",
        "#         self.net_worth = self.balance + (self.shares_held * next_price)\n",
        "#         pnl = ((self.net_worth - self.prev_net_worth) / self.prev_net_worth) * 100\n",
        "#         reward += pnl\n",
        "\n",
        "#         # --- üî• REGIME PENALTY (Floor is Lava ‡πÅ‡∏ö‡∏ö‡∏°‡∏µ‡∏™‡∏°‡∏≠‡∏á) ---\n",
        "#         cash_ratio = self.balance / self.net_worth\n",
        "\n",
        "#         if market_state == \"BULL\":\n",
        "#             # ‡∏ï‡∏•‡∏≤‡∏î‡∏î‡∏µ (Macro ‡πÅ‡∏°‡πà‡∏ô ‡∏´‡∏£‡∏∑‡∏≠ DL ‡∏ä‡πà‡∏ß‡∏¢‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô) -> ‡∏ï‡πâ‡∏≠‡∏á‡∏ñ‡∏∑‡∏≠‡∏´‡∏∏‡πâ‡∏ô!\n",
        "#             if cash_ratio > 0.5: reward -= 0.5\n",
        "\n",
        "#         elif market_state == \"BEAR\":\n",
        "#             # ‡∏ï‡∏•‡∏≤‡∏î‡πÅ‡∏¢‡πà -> ‡∏ï‡πâ‡∏≠‡∏á‡∏ñ‡∏∑‡∏≠‡πÄ‡∏á‡∏¥‡∏ô‡∏™‡∏î!\n",
        "#             if cash_ratio < 0.5: reward -= 0.5\n",
        "\n",
        "#         self.prev_net_worth = self.net_worth\n",
        "#         return self._next_observation(), reward, done, False, {}\n",
        "\n",
        "# # --- Training Loop ---\n",
        "# print(f\"üöÄ Starting Training (Macro First -> Fallback to DL)...\")\n",
        "\n",
        "# TOTAL_TIMESTEPS = 30000\n",
        "\n",
        "# for stock in target_stocks:\n",
        "#     train_df = df_rl_all[(df_rl_all['Stock'] == stock) & (df_rl_all['Date'].dt.year < 2024)]\n",
        "#     if len(train_df) < 50: continue\n",
        "\n",
        "#     env = DummyVecEnv([lambda: StockTradingEnv(train_df)])\n",
        "#     model = PPO(\"MlpPolicy\", env, verbose=0, learning_rate=0.0003, ent_coef=0.1, batch_size=64)\n",
        "\n",
        "#     try:\n",
        "#         model.learn(total_timesteps=TOTAL_TIMESTEPS)\n",
        "#         model.save(f\"trained_models/ppo_{stock}\")\n",
        "#         print(f\"‚úÖ Trained: {stock}\")\n",
        "#     except Exception as e:\n",
        "#         print(f\"‚ùå Error {stock}: {e}\")\n",
        "\n",
        "# print(\"\\nüéâ Training Complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neWLDLI7gcru"
      },
      "outputs": [],
      "source": [
        "# # ============================================================\n",
        "# # üèÜ BLOCK 8: FINAL EVALUATION\n",
        "# # ============================================================\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import warnings\n",
        "# import os\n",
        "# import gymnasium as gym\n",
        "# from gymnasium import spaces\n",
        "# from stable_baselines3 import PPO\n",
        "# from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "\n",
        "# warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# stock_symbols = [\n",
        "#     \"AAV\", \"AEONTS\", \"AOT\", \"BA\", \"BBL\", \"BCH\", \"BDMS\", \"BEM\", \"BH\", \"BTS\",\n",
        "#     \"CHG\", \"JMT\", \"KBANK\", \"KKP\", \"KTB\", \"KTC\", \"PR9\", \"PRM\", \"RCL\", \"SAWAD\",\n",
        "#     \"TCAP\", \"TISCO\", \"TTB\"\n",
        "# ]\n",
        "# initial_balance = 1_000_000\n",
        "\n",
        "# try:\n",
        "#     df_rl_all = pd.read_excel(\"Final_RL_Input_Ready.xlsx\")\n",
        "#     df_rl_all['Date'] = pd.to_datetime(df_rl_all['Date'])\n",
        "# except:\n",
        "#     raise RuntimeError(\"‚ùå Missing Data File\")\n",
        "\n",
        "# class StockTradingEnv(gym.Env):\n",
        "#     def __init__(self, df):\n",
        "#         super().__init__()\n",
        "#         self.df = df.reset_index(drop=True)\n",
        "#         self.balance = initial_balance\n",
        "#         self.shares_held = 0\n",
        "#         self.current_step = 0\n",
        "#         self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(6,), dtype=np.float32)\n",
        "#         self.action_space = spaces.Discrete(3)\n",
        "\n",
        "#     def reset(self, seed=None, options=None):\n",
        "#         self.current_step = 0\n",
        "#         self.balance = initial_balance\n",
        "#         self.shares_held = 0\n",
        "#         return self._next_observation(), {}\n",
        "\n",
        "#     def _next_observation(self):\n",
        "#         obs = self.df.iloc[self.current_step]\n",
        "#         return np.array([\n",
        "#             obs.get('Macro_Signal', 0),\n",
        "#             obs.get('DL_Signal', 0.5),\n",
        "#             self.balance / 1_000_000.0,\n",
        "#             (self.shares_held * obs['Close']) / 1_000_000.0,\n",
        "#             obs.get('RSI', 50) / 100.0,\n",
        "#             obs.get('MACD', 0) / 10.0\n",
        "#         ], dtype=np.float32)\n",
        "\n",
        "#     def step(self, action):\n",
        "#         self.current_step += 1\n",
        "#         done = self.current_step >= len(self.df) - 1\n",
        "#         return self._next_observation(), 0, done, False, {}\n",
        "\n",
        "# # --- Backtest Logic ---\n",
        "# def backtest_logic(env, model):\n",
        "#     if hasattr(env, 'envs'): df = env.envs[0].unwrapped.df\n",
        "#     else: df = env.unwrapped.df\n",
        "\n",
        "#     prices = df['Close'].values\n",
        "#     cash = initial_balance\n",
        "#     shares = 0\n",
        "#     trades = 0\n",
        "#     commission = 0.001\n",
        "\n",
        "#     obs = env.reset()\n",
        "\n",
        "#     for i in range(len(prices)-1):\n",
        "#         action, _ = model.predict(obs, deterministic=True)\n",
        "#         curr_price = prices[i]\n",
        "\n",
        "#         # Buy\n",
        "#         if action == 1 and cash > curr_price:\n",
        "#             budget = cash * 0.5\n",
        "#             buy_amt = int(budget // (curr_price * (1 + commission)))\n",
        "#             if buy_amt > 0:\n",
        "#                 cost = buy_amt * curr_price * (1 + commission)\n",
        "#                 cash -= cost\n",
        "#                 shares += buy_amt\n",
        "#                 trades += 1\n",
        "\n",
        "#         # Sell\n",
        "#         elif action == 2 and shares > 0:\n",
        "#             cash += shares * curr_price * (1 - commission)\n",
        "#             shares = 0\n",
        "#             trades += 1\n",
        "\n",
        "#         obs, _, done, _ = env.step(action)\n",
        "#         if done: break\n",
        "\n",
        "#     final_val = cash + (shares * prices[-1])\n",
        "#     return final_val, trades\n",
        "\n",
        "# # --- Run Loop ---\n",
        "# results = []\n",
        "# print(f\"üöÄ Testing on 2024-2025 Data (Macro-Led Strategy)...\\n\")\n",
        "# print(f\"{'Stock':<10} | {'AI %':<10} | {'Bench %':<10} | {'Diff %':<10} | {'Trades':<8} | {'Status'}\")\n",
        "# print(\"-\" * 75)\n",
        "\n",
        "# for ticker in stock_symbols:\n",
        "#     try:\n",
        "#         df_test = df_rl_all[(df_rl_all['Stock'] == ticker) & (df_rl_all['Date'].dt.year >= 2024)]\n",
        "#         if len(df_test) < 10: continue\n",
        "\n",
        "#         model_path = f\"trained_models/ppo_{ticker}.zip\"\n",
        "\n",
        "#         if os.path.exists(model_path):\n",
        "#             env = DummyVecEnv([lambda: StockTradingEnv(df_test)])\n",
        "#             model = PPO.load(model_path, env=env)\n",
        "#             final_val, trades = backtest_logic(env, model)\n",
        "\n",
        "#             ai_ret = ((final_val - initial_balance)/initial_balance)*100\n",
        "#             bench_ret = ((df_test.iloc[-1]['Close'] - df_test.iloc[0]['Close'])/df_test.iloc[0]['Close'])*100\n",
        "#             diff = ai_ret - bench_ret\n",
        "#             status = \"WIN üèÜ\" if ai_ret > bench_ret else \"LOSS ‚ùå\"\n",
        "\n",
        "#             results.append({'Stock': ticker, 'AI_Return_%': round(ai_ret,2), 'Benchmark_Return_%': round(bench_ret,2), 'Diff_%': round(diff, 2), 'Trades': trades, 'Status': status})\n",
        "#             print(f\"{ticker:<10} | {ai_ret:>9.2f}% | {bench_ret:>9.2f}% | {diff:>9.2f}% | {trades:<8} | {status}\")\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"‚ùå Error {ticker}: {e}\")\n",
        "\n",
        "# if results:\n",
        "#     df_res = pd.DataFrame(results)\n",
        "#     print(f\"\\n{df_res.to_markdown(index=False)}\")\n",
        "#     df_res.to_excel(\"Final_AI_WinLoss_Summary.xlsx\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Es2wg9bI1hB"
      },
      "source": [
        "# Backtesting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ay3FOhbI0bB"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "\n",
        "# # ============================================================\n",
        "# # ‚öôÔ∏è BLOCK: Historical vs Predicted ŒîLogclose (Clean Export)\n",
        "# # ============================================================\n",
        "\n",
        "# def rolling_ecm_forecast_table(stock_name, sector_name, df_macro, df_gamma, df_alpha, df_beta, combined_dfs_selective_diff):\n",
        "#     \"\"\"\n",
        "#     ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ ŒîLogclose (‡πÄ‡∏î‡∏∑‡∏≠‡∏ô t) ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏î‡∏∑‡∏≠‡∏ô t‚àí1 ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö actual\n",
        "#     ‡∏Ñ‡∏∑‡∏ô DataFrame: Date | Actual_dLogclose | Pred_dLogclose | Error | APE_% | Stock | Sector\n",
        "#     \"\"\"\n",
        "#     # --- ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏∏‡πâ‡∏ô‡πÅ‡∏•‡∏∞ macro ---\n",
        "#     df_stock = combined_dfs_selective_diff[sector_name][[f\"Logclose_{stock_name}\"]].copy()\n",
        "#     df_stock.columns = [\"Logclose\"]\n",
        "#     df_macro_aligned = df_macro.reindex(df_stock.index).ffill().copy()\n",
        "\n",
        "#     # --- ‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• ---\n",
        "#     btab = df_beta[df_beta[\"Stock\"] == stock_name]\n",
        "#     gtab = df_gamma[df_gamma[\"Stock\"] == stock_name].copy()\n",
        "#     atab = df_alpha[df_alpha[\"Stock\"] == stock_name]\n",
        "#     if btab.empty or gtab.empty or atab.empty:\n",
        "#         return None\n",
        "\n",
        "#     lr_params = btab.drop_duplicates(subset=\"Variable\").set_index(\"Variable\")[\"coef\"]\n",
        "#     gtab = gtab[gtab[\"Variable\"].str.contains(r\"D\\.L\\d+\\.\", regex=True, na=False)]\n",
        "#     gtab = pd.concat([\n",
        "#         gtab,\n",
        "#         pd.DataFrame([{\"Variable\": \"ECT_lag1\", \"Coef\": float(atab[\"Alpha\"].iloc[0])}])\n",
        "#     ], ignore_index=True)\n",
        "\n",
        "#     # --- ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° DataFrame ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå ---\n",
        "#     df_out = pd.DataFrame(index=df_stock.index)\n",
        "#     df_out[\"Actual_dLogclose\"] = df_stock[\"Logclose\"].diff()\n",
        "#     df_out[\"Pred_dLogclose\"] = np.nan\n",
        "\n",
        "#     # --- Forecast ‡πÅ‡∏ö‡∏ö rolling ---\n",
        "#     for i in range(4, len(df_stock)):\n",
        "#         deltas = {}\n",
        "#         past_window = df_stock.iloc[i-4:i].copy()\n",
        "#         past_macro = df_macro_aligned.iloc[i-4:i].copy()\n",
        "\n",
        "#         # ECT lag\n",
        "#         const = float(lr_params.get(\"const\", 0.0))\n",
        "#         X_lag = {k: float(past_macro[k].iloc[-2]) for k in lr_params.index if k != \"const\" and k in past_macro.columns}\n",
        "#         Y_lag = float(past_window[\"Logclose\"].iloc[-2])\n",
        "#         ect_val = Y_lag - (const + sum(float(lr_params[k]) * X_lag[k] for k in X_lag))\n",
        "#         deltas[\"ECT_lag1\"] = ect_val\n",
        "\n",
        "#         # ŒîY / ŒîX lags\n",
        "#         for var in gtab[\"Variable\"]:\n",
        "#             if var == \"ECT_lag1\":\n",
        "#                 continue\n",
        "#             parts = var.split(\".\")\n",
        "#             lag = int(parts[1].replace(\"L\", \"\"))\n",
        "#             base = parts[2]\n",
        "\n",
        "#             if base.startswith(\"Logclose_\"):\n",
        "#                 stock_base = base.replace(\"Logclose_\", \"\")\n",
        "#                 if stock_base != stock_name:\n",
        "#                     continue\n",
        "#                 dy = float(past_window[\"Logclose\"].iloc[-lag]) - float(past_window[\"Logclose\"].iloc[-(lag + 1)])\n",
        "#                 deltas[var] = dy\n",
        "#             else:\n",
        "#                 if base in past_macro.columns:\n",
        "#                     dx = float(past_macro[base].iloc[-lag]) - float(past_macro[base].iloc[-(lag + 1)])\n",
        "#                     deltas[var] = dx\n",
        "#                 else:\n",
        "#                     deltas[var] = 0.0\n",
        "\n",
        "#         df_pred = pd.DataFrame(list(deltas.items()), columns=[\"Variable\", \"Value\"])\n",
        "#         merged = pd.merge(gtab[[\"Variable\", \"Coef\"]], df_pred, on=\"Variable\", how=\"left\")\n",
        "#         merged[\"Contribution\"] = merged[\"Coef\"].astype(float) * merged[\"Value\"].astype(float)\n",
        "#         df_out.iloc[i, df_out.columns.get_loc(\"Pred_dLogclose\")] = merged[\"Contribution\"].sum()\n",
        "\n",
        "#     # --- Error metrics ---\n",
        "#     EPS = 1e-6\n",
        "#     df_out[\"Error\"] = df_out[\"Pred_dLogclose\"] - df_out[\"Actual_dLogclose\"]\n",
        "#     df_out[\"APE_%\"] = np.where(\n",
        "#         df_out[\"Actual_dLogclose\"].abs() > EPS,\n",
        "#         np.abs(df_out[\"Error\"] / df_out[\"Actual_dLogclose\"]) * 100,\n",
        "#         np.nan\n",
        "#     )\n",
        "#     df_out[\"Stock\"] = stock_name\n",
        "#     df_out[\"Sector\"] = sector_name\n",
        "#     return df_out.dropna(subset=[\"Pred_dLogclose\"])\n",
        "\n",
        "\n",
        "# # ============================================================\n",
        "# # üöÄ Run & Export ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏£‡∏≤‡∏¢‡∏´‡∏∏‡πâ‡∏ô (Sheet 2 ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô)\n",
        "# # ============================================================\n",
        "\n",
        "# evaluation_results = {}\n",
        "\n",
        "# for sector_name, df_sec in combined_dfs_selective_diff.items():\n",
        "#     for col in df_sec.columns:\n",
        "#         if not col.startswith(\"Logclose_\"):\n",
        "#             continue\n",
        "#         stock_name = col.replace(\"Logclose_\", \"\")\n",
        "#         try:\n",
        "#             df_eval = rolling_ecm_forecast_table(\n",
        "#                 stock_name, sector_name, df, df_gamma, df_alpha, df_beta, combined_dfs_selective_diff\n",
        "#             )\n",
        "#             if df_eval is not None and not df_eval.empty:\n",
        "#                 evaluation_results[stock_name] = df_eval\n",
        "#                 mae = df_eval[\"Error\"].abs().mean()\n",
        "#                 rmse = np.sqrt((df_eval[\"Error\"] ** 2).mean())\n",
        "#                 mape = df_eval[\"APE_%\"].replace([np.inf, -np.inf], np.nan).mean()\n",
        "#                 print(f\"‚úÖ {stock_name:<8} | MAE={mae:.5f} | RMSE={rmse:.5f} | MAPE={mape:.2f}% | Obs={len(df_eval)}\")\n",
        "#         except Exception as e:\n",
        "#             print(f\"‚ö†Ô∏è {stock_name} failed: {e}\")\n",
        "\n",
        "# # --- Export ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏£‡∏≤‡∏¢‡∏´‡∏∏‡πâ‡∏ô ---\n",
        "# output_file = \"ECM_Forecast_Evaluation_ByStock.xlsx\"\n",
        "# with pd.ExcelWriter(output_file) as writer:\n",
        "#     for stock, df_eval in evaluation_results.items():\n",
        "#         df_clean = df_eval.replace([np.inf, -np.inf], np.nan).dropna(how=\"all\")\n",
        "#         df_clean.to_excel(writer, sheet_name=stock[:31], index=True)\n",
        "\n",
        "# print(f\"\\n‚úÖ Exported ‚Üí {output_file}\")\n",
        "# print(f\"‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(evaluation_results)} ‡∏´‡∏∏‡πâ‡∏ô (‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Sheet ‡∏£‡∏≤‡∏¢‡∏´‡∏∏‡πâ‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô)\")\n",
        "\n",
        "\n",
        "# # ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏£‡∏±‡∏ô‡πÅ‡∏•‡πâ‡∏ß evaluation_results ‡∏°‡∏µ dictionary ‡∏Ç‡∏≠‡∏á‡∏´‡∏∏‡πâ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡∏±‡∏ß\n",
        "\n",
        "# for stock, df_eval in evaluation_results.items():\n",
        "#     print(f\"\\n==== {stock} ====\")\n",
        "#     print(df_eval.tail(5)[[\"Actual_dLogclose\",\"Pred_dLogclose\",\"Error\",\"APE_%\"]])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4joQksHUQaF"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# df_macro = pd.read_excel(\"Macro_data.xlsx\")\n",
        "# print(df_macro.columns.tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBt6Pq__Mc60"
      },
      "outputs": [],
      "source": [
        "# # ============================================================\n",
        "# # üß† BLOCK 5.2 ‚Äî Regime-aware Hybrid Optimization Strategy (Fixed)\n",
        "# # ============================================================\n",
        "\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# import yfinance as yf\n",
        "# from pathlib import Path\n",
        "\n",
        "# # ---------- INPUT FILES ----------\n",
        "# f_forecast = \"Forecast_ARDL_ECM_NextMonth_Clean.xlsx\"\n",
        "# f_daily = \"Historical_Technical_Indicators_bySector.xlsx\"\n",
        "# f_macro = \"Macro_data.xlsx\"\n",
        "\n",
        "# # ---------- LOAD DATA ----------\n",
        "# df_fore = pd.read_excel(f_forecast)[[\"Stock\", \"Sector\", \"Pred_dLogclose\"]]\n",
        "# df_daily = pd.read_excel(f_daily)\n",
        "# df_daily[\"Date\"] = pd.to_datetime(df_daily[\"Date\"])\n",
        "\n",
        "# # --- Load macro base ---\n",
        "# df_macro = pd.read_excel(f_macro)\n",
        "# df_macro[\"Date\"] = pd.to_datetime(df_macro[\"Date\"])\n",
        "\n",
        "# # --- FX: USD/THB ---\n",
        "# fx1 = yf.download(\"THB=X\", start=\"2015-01-01\", end=\"2025-01-01\", progress=False)\n",
        "# if isinstance(fx1.columns, pd.MultiIndex):\n",
        "#     fx1.columns = fx1.columns.get_level_values(0)\n",
        "# fx1 = fx1.reset_index()[[\"Date\", \"Close\"]].rename(columns={\"Close\": \"THB_per_USD\"})\n",
        "\n",
        "# # --- FX: THB/CNY ---\n",
        "\n",
        "# fx2 = yf.download(\"THBCNY=X\", start=\"2015-01-01\", end=\"2025-01-01\", progress=False)\n",
        "# if isinstance(fx2.columns, pd.MultiIndex):\n",
        "#     fx2.columns = fx2.columns.get_level_values(0)\n",
        "# fx2 = fx2.reset_index()[[\"Date\", \"Close\"]].rename(columns={\"Close\": \"THB_per_CNY\"})\n",
        "\n",
        "\n",
        "# # # --- Oil: Brent ---\n",
        "# # oil = yf.download(\"BZ=F\", start=\"2015-01-01\", end=\"2025-01-01\", progress=False)\n",
        "# # if isinstance(oil.columns, pd.MultiIndex):\n",
        "# #     oil.columns = oil.columns.get_level_values(0)\n",
        "# # oil = oil.reset_index()[[\"Date\", \"Close\"]].rename(columns={\"Close\": \"Brent_Oil_USD_per_bbl\"})\n",
        "\n",
        "# # --- SET Index---\n",
        "# thai = yf.download(\"^SET.BK\", start=\"2015-01-01\", end=\"2025-01-01\", progress=False)\n",
        "# if isinstance(thai.columns, pd.MultiIndex):\n",
        "#     thai.columns = thai.columns.get_level_values(0)\n",
        "# thai = thai.reset_index()[[\"Date\", \"Close\"]].rename(columns={\"Close\": \"SET_Index\"})\n",
        "\n",
        "# # --- S&P500---\n",
        "# usa = yf.download(\"^GSPC\", start=\"2015-01-01\", end=\"2025-01-01\", progress=False)\n",
        "# if isinstance(usa.columns, pd.MultiIndex):\n",
        "#     usa.columns = usa.columns.get_level_values(0)\n",
        "# usa = usa.reset_index()[[\"Date\", \"Close\"]].rename(columns={\"Close\": \"SP500_Index\"})\n",
        "\n",
        "# # --- Merge macro + yfinance series ---\n",
        "# df_macro = (\n",
        "#     df_macro\n",
        "#     .merge(fx1, on=\"Date\", how=\"left\")\n",
        "#     .merge(fx2, on=\"Date\", how=\"left\")\n",
        "#     .merge(thai, on=\"Date\", how=\"left\")\n",
        "#     .merge(usa, on=\"Date\", how=\"left\")\n",
        "\n",
        "# )\n",
        "\n",
        "# # --- Rename for compatibility ---\n",
        "# df_macro.rename(columns={\n",
        "#     \"Bond_spread_10Y_5Y\": \"10Y_5Y_Bond_Spread\",\n",
        "#     \"Bond_spread_5Y_1Y\": \"5Y_1Y_Bond_Spread\",\n",
        "#     \"Bond_spread_10Y_1Y\": \"10Y_1Y_Bond_Spread\"\n",
        "# }, inplace=True)\n",
        "\n",
        "# df_macro = df_macro.set_index(\"Date\").sort_index()\n",
        "\n",
        "# # ============================================================\n",
        "# # STEP 1: Detect Macro Regime\n",
        "# # ============================================================\n",
        "# def detect_regime(df_macro):\n",
        "#     df = df_macro.copy()\n",
        "\n",
        "#     # Handle missing vars gracefully\n",
        "#     for col in [\"10Y_5Y_Bond_Spread\",\"5Y_1Y_Bond_Spread\",\"THOR_6M\",\n",
        "#                \"THB_per_USD\" ]:    # \"Brent_Oil_USD_per_bbl\"\n",
        "#         if col not in df.columns:\n",
        "#             df[col] = df[col].interpolate(limit_direction=\"both\")\n",
        "\n",
        "#     z_10_5 = (df[\"10Y_5Y_Bond_Spread\"] - df[\"10Y_5Y_Bond_Spread\"].mean()) / df[\"10Y_5Y_Bond_Spread\"].std()\n",
        "#     z_5_1 = (df[\"5Y_1Y_Bond_Spread\"] - df[\"5Y_1Y_Bond_Spread\"].mean()) / df[\"5Y_1Y_Bond_Spread\"].std()\n",
        "#     z_thor = (df[\"THOR_6M\"] - df[\"THOR_6M\"].mean()) / df[\"THOR_6M\"].std()\n",
        "#     # z_oil = (df[\"Brent_Oil_USD_per_bbl\"] - df[\"Brent_Oil_USD_per_bbl\"].mean()) / df[\"Brent_Oil_USD_per_bbl\"].std()\n",
        "#     z_fx = (df[\"THB_per_USD\"] - df[\"THB_per_USD\"].mean()) / df[\"THB_per_USD\"].std()\n",
        "#     z_thai = (df[\"SET_Index\"] - df[\"SET_Index\"].mean()) / df[\"SET_Index\"].std()\n",
        "#     z_usa = (df[\"SP500_Index\"] - df[\"SP500_Index\"].mean()) / df[\"SP500_Index\"].std()\n",
        "\n",
        "#     # Composite index\n",
        "#     composite = 0.4*(z_10_5 + z_5_1)/2 - 0.3*z_thor - 0.15*z_fx + 0.15*z_thai + 0.15*z_usa\n",
        "#     df[\"Regime_Score\"] = composite\n",
        "#     df[\"Regime\"] = np.select(\n",
        "#         [composite > 0.7, composite < -0.7],\n",
        "#         [\"Expansion\", \"Contraction\"],\n",
        "#         default=\"Neutral\"\n",
        "#     )\n",
        "#     return df[[\"Regime\",\"Regime_Score\"]]\n",
        "\n",
        "# df_regime = detect_regime(df_macro)\n",
        "\n",
        "# # ============================================================\n",
        "# # STEP 2: Merge Forecast + Daily + Regime\n",
        "# # ============================================================\n",
        "# expanded = []\n",
        "# for _, row in df_fore.iterrows():\n",
        "#     stock, sector, pred = row[\"Stock\"], row[\"Sector\"], row[\"Pred_dLogclose\"]\n",
        "#     df_s = df_daily[df_daily[\"Stock\"] == stock].copy()\n",
        "#     if df_s.empty:\n",
        "#         continue\n",
        "#     df_s[\"Pred_dLogclose\"] = pred\n",
        "#     df_s[\"Sector\"] = sector\n",
        "#     df_s = df_s.merge(df_regime, left_on=\"Date\", right_index=True, how=\"left\")\n",
        "#     expanded.append(df_s)\n",
        "\n",
        "# df_all = pd.concat(expanded, ignore_index=True).sort_values([\"Sector\",\"Stock\",\"Date\"])\n",
        "\n",
        "# # ============================================================\n",
        "# # STEP 3: Regime-dependent Weights\n",
        "# # ============================================================\n",
        "# def regime_weights(r):\n",
        "#     if r == \"Expansion\": return (0.6, 0.25, 0.15)\n",
        "#     elif r == \"Contraction\": return (0.3, 0.5, 0.2)\n",
        "#     else: return (0.4, 0.4, 0.2)\n",
        "\n",
        "# # ============================================================\n",
        "# # STEP 4: Hybrid Score Computation\n",
        "# # ============================================================\n",
        "# df_all[\"Return\"] = df_all.groupby(\"Stock\")[\"Close\"].pct_change()\n",
        "# df_all[\"LogReturn\"] = np.log1p(df_all[\"Return\"])\n",
        "\n",
        "# hybrid_results, equity_curves = [], {}\n",
        "\n",
        "# for stock, sub in df_all.groupby(\"Stock\"):\n",
        "#     sub = sub.copy().sort_values(\"Date\")\n",
        "\n",
        "#     techconfirm = (\n",
        "#         0.3 * sub[\"TechScore\"].fillna(0)\n",
        "#         + 0.2 * sub[\"MACD\"].fillna(0)\n",
        "#         + 0.1 * ((60 - abs(sub[\"RSI_14\"].fillna(50)-50)) / 50)\n",
        "#     )\n",
        "#     wave_align = np.where(sub[\"Wave_Direction\"] == (\"Up\" if sub[\"Pred_dLogclose\"].iloc[0] > 0 else \"Down\"), 1, -1)\n",
        "#     patternwave = (\n",
        "#         0.2 * sub[\"Pattern_Confidence\"].fillna(0)\n",
        "#         + 0.2 * sub[\"Wave_Strength\"].fillna(0) * wave_align\n",
        "#     )\n",
        "\n",
        "#     hybrid_score = []\n",
        "#     for i, regime in enumerate(sub[\"Regime\"]):\n",
        "#         w_macro, w_tech, w_pattern = regime_weights(regime)\n",
        "#         bias = np.sign(sub[\"Pred_dLogclose\"].iloc[0])\n",
        "#         score = (w_macro*bias) + (w_tech*techconfirm.iloc[i]) + (w_pattern*patternwave.iloc[i])\n",
        "#         hybrid_score.append(score)\n",
        "\n",
        "#     sub[\"Score\"] = hybrid_score\n",
        "#     sub[\"FinalSignal\"] = np.where(abs(sub[\"Score\"]) < 0.05, 0, np.sign(sub[\"Score\"]))\n",
        "#     sub[\"Strategy_Return\"] = sub[\"FinalSignal\"].shift(1) * sub[\"Return\"]\n",
        "#     sub[\"Cumulative_Return\"] = (1 + sub[\"Strategy_Return\"]).cumprod() - 1\n",
        "\n",
        "#     # --- Performance Summary ---\n",
        "#     hit_ratio = (np.sign(sub[\"Return\"]) == sub[\"FinalSignal\"].shift(1)).mean() * 100\n",
        "#     cum_ret = sub[\"Cumulative_Return\"].iloc[-1] * 100\n",
        "#     avg_ret = sub[\"Strategy_Return\"].mean() * 100\n",
        "#     std_ret = sub[\"Strategy_Return\"].std() * 100\n",
        "#     sharpe = avg_ret / std_ret if std_ret > 0 else np.nan\n",
        "\n",
        "#     hybrid_results.append({\n",
        "#         \"Stock\": stock, \"Sector\": sub[\"Sector\"].iloc[0],\n",
        "#         \"Hit_Ratio_%\": hit_ratio, \"Cumulative_Return_%\": cum_ret,\n",
        "#         \"Avg_Daily_Return_%\": avg_ret, \"Volatility_%\": std_ret,\n",
        "#         \"Sharpe_Ratio\": sharpe\n",
        "#     })\n",
        "#     equity_curves[stock] = sub[[\"Date\",\"Strategy_Return\",\"Cumulative_Return\",\"Regime\"]]\n",
        "\n",
        "# # ============================================================\n",
        "# # STEP 5: Portfolio Summary\n",
        "# # ============================================================\n",
        "# all_dates = pd.concat([v[\"Date\"] for v in equity_curves.values()]).drop_duplicates().sort_values()\n",
        "# port = pd.DataFrame(index=all_dates)\n",
        "\n",
        "# for k, v in equity_curves.items():\n",
        "#     df_v = v.drop_duplicates(subset=\"Date\").set_index(\"Date\")  # üîß ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô duplicate\n",
        "#     port[k] = df_v[\"Strategy_Return\"].reindex(all_dates)\n",
        "\n",
        "# # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ú‡∏•‡∏ï‡∏≠‡∏ö‡πÅ‡∏ó‡∏ô‡∏û‡∏≠‡∏£‡πå‡∏ï‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏£‡∏≤‡∏¢‡∏ß‡∏±‡∏ô\n",
        "# port[\"Portfolio_Return\"] = port.mean(axis=1, skipna=True)\n",
        "# port[\"Cumulative_Portfolio\"] = (1 + port[\"Portfolio_Return\"].fillna(0)).cumprod() - 1\n",
        "# port_cum = port[\"Cumulative_Portfolio\"].iloc[-1]*100\n",
        "# port_avg = port[\"Portfolio_Return\"].mean()*100\n",
        "# port_std = port[\"Portfolio_Return\"].std()*100\n",
        "# port_sharpe = port_avg/port_std if port_std>0 else np.nan\n",
        "\n",
        "# portfolio_summary = pd.DataFrame([{\n",
        "#     \"Portfolio_CumReturn_%\": port_cum,\n",
        "#     \"Portfolio_AvgDailyReturn_%\": port_avg,\n",
        "#     \"Portfolio_Volatility_%\": port_std,\n",
        "#     \"Portfolio_Sharpe\": port_sharpe\n",
        "# }])\n",
        "\n",
        "# df_strategy_summary = pd.DataFrame(hybrid_results).sort_values(\"Cumulative_Return_%\", ascending=False)\n",
        "\n",
        "# # ============================================================\n",
        "# # STEP 6: Export + Visualization\n",
        "# # ============================================================\n",
        "# out_path = Path(\"Hybrid_Regime_Aware_Strategy.xlsx\")\n",
        "# with pd.ExcelWriter(out_path) as writer:\n",
        "#     df_strategy_summary.to_excel(writer, sheet_name=\"Stock_Summary\", index=False)\n",
        "#     portfolio_summary.to_excel(writer, sheet_name=\"Portfolio_Summary\", index=False)\n",
        "#     port.to_excel(writer, sheet_name=\"Portfolio_EquityCurve\", index=True)\n",
        "\n",
        "# print(f\"‚úÖ Exported ‚Üí {out_path.name}\")\n",
        "\n",
        "# plt.figure(figsize=(10,6))\n",
        "# plt.plot(port[\"Cumulative_Portfolio\"], label=\"Regime-aware Portfolio\", lw=2)\n",
        "# plt.title(\"Regime-Aware Hybrid Macro + Technical Strategy ‚Äî Cumulative Return\")\n",
        "# plt.ylabel(\"Cumulative Return\")\n",
        "# plt.grid(True); plt.legend(); plt.show()\n",
        "\n",
        "# # # ============================================================\n",
        "# # # üì§ STEP 1.5 ‚Äî Export Regime Scores for ML Fusion (used in Block 5.2B)\n",
        "# # # ============================================================\n",
        "# # df_regime_export = df_regime.reset_index()\n",
        "# # df_regime_export.to_excel(\"Macro_Regime_Score.xlsx\", index=False)\n",
        "# # print(\"‚úÖ Exported ‚Üí Macro_Regime_Score.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pePVv5ktazDX"
      },
      "outputs": [],
      "source": [
        "# # ============================================================\n",
        "# # üí∞ BLOCK 5.3 ‚Äî Dynamic Portfolio Simulation + Dashboard (Holdings Summary Version)\n",
        "# # ============================================================\n",
        "\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# import yfinance as yf\n",
        "\n",
        "# # --- Simulation Parameters ---\n",
        "# initial_capital = 10_000_000\n",
        "# trade_frac = 0.05  # 3% per signal\n",
        "\n",
        "# # ============================================================\n",
        "# # üß© FIX ‚Äî Ensure FinalSignal exists\n",
        "# # ============================================================\n",
        "# df_sim = df_all.copy().sort_values([\"Date\", \"Stock\"]).drop_duplicates(subset=[\"Date\", \"Stock\"], keep=\"last\")\n",
        "\n",
        "# # ============================================================\n",
        "# # üß© FIX ‚Äî Ensure FinalSignal exists (Robust)\n",
        "# # ============================================================\n",
        "# df_sim = df_all.copy().sort_values([\"Date\", \"Stock\"]).drop_duplicates(subset=[\"Date\", \"Stock\"], keep=\"last\")\n",
        "\n",
        "# if \"FinalSignal\" not in df_sim.columns:\n",
        "#     print(\"‚ö†Ô∏è  Column 'FinalSignal' not found ‚Üí auto-generating ...\")\n",
        "\n",
        "#     if \"Score\" in df_sim.columns:\n",
        "#         # ‡πÉ‡∏ä‡πâ Score ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ\n",
        "#         df_sim[\"FinalSignal\"] = np.where(abs(df_sim[\"Score\"]) < 0.05, 0, np.sign(df_sim[\"Score\"]))\n",
        "\n",
        "#     elif \"Pred_dLogclose\" in df_sim.columns:\n",
        "#         # ‡πÉ‡∏ä‡πâ Pred_dLogclose ‡∏à‡∏≤‡∏Å ECM forecast\n",
        "#         df_sim[\"FinalSignal\"] = np.sign(df_sim[\"Pred_dLogclose\"])\n",
        "\n",
        "#     elif \"Pred_Return\" in df_sim.columns:\n",
        "#         # fallback ‡∏Å‡∏£‡∏ì‡∏µ‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∑‡πà‡∏ô\n",
        "#         df_sim[\"FinalSignal\"] = np.sign(df_sim[\"Pred_Return\"])\n",
        "\n",
        "#     else:\n",
        "#         # ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏•‡∏¢ ‡πÉ‡∏´‡πâ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ signal (‡∏ñ‡∏∑‡∏≠‡πÄ‡∏á‡∏¥‡∏ô‡∏™‡∏î)\n",
        "#         print(\"‚ö†Ô∏è  Neither Score nor Pred_dLogclose found ‚Äî assuming all signals = 0 (no trades).\")\n",
        "#         df_sim[\"FinalSignal\"] = 0\n",
        "\n",
        "\n",
        "# # ============================================================\n",
        "# # üßÆ Create pivot tables safely (handle duplicates)\n",
        "# # ============================================================\n",
        "# price_map = df_sim.pivot_table(index=\"Date\", columns=\"Stock\", values=\"Close\", aggfunc=\"last\")\n",
        "# signal_map = df_sim.pivot_table(index=\"Date\", columns=\"Stock\", values=\"FinalSignal\", aggfunc=\"last\")\n",
        "\n",
        "# # ============================================================\n",
        "# # üöÄ Portfolio Simulation (No short-selling, no borrowing)\n",
        "# # ============================================================\n",
        "# cash = initial_capital\n",
        "# holdings = {s: 0.0 for s in df_sim[\"Stock\"].unique()}\n",
        "# portfolio_history = []\n",
        "# dates = sorted(df_sim[\"Date\"].unique())\n",
        "\n",
        "# for date in dates:\n",
        "#     prices = price_map.loc[date]\n",
        "#     signals = signal_map.loc[date]\n",
        "\n",
        "#     # Portfolio valuation\n",
        "#     holdings_value = sum(prices[s]*holdings[s] for s in holdings if not np.isnan(prices[s]))\n",
        "#     total_value = cash + holdings_value\n",
        "\n",
        "#     # --- Execute trades ---\n",
        "#     for stock in holdings.keys():\n",
        "#         price = prices[stock]\n",
        "#         if np.isnan(price):\n",
        "#             continue\n",
        "#         sig = signals[stock]\n",
        "\n",
        "#         if sig == 1:  # BUY (max 3% of remaining cash)\n",
        "#             buy_amt = trade_frac * cash\n",
        "#             if buy_amt > 0:\n",
        "#                 qty = buy_amt / price\n",
        "#                 holdings[stock] += qty\n",
        "#                 cash -= qty * price\n",
        "\n",
        "#         elif sig == -1:  # SELL (max 3% of current holdings)\n",
        "#             sell_qty = trade_frac * holdings[stock]\n",
        "#             if sell_qty > 0:\n",
        "#                 holdings[stock] -= sell_qty\n",
        "#                 cash += sell_qty * price\n",
        "\n",
        "#     # --- Update after trades ---\n",
        "#     holdings_value = sum(prices[s]*holdings[s] for s in holdings if not np.isnan(prices[s]))\n",
        "#     total_value = cash + holdings_value\n",
        "\n",
        "#     portfolio_history.append({\n",
        "#         \"Date\": date,\n",
        "#         \"Cash\": cash,\n",
        "#         \"Holdings_Value\": holdings_value,\n",
        "#         \"Total_Portfolio\": total_value\n",
        "#     })\n",
        "\n",
        "# # ============================================================\n",
        "# # üìä Portfolio Performance + Benchmark SET\n",
        "# # ============================================================\n",
        "# df_portfolio = pd.DataFrame(portfolio_history)\n",
        "# df_portfolio[\"Daily_Return\"] = df_portfolio[\"Total_Portfolio\"].pct_change()\n",
        "# df_portfolio[\"Cumulative_Return\"] = (1 + df_portfolio[\"Daily_Return\"].fillna(0)).cumprod() - 1\n",
        "\n",
        "# # ============================================================\n",
        "# # üß≠ Benchmark SET Index (Functional Fix)\n",
        "# # ============================================================\n",
        "# try:\n",
        "#     set_idx = yf.download(\"^SET.BK\", start=df_portfolio[\"Date\"].min(), end=df_portfolio[\"Date\"].max(), progress=False)\n",
        "#     if not set_idx.empty:\n",
        "#         if isinstance(set_idx.columns, pd.MultiIndex):\n",
        "#             set_idx.columns = set_idx.columns.get_level_values(0)\n",
        "#         set_idx = set_idx[\"Close\"].resample(\"D\").ffill().squeeze()\n",
        "#         if isinstance(set_idx, pd.DataFrame):\n",
        "#             set_idx = set_idx.iloc[:, 0]\n",
        "#         set_ret = set_idx.pct_change().fillna(0)\n",
        "#         set_cum = (1 + set_ret).cumprod() - 1\n",
        "#         set_df = pd.DataFrame({\"Date\": set_idx.index, \"SET_Close\": set_idx.values, \"SET_Return\": set_ret.values, \"SET_CumReturn\": set_cum.values})\n",
        "#         set_df[\"Date\"] = pd.to_datetime(set_df[\"Date\"])\n",
        "#         df_portfolio = df_portfolio.reset_index(drop=True)\n",
        "#         df_portfolio[\"Date\"] = pd.to_datetime(df_portfolio[\"Date\"])\n",
        "#         df_portfolio = pd.merge_asof(\n",
        "#             df_portfolio.sort_values(\"Date\"),\n",
        "#             set_df.sort_values(\"Date\"),\n",
        "#             on=\"Date\",\n",
        "#             direction=\"backward\"\n",
        "#         ).set_index(\"Date\")\n",
        "#         print(\"‚úÖ SET Index benchmark successfully merged.\")\n",
        "#     else:\n",
        "#         print(\"‚ö†Ô∏è Warning: SET Index data not available.\")\n",
        "# except Exception as e:\n",
        "#     print(f\"‚ö†Ô∏è Error merging SET Index: {e}\")\n",
        "\n",
        "# # ============================================================\n",
        "# # üìà Visualization Dashboard (Portfolio vs SET)\n",
        "# # ============================================================\n",
        "# plt.figure(figsize=(10,6))\n",
        "# plt.plot(df_portfolio.index, df_portfolio[\"Cumulative_Return\"], label=\"Strategy Portfolio\", lw=2)\n",
        "# plt.plot(df_portfolio.index, df_portfolio[\"SET_CumReturn\"], label=\"SET Index\", lw=2, ls=\"--\")\n",
        "# plt.title(\"Portfolio vs SET Index Benchmark\", fontsize=13, fontweight=\"bold\")\n",
        "# plt.ylabel(\"Cumulative Return\")\n",
        "# plt.grid(True); plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "# # ============================================================\n",
        "# # üìã Latest Holdings Summary\n",
        "# # ============================================================\n",
        "# latest_date = dates[-1]\n",
        "# latest_prices = price_map.loc[latest_date]\n",
        "# hold_df = pd.DataFrame([\n",
        "#     {\"Stock\": s,\n",
        "#      \"Quantity\": holdings[s],\n",
        "#      \"Last_Price\": latest_prices[s],\n",
        "#      \"Market_Value\": holdings[s] * latest_prices[s]}\n",
        "#     for s in holdings.keys() if holdings[s] > 0\n",
        "# ])\n",
        "# hold_df[\"Weight_%\"] = (hold_df[\"Market_Value\"] / hold_df[\"Market_Value\"].sum()) * 100\n",
        "# hold_df = hold_df.sort_values(\"Market_Value\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "# print(\"\\nüìä Latest Portfolio Holdings (as of {})\".format(latest_date.date()))\n",
        "# display(hold_df.round(2))\n",
        "\n",
        "# # ============================================================\n",
        "# # üíæ Export\n",
        "# # ============================================================\n",
        "# with pd.ExcelWriter(\"Hybrid_Portfolio_Dashboard.xlsx\") as writer:\n",
        "#     df_portfolio.to_excel(writer, sheet_name=\"Portfolio_TimeSeries\")\n",
        "#     hold_df.to_excel(writer, sheet_name=\"Latest_Holdings\", index=False)\n",
        "# print(\"‚úÖ Exported ‚Üí Hybrid_Portfolio_Dashboard.xlsx\")\n",
        "\n",
        "# # ============================================================\n",
        "# # üìã Latest Holdings Summary\n",
        "# # ============================================================\n",
        "# latest_date = dates[-1]\n",
        "# latest_prices = price_map.loc[latest_date]\n",
        "# hold_df = pd.DataFrame([\n",
        "#     {\"Stock\": s,\n",
        "#      \"Quantity\": holdings[s],\n",
        "#      \"Last_Price\": latest_prices[s],\n",
        "#      \"Market_Value\": holdings[s] * latest_prices[s]}\n",
        "#     for s in holdings.keys() if holdings[s] > 0\n",
        "# ])\n",
        "# hold_df[\"Weight_%\"] = (hold_df[\"Market_Value\"] / hold_df[\"Market_Value\"].sum()) * 100\n",
        "# hold_df = hold_df.sort_values(\"Market_Value\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "# # --- üßæ Portfolio Summary (Cash vs Equity) ---\n",
        "# latest_cash = cash\n",
        "# latest_equity_value = hold_df[\"Market_Value\"].sum()\n",
        "# total_portfolio_value = latest_cash + latest_equity_value\n",
        "# cash_ratio = (latest_cash / total_portfolio_value) * 100\n",
        "# equity_ratio = (latest_equity_value / total_portfolio_value) * 100\n",
        "\n",
        "# print(\"\\nüìä Latest Portfolio Holdings (as of {})\".format(latest_date.date()))\n",
        "# display(hold_df.round(2))\n",
        "\n",
        "# print(\"\\nüí∞ Portfolio Allocation Summary:\")\n",
        "# print(f\"   ‚Ä¢ Total Portfolio Value : {total_portfolio_value:,.2f} THB\")\n",
        "# print(f\"   ‚Ä¢   ‚îú‚îÄ Cash             : {latest_cash:,.2f} THB ({cash_ratio:.2f}%)\")\n",
        "# print(f\"   ‚Ä¢   ‚îî‚îÄ Equity Holdings  : {latest_equity_value:,.2f} THB ({equity_ratio:.2f}%)\")\n",
        "\n",
        "# # ============================================================\n",
        "# # üíæ Export\n",
        "# # ============================================================\n",
        "# with pd.ExcelWriter(\"Hybrid_Portfolio_Dashboard.xlsx\") as writer:\n",
        "#     df_portfolio.to_excel(writer, sheet_name=\"Portfolio_TimeSeries\")\n",
        "#     hold_df.to_excel(writer, sheet_name=\"Latest_Holdings\", index=False)\n",
        "\n",
        "# summary_df = pd.DataFrame({\n",
        "#     \"Total_Value\": [total_portfolio_value],\n",
        "#     \"Cash\": [latest_cash],\n",
        "#     \"Equity_Value\": [latest_equity_value],\n",
        "#     \"Cash_%\": [cash_ratio],\n",
        "#     \"Equity_%\": [equity_ratio]\n",
        "# })\n",
        "# summary_df.to_excel(writer, sheet_name=\"Allocation_Summary\", index=False)\n",
        "\n",
        "# print(\"\\n‚úÖ Exported ‚Üí Hybrid_Portfolio_Dashboard.xlsx\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75Asf7shXrcQ"
      },
      "outputs": [],
      "source": [
        "# # ============================================================\n",
        "# # üìä BLOCK 5.4 ‚Äî Regime-wise PyFolio Performance Summary (Refined)\n",
        "# # ============================================================\n",
        "\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "\n",
        "# # --- Ensure Regime column exists ---\n",
        "# if \"Regime\" not in df_portfolio.columns:\n",
        "#     df_reg = df_all[[\"Date\", \"Regime\"]].drop_duplicates(subset=\"Date\", keep=\"last\")\n",
        "#     df_reg[\"Date\"] = pd.to_datetime(df_reg[\"Date\"])\n",
        "#     df_portfolio = df_portfolio.reset_index().merge(df_reg, on=\"Date\", how=\"left\").set_index(\"Date\")\n",
        "\n",
        "# # ============================================================\n",
        "# # üßÆ Helper Functions\n",
        "# # ============================================================\n",
        "# def CAGR(series, freq=252):\n",
        "#     if len(series) < 2:\n",
        "#         return np.nan\n",
        "#     if series.iloc[0] != 1:  # normalize\n",
        "#         series = series / series.iloc[0]\n",
        "#     total_ret = series.iloc[-1] - 1\n",
        "#     years = len(series) / freq\n",
        "#     return (1 + total_ret) ** (1 / years) - 1\n",
        "\n",
        "# def max_drawdown(cumret):\n",
        "#     roll_max = np.maximum.accumulate(cumret)\n",
        "#     drawdown = (cumret - roll_max) / roll_max\n",
        "#     return abs(drawdown.min())\n",
        "\n",
        "# def win_rate(returns):\n",
        "#     return (returns > 0).mean()\n",
        "\n",
        "# def sortino_ratio(returns, rf=0.0):\n",
        "#     downside = returns[returns < 0].std()\n",
        "#     if downside == 0 or np.isnan(downside):\n",
        "#         return np.nan\n",
        "#     return (returns.mean() - rf) / downside\n",
        "\n",
        "# def calmar_ratio(cagr, mdd):\n",
        "#     if mdd == 0 or np.isnan(mdd):\n",
        "#         return np.nan\n",
        "#     return cagr / mdd\n",
        "\n",
        "# # ============================================================\n",
        "# # üßæ Compute Metrics per Regime\n",
        "# # ============================================================\n",
        "# regime_stats = []\n",
        "\n",
        "# for regime, df_reg in df_portfolio.groupby(\"Regime\"):\n",
        "#     if df_reg.empty:\n",
        "#         continue\n",
        "\n",
        "#     df_reg = df_reg.copy().sort_index()\n",
        "#     cum = (1 + df_reg[\"Daily_Return\"].fillna(0)).cumprod()\n",
        "\n",
        "#     # --- Monthly compounded returns ---\n",
        "#     monthly_ret = (1 + df_reg[\"Daily_Return\"]).resample(\"M\").prod() - 1\n",
        "#     monthly_vol = df_reg[\"Daily_Return\"].resample(\"M\").std() * np.sqrt(21)\n",
        "\n",
        "#     cagr = CAGR(cum)\n",
        "#     mdd = max_drawdown(cum)\n",
        "#     wr = win_rate(df_reg[\"Daily_Return\"])\n",
        "#     sortino = sortino_ratio(df_reg[\"Daily_Return\"])\n",
        "#     calmar = calmar_ratio(cagr, mdd)\n",
        "\n",
        "#     regime_stats.append({\n",
        "#         \"Regime\": regime,\n",
        "#         \"CAGR_%\": cagr * 100,\n",
        "#         \"Max_Drawdown_%\": mdd * 100,\n",
        "#         \"Win_Rate_%\": wr * 100,\n",
        "#         \"Monthly_Return_%\": np.nanmean(monthly_ret) * 100,\n",
        "#         # \"Monthly_Volatility_%\": np.nanmean(monthly_vol) * 100,\n",
        "#         \"Sortino\": sortino,\n",
        "#         \"Calmar\": calmar\n",
        "#     })\n",
        "\n",
        "# # ============================================================\n",
        "# # üìã Summary Table\n",
        "# # ============================================================\n",
        "# df_regime_stats = pd.DataFrame(regime_stats).round(3)\n",
        "# cols = [\"Regime\", \"CAGR_%\", \"Max_Drawdown_%\", \"Win_Rate_%\",\n",
        "#         \"Monthly_Return_%\", \"Sortino\", \"Calmar\"]\n",
        "# df_regime_stats = df_regime_stats[cols]\n",
        "\n",
        "# print(\"\\nüìà Regime-wise Performance Summary (PyFolio Style)\")\n",
        "# display(df_regime_stats)\n",
        "\n",
        "# # ============================================================\n",
        "# # üíæ Export\n",
        "# # ============================================================\n",
        "# df_regime_stats.to_excel(\"Hybrid_PyFolio_Regime_Summary.xlsx\", index=False)\n",
        "# print(\"‚úÖ Exported ‚Üí Hybrid_PyFolio_Regime_Summary.xlsx\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5itb0OTkjW2I"
      },
      "outputs": [],
      "source": [
        "# # ============================================================\n",
        "# # üìà BLOCK 5.5 ‚Äî Regime-wise Equity Curve & Performance Visualization\n",
        "# # ============================================================\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "\n",
        "# # --- Ensure regime alignment with portfolio ---\n",
        "# if \"Regime\" not in df_portfolio.columns:\n",
        "#     df_reg = df_all[[\"Date\", \"Regime\"]].drop_duplicates(subset=\"Date\", keep=\"last\")\n",
        "#     df_reg[\"Date\"] = pd.to_datetime(df_reg[\"Date\"])\n",
        "#     df_portfolio = df_portfolio.reset_index().merge(df_reg, on=\"Date\", how=\"left\").set_index(\"Date\")\n",
        "\n",
        "# # --- ‡∏™‡∏£‡πâ‡∏≤‡∏á cumulative return ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ regime ---\n",
        "# regime_curves = {}\n",
        "# for regime, df_reg in df_portfolio.groupby(\"Regime\"):\n",
        "#     if df_reg.empty:\n",
        "#         continue\n",
        "#     cum = (1 + df_reg[\"Daily_Return\"].fillna(0)).cumprod() - 1\n",
        "#     regime_curves[regime] = cum\n",
        "\n",
        "# # ============================================================\n",
        "# # üßæ Summary Table (‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å Regime)\n",
        "# # ============================================================\n",
        "# regime_summary = []\n",
        "# for regime, cum in regime_curves.items():\n",
        "#     ann_ret = (1 + cum.iloc[-1]) ** (252 / len(cum)) - 1\n",
        "#     mdd = abs(((1 + cum).cummax() - (1 + cum)) / (1 + cum).cummax()).max()\n",
        "#     sharpe = df_portfolio[df_portfolio[\"Regime\"] == regime][\"Daily_Return\"].mean() / df_portfolio[df_portfolio[\"Regime\"] == regime][\"Daily_Return\"].std()\n",
        "#     regime_summary.append({\n",
        "#         \"Regime\": regime,\n",
        "#         \"Final_Return_%\": cum.iloc[-1] * 100,\n",
        "#         \"Annualized_Return_%\": ann_ret * 100,\n",
        "#         \"Max_Drawdown_%\": mdd * 100,\n",
        "#         \"Sharpe\": sharpe\n",
        "#     })\n",
        "\n",
        "# df_regime_equity = pd.DataFrame(regime_summary).round(3)\n",
        "# print(\"\\nüìä Regime-wise Equity Curve Summary\")\n",
        "# display(df_regime_equity)\n",
        "\n",
        "# # ============================================================\n",
        "# # üé® Visualization ‚Äî Overlayed Regime Equity Curves\n",
        "# # ============================================================\n",
        "# palette = {\"Expansion\": \"#2ecc71\", \"Neutral\": \"#f1c40f\", \"Contraction\": \"#e74c3c\"}\n",
        "\n",
        "# plt.figure(figsize=(12, 6))\n",
        "# for regime, cum in regime_curves.items():\n",
        "#     plt.plot(cum.index, cum, label=regime, lw=2, color=palette.get(regime, \"gray\"))\n",
        "\n",
        "# plt.axhline(0, color=\"black\", lw=1)\n",
        "# plt.title(\"Regime-wise Equity Curves (Cumulative Return)\", fontsize=14, fontweight=\"bold\")\n",
        "# plt.ylabel(\"Cumulative Return\")\n",
        "# plt.legend(title=\"Regime\")\n",
        "# plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n",
        "\n",
        "# # ============================================================\n",
        "# # üì¶ Export\n",
        "# # ============================================================\n",
        "# with pd.ExcelWriter(\"Hybrid_Regime_Equity_Summary.xlsx\") as writer:\n",
        "#     df_regime_equity.to_excel(writer, sheet_name=\"Regime_Equity_Summary\", index=False)\n",
        "#     for regime, cum in regime_curves.items():\n",
        "#         cum_df = cum.reset_index()\n",
        "#         cum_df.columns = [\"Date\", f\"{regime}_Cumulative_Return\"]\n",
        "#         cum_df.to_excel(writer, sheet_name=f\"{regime}_Curve\", index=False)\n",
        "\n",
        "# print(\"‚úÖ Exported ‚Üí Hybrid_Regime_Equity_Summary.xlsx\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZdrW4XpZCuS"
      },
      "outputs": [],
      "source": [
        "# # ============================================================\n",
        "# # üìä BLOCK 5.6 ‚Äî Stock-wise Profit/Loss per Regime (Linked + Ranking Table)\n",
        "# # ============================================================\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "\n",
        "# # --- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì FinalSignal ---\n",
        "# df_price_sig = df_all.copy()\n",
        "# if \"FinalSignal\" not in df_price_sig.columns:\n",
        "#     print(\"‚ö†Ô∏è Auto-generating FinalSignal from Score / Pred_dLogclose ...\")\n",
        "#     if \"Score\" in df_price_sig.columns:\n",
        "#         df_price_sig[\"FinalSignal\"] = np.where(abs(df_price_sig[\"Score\"]) < 0.05, 0, np.sign(df_price_sig[\"Score\"]))\n",
        "#     elif \"Pred_dLogclose\" in df_price_sig.columns:\n",
        "#         df_price_sig[\"FinalSignal\"] = np.sign(df_price_sig[\"Pred_dLogclose\"])\n",
        "#     else:\n",
        "#         raise KeyError(\"No Score or Pred_dLogclose found to create FinalSignal.\")\n",
        "\n",
        "# # --- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Regime ---\n",
        "# if \"Regime\" not in df_price_sig.columns:\n",
        "#     df_reg = df_portfolio.reset_index()[[\"Date\", \"Regime\"]].drop_duplicates()\n",
        "#     df_price_sig = df_price_sig.merge(df_reg, on=\"Date\", how=\"left\")\n",
        "\n",
        "# # --- ‡πÄ‡∏û‡∏¥‡πà‡∏° Weight ‡∏à‡∏≤‡∏Å‡∏û‡∏≠‡∏£‡πå‡∏ï‡∏à‡∏£‡∏¥‡∏á (‡∏ñ‡∏∑‡∏≠‡∏´‡∏∏‡πâ‡∏ô‡∏°‡∏≤‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡πÅ‡∏Ñ‡πà‡πÑ‡∏´‡∏ô) ---\n",
        "# df_portfolio_reset = df_portfolio.reset_index()[[\"Date\", \"Total_Portfolio\", \"Holdings_Value\", \"Cash\"]].copy()\n",
        "# df_price_sig = df_price_sig.merge(df_portfolio_reset, on=\"Date\", how=\"left\")\n",
        "\n",
        "# # ‡∏™‡∏°‡∏°‡∏ï‡∏¥‡πÉ‡∏´‡πâ Weight ‡∏ï‡πà‡∏≠‡∏´‡∏∏‡πâ‡∏ô (position fraction) ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå‡∏à‡∏£‡∏¥‡∏á (3%)\n",
        "# df_price_sig[\"Weight\"] = 0.03 * (df_price_sig[\"FinalSignal\"].shift(1) != 0).astype(int)\n",
        "\n",
        "# # --- ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Return ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏´‡∏∏‡πâ‡∏ô‡∏ï‡∏≤‡∏°‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏à‡∏£‡∏¥‡∏á ---\n",
        "# df_price_sig[\"Return\"] = df_price_sig.groupby(\"Stock\")[\"Close\"].pct_change()\n",
        "# df_price_sig[\"Strategy_Return\"] = df_price_sig[\"Return\"] * df_price_sig[\"Weight\"] * df_price_sig[\"FinalSignal\"].shift(1)\n",
        "\n",
        "# # ============================================================\n",
        "# # üßÆ ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ú‡∏•‡∏ï‡∏≠‡∏ö‡πÅ‡∏ó‡∏ô‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏ï‡πà‡∏≠‡∏´‡∏∏‡πâ‡∏ô‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏° Regime\n",
        "# # ============================================================\n",
        "# regime_profit = (\n",
        "#     df_price_sig.groupby([\"Regime\", \"Stock\"])[\"Strategy_Return\"]\n",
        "#     .mean()\n",
        "#     .reset_index()\n",
        "# )\n",
        "\n",
        "# # Annualize (‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì 252 ‡∏ß‡∏±‡∏ô)\n",
        "# regime_profit[\"Avg_Ann_Return_%\"] = regime_profit[\"Strategy_Return\"] * 252 * 100\n",
        "\n",
        "# # ============================================================\n",
        "# # üé® Visualization + Ranking\n",
        "# # ============================================================\n",
        "# regime_order = [\"Expansion\", \"Neutral\", \"Contraction\"]\n",
        "# palette = {\"Expansion\": \"#2ecc71\", \"Neutral\": \"#f1c40f\", \"Contraction\": \"#e74c3c\"}\n",
        "\n",
        "# ranking_tables = []\n",
        "\n",
        "# for regime in regime_order:\n",
        "#     sub = regime_profit[regime_profit[\"Regime\"] == regime]\n",
        "#     if sub.empty:\n",
        "#         continue\n",
        "\n",
        "#     sub_sorted = sub.sort_values(\"Avg_Ann_Return_%\", ascending=False)\n",
        "\n",
        "#     # --- Plot Bar Chart ---\n",
        "#     plt.figure(figsize=(10, 5))\n",
        "#     sns.barplot(\n",
        "#         data=sub_sorted,\n",
        "#         x=\"Stock\", y=\"Avg_Ann_Return_%\", color=palette[regime]\n",
        "#     )\n",
        "#     plt.axhline(0, color=\"black\", linewidth=1)\n",
        "#     plt.title(f\"Strategy Profit/Loss by Stock ‚Äî {regime} Regime\", fontsize=14, fontweight='bold')\n",
        "#     plt.ylabel(\"Average Annualized Return (%)\")\n",
        "#     plt.xlabel(\"Stock\")\n",
        "#     plt.xticks(rotation=45, ha=\"right\")\n",
        "#     plt.tight_layout()\n",
        "#     plt.show()\n",
        "\n",
        "#     # --- Top & Bottom 3 Ranking ---\n",
        "#     top3 = sub_sorted.head(3).assign(Rank=\"Top 3\")\n",
        "#     worst3 = sub_sorted.tail(3).assign(Rank=\"Bottom 3\")\n",
        "#     ranking_tables.append(pd.concat([top3, worst3], ignore_index=True))\n",
        "\n",
        "# # ============================================================\n",
        "# # üìã Combine Ranking Table\n",
        "# # ============================================================\n",
        "# df_ranking = pd.concat(ranking_tables, ignore_index=True)[\n",
        "#     [\"Regime\", \"Rank\", \"Stock\", \"Avg_Ann_Return_%\"]\n",
        "# ]\n",
        "# df_ranking = df_ranking.sort_values([\"Regime\", \"Rank\", \"Avg_Ann_Return_%\"], ascending=[True, True, False])\n",
        "\n",
        "# print(\"\\nüèÜ Top 3 / Bottom 3 Stocks by Regime (based on Avg Annualized Return %)\")\n",
        "# display(df_ranking.round(2))\n",
        "\n",
        "# # ============================================================\n",
        "# # üíæ Export\n",
        "# # ============================================================\n",
        "# with pd.ExcelWriter(\"Hybrid_Regime_StockPerformance_Linked.xlsx\") as writer:\n",
        "#     regime_profit.to_excel(writer, sheet_name=\"Stock_Returns\", index=False)\n",
        "#     df_ranking.to_excel(writer, sheet_name=\"Ranking_TopBottom\", index=False)\n",
        "\n",
        "# print(\"‚úÖ Exported ‚Üí Hybrid_Regime_StockPerformance_Linked.xlsx\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9qyuzYMWaAe"
      },
      "source": [
        "# Next period signal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wmv7nRibnd_1"
      },
      "outputs": [],
      "source": [
        "!pip install minisom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZS2XNdNrWfGR"
      },
      "outputs": [],
      "source": [
        "# # ============================================================\n",
        "# # üß≠ BLOCK 5.7 ‚Äî Next-Month Signal + Technical + SOM Suggestion\n",
        "# # ============================================================\n",
        "\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "\n",
        "# # ============================================================\n",
        "# # 1Ô∏è‚É£ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á Technical Summary\n",
        "# # ============================================================\n",
        "\n",
        "# try:\n",
        "#     df_technical_latest\n",
        "#     print(\"‚úÖ Using existing df_technical_latest.\")\n",
        "# except NameError:\n",
        "#     print(\"‚ö†Ô∏è df_technical_latest not found ‚Äî auto-generating mock version...\")\n",
        "#     df_technical_latest = pd.DataFrame({\n",
        "#         \"Stock\": df_forecast_summary[\"Stock\"].unique(),\n",
        "#         \"TechScore\": np.random.uniform(-1, 1, len(df_forecast_summary[\"Stock\"].unique())),\n",
        "#         \"MACD\": np.random.uniform(-1, 1, len(df_forecast_summary[\"Stock\"].unique())),\n",
        "#         \"RSI_14\": np.random.uniform(30, 70, len(df_forecast_summary[\"Stock\"].unique())),\n",
        "#         \"Pattern_Confidence\": np.random.uniform(0, 1, len(df_forecast_summary[\"Stock\"].unique())),\n",
        "#         \"Wave_Direction\": np.random.choice([\"Up\", \"Down\"], len(df_forecast_summary[\"Stock\"].unique())),\n",
        "#         \"Wave_Strength\": np.random.uniform(0, 1, len(df_forecast_summary[\"Stock\"].unique()))\n",
        "#     })\n",
        "#     print(\"‚úÖ df_technical_latest mock created.\")\n",
        "\n",
        "# # ============================================================\n",
        "# # 2Ô∏è‚É£ ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Macro + Technical ‚Üí Hybrid Signal\n",
        "# # ============================================================\n",
        "\n",
        "# df_signal = df_forecast_summary.copy()\n",
        "# df_signal = df_signal.merge(df_technical_latest, on=\"Stock\", how=\"left\")\n",
        "\n",
        "# # --- Macro bias ---\n",
        "# bias = np.sign(df_signal[\"Pred_dLogclose\"])\n",
        "\n",
        "# # --- Technical confirmation ---\n",
        "# techconfirm = (\n",
        "#     0.3 * df_signal[\"TechScore\"].fillna(0)\n",
        "#     + 0.2 * df_signal[\"MACD\"].fillna(0)\n",
        "#     + 0.1 * ((60 - abs(df_signal[\"RSI_14\"].fillna(50) - 50)) / 50)\n",
        "# )\n",
        "\n",
        "# # --- Pattern + Wave alignment ---\n",
        "# wave_align = np.where(df_signal[\"Wave_Direction\"] == np.where(bias>0, \"Up\", \"Down\"), 1, -1)\n",
        "# patternwave = (\n",
        "#     0.2 * df_signal[\"Pattern_Confidence\"].fillna(0)\n",
        "#     + 0.2 * df_signal[\"Wave_Strength\"].fillna(0) * wave_align\n",
        "# )\n",
        "\n",
        "# # --- Hybrid score ---\n",
        "# df_signal[\"Hybrid_Score\"] = 0.5*bias + 0.3*techconfirm + 0.2*patternwave\n",
        "\n",
        "# # --- Expected Return ---\n",
        "# df_signal[\"Expected_Return_%\"] = df_signal[\"Pred_dLogclose\"] * 100\n",
        "\n",
        "# # ============================================================\n",
        "# # 3Ô∏è‚É£ Self-Organizing Map (SOM-style) Decision Zone\n",
        "# # ============================================================\n",
        "\n",
        "# def som_zone(row):\n",
        "#     if row[\"Hybrid_Score\"] > 0.1 and row[\"Pred_dLogclose\"] > 0:\n",
        "#         return \"BUY\"\n",
        "#     elif -0.1 <= row[\"Hybrid_Score\"] <= 0.1:\n",
        "#         return \"HOLD\"\n",
        "#     elif row[\"Hybrid_Score\"] < -0.1 and row[\"Pred_dLogclose\"] < 0:\n",
        "#         return \"SELL\"\n",
        "#     else:\n",
        "#         return \"HOLD\"\n",
        "\n",
        "# df_signal[\"SOM_Action\"] = df_signal.apply(som_zone, axis=1)\n",
        "\n",
        "# # ============================================================\n",
        "# # 4Ô∏è‚É£ Sector Summary Table\n",
        "# # ============================================================\n",
        "\n",
        "# sector_summary = (\n",
        "#     df_signal.groupby(\"Sector\")\n",
        "#     .agg(\n",
        "#         N_Stocks=(\"Stock\", \"count\"),\n",
        "#         Avg_Hybrid_Score=(\"Hybrid_Score\", \"mean\"),\n",
        "#         Avg_Exp_Return=(\"Expected_Return_%\", \"mean\"),\n",
        "#         N_BUY=(\"SOM_Action\", lambda x: (x == \"BUY\").sum()),\n",
        "#         N_HOLD=(\"SOM_Action\", lambda x: (x == \"HOLD\").sum()),\n",
        "#         N_SELL=(\"SOM_Action\", lambda x: (x == \"SELL\").sum())\n",
        "#     )\n",
        "#     .reset_index()\n",
        "# )\n",
        "\n",
        "# sector_summary[\"%BUY\"] = sector_summary[\"N_BUY\"] / sector_summary[\"N_Stocks\"] * 100\n",
        "# sector_summary[\"%SELL\"] = sector_summary[\"N_SELL\"] / sector_summary[\"N_Stocks\"] * 100\n",
        "\n",
        "# def suggest_position(row):\n",
        "#     if row[\"%BUY\"] > 60 and row[\"Avg_Hybrid_Score\"] > 0.1:\n",
        "#         return \"Overweight\"\n",
        "#     elif row[\"%SELL\"] > 60 and row[\"Avg_Hybrid_Score\"] < -0.1:\n",
        "#         return \"Underweight\"\n",
        "#     else:\n",
        "#         return \"Neutral\"\n",
        "\n",
        "# sector_summary[\"Position_Suggestion\"] = sector_summary.apply(suggest_position, axis=1)\n",
        "# sector_summary = sector_summary.sort_values(\"Avg_Hybrid_Score\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "# # ============================================================\n",
        "# # 5Ô∏è‚É£ ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏£‡∏ß‡∏°\n",
        "# # ============================================================\n",
        "\n",
        "# print(\"\\n=== üìà Next-Month Hybrid Trading Signals (Stock Level) ===\")\n",
        "# display(\n",
        "#     df_signal[[\n",
        "#         \"Stock\",\"Sector\",\"Pred_dLogclose\",\"Expected_Return_%\",\n",
        "#         \"TechScore\",\"Hybrid_Score\",\"SOM_Action\"\n",
        "#     ]].sort_values(\"Hybrid_Score\", ascending=False).round(3)\n",
        "# )\n",
        "\n",
        "# print(\"\\n=== üíº Sector Position Suggestion Table ===\")\n",
        "# display(\n",
        "#     sector_summary[[\n",
        "#         \"Sector\",\"N_Stocks\",\"N_BUY\",\"N_HOLD\",\"N_SELL\",\n",
        "#         \"%BUY\",\"%SELL\",\"Avg_Hybrid_Score\",\"Avg_Exp_Return\",\"Position_Suggestion\"\n",
        "#     ]].round(3)\n",
        "# )\n",
        "\n",
        "# # ============================================================\n",
        "# # üé® SOM Visualization ‚Äî Stock Labels + Hybrid Score\n",
        "# # ============================================================\n",
        "\n",
        "# from minisom import MiniSom\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# import numpy as np\n",
        "\n",
        "# # --- ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° features ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö SOM ---\n",
        "# features = [\"Pred_dLogclose\", \"TechScore\", \"MACD\", \"RSI_14\", \"Pattern_Confidence\", \"Wave_Strength\"]\n",
        "# X = StandardScaler().fit_transform(df_signal[features].fillna(0))\n",
        "\n",
        "# # --- Train SOM ---\n",
        "# som_x, som_y = 8, 8\n",
        "# som = MiniSom(x=som_x, y=som_y, input_len=X.shape[1],\n",
        "#               sigma=1.0, learning_rate=0.5,\n",
        "#               neighborhood_function='gaussian', random_seed=42)\n",
        "# som.random_weights_init(X)\n",
        "# som.train_random(X, 1000, verbose=False)\n",
        "\n",
        "# # --- ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á node ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏´‡∏∏‡πâ‡∏ô ---\n",
        "# win_map = np.array([som.winner(x) for x in X])\n",
        "# df_signal[\"SOM_X\"] = win_map[:,0]\n",
        "# df_signal[\"SOM_Y\"] = win_map[:,1]\n",
        "\n",
        "# # --- ‡∏™‡∏µ‡∏Ç‡∏≠‡∏á Action ---\n",
        "# color_map = {\"BUY\": \"#2ecc71\", \"HOLD\": \"#f1c40f\", \"SELL\": \"#e74c3c\"}\n",
        "\n",
        "# # --- ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ Hybrid Score ‡∏ï‡πà‡∏≠ node ---\n",
        "# node_mean = (\n",
        "#     df_signal.groupby([\"SOM_X\",\"SOM_Y\"])[\"Hybrid_Score\"]\n",
        "#     .mean().unstack().fillna(0)\n",
        "# )\n",
        "\n",
        "# # ============================================================\n",
        "# # üß† BLOCK 5.7 ‚Äî Enhanced SOM Cluster Map (Hybrid + Technical)\n",
        "# # ============================================================\n",
        "\n",
        "# from minisom import MiniSom\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# import numpy as np\n",
        "\n",
        "# # --- ‚öôÔ∏è ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° features ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö SOM ---\n",
        "# df_signal[\"RSI_14_scaled\"] = (df_signal[\"RSI_14\"] - 50) / 25           # RSI 25‚Äì75 ‚Üí -1 ‡∏ñ‡∏∂‡∏á +1\n",
        "# df_signal[\"Hybrid_Score_Scaled\"] = df_signal[\"Hybrid_Score\"] * 2.5     # ‡∏Ç‡∏¢‡∏≤‡∏¢ dynamic range\n",
        "\n",
        "# features = [\n",
        "#     \"Pred_dLogclose\", \"TechScore\", \"MACD\",\n",
        "#     \"RSI_14_scaled\", \"Pattern_Confidence\", \"Wave_Strength\"\n",
        "# ]\n",
        "# X = StandardScaler().fit_transform(df_signal[features].fillna(0))\n",
        "\n",
        "# # --- üîÑ Train SOM ---\n",
        "# som_x, som_y = 8, 8\n",
        "# som = MiniSom(\n",
        "#     x=som_x, y=som_y, input_len=X.shape[1],\n",
        "#     sigma=1.0, learning_rate=0.5,\n",
        "#     neighborhood_function='gaussian', random_seed=42\n",
        "# )\n",
        "# som.random_weights_init(X)\n",
        "# som.train_random(X, 1000, verbose=False)\n",
        "\n",
        "# # --- üìç ‡∏´‡∏≤ node ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏´‡∏∏‡πâ‡∏ô ---\n",
        "# win_map = np.array([som.winner(x) for x in X])\n",
        "# df_signal[\"SOM_X\"] = win_map[:, 0]\n",
        "# df_signal[\"SOM_Y\"] = win_map[:, 1]\n",
        "\n",
        "# # --- üé® ‡∏™‡∏µ Action ---\n",
        "# color_map = {\"BUY\": \"#2ecc71\", \"HOLD\": \"#f1c40f\", \"SELL\": \"#e74c3c\"}\n",
        "\n",
        "# # --- üßÆ ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ Hybrid Score ‡∏ï‡πà‡∏≠ node ---\n",
        "# node_mean = (\n",
        "#     df_signal.groupby([\"SOM_X\", \"SOM_Y\"])[\"Hybrid_Score_Scaled\"]\n",
        "#     .mean().unstack().fillna(0)\n",
        "# )\n",
        "\n",
        "# # ============================================================\n",
        "# # üé® Visualization ‚Äî SOM Heatmap + Stock Labels + Score\n",
        "# # ============================================================\n",
        "# plt.figure(figsize=(9, 8))\n",
        "# plt.title(\"üß† SOM Cluster Map ‚Äî Hybrid (Macro + Technical)\", fontsize=14, fontweight=\"bold\")\n",
        "\n",
        "# # --- Heatmap ‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á (Dynamic scale) ---\n",
        "# vmin, vmax = node_mean.min().min(), node_mean.max().max()\n",
        "# sns.heatmap(\n",
        "#     node_mean,\n",
        "#     cmap=\"RdYlGn\", vmin=vmin, vmax=vmax,\n",
        "#     cbar_kws={\"label\": \"Mean Hybrid Score\"},\n",
        "#     square=True, linewidths=0.5, alpha=0.25\n",
        "# )\n",
        "\n",
        "# # --- Plot ‡∏´‡∏∏‡πâ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡∏±‡∏ß (‡∏ä‡∏∑‡πà‡∏≠ + Score + ‡∏™‡∏µ Action) ---\n",
        "# for _, row in df_signal.iterrows():\n",
        "#     x, y = row[\"SOM_X\"] + 0.5, row[\"SOM_Y\"] + 0.5\n",
        "#     color = color_map.get(row[\"SOM_Action\"], \"gray\")\n",
        "#     plt.scatter(x, y, s=200, color=color, edgecolor=\"black\", alpha=0.9, zorder=3)\n",
        "#     plt.text(\n",
        "#         x, y,\n",
        "#         f\"{row['Stock']} ({row['Hybrid_Score']:+.2f})\",\n",
        "#         fontsize=8, ha=\"center\", va=\"center\",\n",
        "#         color=\"black\", fontweight=\"bold\"\n",
        "#     )\n",
        "\n",
        "# plt.xlabel(\"SOM X (Cluster Column)\")\n",
        "# plt.ylabel(\"SOM Y (Cluster Row)\")\n",
        "# plt.grid(False)\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # ============================================================\n",
        "# # 7Ô∏è‚É£ Export Excel\n",
        "# # ============================================================\n",
        "\n",
        "# with pd.ExcelWriter(\"Hybrid_SOM_Position_Suggestion.xlsx\") as writer:\n",
        "#     df_signal.to_excel(writer, sheet_name=\"Stock_Signals\", index=False)\n",
        "#     sector_summary.to_excel(writer, sheet_name=\"Sector_Suggestion\", index=False)\n",
        "\n",
        "# print(\"‚úÖ Exported ‚Üí Hybrid_SOM_Position_Suggestion.xlsx\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUCqn-QRRbre"
      },
      "source": [
        "# Dynamic portfolio = Quantitative deterministic (Sharpe-weighted + Signal flip)\n",
        "\n",
        "=> ‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤, ‡πÉ‡∏ä‡πâ‡πÅ‡∏ô‡∏ß Bellman update ‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á train RL model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ttADXjSRby9"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "\n",
        "# # ============================================================\n",
        "# # ‚öôÔ∏è BLOCK 6 (Revised): Long-Only RL Deterministic Allocation (All outputs in %)\n",
        "# # ============================================================\n",
        "\n",
        "# def adaptive_portfolio_rl_longonly(evaluation_results, window_corr=12, window_sharpe=6):\n",
        "#     all_dates = sorted(list(set().union(*[df.index for df in evaluation_results.values()])))\n",
        "#     portfolio_returns = pd.DataFrame(index=all_dates)\n",
        "\n",
        "#     adj_signals = {}\n",
        "#     sh_ratio = {}\n",
        "\n",
        "#     # --- Step 1: Compute adjusted signal and Sharpe ---\n",
        "#     for stock, df_eval in evaluation_results.items():\n",
        "#         df = df_eval.copy()\n",
        "#         df[\"Signal_raw\"] = np.sign(df[\"Pred_dLogclose\"])\n",
        "#         df[\"Corr_Pred_Actual\"] = df[\"Pred_dLogclose\"].rolling(window_corr).corr(df[\"Actual_dLogclose\"])\n",
        "#         df[\"Signal_adj\"] = np.where(df[\"Corr_Pred_Actual\"] < 0, -df[\"Signal_raw\"], df[\"Signal_raw\"])\n",
        "#         df[\"Return\"] = df[\"Actual_dLogclose\"]\n",
        "#         df[\"Sharpe\"] = (\n",
        "#             df[\"Return\"].rolling(window_sharpe).mean() / df[\"Return\"].rolling(window_sharpe).std()\n",
        "#         )\n",
        "#         adj_signals[stock] = df[\"Signal_adj\"]\n",
        "#         sh_ratio[stock] = df[\"Sharpe\"]\n",
        "#         portfolio_returns[stock] = df[\"Return\"]\n",
        "\n",
        "#     weights_df = pd.DataFrame(index=all_dates, columns=list(evaluation_results.keys()))\n",
        "#     port_ret_series = []\n",
        "\n",
        "#     # --- Step 2: Compute weights (non-negative long-only) ---\n",
        "#     for t, date in enumerate(all_dates):\n",
        "#         w_list, r_list = [], []\n",
        "\n",
        "#         for stock in evaluation_results.keys():\n",
        "#             sig = adj_signals[stock].reindex(all_dates).iloc[t]\n",
        "#             shrp = sh_ratio[stock].reindex(all_dates).iloc[t]\n",
        "#             ret = portfolio_returns[stock].reindex(all_dates).iloc[t]\n",
        "\n",
        "#             if np.isnan(sig) or np.isnan(shrp) or np.isnan(ret):\n",
        "#                 continue\n",
        "\n",
        "#             w_val = sig * abs(shrp)\n",
        "#             w_list.append((stock, w_val))\n",
        "#             r_list.append((stock, ret))\n",
        "\n",
        "#         if not w_list:\n",
        "#             port_ret_series.append(0.0)\n",
        "#             continue\n",
        "\n",
        "#         w_df = pd.DataFrame(w_list, columns=[\"Stock\", \"w\"])\n",
        "#         w_df[\"w\"] = np.clip(w_df[\"w\"], 0, None)\n",
        "\n",
        "#         if w_df[\"w\"].sum() > 0:\n",
        "#             w_df[\"w\"] /= w_df[\"w\"].sum()\n",
        "#         else:\n",
        "#             w_df[\"w\"] = 1.0 / len(w_df)\n",
        "\n",
        "#         for s in w_df[\"Stock\"]:\n",
        "#             weights_df.loc[date, s] = w_df.loc[w_df[\"Stock\"] == s, \"w\"].iloc[0]\n",
        "\n",
        "#         r_df = pd.DataFrame(r_list, columns=[\"Stock\", \"Return\"])\n",
        "#         merged = pd.merge(w_df, r_df, on=\"Stock\")\n",
        "#         port_ret = np.sum(merged[\"w\"] * merged[\"Return\"])\n",
        "#         port_ret_series.append(port_ret)\n",
        "\n",
        "#     # --- Step 3: Portfolio performance summary ---\n",
        "#     portfolio_returns[\"Portfolio_Return\"] = port_ret_series\n",
        "#     portfolio_returns[\"Cumulative_Portfolio\"] = np.exp(portfolio_returns[\"Portfolio_Return\"].cumsum()) - 1\n",
        "\n",
        "#     # ‚úÖ Convert ALL numeric columns to percentage\n",
        "#     portfolio_returns_pct = portfolio_returns.copy() * 100\n",
        "#     portfolio_returns_pct.columns = [col + \"(%)\" for col in portfolio_returns.columns]\n",
        "\n",
        "#     # Compute summary statistics in %\n",
        "#     avg_r = portfolio_returns[\"Portfolio_Return\"].mean() * 100\n",
        "#     std_r = portfolio_returns[\"Portfolio_Return\"].std() * 100\n",
        "#     sharpe_r = avg_r / std_r if std_r > 0 else np.nan\n",
        "#     cum_r = portfolio_returns[\"Cumulative_Portfolio\"].iloc[-1] * 100\n",
        "\n",
        "#     summary = pd.DataFrame([{\n",
        "#         \"CumReturn_%\": cum_r,\n",
        "#         \"AvgMonthlyReturn_%\": avg_r,\n",
        "#         \"Volatility_%\": std_r,\n",
        "#         \"Sharpe\": sharpe_r\n",
        "#     }])\n",
        "\n",
        "#     weights_df = weights_df * 100  # export weights in %\n",
        "#     return portfolio_returns_pct, weights_df, summary\n",
        "\n",
        "\n",
        "# # ============================================================\n",
        "# # üöÄ Run Adaptive Allocation (Long-only, % export)\n",
        "# # ============================================================\n",
        "\n",
        "# portfolio_rl, weights_rl, summary_rl = adaptive_portfolio_rl_longonly(evaluation_results)\n",
        "\n",
        "# with pd.ExcelWriter(\"ECM_RL_AdaptivePortfolio_LongOnly_Percent.xlsx\") as writer:\n",
        "#     summary_rl.to_excel(writer, sheet_name=\"Portfolio_Summary\", index=False)\n",
        "#     weights_rl.to_excel(writer, sheet_name=\"Dynamic_Weights(%)\")\n",
        "#     portfolio_rl.to_excel(writer, sheet_name=\"Portfolio_Returns(%)\")\n",
        "\n",
        "# print(\"\\n‚úÖ Exported ‚Üí ECM_RL_AdaptivePortfolio_LongOnly_Percent.xlsx\")\n",
        "\n",
        "# print(\"\\n=== üíº Portfolio Summary ===\")\n",
        "# display(summary_rl)\n",
        "\n",
        "# print(\"\\n=== üìä Dynamic Weights (last 5 dates, %) ===\")\n",
        "# display(weights_rl.tail(5))\n",
        "\n",
        "# print(\"\\n=== üìà Portfolio Return Curve (last 10, in %) ===\")\n",
        "# display(portfolio_rl.tail(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJhOJJ0JS_MH"
      },
      "outputs": [],
      "source": [
        "# # ============================================================\n",
        "# # üé® BLOCK 7: Visualization of Dynamic Portfolio Allocation (By Sector)\n",
        "# # ============================================================\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "\n",
        "# plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
        "# sns.set(font_scale=0.9)\n",
        "\n",
        "# # ============================================================\n",
        "# # üîπ STEP 1: Prepare sector mapping\n",
        "# # ============================================================\n",
        "\n",
        "# # ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame mapping ‡∏à‡∏≤‡∏Å evaluation_results (‡∏´‡∏£‡∏∑‡∏≠ summary ‡πÄ‡∏î‡∏¥‡∏°)\n",
        "# sector_map = {}\n",
        "# for stock, df_eval in evaluation_results.items():\n",
        "#     sector = df_eval[\"Sector\"].iloc[0]\n",
        "#     sector_map[stock] = sector\n",
        "\n",
        "# # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ mapping ‡∏Ñ‡∏£‡∏ö‡πÑ‡∏´‡∏°\n",
        "# print(\"üìä Sector mapping:\", sector_map)\n",
        "\n",
        "# # ============================================================\n",
        "# # üîπ STEP 2: Convert weights_rl ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏≤‡∏¢ Sector\n",
        "# # ============================================================\n",
        "\n",
        "# weights_sector = pd.DataFrame(index=weights_rl.index)\n",
        "\n",
        "# for stock in weights_rl.columns:\n",
        "#     sector = sector_map.get(stock, \"Unknown\")\n",
        "#     if sector not in weights_sector.columns:\n",
        "#         weights_sector[sector] = 0.0\n",
        "#     weights_sector[sector] += pd.to_numeric(weights_rl[stock], errors=\"coerce\").fillna(0)\n",
        "\n",
        "# # Normalize ‡πÉ‡∏´‡πâ sum ‡∏ï‡πà‡∏≠‡πÅ‡∏ñ‡∏ß = 100%\n",
        "# weights_sector = weights_sector.div(weights_sector.sum(axis=1), axis=0) * 100\n",
        "\n",
        "# print(\"\\n‚úÖ Sector-level weights created:\")\n",
        "# display(weights_sector.tail(3))\n",
        "\n",
        "# # ============================================================\n",
        "# # üîπ STEP 3: Heatmap by Sector\n",
        "# # ============================================================\n",
        "\n",
        "# fig, ax = plt.subplots(figsize=(10, 5))\n",
        "# sns.heatmap(weights_sector.T, cmap=\"YlOrRd\", cbar_kws={'label': 'Weight (%)'}, ax=ax)\n",
        "# ax.set_title(\"Dynamic Portfolio Allocation by Sector (%)\", fontsize=14, weight=\"bold\")\n",
        "# ax.set_xlabel(\"Date\")\n",
        "# ax.set_ylabel(\"Sector\")\n",
        "# plt.xticks(rotation=45)\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n",
        "\n",
        "# # ============================================================\n",
        "# # üîπ STEP 4: Area Chart by Sector\n",
        "# # ============================================================\n",
        "\n",
        "# fig, ax = plt.subplots(figsize=(12, 6))\n",
        "# weights_sector.plot.area(ax=ax, stacked=True, alpha=0.8)\n",
        "# ax.set_title(\"Portfolio Allocation Composition by Sector (%)\", fontsize=14, weight=\"bold\")\n",
        "# ax.set_ylabel(\"Weight (%)\")\n",
        "# ax.set_xlabel(\"Date\")\n",
        "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', title=\"Sector\")\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n",
        "\n",
        "# # ============================================================\n",
        "# # üîπ STEP 5: Pie Chart (‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î)\n",
        "# # ============================================================\n",
        "\n",
        "# last_date = weights_sector.index[-1]\n",
        "# last_weights = weights_sector.loc[last_date].dropna()\n",
        "# fig, ax = plt.subplots(figsize=(6, 6))\n",
        "# ax.pie(last_weights, labels=last_weights.index, autopct='%1.1f%%', startangle=90)\n",
        "# ax.set_title(f\"Sector Allocation on {last_date.strftime('%Y-%m')}\", fontsize=13, weight=\"bold\")\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdJUB1kDXoET"
      },
      "source": [
        "# Next-Month Trading Plan after Bellman theory  => Exclude it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFOUxtSMVvM4"
      },
      "outputs": [],
      "source": [
        "# # ============================================================\n",
        "# # üìà BLOCK: Sharpe-weighted + Signal Flip (with Flip Info + Comments)\n",
        "# # ============================================================\n",
        "\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "\n",
        "# # ===== 1Ô∏è‚É£ Sharpe-weighted Portfolio Allocation =====\n",
        "# df_perf = df_strategy_summary.copy()\n",
        "# df_perf[\"Sharpe_Positive\"] = np.where(df_perf[\"Sharpe_Ratio\"] > 0, df_perf[\"Sharpe_Ratio\"], 0)\n",
        "# total_sharpe = df_perf[\"Sharpe_Positive\"].sum()\n",
        "# df_perf[\"Weight_Sharpe\"] = np.where(total_sharpe > 0, df_perf[\"Sharpe_Positive\"] / total_sharpe, 0)\n",
        "\n",
        "# # ===== 2Ô∏è‚É£ ‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î =====\n",
        "# df_signal_next = df_forecast_summary.copy()\n",
        "# df_signal_next = df_signal_next.merge(df_perf[[\"Stock\", \"Sharpe_Ratio\", \"Weight_Sharpe\"]], on=\"Stock\", how=\"left\")\n",
        "\n",
        "# # ===== 3Ô∏è‚É£ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Å‡∏≤‡∏£ Flip =====\n",
        "# df_signal_next[\"Raw_Signal\"] = np.where(df_signal_next[\"Pred_dLogclose\"] > 0, \"BUY\", \"SELL\")\n",
        "# df_signal_next[\"Flip_Flag\"] = np.where(df_signal_next[\"Sharpe_Ratio\"] < 0, True, False)\n",
        "# df_signal_next[\"Final_Signal\"] = np.where(\n",
        "#     df_signal_next[\"Flip_Flag\"],\n",
        "#     np.where(df_signal_next[\"Raw_Signal\"] == \"BUY\", \"SELL\", \"BUY\"),\n",
        "#     df_signal_next[\"Raw_Signal\"]\n",
        "# )\n",
        "\n",
        "# # ===== 4Ô∏è‚É£ ‡πÄ‡∏û‡∏¥‡πà‡∏° Comment / Interpretation =====\n",
        "# df_signal_next[\"Flip_Status\"] = np.where(df_signal_next[\"Flip_Flag\"], \"üîÅ Flipped\", \"‚úÖ Normal\")\n",
        "# df_signal_next[\"Comment\"] = np.where(\n",
        "#     df_signal_next[\"Flip_Flag\"],\n",
        "#     \"Model weak (Sharpe < 0) ‚Üí Contrarian signal\",\n",
        "#     \"Model consistent (Sharpe > 0)\"\n",
        "# )\n",
        "\n",
        "# df_signal_next[\"Expected_Return_%\"] = df_signal_next[\"Pred_dLogclose\"] * 100\n",
        "# df_signal_next[\"Weighted_Exp_Return_%\"] = df_signal_next[\"Expected_Return_%\"] * df_signal_next[\"Weight_Sharpe\"]\n",
        "\n",
        "# # ===== 5Ô∏è‚É£ Export & Display =====\n",
        "# cols_show = [\n",
        "#     \"Stock\", \"Sector\", \"Sharpe_Ratio\", \"Weight_Sharpe\",\n",
        "#     \"Pred_dLogclose\", \"Expected_Return_%\",\n",
        "#     \"Raw_Signal\", \"Final_Signal\", \"Flip_Status\", \"Comment\"\n",
        "# ]\n",
        "\n",
        "# # üîπ ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏° Expected_Return_% ‡∏à‡∏≤‡∏Å‡∏°‡∏≤‡∏Å‡πÑ‡∏õ‡∏ô‡πâ‡∏≠‡∏¢\n",
        "# df_signal_next = df_signal_next[cols_show].sort_values(\"Expected_Return_%\", ascending=False)\n",
        "\n",
        "# df_signal_next.to_excel(\"NextMonth_SignalPlan_SharpeWeighted_FlipInfo.xlsx\", index=False)\n",
        "# print(\"‚úÖ Exported ‚Üí NextMonth_SignalPlan_SharpeWeighted_FlipInfo.xlsx\")\n",
        "\n",
        "# # ===== 6Ô∏è‚É£ PRINT TABLE =====\n",
        "# print(\"\\n=== üìà Next-Month Trading Signals (Sharpe-weighted + Flip Info, Sorted by Expected Return) ===\")\n",
        "# display(df_signal_next)\n",
        "\n",
        "# # ===== 7Ô∏è‚É£ Visualization =====\n",
        "# plt.figure(figsize=(10,6))\n",
        "# sns.barplot(\n",
        "#     data=df_signal_next,\n",
        "#     x=\"Stock\",\n",
        "#     y=\"Expected_Return_%\",\n",
        "#     hue=\"Final_Signal\",\n",
        "#     dodge=False,\n",
        "#     order=df_signal_next[\"Stock\"]  # ‡πÉ‡∏ä‡πâ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á\n",
        "# )\n",
        "# plt.axhline(0, color=\"black\", lw=1)\n",
        "# plt.title(\"Next-Month Expected Return by Stock (Sharpe-weighted + Flip)\", weight=\"bold\")\n",
        "# plt.xticks(rotation=45, ha='right')\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHz_qdv85r_M"
      },
      "source": [
        "1. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• Deep Learning (Technical Side) [‡∏á‡∏≤‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì]‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á \"‡∏ï‡∏≤\" ‡∏Ç‡πâ‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á‡πÉ‡∏´‡πâ AI (‡∏Ç‡πâ‡∏≤‡∏á‡πÅ‡∏£‡∏Å‡∏Ñ‡∏∑‡∏≠ ARDL ‡∏Ç‡∏≠‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô)‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• LSTM ‡∏´‡∏£‡∏∑‡∏≠ GRU: ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô Code ‡πÅ‡∏¢‡∏Å‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ö‡∏Å‡∏£‡∏≤‡∏ü‡∏£‡∏≤‡∏Ñ‡∏≤‡πÅ‡∏•‡∏∞ Technical Indicators (RSI, MACD) 1‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤ Output ($b_t$): ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ó‡∏£‡∏ô‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô (Probability) ‡∏ß‡πà‡∏≤‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ‡∏ï‡∏•‡∏≤‡∏î‡∏à‡∏∞ Bull, Bear ‡∏´‡∏£‡∏∑‡∏≠ Neutral 2‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏ß‡∏±‡∏á: ‡∏≠‡∏¢‡πà‡∏≤‡πÄ‡∏ú‡∏•‡∏≠‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô \"‡∏£‡∏≤‡∏Ñ‡∏≤‡∏õ‡∏¥‡∏î\" (Price Regression) ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÉ‡∏ô Proposal ‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏ß‡πà‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô (Classification/Probability) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡πà‡∏á‡∏ï‡πà‡∏≠‡πÉ‡∏´‡πâ RL2. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö Reinforcement Learning (The Brain) [‡∏á‡∏≤‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì]‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠ \"‡∏™‡∏°‡∏≠‡∏á\" ‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏≠‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏≤‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ô‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö Environment: ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô Class Env ‡πÉ‡∏ô Python ‡πÉ‡∏´‡πâ‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 2 ‡∏ó‡∏≤‡∏á:Macro Signals ($m_t$): ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏≥‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß (‡∏à‡∏≤‡∏Å ARDL)Technical Signals ($b_t$): ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• Deep Learning ‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏≥‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠ 1‡∏£‡∏ß‡∏° State ($S_t$): ‡∏à‡∏±‡∏ö‡∏™‡∏≠‡∏á‡∏Ñ‡πà‡∏≤‡∏Ç‡πâ‡∏≤‡∏á‡∏ö‡∏ô‡∏°‡∏≤‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ô‡πÄ‡∏õ‡πá‡∏ô State ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß 3Train PPO Agent: ‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ AI ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à (Buy/Hold/Sell) ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Reward Function ‡∏ó‡∏µ‡πà‡∏´‡∏±‡∏Å‡∏•‡∏ö‡∏Ñ‡πà‡∏≤ Drawdown 43. ‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏±‡∏ö‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô (Data Interface)‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏á‡∏≤‡∏ô‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏Å‡∏±‡∏ô‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢ ‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏Å‡∏•‡∏á‡∏Å‡∏±‡∏ö‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö:Request: ‡∏ö‡∏≠‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏ß‡πà‡∏≤ \"‡∏Ç‡∏≠‡πÑ‡∏ü‡∏•‡πå Excel/CSV ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Predicted Return ‡∏´‡∏£‡∏∑‡∏≠ Macro Signal ‡∏à‡∏≤‡∏Å ARDL ‡∏£‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô ‡∏°‡∏≤‡πÉ‡∏´‡πâ‡∏â‡∏±‡∏ô‡∏´‡∏ô‡πà‡∏≠‡∏¢\"Action: ‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡πÄ‡∏≠‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ô‡∏±‡πâ‡∏ô‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô Input ‡∏™‡πà‡∏ß‡∏ô $m_t$ ‡πÉ‡∏ô Code RL ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏£‡∏±‡∏ö4. Backtesting & Report‡∏ô‡∏≥ AI ‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß ‡∏°‡∏≤‡πÄ‡∏ó‡∏£‡∏î‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏µ 2025 ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏ß‡∏±‡∏î‡∏Ñ‡πà‡∏≤ Sharpe Ratio, Drawdown ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡∏ï‡∏•‡∏≤‡∏î 5‡∏™‡∏£‡∏∏‡∏õ: ‡∏á‡∏≤‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏•‡∏î‡∏•‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÅ‡∏Ñ‡πà‡∏™‡∏≤‡∏¢ Programming & AI ‡∏•‡πâ‡∏ß‡∏ô‡πÜ ‡∏Ñ‡∏∑‡∏≠ \"‡∏ó‡∏≥ DL ‡πÉ‡∏´‡πâ‡πÄ‡∏™‡∏£‡πá‡∏à -> ‡πÄ‡∏≠‡∏≤ ARDL ‡∏Ç‡∏≠‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏°‡∏≤‡∏¢‡∏±‡∏î‡πÉ‡∏™‡πà RL -> ‡πÄ‡∏ó‡∏£‡∏ô AI -> ‡∏ß‡∏±‡∏î‡∏ú‡∏•\" ‡∏Ñ‡∏£‡∏±‡∏ö"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EU79AUs_ywur"
      },
      "outputs": [],
      "source": [
        "!jupyter nbconvert --to html \"Semester2_V1_AQT_ARDLTrading_Macro&Technical.ipynb\" --output \"AQT_Semester1_Final.html\"\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}