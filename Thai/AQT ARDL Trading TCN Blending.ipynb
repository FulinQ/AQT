{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRdkUxDEoTHL"
      },
      "source": [
        "**1 Collecting Data**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqWAq7nVFmr5"
      },
      "source": [
        "## Improve thing\n",
        "\n",
        "  2) A. à¸ªà¸£à¹‰à¸²à¸‡ Environment à¹à¸¥à¸° State Vector (à¸•à¸²à¸¡à¸«à¸±à¸§à¸‚à¹‰à¸­ 5. Method à¹ƒà¸™ Paper)à¹à¸œà¸™à¸‚à¸­à¸‡à¸„à¸¸à¸“à¸£à¸°à¸šà¸¸à¸§à¹ˆà¸²à¸ˆà¸°à¹ƒà¸Šà¹‰ Reinforcement Learning (RL) à¸‹à¸¶à¹ˆà¸‡à¸•à¹‰à¸­à¸‡à¸à¸²à¸£ \"à¸ªà¸ à¸²à¸à¹à¸§à¸”à¸¥à¹‰à¸­à¸¡ (Environment)\" à¹ƒà¸™à¸à¸²à¸£à¸•à¸±à¸”à¸ªà¸´à¸™à¹ƒà¸ˆ à¸„à¸¸à¸“à¸•à¹‰à¸­à¸‡à¹€à¸‚à¸µà¸¢à¸™ Code à¹€à¸à¸·à¹ˆà¸­à¸£à¸§à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸à¸ªà¸­à¸‡à¸ªà¹ˆà¸§à¸™à¹€à¸‚à¹‰à¸²à¸”à¹‰à¸§à¸¢à¸à¸±à¸™à¹€à¸›à¹‡à¸™ $S_t$:Macro Signal ($m_t$): à¹€à¸­à¸²à¸œà¸¥ Forecast à¸«à¸£à¸·à¸­à¸„à¹ˆà¸² ECT/Coefficients à¸ˆà¸²à¸à¹‚à¸¡à¹€à¸”à¸¥ ARDL-ECM à¸—à¸µà¹ˆà¸„à¸¸à¸“à¸—à¸³à¹€à¸ªà¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§à¸¡à¸²à¹€à¸›à¹‡à¸™ FeatureTechnical Signal ($b_t$): à¹€à¸­à¸²à¸„à¸§à¸²à¸¡à¸™à¹ˆà¸²à¸ˆà¸°à¹€à¸›à¹‡à¸™ ($P_{bull}, P_{bear}, P_{neutral}$) à¸«à¸£à¸·à¸­à¸ªà¸±à¸à¸à¸²à¸“à¸ˆà¸²à¸à¹‚à¸¡à¹€à¸”à¸¥ LSTM/GRU à¸¡à¸²à¹€à¸›à¹‡à¸™ FeaturePortfolio State: à¸ªà¸–à¸²à¸™à¸°à¸›à¸±à¸ˆà¸ˆà¸¸à¸šà¸±à¸™ (à¸–à¸·à¸­à¹€à¸‡à¸´à¸™à¸ªà¸”, à¸–à¸·à¸­à¸«à¸¸à¹‰à¸™, à¸•à¹‰à¸™à¸—à¸¸à¸™)à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸—à¸³: à¸ªà¸£à¹‰à¸²à¸‡ Class Environment (à¹€à¸Šà¹ˆà¸™à¸ªà¸·à¸šà¸—à¸­à¸”à¸ˆà¸²à¸ gym.Env) à¸—à¸µà¹ˆà¸£à¸±à¸šà¸„à¹ˆà¸²à¹€à¸«à¸¥à¹ˆà¸²à¸™à¸µà¹‰à¹€à¸‚à¹‰à¸²à¹„à¸›à¹ƒà¸™à¹à¸•à¹ˆà¸¥à¸° Step\n",
        "  3) B. à¸à¸±à¸’à¸™à¸²à¸ªà¹ˆà¸§à¸™ Reinforcement Learning (PPO Algorithm)à¹ƒà¸™ Code à¸›à¸±à¸ˆà¸ˆà¸¸à¸šà¸±à¸™à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸à¸šà¸ªà¹ˆà¸§à¸™à¸—à¸µà¹ˆà¹€à¸›à¹‡à¸™ PPO (Proximal Policy Optimization) à¸«à¸£à¸·à¸­ Agent à¸—à¸µà¹ˆà¸•à¸±à¸”à¸ªà¸´à¸™à¹ƒà¸ˆ \"à¸‹à¸·à¹‰à¸­/à¸‚à¸²à¸¢/à¸–à¸·à¸­\"Action: à¸„à¸¸à¸“à¸•à¹‰à¸­à¸‡à¸à¸³à¸«à¸™à¸” Action Space à¹€à¸›à¹‡à¸™ {Buy, Hold, Sell}Reward Function: à¹€à¸‚à¸µà¸¢à¸™à¸ªà¸¡à¸à¸²à¸£ Reward à¸•à¸²à¸¡à¹à¸œà¸™: $\\text{Reward} = \\text{Portfolio Value} - (\\lambda \\times \\text{Drawdown Penalty})$Implementation: à¹ƒà¸Šà¹‰ Library à¹€à¸Šà¹ˆà¸™ stable-baselines3 à¸«à¸£à¸·à¸­ rllib à¹€à¸à¸·à¹ˆà¸­à¸ªà¸£à¹‰à¸²à¸‡ PPO Agent à¹à¸¥à¹‰à¸§à¸ªà¸±à¹ˆà¸‡ Train à¸”à¹‰à¸§à¸¢ Environment à¸—à¸µà¹ˆà¸ªà¸£à¹‰à¸²à¸‡à¹ƒà¸™à¸‚à¹‰à¸­ A\n",
        "  4) C. à¹€à¸à¸´à¹ˆà¸¡à¹‚à¸¡à¹€à¸”à¸¥ CNN (Optional à¸•à¸²à¸¡à¹à¸œà¸™)\n",
        "à¹ƒà¸™à¹à¸œà¸™à¸£à¸°à¸šà¸¸à¸§à¹ˆà¸²à¸ˆà¸°à¹ƒà¸Šà¹‰ CNN (Convolutional Neural Networks) à¸£à¹ˆà¸§à¸¡à¸à¸±à¸š LSTM à¹€à¸à¸·à¹ˆà¸­à¸ˆà¸±à¸š Pattern à¸à¸£à¸²à¸Ÿ à¹à¸•à¹ˆà¹ƒà¸™ Code à¸à¸šà¹à¸„à¹ˆ LSTM/GRU\n",
        "\n",
        "\n",
        "5) D. à¸à¸²à¸£à¸£à¸§à¸¡à¸£à¸°à¸šà¸šà¹à¸¥à¸° Backtesting (Phase 4)\n",
        "Rolling Window Training: à¸•à¹‰à¸­à¸‡à¹€à¸‚à¸µà¸¢à¸™ Loop à¹€à¸à¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¹‚à¸¡à¹€à¸”à¸¥ Train à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸›à¸µ 2010-2024 à¹à¸¥à¸° Test à¸›à¸µ 2025 (Out-of-sample)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m32krxZ3oYCD",
        "outputId": "e923059b-abe4-4352-f8df-ce8292ac6c95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fredapi\n",
            "  Downloading fredapi-0.5.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from fredapi) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas->fredapi) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->fredapi) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->fredapi) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->fredapi) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->fredapi) (1.17.0)\n",
            "Downloading fredapi-0.5.2-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: fredapi\n",
            "Successfully installed fredapi-0.5.2\n"
          ]
        }
      ],
      "source": [
        "!pip install fredapi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38oP341GrfFn"
      },
      "source": [
        "GDP Data\n",
        "(https://)https://lookerstudio.google.com/u/0/reporting/52a283c8-91f9-4b35-8157-2b2b42312602/page/p_l7cxsbayvc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhTALLCnoY74",
        "outputId": "1a26cae1-520c-4da0-e8e9-c16bde8da77c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-645295282.py:112: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker_yf, start=START, end=END, interval=\"1mo\")['Close']\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-645295282.py:112: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker_yf, start=START, end=END, interval=\"1mo\")['Close']\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-645295282.py:112: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker_yf, start=START, end=END, interval=\"1mo\")['Close']\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-645295282.py:112: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker_yf, start=START, end=END, interval=\"1mo\")['Close']\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-645295282.py:112: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker_yf, start=START, end=END, interval=\"1mo\")['Close']\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-645295282.py:112: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker_yf, start=START, end=END, interval=\"1mo\")['Close']\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-645295282.py:112: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker_yf, start=START, end=END, interval=\"1mo\")['Close']\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-645295282.py:112: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker_yf, start=START, end=END, interval=\"1mo\")['Close']\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-645295282.py:112: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker_yf, start=START, end=END, interval=\"1mo\")['Close']\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-645295282.py:112: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker_yf, start=START, end=END, interval=\"1mo\")['Close']\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-645295282.py:112: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker_yf, start=START, end=END, interval=\"1mo\")['Close']\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-645295282.py:134: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  fx_thb_usd = yf.download(\"THB=X\", start=START, end=END, interval=\"1mo\")[\"Close\"]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-645295282.py:138: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  fx_thb_cny = yf.download(\"THBCNY=X\", start=START, end=END, interval=\"1mo\")[\"Close\"]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-645295282.py:142: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  fx_thb_inr = yf.download(\"THBINR=X\", start=START, end=END, interval=\"1mo\")[\"Close\"]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-645295282.py:146: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  brent_data = yf.download(\"BZ=F\", start=START, end=END, interval=\"1mo\")[\"Close\"]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-645295282.py:150: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  crb_data = yf.download(\"^CRB\", start=START, end=END, interval=\"1mo\")[\"Close\"]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['^CRB']: YFPricesMissingError('possibly delisted; no price data found  (1mo 2013-01-01 -> 2026-02-01)')\n",
            "/tmp/ipython-input-645295282.py:154: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  sp500_data = yf.download(\"^GSPC\", start=START, end=END, interval=\"1mo\")[\"Close\"]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-645295282.py:158: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  set_daily = yf.download(\"^SET.BK\", start=START, end=END, interval=\"1d\")[\"Close\"]\n",
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "             Close_BBL  Close_KBANK  Close_KKP  Close_KTB  Close_TCAP  \\\n",
            "Date                                                                    \n",
            "2015-02-01  120.324234   151.045578  18.905380  13.843619   16.486799   \n",
            "2015-03-01  121.310501   159.398285  18.784960  13.843619   16.369032   \n",
            "2015-04-01  121.639297   146.173111  17.821630  12.143525   16.015745   \n",
            "2015-05-01  122.538757   137.793152  17.965874  11.427542   16.611538   \n",
            "2015-06-01  119.845566   133.553375  17.591581  10.796185   16.126526   \n",
            "...                ...          ...        ...        ...         ...   \n",
            "2025-09-01  147.045898   165.540939  57.287346  24.412216   48.975368   \n",
            "2025-10-01  158.500000   186.500000  65.750000  26.823908   51.000000   \n",
            "2025-11-01  158.000000   186.500000  64.250000  27.070000   54.500000   \n",
            "2025-12-01  169.500000   194.500000  68.000000  28.250000   58.250000   \n",
            "2026-01-01  155.500000   187.000000  71.000000  28.500000   58.250000   \n",
            "\n",
            "            Close_TISCO  Close_TTB  Close_KTC  Close_AEONTS  Close_JMT  ...  \\\n",
            "Date                                                                    ...   \n",
            "2015-02-01    21.595560   1.766926   6.761018     75.498405   7.235693  ...   \n",
            "2015-03-01    21.021212   1.743522   7.632540     72.367126   6.783462  ...   \n",
            "2015-04-01    20.791470   1.521194   8.362267     70.279602   6.671339  ...   \n",
            "2015-05-01    21.600693   1.518632   7.376149     67.142464   6.445743  ...   \n",
            "2015-06-01    22.080709   1.399055   7.750874     66.788162   5.545500  ...   \n",
            "...                 ...        ...        ...           ...        ...  ...   \n",
            "2025-09-01   100.009758   1.834346  30.000000    113.939011  11.800000  ...   \n",
            "2025-10-01   107.500000   1.786073  28.500000    103.180824   9.750000  ...   \n",
            "2025-11-01   106.000000   1.930000  27.250000     96.000000   8.600000  ...   \n",
            "2025-12-01   110.500000   2.020000  26.250000    107.500000   8.750000  ...   \n",
            "2026-01-01   111.000000   1.990000  28.000000     96.250000   8.750000  ...   \n",
            "\n",
            "            THB_per_CNY  THB_per_INR  SP500_Index    SET_Index  IPI_Surprise  \\\n",
            "Date                                                                           \n",
            "2015-02-01     0.193350     1.906796  2104.500000  1582.699951     -0.000066   \n",
            "2015-03-01     0.190400     1.918100  2067.889893  1582.140015      0.000380   \n",
            "2015-04-01     0.188270     1.930500  2085.510010  1525.579956     -0.000670   \n",
            "2015-05-01     0.183510     1.889400  2107.389893  1519.880005     -0.000330   \n",
            "2015-06-01     0.183590     1.888000  2063.110107  1476.869995     -0.000280   \n",
            "...                 ...          ...          ...          ...           ...   \n",
            "2025-09-01     0.220962     2.753088  6688.459961  1244.479980     -0.000291   \n",
            "2025-10-01     0.220050     2.741562  6840.200195  1275.030029     -0.000291   \n",
            "2025-11-01     0.220339     2.782622  6849.089844  1308.859985     -0.000291   \n",
            "2025-12-01     0.222381     2.852539  6845.500000  1276.569946     -0.000291   \n",
            "2026-01-01     0.223474     2.955710  6939.029785  1280.050049     -0.000291   \n",
            "\n",
            "            Inflation_Surprise  5Y_1Y_Bond_Spread  10Y_5Y_Bond_Spread  \\\n",
            "Date                                                                    \n",
            "2015-02-01             -0.0066             0.0035              0.0056   \n",
            "2015-03-01             -0.0019             0.0045              0.0058   \n",
            "2015-04-01             -0.0012             0.0048              0.0051   \n",
            "2015-05-01             -0.0024             0.0042              0.0078   \n",
            "2015-06-01             -0.0015             0.0056              0.0082   \n",
            "...                        ...                ...                 ...   \n",
            "2025-09-01              0.0013            -0.0010              0.0027   \n",
            "2025-10-01              0.0013            -0.0010              0.0027   \n",
            "2025-11-01              0.0013            -0.0010              0.0027   \n",
            "2025-12-01              0.0013            -0.0010              0.0027   \n",
            "2026-01-01              0.0013            -0.0010              0.0027   \n",
            "\n",
            "            3M_1M_THOR_Spread  6M_1M_THOR_Spread  \n",
            "Date                                              \n",
            "2015-02-01           0.000015           0.000068  \n",
            "2015-03-01           0.000032           0.000077  \n",
            "2015-04-01           0.001167           0.001528  \n",
            "2015-05-01           0.001280           0.002220  \n",
            "2015-06-01           0.001854           0.003469  \n",
            "...                       ...                ...  \n",
            "2025-09-01           0.000052           0.000139  \n",
            "2025-10-01           0.000052           0.000139  \n",
            "2025-11-01           0.000052           0.000139  \n",
            "2025-12-01           0.000052           0.000139  \n",
            "2026-01-01           0.000052           0.000139  \n",
            "\n",
            "[132 rows x 36 columns]\n",
            "\n",
            "=== HEAD ===\n",
            "             Close_BBL  Close_KBANK  Close_KKP  Close_KTB  Close_TCAP  \\\n",
            "Date                                                                    \n",
            "2015-02-01  120.324234   151.045578  18.905380  13.843619   16.486799   \n",
            "2015-03-01  121.310501   159.398285  18.784960  13.843619   16.369032   \n",
            "2015-04-01  121.639297   146.173111  17.821630  12.143525   16.015745   \n",
            "2015-05-01  122.538757   137.793152  17.965874  11.427542   16.611538   \n",
            "2015-06-01  119.845566   133.553375  17.591581  10.796185   16.126526   \n",
            "2015-07-01  111.766075   125.780434  15.221086  11.048729   15.156510   \n",
            "2015-08-01  110.756187   127.546997  16.094425  11.490678   14.307749   \n",
            "2015-09-01  107.726357   120.834023  15.345853  10.796185   15.399013   \n",
            "2015-10-01  114.194618   122.236374  17.232647  10.796185   16.247780   \n",
            "2015-11-01  114.194618   121.173454  18.775873  10.733050   17.481974   \n",
            "\n",
            "            Close_TISCO  Close_TTB  Close_KTC  Close_AEONTS  Close_JMT  ...  \\\n",
            "Date                                                                    ...   \n",
            "2015-02-01    21.595560   1.766926   6.761018     75.498405   7.235693  ...   \n",
            "2015-03-01    21.021212   1.743522   7.632540     72.367126   6.783462  ...   \n",
            "2015-04-01    20.791470   1.521194   8.362267     70.279602   6.671339  ...   \n",
            "2015-05-01    21.600693   1.518632   7.376149     67.142464   6.445743  ...   \n",
            "2015-06-01    22.080709   1.399055   7.750874     66.788162   5.545500  ...   \n",
            "2015-07-01    20.400656   1.399055   6.251977     62.359215   5.401460  ...   \n",
            "2015-08-01    18.960608   1.411012   6.942258     60.233353   4.969343  ...   \n",
            "2015-09-01    17.040548   1.446886   7.395872     67.851097   5.401460  ...   \n",
            "2015-10-01    18.120581   1.590377   7.869207     69.799820   5.617519  ...   \n",
            "2015-11-01    20.160648   1.554505   7.770598     70.834808   4.789295  ...   \n",
            "\n",
            "            THB_per_CNY  THB_per_INR  SP500_Index    SET_Index  IPI_Surprise  \\\n",
            "Date                                                                           \n",
            "2015-02-01      0.19335     1.906796  2104.500000  1582.699951     -0.000066   \n",
            "2015-03-01      0.19040     1.918100  2067.889893  1582.140015      0.000380   \n",
            "2015-04-01      0.18827     1.930500  2085.510010  1525.579956     -0.000670   \n",
            "2015-05-01      0.18351     1.889400  2107.389893  1519.880005     -0.000330   \n",
            "2015-06-01      0.18359     1.888000  2063.110107  1476.869995     -0.000280   \n",
            "2015-07-01      0.17655     1.824900  2103.840088  1491.619995     -0.000285   \n",
            "2015-08-01      0.17805     1.844600  1972.180054  1442.040039      0.000045   \n",
            "2015-09-01      0.17444     1.809500  1920.030029  1362.390015     -0.000200   \n",
            "2015-10-01      0.17707     1.837830  2079.360107  1345.150024     -0.000200   \n",
            "2015-11-01      0.17655     1.867500  2080.409912  1413.339966     -0.000042   \n",
            "\n",
            "            Inflation_Surprise  5Y_1Y_Bond_Spread  10Y_5Y_Bond_Spread  \\\n",
            "Date                                                                    \n",
            "2015-02-01             -0.0066            0.00350             0.00560   \n",
            "2015-03-01             -0.0019            0.00450             0.00580   \n",
            "2015-04-01             -0.0012            0.00480             0.00510   \n",
            "2015-05-01             -0.0024            0.00420             0.00780   \n",
            "2015-06-01             -0.0015            0.00560             0.00820   \n",
            "2015-07-01             -0.0007            0.00630             0.00630   \n",
            "2015-08-01             -0.0007            0.00530             0.00620   \n",
            "2015-09-01              0.0001            0.00575             0.00535   \n",
            "2015-10-01              0.0001            0.00575             0.00535   \n",
            "2015-11-01              0.0017            0.00530             0.00640   \n",
            "\n",
            "            3M_1M_THOR_Spread  6M_1M_THOR_Spread  \n",
            "Date                                              \n",
            "2015-02-01           0.000015           0.000068  \n",
            "2015-03-01           0.000032           0.000077  \n",
            "2015-04-01           0.001167           0.001528  \n",
            "2015-05-01           0.001280           0.002220  \n",
            "2015-06-01           0.001854           0.003469  \n",
            "2015-07-01           0.000772           0.002587  \n",
            "2015-08-01           0.000024           0.001743  \n",
            "2015-09-01           0.000020           0.000980  \n",
            "2015-10-01           0.000020           0.000980  \n",
            "2015-11-01           0.000020           0.000049  \n",
            "\n",
            "[10 rows x 36 columns]\n",
            "\n",
            "=== TAIL ===\n",
            "             Close_BBL  Close_KBANK  Close_KKP  Close_KTB  Close_TCAP  \\\n",
            "Date                                                                    \n",
            "2025-04-01  131.839539   147.193665  46.073650  19.992119   44.601631   \n",
            "2025-05-01  139.644257   149.878723  41.927025  21.852873   46.051464   \n",
            "2025-06-01  137.177048   151.704681  44.123444  20.966944   44.589512   \n",
            "2025-07-01  146.059021   160.105255  53.874481  21.656000   48.000732   \n",
            "2025-08-01  153.460663   166.529236  58.018673  24.215345   49.462685   \n",
            "2025-09-01  147.045898   165.540939  57.287346  24.412216   48.975368   \n",
            "2025-10-01  158.500000   186.500000  65.750000  26.823908   51.000000   \n",
            "2025-11-01  158.000000   186.500000  64.250000  27.070000   54.500000   \n",
            "2025-12-01  169.500000   194.500000  68.000000  28.250000   58.250000   \n",
            "2026-01-01  155.500000   187.000000  71.000000  28.500000   58.250000   \n",
            "\n",
            "            Close_TISCO  Close_TTB  Close_KTC  Close_AEONTS  Close_JMT  ...  \\\n",
            "Date                                                                    ...   \n",
            "2025-04-01    90.793785   1.703317   45.15099    100.401070  13.528524  ...   \n",
            "2025-05-01    95.597565   1.853654   38.50000    100.735779   9.068032  ...   \n",
            "2025-06-01    94.862198   1.824691   24.00000     91.689117   8.724917  ...   \n",
            "2025-07-01    97.313416   1.863309   28.50000     96.579208  10.881639  ...   \n",
            "2025-08-01    99.029266   1.834346   27.25000    107.092888  11.469835  ...   \n",
            "2025-09-01   100.009758   1.834346   30.00000    113.939011  11.800000  ...   \n",
            "2025-10-01   107.500000   1.786073   28.50000    103.180824   9.750000  ...   \n",
            "2025-11-01   106.000000   1.930000   27.25000     96.000000   8.600000  ...   \n",
            "2025-12-01   110.500000   2.020000   26.25000    107.500000   8.750000  ...   \n",
            "2026-01-01   111.000000   1.990000   28.00000     96.250000   8.750000  ...   \n",
            "\n",
            "            THB_per_CNY  THB_per_INR  SP500_Index    SET_Index  IPI_Surprise  \\\n",
            "Date                                                                           \n",
            "2025-04-01     0.217374     2.546977  5569.060059  1168.020020     -0.000291   \n",
            "2025-05-01     0.219625     2.623555  5911.689941  1198.979980     -0.000291   \n",
            "2025-06-01     0.219666     2.618918  6204.950195  1132.020020     -0.000291   \n",
            "2025-07-01     0.219328     2.681052  6339.390137  1110.010010     -0.000291   \n",
            "2025-08-01     0.220721     2.729206  6460.259766  1218.329956     -0.000291   \n",
            "2025-09-01     0.220962     2.753088  6688.459961  1244.479980     -0.000291   \n",
            "2025-10-01     0.220050     2.741562  6840.200195  1275.030029     -0.000291   \n",
            "2025-11-01     0.220339     2.782622  6849.089844  1308.859985     -0.000291   \n",
            "2025-12-01     0.222381     2.852539  6845.500000  1276.569946     -0.000291   \n",
            "2026-01-01     0.223474     2.955710  6939.029785  1280.050049     -0.000291   \n",
            "\n",
            "            Inflation_Surprise  5Y_1Y_Bond_Spread  10Y_5Y_Bond_Spread  \\\n",
            "Date                                                                    \n",
            "2025-04-01              0.0013             -0.001              0.0027   \n",
            "2025-05-01              0.0013             -0.001              0.0027   \n",
            "2025-06-01              0.0013             -0.001              0.0027   \n",
            "2025-07-01              0.0013             -0.001              0.0027   \n",
            "2025-08-01              0.0013             -0.001              0.0027   \n",
            "2025-09-01              0.0013             -0.001              0.0027   \n",
            "2025-10-01              0.0013             -0.001              0.0027   \n",
            "2025-11-01              0.0013             -0.001              0.0027   \n",
            "2025-12-01              0.0013             -0.001              0.0027   \n",
            "2026-01-01              0.0013             -0.001              0.0027   \n",
            "\n",
            "            3M_1M_THOR_Spread  6M_1M_THOR_Spread  \n",
            "Date                                              \n",
            "2025-04-01           0.000052           0.000139  \n",
            "2025-05-01           0.000052           0.000139  \n",
            "2025-06-01           0.000052           0.000139  \n",
            "2025-07-01           0.000052           0.000139  \n",
            "2025-08-01           0.000052           0.000139  \n",
            "2025-09-01           0.000052           0.000139  \n",
            "2025-10-01           0.000052           0.000139  \n",
            "2025-11-01           0.000052           0.000139  \n",
            "2025-12-01           0.000052           0.000139  \n",
            "2026-01-01           0.000052           0.000139  \n",
            "\n",
            "[10 rows x 36 columns]\n",
            "\n",
            "=== COLUMNS ===\n",
            "['Close_BBL', 'Close_KBANK', 'Close_KKP', 'Close_KTB', 'Close_TCAP', 'Close_TISCO', 'Close_TTB', 'Close_KTC', 'Close_AEONTS', 'Close_JMT', 'Close_SAWAD', 'Inflation', 'Inflation_Forecast', 'IPI', 'IPI_Forecast', 'BroadMoney_M1M2_Growth', 'THOR_1M', 'THOR_3M', 'THOR_6M', 'Bond_Yield_1Y', 'Bond_Yield_5Y', 'Bond_Yield_10Y', 'Yield_Spread_10Y_5Y', 'Yield_Spread_5Y_1Y', 'Yield_Spread_10Y_1Y', 'THB_per_USD', 'THB_per_CNY', 'THB_per_INR', 'SP500_Index', 'SET_Index', 'IPI_Surprise', 'Inflation_Surprise', '5Y_1Y_Bond_Spread', '10Y_5Y_Bond_Spread', '3M_1M_THOR_Spread', '6M_1M_THOR_Spread']\n",
            "\n",
            "=== NA COUNTS ===\n",
            "Close_BBL                 0\n",
            "Close_KBANK               0\n",
            "Close_KKP                 0\n",
            "Close_KTB                 0\n",
            "Close_TCAP                0\n",
            "Close_TISCO               0\n",
            "Close_TTB                 0\n",
            "Close_KTC                 0\n",
            "Close_AEONTS              0\n",
            "Close_JMT                 0\n",
            "Close_SAWAD               0\n",
            "Inflation                 0\n",
            "Inflation_Forecast        0\n",
            "IPI                       0\n",
            "IPI_Forecast              0\n",
            "BroadMoney_M1M2_Growth    0\n",
            "THOR_1M                   0\n",
            "THOR_3M                   0\n",
            "THOR_6M                   0\n",
            "Bond_Yield_1Y             0\n",
            "Bond_Yield_5Y             0\n",
            "Bond_Yield_10Y            0\n",
            "Yield_Spread_10Y_5Y       0\n",
            "Yield_Spread_5Y_1Y        0\n",
            "Yield_Spread_10Y_1Y       0\n",
            "THB_per_USD               0\n",
            "THB_per_CNY               0\n",
            "THB_per_INR               0\n",
            "SP500_Index               0\n",
            "SET_Index                 0\n",
            "IPI_Surprise              0\n",
            "Inflation_Surprise        0\n",
            "5Y_1Y_Bond_Spread         0\n",
            "10Y_5Y_Bond_Spread        0\n",
            "3M_1M_THOR_Spread         0\n",
            "6M_1M_THOR_Spread         0\n",
            "dtype: int64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ================== Setup ==================\n",
        "# pip install yfinance fredapi pandas pandas-datareader\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from fredapi import Fred\n",
        "from pandas_datareader import wb\n",
        "from datetime import date\n",
        "import io, requests\n",
        "from pathlib import Path\n",
        "\n",
        "# ----- Parameters -----\n",
        "START = \"2013-01-01\"\n",
        "END   = date.today().isoformat()         # à¸§à¸±à¸™à¸™à¸µà¹‰\n",
        "FRED_API_KEY = \"c948956426006ca126a2dd3bd1f07cee\"\n",
        "\n",
        "# FRED client (à¸à¸±à¸™à¸­à¸´à¸™à¹€à¸—à¸­à¸£à¹Œà¹€à¸™à¹‡à¸•à¸¥à¹ˆà¸¡)\n",
        "try:\n",
        "    fred = Fred(api_key=FRED_API_KEY)\n",
        "except Exception:\n",
        "    fred = None\n",
        "\n",
        "# ================== Helper Functions ==================\n",
        "def get_fred_series(series_id: str, rename_to: str = None) -> pd.Series:\n",
        "    \"\"\"à¸”à¸¶à¸‡à¸‹à¸µà¸£à¸µà¸ªà¹Œà¸ˆà¸²à¸ FRED\"\"\"\n",
        "    if fred is None:\n",
        "        return pd.Series(dtype=\"float64\", name=rename_to or series_id)\n",
        "    s = fred.get_series(series_id)\n",
        "    s.name = rename_to or series_id\n",
        "    s.index = pd.to_datetime(s.index)\n",
        "    return s.sort_index()\n",
        "\n",
        "def expand_period_to_target_index(target_index: pd.DatetimeIndex,\n",
        "                                  lowfreq_series: pd.Series,\n",
        "                                  freq: str) -> pd.Series:\n",
        "    \"\"\"à¸‚à¸¢à¸²à¸¢à¸„à¹ˆà¸²à¸„à¸§à¸²à¸¡à¸–à¸µà¹ˆà¸•à¹ˆà¸³à¹„à¸›à¸—à¸µà¹ˆ target_index\"\"\"\n",
        "    if lowfreq_series is None or lowfreq_series.empty:\n",
        "        return pd.Series(index=target_index, dtype=\"float64\", name=getattr(lowfreq_series, \"name\", None))\n",
        "    s = lowfreq_series.dropna().copy()\n",
        "    s.index = pd.PeriodIndex(s.index, freq=freq)\n",
        "    df = pd.DataFrame(index=target_index)\n",
        "    df[\"period\"] = df.index.to_period(freq)\n",
        "    out = df.join(s.rename(s.name), on=\"period\")[s.name]\n",
        "    out.name = s.name\n",
        "    return out\n",
        "\n",
        "# ================== 2) Macro: à¹ƒà¸Šà¹‰ Macro_data.xlsx ==================\n",
        "macro_candidates = [Path(\"/mnt/data/Macro_data.xlsx\"), Path(\"Macro_data.xlsx\")]\n",
        "macro_path = next((str(p) for p in macro_candidates if p.exists()), \"Macro_data.xlsx\")\n",
        "\n",
        "macro = pd.read_excel(macro_path, sheet_name=0)\n",
        "\n",
        "def _pct_to_float(col: pd.Series) -> pd.Series:\n",
        "    \"\"\"à¹à¸›à¸¥à¸‡à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ % à¹ƒà¸«à¹‰à¹€à¸›à¹‡à¸™à¸•à¸±à¸§à¹€à¸¥à¸‚\"\"\"\n",
        "    return (\n",
        "        col.astype(str)\n",
        "           .str.strip()\n",
        "           .str.replace(\",\", \"\", regex=False)\n",
        "           .str.replace(\"%\", \"\", regex=False)\n",
        "           .str.replace(\"(\", \"-\", regex=False)\n",
        "           .str.replace(\")\", \"\", regex=False)\n",
        "           .replace({\"\": None})\n",
        "           .pipe(pd.to_numeric, errors=\"coerce\")\n",
        "    )\n",
        "\n",
        "macro[\"Date\"] = pd.to_datetime(macro[\"Date\"], dayfirst=True, errors=\"coerce\")\n",
        "\n",
        "for col in [\"CPI_Actual\", \"CPI_Forecast\", \"IPI_Actual\", \"IPI_Forecast\"]:\n",
        "    if col in macro.columns:\n",
        "        macro[col] = _pct_to_float(macro[col])\n",
        "\n",
        "macro = (macro.rename(columns={\n",
        "            \"M1M2_Actual\": \"BroadMoney_M1M2_Level\",\n",
        "            \"CPI_Actual\": \"Inflation\",\n",
        "            \"CPI_Forecast\": \"Inflation_Forecast\",\n",
        "            \"THOR_1M\": \"THOR_1M\",\n",
        "            \"THOR_3M\": \"THOR_3M\",\n",
        "            \"THOR_6M\": \"THOR_6M\",\n",
        "            \"IPI_Actual\": \"IPI\",\n",
        "            \"IPI_Forecast\": \"IPI_Forecast\",\n",
        "            \"Bond_1Y\": \"Bond_Yield_1Y\",\n",
        "            \"Bond_5Y\": \"Bond_Yield_5Y\",\n",
        "            \"Bond_10Y\": \"Bond_Yield_10Y\",\n",
        "            \"Bond_spread_10Y_5Y\": \"Yield_Spread_10Y_5Y\",\n",
        "            \"Bond_spread_5Y_1Y\": \"Yield_Spread_5Y_1Y\",\n",
        "            \"Bond_spread_10Y_1Y\": \"Yield_Spread_10Y_1Y\"\n",
        "        })\n",
        "        .sort_values(\"Date\")\n",
        "        .set_index(\"Date\"))\n",
        "\n",
        "# ================== 1) Stock Prices ==================\n",
        "SECTORS = {\n",
        "    \"Banking\": [\"BBL\",\"KBANK\",\"KKP\",\"KTB\",\"TCAP\",\"TISCO\",\"TTB\"],\n",
        "    \"Finance_Securities\": [\"KTC\",\"AEONTS\",\"JMT\",\"SAWAD\"],\n",
        "    # \"Energy_Utilities\": [\"BANPU\",\"BCP\",\"EGCO\",\"GPSC\",\"GULF\",\"OR\",\"PTT\",\"PTTEP\",\"RATCH\",\"TOP\",\"BGRIM\",\"BCPG\",\"EA\",\"GUNKUL\",\"IRPC\",\"SPRC\",\"WHAUP\",\"CKP\"],\n",
        "    # \"Food_Beverage\": [\"CBG\",\"CPF\",\"OSP\",\"TU\",\"ITC\",\"BTG\",\"ICHI\",\"M\",\"TFG\",\"COCOCO\",\"SAPPE\",\"SNNP\"],\n",
        "    # \"Commerce\": [\"BJC\",\"COM7\",\"CPALL\",\"CRC\",\"HMPRO\",\"GLOBAL\",\"DOHOME\",\"MEGA\",\"MOSHI\"],\n",
        "    # \"Property_Development\": [\"AWC\",\"CPN\",\"LH\",\"WHA\",\"AMATA\",\"AP\",\"MBK\",\"QH\",\"SIRI\",\"SPALI\",\"ROJNA\"],\n",
        "    # \"Health_Care_Services\": [\"BDMS\",\"BH\",\"BCH\",\"CHG\"],       =>\n",
        "    # \"Electronic_Components\": [\"CCET\",\"DELTA\",\"HANA\",\"KCE\"],\n",
        "    # \"Construction_Materials\": [\"SCC\",\"TASCO\",\"TOA\"],\n",
        "    # \"ICT\": [\"ADVANC\",\"TRUE\",\"JAS\",\"JMART\",\"JTS\",\"SKY\"],\n",
        "    # \"Transportation_Logistics\": [\"AOT\",\"BEM\",\"BTS\",\"AAV\",\"BA\",\"RCL\"],     =>\n",
        "}\n",
        "\n",
        "df_stocks = pd.DataFrame()\n",
        "for sector, tickers in SECTORS.items():\n",
        "    for ticker in tickers:\n",
        "        try:\n",
        "            ticker_yf = ticker + \".BK\"\n",
        "            data = yf.download(ticker_yf, start=START, end=END, interval=\"1mo\")['Close']\n",
        "            if isinstance(data, pd.Series):\n",
        "                df_stocks[f\"Close_{ticker}\"] = data\n",
        "            else:\n",
        "                df_stocks[f\"Close_{ticker}\"] = data[ticker_yf]\n",
        "        except Exception:\n",
        "            df_stocks[f\"Close_{ticker}\"] = pd.Series(dtype=\"float64\")\n",
        "\n",
        "df_stocks = df_stocks.dropna(how=\"all\")\n",
        "\n",
        "if not df_stocks.empty:\n",
        "    quarterly_index = df_stocks.index\n",
        "else:\n",
        "    quarterly_index = pd.date_range(start=pd.to_datetime(START), end=pd.to_datetime(END), freq=\"QS\")\n",
        "\n",
        "# ================== 2) Align Macro ==================\n",
        "if not macro.index.is_unique:\n",
        "    macro = macro[~macro.index.duplicated(keep=\"last\")]\n",
        "\n",
        "macro_q = macro.reindex(quarterly_index, method=\"ffill\")\n",
        "\n",
        "# FX THB/USD\n",
        "fx_thb_usd = yf.download(\"THB=X\", start=START, end=END, interval=\"1mo\")[\"Close\"]\n",
        "fx_thb_usd.name = \"THB_per_USD\"\n",
        "\n",
        "# FX THB/CNY\n",
        "fx_thb_cny = yf.download(\"THBCNY=X\", start=START, end=END, interval=\"1mo\")[\"Close\"]\n",
        "fx_thb_cny.name = \"THB_per_CNY\"\n",
        "\n",
        "# FX THB/INR\n",
        "fx_thb_inr = yf.download(\"THBINR=X\", start=START, end=END, interval=\"1mo\")[\"Close\"]\n",
        "fx_thb_inr.name = \"THB_per_INR\"\n",
        "\n",
        "# Brent Oil (USD per barrel)\n",
        "brent_data = yf.download(\"BZ=F\", start=START, end=END, interval=\"1mo\")[\"Close\"]\n",
        "brent_data.name = \"Brent_Oil_USD_per_bbl\"\n",
        "\n",
        "# CRB Index\n",
        "crb_data = yf.download(\"^CRB\", start=START, end=END, interval=\"1mo\")[\"Close\"]\n",
        "crb_data.name = \"CRB_Index\"\n",
        "\n",
        "# S&P 500 Index\n",
        "sp500_data = yf.download(\"^GSPC\", start=START, end=END, interval=\"1mo\")[\"Close\"]\n",
        "sp500_data.name = \"SP500_Index\"\n",
        "\n",
        "# SET Index (Thailand)\n",
        "set_daily = yf.download(\"^SET.BK\", start=START, end=END, interval=\"1d\")[\"Close\"]\n",
        "\n",
        "# --- à¹€à¸¥à¸·à¸­à¸à¸£à¸²à¸„à¸²à¸›à¸´à¸”à¸‚à¸­à¸‡ \"à¸§à¸±à¸™à¹à¸£à¸à¸‚à¸­à¸‡à¹à¸•à¹ˆà¸¥à¸°à¹€à¸”à¸·à¸­à¸™\" ---\n",
        "set_monthly = set_daily.resample(\"MS\").first()\n",
        "set_monthly.name = \"SET_Index\"\n",
        "\n",
        "# ================== 4) Combine à¸«à¸¸à¹‰à¸™ + Macro ==================\n",
        "df = df_stocks.copy()\n",
        "if df.empty:\n",
        "    df = pd.DataFrame(index=quarterly_index)\n",
        "\n",
        "# Macro Variables\n",
        "if \"Inflation\" in macro_q.columns:\n",
        "    df[\"Inflation\"] = macro_q[\"Inflation\"] / 100.0\n",
        "if \"Inflation_Forecast\" in macro_q.columns:\n",
        "    df[\"Inflation_Forecast\"] = macro_q[\"Inflation_Forecast\"] / 100.0\n",
        "if \"IPI\" in macro_q.columns:\n",
        "    df[\"IPI\"] = macro_q[\"IPI\"] / 100.0\n",
        "if \"IPI_Forecast\" in macro_q.columns:\n",
        "    df[\"IPI_Forecast\"] = macro_q[\"IPI_Forecast\"] / 100.0\n",
        "\n",
        "# âœ… BroadMoney: à¹ƒà¸Šà¹‰à¸ªà¸¹à¸•à¸£ ln(S_t / S_{t-1}) à¹à¸¥à¸°à¹ƒà¸«à¹‰à¹à¸–à¸§à¹à¸£à¸à¹€à¸›à¹‡à¸™ 0\n",
        "if \"BroadMoney_M1M2_Level\" in macro_q.columns:\n",
        "    money_series = macro_q[\"BroadMoney_M1M2_Level\"]\n",
        "    money_growth = np.log(money_series / money_series.shift(1))\n",
        "    money_growth.iloc[0] = 0.0  # à¹à¸–à¸§à¹à¸£à¸à¹ƒà¸«à¹‰à¹€à¸›à¹‡à¸™ 0%\n",
        "    df[\"BroadMoney_M1M2_Growth\"] = money_growth\n",
        "\n",
        "# Interest Rates\n",
        "for col in [\"THOR_1M\", \"THOR_3M\", \"THOR_6M\",\n",
        "            \"Bond_Yield_1Y\", \"Bond_Yield_5Y\", \"Bond_Yield_10Y\",\n",
        "            \"Yield_Spread_10Y_5Y\", \"Yield_Spread_5Y_1Y\", \"Yield_Spread_10Y_1Y\"]:\n",
        "    if col in macro_q.columns:\n",
        "        df[col] = macro_q[col]\n",
        "\n",
        "# Combine Global Indicators\n",
        "df[\"THB_per_USD\"] = fx_thb_usd\n",
        "df[\"THB_per_CNY\"] = fx_thb_cny\n",
        "df[\"THB_per_INR\"] = fx_thb_inr\n",
        "# df[\"Brent_Oil_USD_per_bbl\"] = brent_data\n",
        "df[\"CRB_Index\"] = crb_data\n",
        "df[\"SP500_Index\"] = sp500_data\n",
        "df[\"SET_Index\"] = set_monthly\n",
        "\n",
        "df['IPI_Surprise'] = df['IPI'] - df['IPI_Forecast']\n",
        "df['Inflation_Surprise'] = df['Inflation'] - df['Inflation_Forecast']\n",
        "df['5Y_1Y_Bond_Spread'] = df[\"Bond_Yield_5Y\"] - df[\"Bond_Yield_1Y\"]\n",
        "df['10Y_5Y_Bond_Spread'] = df[\"Bond_Yield_10Y\"] - df[\"Bond_Yield_5Y\"]\n",
        "df['3M_1M_THOR_Spread'] = df[\"THOR_3M\"] - df[\"THOR_1M\"]\n",
        "df['6M_1M_THOR_Spread'] = df[\"THOR_6M\"] - df[\"THOR_1M\"]\n",
        "\n",
        "\n",
        "\n",
        "# ================== 5) à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ ==================\n",
        "df = df.iloc[25:]\n",
        "df.drop([\"CRB_Index\"], axis=1, inplace=True)\n",
        "\n",
        "print(df)\n",
        "print(\"\\n=== HEAD ===\")\n",
        "print(df.head(10))\n",
        "print(\"\\n=== TAIL ===\")\n",
        "print(df.tail(10))\n",
        "print(\"\\n=== COLUMNS ===\")\n",
        "print(df.columns.tolist())\n",
        "print(\"\\n=== NA COUNTS ===\")\n",
        "print(df.isna().sum())\n",
        "\n",
        "# (Optional) Save to CSV\n",
        "# df.to_csv(\"th_stock_macro_2013_today_quarterly.csv\", encoding=\"utf-8-sig\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J12Zxwlv8qbt"
      },
      "source": [
        "| Component               | Description                                    | Paper                 |\n",
        "| ----------------------- | ---------------------------------------------- | --------------------- |\n",
        "| Proxy selection         | Dynamic Factor / PCA on macro dataset          | Stock & Watson (2002) |\n",
        "| Temporal disaggregation | Chow-Lin linear regression                     | Chow & Lin (1971)     |\n",
        "| Extrapolation           | AR(1) residual correction (Fernandez model)    | Fernandez (1981)      |\n",
        "| Ratio preservation      | Denton (1971) for % variables (e.g., Debt/GDP) | Denton (1971)         |\n",
        "\n",
        "ğŸ“˜ Academic Framework (à¸ªà¸³à¸«à¸£à¸±à¸š citation à¹ƒà¸™ report)\n",
        "\n",
        "Chow & Lin (1971) â€“ Best Linear Unbiased Interpolation by Related Series\n",
        "\n",
        "Stock & Watson (2002) â€“ Macroeconomic Forecasting Using Diffusion Indexes\n",
        "\n",
        "Mariano & Murasawa (2003) â€“ A New Coincident Index of Business Cycles Based on Monthly and Quarterly Series\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSokRAAP4TTp",
        "outputId": "4135a9db-dd1c-4c0c-c60b-4821cd76bd5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "ğŸ“Š BLOCK 1.5: Chow-Lin Temporal Disaggregation\n",
            "============================================================\n",
            "\n",
            "ğŸ“¥ Loading GDP Quarterly data...\n",
            "âœ… GDP Quarterly loaded: 51 quarters\n",
            "   Period: 2013-01 to 2025-07\n",
            "\n",
            "ğŸ“¥ Preparing IPI as high-frequency indicator...\n",
            "âœ… IPI Monthly loaded: 132 months\n",
            "   Period: 2015-02 to 2026-01\n",
            "\n",
            "ğŸ”„ Applying Chow-Lin disaggregation (GDP Quarterly â†’ Monthly)...\n",
            "âš ï¸ Warning: Not enough high-freq data. Need 129, have 128\n",
            "\n",
            "âœ… Chow-Lin disaggregation completed!\n",
            "   - Estimated AR(1) rho: 0.8322\n",
            "   - Monthly GDP observations: 129\n",
            "\n",
            "ğŸ” Validation: Aggregating monthly back to quarterly...\n",
            "âœ… Mean Aggregation Error: 1.868700%\n",
            "   (Should be ~0% if Chow-Lin is working correctly)\n",
            "\n",
            "ğŸ“Œ Adding GDP_Monthly and GDP_Growth to main dataframe...\n",
            "âœ… Added 'GDP_Monthly' and 'GDP_Growth' to df\n",
            "   df shape: (132, 38)\n",
            "\n",
            "ğŸ“Š GDP columns preview:\n",
            "             GDP_Monthly  GDP_Growth\n",
            "Date                                \n",
            "2025-04-01  1.566892e+06   -0.014493\n",
            "2025-05-01  1.536566e+06   -0.019544\n",
            "2025-06-01  1.521829e+06   -0.009637\n",
            "2025-07-01  1.522122e+06    0.000192\n",
            "2025-08-01  1.537391e+06    0.009982\n",
            "2025-09-01  1.543481e+06    0.003953\n",
            "2025-10-01  1.538713e+06   -0.003094\n",
            "2025-11-01  1.538713e+06   -0.003094\n",
            "2025-12-01  1.538713e+06   -0.003094\n",
            "2026-01-01  1.538713e+06   -0.003094\n",
            "\n",
            "============================================================\n",
            "âœ… BLOCK 1.5 COMPLETED: Chow-Lin Temporal Disaggregation\n",
            "============================================================\n",
            "\n",
            "Summary:\n",
            "- Input:  GDP Quarterly (Total_CUR) - 51 quarters\n",
            "- Output: GDP Monthly - 129 months\n",
            "- Indicator used: IPI (Industrial Production Index)\n",
            "- Method: Chow-Lin (1971) with AR(1) residual structure\n",
            "- Estimated rho: 0.8322\n",
            "\n",
            "New columns added to df:\n",
            "- 'GDP_Monthly': Monthly GDP level (Current Price, Mil THB)\n",
            "- 'GDP_Growth': Monthly GDP growth rate (Log %)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# ğŸ“Š BLOCK 1.5: Chow-Lin Temporal Disaggregation (GDP Quarterly â†’ Monthly)\n",
        "#    Reference: Chow & Lin (1971) - Best Linear Unbiased Interpolation\n",
        "#    Insert this block AFTER Block 1 (Data Collection) and BEFORE Block 2\n",
        "# ============================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import linalg\n",
        "\n",
        "# ================== 1) Chow-Lin Function ==================\n",
        "def chow_lin_disaggregate(y_low: pd.Series, X_high: pd.DataFrame,\n",
        "                          agg_method: str = 'sum', rho: float = None) -> tuple:\n",
        "    \"\"\"\n",
        "    Chow-Lin temporal disaggregation: à¹à¸›à¸¥à¸‡ Low-frequency â†’ High-frequency\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    y_low : pd.Series\n",
        "        Low-frequency series (e.g., Quarterly GDP) with DatetimeIndex\n",
        "    X_high : pd.DataFrame\n",
        "        High-frequency indicator(s) (e.g., Monthly IPI) with DatetimeIndex\n",
        "    agg_method : str\n",
        "        'sum' for flow variables (GDP), 'mean' for stock/average variables\n",
        "    rho : float or None\n",
        "        AR(1) autocorrelation parameter. If None, estimate from data.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    tuple: (pd.Series of monthly data, beta coefficients, estimated rho)\n",
        "    \"\"\"\n",
        "\n",
        "    # 1) Align data\n",
        "    y_low = y_low.dropna().copy()\n",
        "    X_high = X_high.dropna().copy()\n",
        "\n",
        "    # Determine frequency ratio (3 for Qâ†’M)\n",
        "    n_high_per_low = 3  # Monthly to Quarterly\n",
        "\n",
        "    # 2) Create date mapping\n",
        "    quarters = y_low.index\n",
        "    months = X_high.index\n",
        "\n",
        "    # Filter to overlapping period\n",
        "    min_date = max(quarters.min(), months.min().to_period('Q').to_timestamp())\n",
        "    max_date = min(quarters.max(), months.max().to_period('Q').to_timestamp())\n",
        "\n",
        "    y_low = y_low[(y_low.index >= min_date) & (y_low.index <= max_date)]\n",
        "\n",
        "    # Get monthly data for the period\n",
        "    month_start = y_low.index.min()\n",
        "    month_end = (y_low.index.max() + pd.offsets.QuarterEnd()).to_period('M').to_timestamp()\n",
        "\n",
        "    X_high = X_high[(X_high.index >= month_start) & (X_high.index <= month_end)]\n",
        "\n",
        "    n_low = len(y_low)\n",
        "    n_high = n_low * n_high_per_low\n",
        "\n",
        "    # Trim X_high to exact size\n",
        "    X_high = X_high.iloc[:n_high]\n",
        "\n",
        "    if len(X_high) < n_high:\n",
        "        print(f\"âš ï¸ Warning: Not enough high-freq data. Need {n_high}, have {len(X_high)}\")\n",
        "        # Pad with last value\n",
        "        pad_size = n_high - len(X_high)\n",
        "        last_idx = X_high.index[-1]\n",
        "        new_idx = pd.date_range(start=last_idx + pd.offsets.MonthBegin(), periods=pad_size, freq='MS')\n",
        "        pad_df = pd.DataFrame(index=new_idx, columns=X_high.columns)\n",
        "        for col in X_high.columns:\n",
        "            pad_df[col] = X_high[col].iloc[-1]\n",
        "        X_high = pd.concat([X_high, pad_df])\n",
        "\n",
        "    # 3) Build aggregation matrix C (n_low x n_high)\n",
        "    C = np.zeros((n_low, n_high))\n",
        "    for i in range(n_low):\n",
        "        start_col = i * n_high_per_low\n",
        "        end_col = start_col + n_high_per_low\n",
        "        if agg_method == 'sum':\n",
        "            C[i, start_col:end_col] = 1.0\n",
        "        elif agg_method == 'mean':\n",
        "            C[i, start_col:end_col] = 1.0 / n_high_per_low\n",
        "        else:  # 'last'\n",
        "            C[i, end_col - 1] = 1.0\n",
        "\n",
        "    # 4) Prepare X matrix (add constant)\n",
        "    X = X_high.values\n",
        "    if X.ndim == 1:\n",
        "        X = X.reshape(-1, 1)\n",
        "    X = np.column_stack([np.ones(n_high), X])  # Add intercept\n",
        "\n",
        "    # 5) Aggregate X to match y_low\n",
        "    X_low = C @ X\n",
        "    y = y_low.values.flatten()\n",
        "\n",
        "    # 6) OLS on aggregated data\n",
        "    beta_ols = np.linalg.lstsq(X_low, y, rcond=None)[0]\n",
        "    u_low = y - X_low @ beta_ols\n",
        "\n",
        "    # 7) Estimate rho (AR1 coefficient) if not provided\n",
        "    if rho is None:\n",
        "        if len(u_low) > 1:\n",
        "            rho = np.corrcoef(u_low[:-1], u_low[1:])[0, 1]\n",
        "            rho = np.clip(rho, -0.99, 0.99)\n",
        "        else:\n",
        "            rho = 0.0\n",
        "\n",
        "    # 8) Build covariance matrix V (AR1 structure)\n",
        "    V = np.zeros((n_high, n_high))\n",
        "    for i in range(n_high):\n",
        "        for j in range(n_high):\n",
        "            V[i, j] = rho ** abs(i - j)\n",
        "\n",
        "    # 9) GLS estimation\n",
        "    V_low = C @ V @ C.T\n",
        "    try:\n",
        "        V_low_inv = np.linalg.inv(V_low)\n",
        "    except np.linalg.LinAlgError:\n",
        "        V_low_inv = np.linalg.pinv(V_low)\n",
        "\n",
        "    XVX = X_low.T @ V_low_inv @ X_low\n",
        "    XVy = X_low.T @ V_low_inv @ y\n",
        "    try:\n",
        "        beta_gls = np.linalg.solve(XVX, XVy)\n",
        "    except np.linalg.LinAlgError:\n",
        "        beta_gls = np.linalg.lstsq(XVX, XVy, rcond=None)[0]\n",
        "\n",
        "    # 10) Preliminary high-frequency estimate\n",
        "    p_high = X @ beta_gls\n",
        "\n",
        "    # 11) Distribute residuals\n",
        "    u_low_gls = y - X_low @ beta_gls\n",
        "    VCt = V @ C.T\n",
        "    try:\n",
        "        dist_matrix = VCt @ np.linalg.inv(V_low)\n",
        "    except np.linalg.LinAlgError:\n",
        "        dist_matrix = VCt @ np.linalg.pinv(V_low)\n",
        "\n",
        "    # Final disaggregated series\n",
        "    y_high = p_high + dist_matrix @ u_low_gls\n",
        "\n",
        "    # 12) Create output Series\n",
        "    result = pd.Series(y_high, index=X_high.index, name=y_low.name or 'GDP_Monthly')\n",
        "\n",
        "    return result, beta_gls, rho\n",
        "\n",
        "\n",
        "# ================== 2) Load GDP Quarterly Data ==================\n",
        "print(\"=\"*60)\n",
        "print(\"ğŸ“Š BLOCK 1.5: Chow-Lin Temporal Disaggregation\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nğŸ“¥ Loading GDP Quarterly data...\")\n",
        "\n",
        "gdp_df = pd.read_excel(\"thai_gdp_quarterly_full.xlsx\", sheet_name=0)\n",
        "\n",
        "# Create proper datetime index\n",
        "quarter_map = {'Q1': '01', 'Q2': '04', 'Q3': '07', 'Q4': '10'}\n",
        "gdp_df['Date'] = gdp_df.apply(\n",
        "    lambda row: pd.Timestamp(f\"{row['Year']}-{quarter_map[row['Quarter']]}-01\"),\n",
        "    axis=1\n",
        ")\n",
        "gdp_df = gdp_df.set_index('Date').sort_index()\n",
        "\n",
        "# Use Total_CUR (Current Price GDP)\n",
        "gdp_quarterly = gdp_df['Total_CUR'].copy()\n",
        "gdp_quarterly.name = 'GDP_CUR'\n",
        "\n",
        "print(f\"âœ… GDP Quarterly loaded: {len(gdp_quarterly)} quarters\")\n",
        "print(f\"   Period: {gdp_quarterly.index.min().strftime('%Y-%m')} to {gdp_quarterly.index.max().strftime('%Y-%m')}\")\n",
        "\n",
        "\n",
        "# ================== 3) Prepare IPI as High-Frequency Indicator ==================\n",
        "print(\"\\nğŸ“¥ Preparing IPI as high-frequency indicator...\")\n",
        "\n",
        "# IPI should already be in 'df' from Block 1\n",
        "# If running standalone, load from Macro_data.xlsx\n",
        "if 'df' not in globals() or 'IPI' not in df.columns:\n",
        "    macro_temp = pd.read_excel(\"Macro_data.xlsx\", sheet_name=0)\n",
        "    macro_temp['Date'] = pd.to_datetime(macro_temp['Date'], dayfirst=True, errors='coerce')\n",
        "    macro_temp = macro_temp.set_index('Date').sort_index()\n",
        "    ipi_monthly = macro_temp['IPI_Actual'].dropna().copy()\n",
        "else:\n",
        "    ipi_monthly = df['IPI'].dropna().copy()\n",
        "\n",
        "ipi_monthly.name = 'IPI'\n",
        "\n",
        "# Convert to level if it's in growth rate form\n",
        "if ipi_monthly.abs().mean() < 1:  # It's in decimal/percentage\n",
        "    ipi_level = (1 + ipi_monthly).cumprod() * 100\n",
        "else:\n",
        "    ipi_level = ipi_monthly\n",
        "\n",
        "ipi_level.name = 'IPI_Level'\n",
        "\n",
        "print(f\"âœ… IPI Monthly loaded: {len(ipi_level)} months\")\n",
        "print(f\"   Period: {ipi_level.index.min().strftime('%Y-%m')} to {ipi_level.index.max().strftime('%Y-%m')}\")\n",
        "\n",
        "\n",
        "# ================== 4) Apply Chow-Lin Disaggregation ==================\n",
        "print(\"\\nğŸ”„ Applying Chow-Lin disaggregation (GDP Quarterly â†’ Monthly)...\")\n",
        "\n",
        "X_indicator = pd.DataFrame({'IPI': ipi_level})\n",
        "\n",
        "gdp_monthly, beta_chowlin, rho_chowlin = chow_lin_disaggregate(\n",
        "    y_low=gdp_quarterly,\n",
        "    X_high=X_indicator,\n",
        "    agg_method='sum',  # GDP is a flow variable\n",
        "    rho=None  # Auto-estimate\n",
        ")\n",
        "\n",
        "# Calculate GDP Growth Rate (Monthly, Log %)\n",
        "gdp_growth_monthly = np.log(gdp_monthly / gdp_monthly.shift(1))\n",
        "gdp_growth_monthly.name = 'GDP_Growth_Monthly'\n",
        "\n",
        "print(f\"\\nâœ… Chow-Lin disaggregation completed!\")\n",
        "print(f\"   - Estimated AR(1) rho: {rho_chowlin:.4f}\")\n",
        "print(f\"   - Monthly GDP observations: {len(gdp_monthly)}\")\n",
        "\n",
        "\n",
        "# ================== 5) Validation ==================\n",
        "print(\"\\nğŸ” Validation: Aggregating monthly back to quarterly...\")\n",
        "\n",
        "gdp_monthly_to_q = gdp_monthly.resample('QS').sum()\n",
        "validation = pd.DataFrame({\n",
        "    'Original_Q': gdp_quarterly,\n",
        "    'ChowLin_Agg_Q': gdp_monthly_to_q\n",
        "}).dropna()\n",
        "validation['Error_%'] = abs(validation['ChowLin_Agg_Q'] - validation['Original_Q']) / validation['Original_Q'] * 100\n",
        "\n",
        "print(f\"âœ… Mean Aggregation Error: {validation['Error_%'].mean():.6f}%\")\n",
        "print(\"   (Should be ~0% if Chow-Lin is working correctly)\")\n",
        "\n",
        "\n",
        "# ================== 6) Add to Main DataFrame ==================\n",
        "print(\"\\nğŸ“Œ Adding GDP_Monthly and GDP_Growth to main dataframe...\")\n",
        "\n",
        "# Reindex to match the main df index\n",
        "if 'df' in globals():\n",
        "    # Add GDP columns to df\n",
        "    df['GDP_Monthly'] = gdp_monthly.reindex(df.index)\n",
        "    df['GDP_Growth'] = gdp_growth_monthly.reindex(df.index)\n",
        "\n",
        "    # Forward fill any gaps (for dates where we have stock data but no GDP yet)\n",
        "    df['GDP_Monthly'] = df['GDP_Monthly'].ffill()\n",
        "    df['GDP_Growth'] = df['GDP_Growth'].ffill()\n",
        "\n",
        "    print(f\"âœ… Added 'GDP_Monthly' and 'GDP_Growth' to df\")\n",
        "    print(f\"   df shape: {df.shape}\")\n",
        "    print(f\"\\nğŸ“Š GDP columns preview:\")\n",
        "    print(df[['GDP_Monthly', 'GDP_Growth']].dropna().tail(10))\n",
        "else:\n",
        "    print(\"âš ï¸ Main dataframe 'df' not found. Creating standalone GDP dataframe...\")\n",
        "    gdp_output = pd.DataFrame({\n",
        "        'GDP_Monthly': gdp_monthly,\n",
        "        'GDP_Growth': gdp_growth_monthly\n",
        "    })\n",
        "    print(gdp_output.tail(10))\n",
        "\n",
        "\n",
        "# ================== 7) Summary ==================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"âœ… BLOCK 1.5 COMPLETED: Chow-Lin Temporal Disaggregation\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\"\"\n",
        "Summary:\n",
        "- Input:  GDP Quarterly (Total_CUR) - {len(gdp_quarterly)} quarters\n",
        "- Output: GDP Monthly - {len(gdp_monthly)} months\n",
        "- Indicator used: IPI (Industrial Production Index)\n",
        "- Method: Chow-Lin (1971) with AR(1) residual structure\n",
        "- Estimated rho: {rho_chowlin:.4f}\n",
        "\n",
        "New columns added to df:\n",
        "- 'GDP_Monthly': Monthly GDP level (Current Price, Mil THB)\n",
        "- 'GDP_Growth': Monthly GDP growth rate (Log %)\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kbl9fHdopGI_"
      },
      "source": [
        "**2 Data preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 849
        },
        "id": "ZXefL-WtoerI",
        "outputId": "25bc311b-2d70-4b77-b819-ae1ee4004a99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Applied macro shifts: {'GDP_Growth': 2, 'BroadMoney_M1M2_Growth': 2, 'IPI_Surprise': 1, 'Inflation_Surprise': 1}\n",
            "âœ… Combined data shape: (116, 26)\n",
            "âœ… Stocks: 11 | Macros: 15\n",
            "âœ… Differenced data ready: (115, 48)\n",
            "\n",
            "=== Combined_dfs (Levels) ===\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-86722810-6bbc-48e8-9ec3-7573c135ea0b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Close_BBL</th>\n",
              "      <th>Close_KBANK</th>\n",
              "      <th>Close_KKP</th>\n",
              "      <th>Close_KTB</th>\n",
              "      <th>Close_TCAP</th>\n",
              "      <th>Close_TISCO</th>\n",
              "      <th>Close_TTB</th>\n",
              "      <th>Close_KTC</th>\n",
              "      <th>Close_AEONTS</th>\n",
              "      <th>Close_JMT</th>\n",
              "      <th>...</th>\n",
              "      <th>Logclose_KBANK</th>\n",
              "      <th>Logclose_KKP</th>\n",
              "      <th>Logclose_KTB</th>\n",
              "      <th>Logclose_TCAP</th>\n",
              "      <th>Logclose_TISCO</th>\n",
              "      <th>Logclose_TTB</th>\n",
              "      <th>Logclose_KTC</th>\n",
              "      <th>Logclose_AEONTS</th>\n",
              "      <th>Logclose_JMT</th>\n",
              "      <th>Logclose_SAWAD</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2016-06-01</th>\n",
              "      <td>111.023804</td>\n",
              "      <td>123.027885</td>\n",
              "      <td>23.455120</td>\n",
              "      <td>10.761127</td>\n",
              "      <td>17.897364</td>\n",
              "      <td>25.046576</td>\n",
              "      <td>1.323992</td>\n",
              "      <td>8.134516</td>\n",
              "      <td>70.771042</td>\n",
              "      <td>4.203392</td>\n",
              "      <td>...</td>\n",
              "      <td>4.812411</td>\n",
              "      <td>3.155089</td>\n",
              "      <td>2.375940</td>\n",
              "      <td>2.884653</td>\n",
              "      <td>3.220737</td>\n",
              "      <td>0.280651</td>\n",
              "      <td>2.096116</td>\n",
              "      <td>4.259450</td>\n",
              "      <td>1.435892</td>\n",
              "      <td>3.124680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-07-01</th>\n",
              "      <td>119.429382</td>\n",
              "      <td>142.929443</td>\n",
              "      <td>28.307903</td>\n",
              "      <td>11.487337</td>\n",
              "      <td>20.837641</td>\n",
              "      <td>27.323538</td>\n",
              "      <td>1.385288</td>\n",
              "      <td>10.040080</td>\n",
              "      <td>73.528358</td>\n",
              "      <td>5.117174</td>\n",
              "      <td>...</td>\n",
              "      <td>4.962351</td>\n",
              "      <td>3.343141</td>\n",
              "      <td>2.441245</td>\n",
              "      <td>3.036761</td>\n",
              "      <td>3.307749</td>\n",
              "      <td>0.325908</td>\n",
              "      <td>2.306585</td>\n",
              "      <td>4.297671</td>\n",
              "      <td>1.632602</td>\n",
              "      <td>3.137752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-08-01</th>\n",
              "      <td>118.728935</td>\n",
              "      <td>142.929443</td>\n",
              "      <td>27.903503</td>\n",
              "      <td>12.543647</td>\n",
              "      <td>20.454126</td>\n",
              "      <td>27.323538</td>\n",
              "      <td>1.385288</td>\n",
              "      <td>11.392418</td>\n",
              "      <td>72.609245</td>\n",
              "      <td>5.336482</td>\n",
              "      <td>...</td>\n",
              "      <td>4.962351</td>\n",
              "      <td>3.328752</td>\n",
              "      <td>2.529214</td>\n",
              "      <td>3.018185</td>\n",
              "      <td>3.307749</td>\n",
              "      <td>0.325908</td>\n",
              "      <td>2.432948</td>\n",
              "      <td>4.285092</td>\n",
              "      <td>1.674567</td>\n",
              "      <td>3.163394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-09-01</th>\n",
              "      <td>113.825661</td>\n",
              "      <td>135.692535</td>\n",
              "      <td>28.577503</td>\n",
              "      <td>11.619376</td>\n",
              "      <td>20.709799</td>\n",
              "      <td>26.564552</td>\n",
              "      <td>1.299473</td>\n",
              "      <td>12.089076</td>\n",
              "      <td>73.344536</td>\n",
              "      <td>5.117174</td>\n",
              "      <td>...</td>\n",
              "      <td>4.910392</td>\n",
              "      <td>3.352620</td>\n",
              "      <td>2.452674</td>\n",
              "      <td>3.030607</td>\n",
              "      <td>3.279578</td>\n",
              "      <td>0.261959</td>\n",
              "      <td>2.492302</td>\n",
              "      <td>4.295168</td>\n",
              "      <td>1.632602</td>\n",
              "      <td>3.070613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-10-01</th>\n",
              "      <td>113.074417</td>\n",
              "      <td>124.805466</td>\n",
              "      <td>32.871223</td>\n",
              "      <td>11.355299</td>\n",
              "      <td>20.198450</td>\n",
              "      <td>26.185057</td>\n",
              "      <td>1.287215</td>\n",
              "      <td>12.293977</td>\n",
              "      <td>72.057785</td>\n",
              "      <td>5.519238</td>\n",
              "      <td>...</td>\n",
              "      <td>4.826756</td>\n",
              "      <td>3.492598</td>\n",
              "      <td>2.429685</td>\n",
              "      <td>3.005606</td>\n",
              "      <td>3.265189</td>\n",
              "      <td>0.252481</td>\n",
              "      <td>2.509109</td>\n",
              "      <td>4.277468</td>\n",
              "      <td>1.708240</td>\n",
              "      <td>3.175973</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 37 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-86722810-6bbc-48e8-9ec3-7573c135ea0b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-86722810-6bbc-48e8-9ec3-7573c135ea0b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-86722810-6bbc-48e8-9ec3-7573c135ea0b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "             Close_BBL  Close_KBANK  Close_KKP  Close_KTB  Close_TCAP  \\\n",
              "Date                                                                    \n",
              "2016-06-01  111.023804   123.027885  23.455120  10.761127   17.897364   \n",
              "2016-07-01  119.429382   142.929443  28.307903  11.487337   20.837641   \n",
              "2016-08-01  118.728935   142.929443  27.903503  12.543647   20.454126   \n",
              "2016-09-01  113.825661   135.692535  28.577503  11.619376   20.709799   \n",
              "2016-10-01  113.074417   124.805466  32.871223  11.355299   20.198450   \n",
              "\n",
              "            Close_TISCO  Close_TTB  Close_KTC  Close_AEONTS  Close_JMT  ...  \\\n",
              "Date                                                                    ...   \n",
              "2016-06-01    25.046576   1.323992   8.134516     70.771042   4.203392  ...   \n",
              "2016-07-01    27.323538   1.385288  10.040080     73.528358   5.117174  ...   \n",
              "2016-08-01    27.323538   1.385288  11.392418     72.609245   5.336482  ...   \n",
              "2016-09-01    26.564552   1.299473  12.089076     73.344536   5.117174  ...   \n",
              "2016-10-01    26.185057   1.287215  12.293977     72.057785   5.519238  ...   \n",
              "\n",
              "            Logclose_KBANK  Logclose_KKP  Logclose_KTB  Logclose_TCAP  \\\n",
              "Date                                                                    \n",
              "2016-06-01        4.812411      3.155089      2.375940       2.884653   \n",
              "2016-07-01        4.962351      3.343141      2.441245       3.036761   \n",
              "2016-08-01        4.962351      3.328752      2.529214       3.018185   \n",
              "2016-09-01        4.910392      3.352620      2.452674       3.030607   \n",
              "2016-10-01        4.826756      3.492598      2.429685       3.005606   \n",
              "\n",
              "            Logclose_TISCO  Logclose_TTB  Logclose_KTC  Logclose_AEONTS  \\\n",
              "Date                                                                      \n",
              "2016-06-01        3.220737      0.280651      2.096116         4.259450   \n",
              "2016-07-01        3.307749      0.325908      2.306585         4.297671   \n",
              "2016-08-01        3.307749      0.325908      2.432948         4.285092   \n",
              "2016-09-01        3.279578      0.261959      2.492302         4.295168   \n",
              "2016-10-01        3.265189      0.252481      2.509109         4.277468   \n",
              "\n",
              "            Logclose_JMT  Logclose_SAWAD  \n",
              "Date                                      \n",
              "2016-06-01      1.435892        3.124680  \n",
              "2016-07-01      1.632602        3.137752  \n",
              "2016-08-01      1.674567        3.163394  \n",
              "2016-09-01      1.632602        3.070613  \n",
              "2016-10-01      1.708240        3.175973  \n",
              "\n",
              "[5 rows x 37 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Combined_dfs_diff (Differenced) ===\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-ef7c910b-d330-4352-a6fa-ecf89ced7aea\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Close_BBL</th>\n",
              "      <th>Close_KBANK</th>\n",
              "      <th>Close_KKP</th>\n",
              "      <th>Close_KTB</th>\n",
              "      <th>Close_TCAP</th>\n",
              "      <th>Close_TISCO</th>\n",
              "      <th>Close_TTB</th>\n",
              "      <th>Close_KTC</th>\n",
              "      <th>Close_AEONTS</th>\n",
              "      <th>Close_JMT</th>\n",
              "      <th>...</th>\n",
              "      <th>D_Logclose_KBANK</th>\n",
              "      <th>D_Logclose_KKP</th>\n",
              "      <th>D_Logclose_KTB</th>\n",
              "      <th>D_Logclose_TCAP</th>\n",
              "      <th>D_Logclose_TISCO</th>\n",
              "      <th>D_Logclose_TTB</th>\n",
              "      <th>D_Logclose_KTC</th>\n",
              "      <th>D_Logclose_AEONTS</th>\n",
              "      <th>D_Logclose_JMT</th>\n",
              "      <th>D_Logclose_SAWAD</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2016-07-01</th>\n",
              "      <td>119.429382</td>\n",
              "      <td>142.929443</td>\n",
              "      <td>28.307903</td>\n",
              "      <td>11.487337</td>\n",
              "      <td>20.837641</td>\n",
              "      <td>27.323538</td>\n",
              "      <td>1.385288</td>\n",
              "      <td>10.040080</td>\n",
              "      <td>73.528358</td>\n",
              "      <td>5.117174</td>\n",
              "      <td>...</td>\n",
              "      <td>0.149940</td>\n",
              "      <td>0.188052</td>\n",
              "      <td>0.065305</td>\n",
              "      <td>0.152108</td>\n",
              "      <td>0.087011</td>\n",
              "      <td>0.045257</td>\n",
              "      <td>0.210469</td>\n",
              "      <td>0.038221</td>\n",
              "      <td>0.196711</td>\n",
              "      <td>0.013072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-08-01</th>\n",
              "      <td>118.728935</td>\n",
              "      <td>142.929443</td>\n",
              "      <td>27.903503</td>\n",
              "      <td>12.543647</td>\n",
              "      <td>20.454126</td>\n",
              "      <td>27.323538</td>\n",
              "      <td>1.385288</td>\n",
              "      <td>11.392418</td>\n",
              "      <td>72.609245</td>\n",
              "      <td>5.336482</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.014389</td>\n",
              "      <td>0.087969</td>\n",
              "      <td>-0.018576</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.126363</td>\n",
              "      <td>-0.012579</td>\n",
              "      <td>0.041964</td>\n",
              "      <td>0.025642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-09-01</th>\n",
              "      <td>113.825661</td>\n",
              "      <td>135.692535</td>\n",
              "      <td>28.577503</td>\n",
              "      <td>11.619376</td>\n",
              "      <td>20.709799</td>\n",
              "      <td>26.564552</td>\n",
              "      <td>1.299473</td>\n",
              "      <td>12.089076</td>\n",
              "      <td>73.344536</td>\n",
              "      <td>5.117174</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.051960</td>\n",
              "      <td>0.023868</td>\n",
              "      <td>-0.076540</td>\n",
              "      <td>0.012422</td>\n",
              "      <td>-0.028171</td>\n",
              "      <td>-0.063949</td>\n",
              "      <td>0.059354</td>\n",
              "      <td>0.010076</td>\n",
              "      <td>-0.041964</td>\n",
              "      <td>-0.092782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-10-01</th>\n",
              "      <td>113.074417</td>\n",
              "      <td>124.805466</td>\n",
              "      <td>32.871223</td>\n",
              "      <td>11.355299</td>\n",
              "      <td>20.198450</td>\n",
              "      <td>26.185057</td>\n",
              "      <td>1.287215</td>\n",
              "      <td>12.293977</td>\n",
              "      <td>72.057785</td>\n",
              "      <td>5.519238</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.083635</td>\n",
              "      <td>0.139978</td>\n",
              "      <td>-0.022990</td>\n",
              "      <td>-0.025001</td>\n",
              "      <td>-0.014389</td>\n",
              "      <td>-0.009478</td>\n",
              "      <td>0.016807</td>\n",
              "      <td>-0.017700</td>\n",
              "      <td>0.075637</td>\n",
              "      <td>0.105361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-11-01</th>\n",
              "      <td>110.593155</td>\n",
              "      <td>122.991440</td>\n",
              "      <td>31.045038</td>\n",
              "      <td>11.619376</td>\n",
              "      <td>22.944523</td>\n",
              "      <td>27.323538</td>\n",
              "      <td>1.238178</td>\n",
              "      <td>11.966137</td>\n",
              "      <td>77.745316</td>\n",
              "      <td>6.688877</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.014641</td>\n",
              "      <td>-0.057159</td>\n",
              "      <td>0.022990</td>\n",
              "      <td>0.127473</td>\n",
              "      <td>0.042560</td>\n",
              "      <td>-0.038840</td>\n",
              "      <td>-0.027029</td>\n",
              "      <td>0.075970</td>\n",
              "      <td>0.192206</td>\n",
              "      <td>0.024693</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 48 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef7c910b-d330-4352-a6fa-ecf89ced7aea')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ef7c910b-d330-4352-a6fa-ecf89ced7aea button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ef7c910b-d330-4352-a6fa-ecf89ced7aea');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "             Close_BBL  Close_KBANK  Close_KKP  Close_KTB  Close_TCAP  \\\n",
              "Date                                                                    \n",
              "2016-07-01  119.429382   142.929443  28.307903  11.487337   20.837641   \n",
              "2016-08-01  118.728935   142.929443  27.903503  12.543647   20.454126   \n",
              "2016-09-01  113.825661   135.692535  28.577503  11.619376   20.709799   \n",
              "2016-10-01  113.074417   124.805466  32.871223  11.355299   20.198450   \n",
              "2016-11-01  110.593155   122.991440  31.045038  11.619376   22.944523   \n",
              "\n",
              "            Close_TISCO  Close_TTB  Close_KTC  Close_AEONTS  Close_JMT  ...  \\\n",
              "Date                                                                    ...   \n",
              "2016-07-01    27.323538   1.385288  10.040080     73.528358   5.117174  ...   \n",
              "2016-08-01    27.323538   1.385288  11.392418     72.609245   5.336482  ...   \n",
              "2016-09-01    26.564552   1.299473  12.089076     73.344536   5.117174  ...   \n",
              "2016-10-01    26.185057   1.287215  12.293977     72.057785   5.519238  ...   \n",
              "2016-11-01    27.323538   1.238178  11.966137     77.745316   6.688877  ...   \n",
              "\n",
              "            D_Logclose_KBANK  D_Logclose_KKP  D_Logclose_KTB  D_Logclose_TCAP  \\\n",
              "Date                                                                            \n",
              "2016-07-01          0.149940        0.188052        0.065305         0.152108   \n",
              "2016-08-01          0.000000       -0.014389        0.087969        -0.018576   \n",
              "2016-09-01         -0.051960        0.023868       -0.076540         0.012422   \n",
              "2016-10-01         -0.083635        0.139978       -0.022990        -0.025001   \n",
              "2016-11-01         -0.014641       -0.057159        0.022990         0.127473   \n",
              "\n",
              "            D_Logclose_TISCO  D_Logclose_TTB  D_Logclose_KTC  \\\n",
              "Date                                                           \n",
              "2016-07-01          0.087011        0.045257        0.210469   \n",
              "2016-08-01          0.000000        0.000000        0.126363   \n",
              "2016-09-01         -0.028171       -0.063949        0.059354   \n",
              "2016-10-01         -0.014389       -0.009478        0.016807   \n",
              "2016-11-01          0.042560       -0.038840       -0.027029   \n",
              "\n",
              "            D_Logclose_AEONTS  D_Logclose_JMT  D_Logclose_SAWAD  \n",
              "Date                                                             \n",
              "2016-07-01           0.038221        0.196711          0.013072  \n",
              "2016-08-01          -0.012579        0.041964          0.025642  \n",
              "2016-09-01           0.010076       -0.041964         -0.092782  \n",
              "2016-10-01          -0.017700        0.075637          0.105361  \n",
              "2016-11-01           0.075970        0.192206          0.024693  \n",
              "\n",
              "[5 rows x 48 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# =====================================================\n",
        "# âš™ï¸ BLOCK 2: Prepare Combined Data (No PCA, No LASSO)\n",
        "#   âœ… PATCH: Macro release-lag shift (no look-ahead)\n",
        "# =====================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ======== 1) Filter & split ========\n",
        "df_filtered = df.iloc[14:].copy()  # à¸•à¸±à¸”à¸Šà¹ˆà¸§à¸‡à¹à¸£à¸à¸—à¸µà¹ˆ NA à¹€à¸¢à¸­à¸°\n",
        "\n",
        "# à¹€à¸¥à¸·à¸­à¸à¸«à¸¸à¹‰à¸™\n",
        "stock_columns = [c for c in df_filtered.columns if c.startswith(\"Close_\")]\n",
        "selected_stock_data = df_filtered[stock_columns]\n",
        "\n",
        "# à¹€à¸¥à¸·à¸­à¸à¸•à¸±à¸§à¹à¸›à¸£ macro à¸—à¸µà¹ˆà¸¡à¸µà¸­à¸¢à¸¹à¹ˆà¸ˆà¸£à¸´à¸‡\n",
        "macro_columns = [\n",
        "    \"BroadMoney_M1M2_Growth\",\n",
        "    \"Inflation_Surprise\",   # CPI\n",
        "    \"IPI_Surprise\",\n",
        "    \"THOR_1M\",\n",
        "    \"THOR_6M\",\n",
        "    \"3M_1M_THOR_Spread\",\n",
        "    \"6M_1M_THOR_Spread\",\n",
        "    \"5Y_1Y_Bond_Spread\",\n",
        "    \"10Y_5Y_Bond_Spread\",\n",
        "    \"THB_per_USD\",\n",
        "    \"SP500_Index\",\n",
        "    \"SET_Index\",\n",
        "    \"THB_per_CNY\",\n",
        "    \"GDP_Growth\",\n",
        "    \"THB_per_INR\"\n",
        "]\n",
        "macro_columns = [c for c in macro_columns if c in df_filtered.columns]\n",
        "selected_macro_data = df_filtered[macro_columns].copy()\n",
        "\n",
        "# ======== ğŸ†• 1.5) SHIFT MACROS (release-lag) ========\n",
        "SHIFT_MAP = {\n",
        "    \"GDP_Growth\": 2,\n",
        "    \"BroadMoney_M1M2_Growth\": 2,\n",
        "    \"IPI_Surprise\": 1,\n",
        "    \"Inflation_Surprise\": 1,\n",
        "}\n",
        "\n",
        "for col, s in SHIFT_MAP.items():\n",
        "    if col in selected_macro_data.columns:\n",
        "        selected_macro_data[col] = selected_macro_data[col].shift(s)\n",
        "\n",
        "# à¸ªà¸³à¸„à¸±à¸: à¸«à¹‰à¸²à¸¡ bfill (à¸ˆà¸°à¸”à¸¶à¸‡à¸­à¸™à¸²à¸„à¸•à¸¢à¹‰à¸­à¸™à¸à¸¥à¸±à¸šà¸¡à¸²)\n",
        "# à¸ˆà¸° ffill à¸«à¸£à¸·à¸­à¸›à¸¥à¹ˆà¸­à¸¢ NaN à¹à¸¥à¹‰à¸§ drop à¸•à¸­à¸™à¸«à¸¥à¸±à¸‡ à¸à¹‡à¹„à¸”à¹‰\n",
        "selected_macro_data = selected_macro_data.ffill()\n",
        "\n",
        "print(\"âœ… Applied macro shifts:\",\n",
        "      {k: v for k, v in SHIFT_MAP.items() if k in selected_macro_data.columns})\n",
        "\n",
        "# ======== 2) Combine + clean ========\n",
        "combined_df = pd.concat([selected_stock_data, selected_macro_data], axis=1)\n",
        "combined_df = combined_df.ffill().replace([np.inf, -np.inf], np.nan).dropna(how=\"any\")\n",
        "\n",
        "print(\"âœ… Combined data shape:\", combined_df.shape)\n",
        "print(\"âœ… Stocks:\", len(stock_columns), \"| Macros:\", len(macro_columns))\n",
        "\n",
        "# ======== 3) Log-transform à¸«à¸¸à¹‰à¸™à¹à¸¥à¸°à¸ªà¸£à¹‰à¸²à¸‡ Î”log ========\n",
        "combined_dfs = combined_df.copy()\n",
        "for c in stock_columns:\n",
        "    combined_dfs[f\"Logclose_{c.replace('Close_','')}\"] = np.log(combined_df[c])\n",
        "\n",
        "combined_dfs_diff = combined_dfs.copy()\n",
        "for c in stock_columns:\n",
        "    stock_name = c.replace(\"Close_\",\"\")\n",
        "    combined_dfs_diff[f\"D_Logclose_{stock_name}\"] = combined_dfs[f\"Logclose_{stock_name}\"].diff()\n",
        "\n",
        "# ======== 4) Drop à¹à¸–à¸§à¹à¸£à¸à¸‚à¸­à¸‡ differenced ========\n",
        "combined_dfs_diff = combined_dfs_diff.dropna()\n",
        "\n",
        "print(\"âœ… Differenced data ready:\", combined_dfs_diff.shape)\n",
        "\n",
        "# ======== 5) à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ ========\n",
        "print(\"\\n=== Combined_dfs (Levels) ===\")\n",
        "display(combined_dfs.head())\n",
        "\n",
        "print(\"\\n=== Combined_dfs_diff (Differenced) ===\")\n",
        "display(combined_dfs_diff.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 750
        },
        "id": "mSL8-kKqouv3",
        "outputId": "3126ecb8-1d54-4dc4-8746-b9747de27fc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“Š Combined data for sector: Banking\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-ed9f1b08-421e-45af-8803-61fb105c9eff\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Logclose_BBL</th>\n",
              "      <th>Logclose_KBANK</th>\n",
              "      <th>Logclose_KKP</th>\n",
              "      <th>Logclose_KTB</th>\n",
              "      <th>Logclose_TCAP</th>\n",
              "      <th>Logclose_TISCO</th>\n",
              "      <th>Logclose_TTB</th>\n",
              "      <th>BroadMoney_M1M2_Growth</th>\n",
              "      <th>Inflation_Surprise</th>\n",
              "      <th>IPI_Surprise</th>\n",
              "      <th>...</th>\n",
              "      <th>3M_1M_THOR_Spread</th>\n",
              "      <th>6M_1M_THOR_Spread</th>\n",
              "      <th>5Y_1Y_Bond_Spread</th>\n",
              "      <th>10Y_5Y_Bond_Spread</th>\n",
              "      <th>THB_per_USD</th>\n",
              "      <th>SP500_Index</th>\n",
              "      <th>SET_Index</th>\n",
              "      <th>THB_per_CNY</th>\n",
              "      <th>GDP_Growth</th>\n",
              "      <th>THB_per_INR</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2015-02-01</th>\n",
              "      <td>4.790190</td>\n",
              "      <td>5.017582</td>\n",
              "      <td>2.939447</td>\n",
              "      <td>2.627824</td>\n",
              "      <td>2.802560</td>\n",
              "      <td>3.072488</td>\n",
              "      <td>0.569241</td>\n",
              "      <td>0.009765</td>\n",
              "      <td>-0.0066</td>\n",
              "      <td>-0.000066</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000068</td>\n",
              "      <td>0.0035</td>\n",
              "      <td>0.0056</td>\n",
              "      <td>32.341000</td>\n",
              "      <td>2104.500000</td>\n",
              "      <td>1582.699951</td>\n",
              "      <td>0.19335</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.906796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-03-01</th>\n",
              "      <td>4.798353</td>\n",
              "      <td>5.071406</td>\n",
              "      <td>2.933057</td>\n",
              "      <td>2.627824</td>\n",
              "      <td>2.795391</td>\n",
              "      <td>3.045532</td>\n",
              "      <td>0.555907</td>\n",
              "      <td>0.004617</td>\n",
              "      <td>-0.0019</td>\n",
              "      <td>0.000380</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000077</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0058</td>\n",
              "      <td>32.540001</td>\n",
              "      <td>2067.889893</td>\n",
              "      <td>1582.140015</td>\n",
              "      <td>0.19040</td>\n",
              "      <td>-0.020455</td>\n",
              "      <td>1.918100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-04-01</th>\n",
              "      <td>4.801060</td>\n",
              "      <td>4.984792</td>\n",
              "      <td>2.880413</td>\n",
              "      <td>2.496796</td>\n",
              "      <td>2.773572</td>\n",
              "      <td>3.034543</td>\n",
              "      <td>0.419496</td>\n",
              "      <td>-0.001550</td>\n",
              "      <td>-0.0012</td>\n",
              "      <td>-0.000670</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001167</td>\n",
              "      <td>0.001528</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0051</td>\n",
              "      <td>32.838001</td>\n",
              "      <td>2085.510010</td>\n",
              "      <td>1525.579956</td>\n",
              "      <td>0.18827</td>\n",
              "      <td>-0.015059</td>\n",
              "      <td>1.930500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-05-01</th>\n",
              "      <td>4.808427</td>\n",
              "      <td>4.925754</td>\n",
              "      <td>2.888474</td>\n",
              "      <td>2.436026</td>\n",
              "      <td>2.810098</td>\n",
              "      <td>3.072725</td>\n",
              "      <td>0.417810</td>\n",
              "      <td>0.001422</td>\n",
              "      <td>-0.0024</td>\n",
              "      <td>-0.000330</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001280</td>\n",
              "      <td>0.002220</td>\n",
              "      <td>0.0042</td>\n",
              "      <td>0.0078</td>\n",
              "      <td>33.734001</td>\n",
              "      <td>2107.389893</td>\n",
              "      <td>1519.880005</td>\n",
              "      <td>0.18351</td>\n",
              "      <td>-0.011596</td>\n",
              "      <td>1.889400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-06-01</th>\n",
              "      <td>4.786204</td>\n",
              "      <td>4.894501</td>\n",
              "      <td>2.867420</td>\n",
              "      <td>2.379193</td>\n",
              "      <td>2.780465</td>\n",
              "      <td>3.094704</td>\n",
              "      <td>0.335797</td>\n",
              "      <td>-0.005075</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.000280</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001854</td>\n",
              "      <td>0.003469</td>\n",
              "      <td>0.0056</td>\n",
              "      <td>0.0082</td>\n",
              "      <td>33.729000</td>\n",
              "      <td>2063.110107</td>\n",
              "      <td>1476.869995</td>\n",
              "      <td>0.18359</td>\n",
              "      <td>-0.002867</td>\n",
              "      <td>1.888000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 22 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed9f1b08-421e-45af-8803-61fb105c9eff')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ed9f1b08-421e-45af-8803-61fb105c9eff button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ed9f1b08-421e-45af-8803-61fb105c9eff');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "            Logclose_BBL  Logclose_KBANK  Logclose_KKP  Logclose_KTB  \\\n",
              "Date                                                                   \n",
              "2015-02-01      4.790190        5.017582      2.939447      2.627824   \n",
              "2015-03-01      4.798353        5.071406      2.933057      2.627824   \n",
              "2015-04-01      4.801060        4.984792      2.880413      2.496796   \n",
              "2015-05-01      4.808427        4.925754      2.888474      2.436026   \n",
              "2015-06-01      4.786204        4.894501      2.867420      2.379193   \n",
              "\n",
              "            Logclose_TCAP  Logclose_TISCO  Logclose_TTB  \\\n",
              "Date                                                      \n",
              "2015-02-01       2.802560        3.072488      0.569241   \n",
              "2015-03-01       2.795391        3.045532      0.555907   \n",
              "2015-04-01       2.773572        3.034543      0.419496   \n",
              "2015-05-01       2.810098        3.072725      0.417810   \n",
              "2015-06-01       2.780465        3.094704      0.335797   \n",
              "\n",
              "            BroadMoney_M1M2_Growth  Inflation_Surprise  IPI_Surprise  ...  \\\n",
              "Date                                                                  ...   \n",
              "2015-02-01                0.009765             -0.0066     -0.000066  ...   \n",
              "2015-03-01                0.004617             -0.0019      0.000380  ...   \n",
              "2015-04-01               -0.001550             -0.0012     -0.000670  ...   \n",
              "2015-05-01                0.001422             -0.0024     -0.000330  ...   \n",
              "2015-06-01               -0.005075             -0.0015     -0.000280  ...   \n",
              "\n",
              "            3M_1M_THOR_Spread  6M_1M_THOR_Spread  5Y_1Y_Bond_Spread  \\\n",
              "Date                                                                  \n",
              "2015-02-01           0.000015           0.000068             0.0035   \n",
              "2015-03-01           0.000032           0.000077             0.0045   \n",
              "2015-04-01           0.001167           0.001528             0.0048   \n",
              "2015-05-01           0.001280           0.002220             0.0042   \n",
              "2015-06-01           0.001854           0.003469             0.0056   \n",
              "\n",
              "            10Y_5Y_Bond_Spread  THB_per_USD  SP500_Index    SET_Index  \\\n",
              "Date                                                                    \n",
              "2015-02-01              0.0056    32.341000  2104.500000  1582.699951   \n",
              "2015-03-01              0.0058    32.540001  2067.889893  1582.140015   \n",
              "2015-04-01              0.0051    32.838001  2085.510010  1525.579956   \n",
              "2015-05-01              0.0078    33.734001  2107.389893  1519.880005   \n",
              "2015-06-01              0.0082    33.729000  2063.110107  1476.869995   \n",
              "\n",
              "            THB_per_CNY  GDP_Growth  THB_per_INR  \n",
              "Date                                              \n",
              "2015-02-01      0.19335         NaN     1.906796  \n",
              "2015-03-01      0.19040   -0.020455     1.918100  \n",
              "2015-04-01      0.18827   -0.015059     1.930500  \n",
              "2015-05-01      0.18351   -0.011596     1.889400  \n",
              "2015-06-01      0.18359   -0.002867     1.888000  \n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“Š Combined data for sector: Finance_Securities\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"    display(combined_df[cols_to_show_present]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2015-02-01 00:00:00\",\n        \"max\": \"2015-06-01 00:00:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2015-03-01 00:00:00\",\n          \"2015-06-01 00:00:00\",\n          \"2015-04-01 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_KTC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07740739036335739,\n        \"min\": 1.9111735112870496,\n        \"max\": 2.1237295076389198,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2.0324207159677625,\n          2.047805555164504,\n          2.1237295076389198\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_AEONTS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05163749028138039,\n        \"min\": 4.201525852734568,\n        \"max\": 4.324111536251065,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4.281752141924792,\n          4.201525852734568,\n          4.252481600963384\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_JMT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09908748582025127,\n        \"min\": 1.7129867522923479,\n        \"max\": 1.979026070923629,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.9144875278191593,\n          1.7129867522923479,\n          1.8978205946566566\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_SAWAD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03791407542352227,\n        \"min\": 3.1060197207482094,\n        \"max\": 3.2000023175031647,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3.1060197207482094,\n          3.1512121455589774,\n          3.1939603767065883\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BroadMoney_M1M2_Growth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005700984043555338,\n        \"min\": -0.005074892972240728,\n        \"max\": 0.009765467965924778,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.004616556335225512,\n          -0.005074892972240728,\n          -0.0015500193021271292\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Inflation_Surprise\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.002215174936658503,\n        \"min\": -0.0066,\n        \"max\": -0.0011999999999999988,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.0018999999999999998,\n          -0.0014999999999999979,\n          -0.0011999999999999988\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IPI_Surprise\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00038675728823126264,\n        \"min\": -0.00067,\n        \"max\": 0.00037999999999999997,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.00037999999999999997,\n          -0.0002799999999999999,\n          -0.00067\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"THOR_1M\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.002129944855624201,\n        \"min\": 0.0149395,\n        \"max\": 0.0199545,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.0199419,\n          0.0149395,\n          0.018201099999999998\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"THOR_6M\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0006903075669583813,\n        \"min\": 0.018408,\n        \"max\": 0.020023,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.020019300000000004,\n          0.018408,\n          0.0197291\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"3M_1M_THOR_Spread\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0008153057475573194,\n        \"min\": 1.5000000000001124e-05,\n        \"max\": 0.001854200000000002,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3.170000000000256e-05,\n          0.001854200000000002,\n          0.0011670000000000014\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"6M_1M_THOR_Spread\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0014545681087525597,\n        \"min\": 6.849999999999912e-05,\n        \"max\": 0.003468500000000001,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7.740000000000524e-05,\n          0.003468500000000001,\n          0.0015280000000000016\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"5Y_1Y_Bond_Spread\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0007726577508832749,\n        \"min\": 0.0034999999999999996,\n        \"max\": 0.005600000000000001,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.0045000000000000005,\n          0.005600000000000001,\n          0.0048000000000000004\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"10Y_5Y_Bond_Spread\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0013999999999999998,\n        \"min\": 0.0051,\n        \"max\": 0.008199999999999999,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.0058,\n          0.008199999999999999,\n          0.0051\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"THB_per_USD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6587294761773956,\n        \"min\": 32.340999603271484,\n        \"max\": 33.73400115966797,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          32.540000915527344,\n          33.729000091552734,\n          32.8380012512207\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SP500_Index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20.318887183489874,\n        \"min\": 2063.110107421875,\n        \"max\": 2107.389892578125,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2067.889892578125,\n          2063.110107421875,\n          2085.510009765625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SET_Index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 45.17824108770902,\n        \"min\": 1476.8699951171875,\n        \"max\": 1582.699951171875,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1582.1400146484375,\n          1476.8699951171875,\n          1525.5799560546875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"THB_per_CNY\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.004298510346507137,\n        \"min\": 0.18351000547409058,\n        \"max\": 0.19335000216960907,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.19040000438690186,\n          0.18358999490737915,\n          0.18827000260353088\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GDP_Growth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007381267122894923,\n        \"min\": -0.020455447676879235,\n        \"max\": -0.002867079683681288,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -0.015059346674021852,\n          -0.002867079683681288,\n          -0.020455447676879235\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"THB_per_INR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01833910386713008,\n        \"min\": 1.8880000114440918,\n        \"max\": 1.9305000305175781,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.9180999994277954,\n          1.8880000114440918,\n          1.9305000305175781\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-5c5045df-7e06-4abb-a394-f2b98f42850a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Logclose_KTC</th>\n",
              "      <th>Logclose_AEONTS</th>\n",
              "      <th>Logclose_JMT</th>\n",
              "      <th>Logclose_SAWAD</th>\n",
              "      <th>BroadMoney_M1M2_Growth</th>\n",
              "      <th>Inflation_Surprise</th>\n",
              "      <th>IPI_Surprise</th>\n",
              "      <th>THOR_1M</th>\n",
              "      <th>THOR_6M</th>\n",
              "      <th>3M_1M_THOR_Spread</th>\n",
              "      <th>6M_1M_THOR_Spread</th>\n",
              "      <th>5Y_1Y_Bond_Spread</th>\n",
              "      <th>10Y_5Y_Bond_Spread</th>\n",
              "      <th>THB_per_USD</th>\n",
              "      <th>SP500_Index</th>\n",
              "      <th>SET_Index</th>\n",
              "      <th>THB_per_CNY</th>\n",
              "      <th>GDP_Growth</th>\n",
              "      <th>THB_per_INR</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2015-02-01</th>\n",
              "      <td>1.911174</td>\n",
              "      <td>4.324112</td>\n",
              "      <td>1.979026</td>\n",
              "      <td>3.156030</td>\n",
              "      <td>0.009765</td>\n",
              "      <td>-0.0066</td>\n",
              "      <td>-0.000066</td>\n",
              "      <td>0.019955</td>\n",
              "      <td>0.020023</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000068</td>\n",
              "      <td>0.0035</td>\n",
              "      <td>0.0056</td>\n",
              "      <td>32.341000</td>\n",
              "      <td>2104.500000</td>\n",
              "      <td>1582.699951</td>\n",
              "      <td>0.19335</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.906796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-03-01</th>\n",
              "      <td>2.032421</td>\n",
              "      <td>4.281752</td>\n",
              "      <td>1.914488</td>\n",
              "      <td>3.106020</td>\n",
              "      <td>0.004617</td>\n",
              "      <td>-0.0019</td>\n",
              "      <td>0.000380</td>\n",
              "      <td>0.019942</td>\n",
              "      <td>0.020019</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000077</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0058</td>\n",
              "      <td>32.540001</td>\n",
              "      <td>2067.889893</td>\n",
              "      <td>1582.140015</td>\n",
              "      <td>0.19040</td>\n",
              "      <td>-0.020455</td>\n",
              "      <td>1.918100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-04-01</th>\n",
              "      <td>2.123730</td>\n",
              "      <td>4.252482</td>\n",
              "      <td>1.897821</td>\n",
              "      <td>3.193960</td>\n",
              "      <td>-0.001550</td>\n",
              "      <td>-0.0012</td>\n",
              "      <td>-0.000670</td>\n",
              "      <td>0.018201</td>\n",
              "      <td>0.019729</td>\n",
              "      <td>0.001167</td>\n",
              "      <td>0.001528</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0051</td>\n",
              "      <td>32.838001</td>\n",
              "      <td>2085.510010</td>\n",
              "      <td>1525.579956</td>\n",
              "      <td>0.18827</td>\n",
              "      <td>-0.015059</td>\n",
              "      <td>1.930500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-05-01</th>\n",
              "      <td>1.998252</td>\n",
              "      <td>4.206817</td>\n",
              "      <td>1.863420</td>\n",
              "      <td>3.200002</td>\n",
              "      <td>0.001422</td>\n",
              "      <td>-0.0024</td>\n",
              "      <td>-0.000330</td>\n",
              "      <td>0.016928</td>\n",
              "      <td>0.019148</td>\n",
              "      <td>0.001280</td>\n",
              "      <td>0.002220</td>\n",
              "      <td>0.0042</td>\n",
              "      <td>0.0078</td>\n",
              "      <td>33.734001</td>\n",
              "      <td>2107.389893</td>\n",
              "      <td>1519.880005</td>\n",
              "      <td>0.18351</td>\n",
              "      <td>-0.011596</td>\n",
              "      <td>1.889400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-06-01</th>\n",
              "      <td>2.047806</td>\n",
              "      <td>4.201526</td>\n",
              "      <td>1.712987</td>\n",
              "      <td>3.151212</td>\n",
              "      <td>-0.005075</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.000280</td>\n",
              "      <td>0.014939</td>\n",
              "      <td>0.018408</td>\n",
              "      <td>0.001854</td>\n",
              "      <td>0.003469</td>\n",
              "      <td>0.0056</td>\n",
              "      <td>0.0082</td>\n",
              "      <td>33.729000</td>\n",
              "      <td>2063.110107</td>\n",
              "      <td>1476.869995</td>\n",
              "      <td>0.18359</td>\n",
              "      <td>-0.002867</td>\n",
              "      <td>1.888000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c5045df-7e06-4abb-a394-f2b98f42850a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5c5045df-7e06-4abb-a394-f2b98f42850a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5c5045df-7e06-4abb-a394-f2b98f42850a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "            Logclose_KTC  Logclose_AEONTS  Logclose_JMT  Logclose_SAWAD  \\\n",
              "Date                                                                      \n",
              "2015-02-01      1.911174         4.324112      1.979026        3.156030   \n",
              "2015-03-01      2.032421         4.281752      1.914488        3.106020   \n",
              "2015-04-01      2.123730         4.252482      1.897821        3.193960   \n",
              "2015-05-01      1.998252         4.206817      1.863420        3.200002   \n",
              "2015-06-01      2.047806         4.201526      1.712987        3.151212   \n",
              "\n",
              "            BroadMoney_M1M2_Growth  Inflation_Surprise  IPI_Surprise  \\\n",
              "Date                                                                   \n",
              "2015-02-01                0.009765             -0.0066     -0.000066   \n",
              "2015-03-01                0.004617             -0.0019      0.000380   \n",
              "2015-04-01               -0.001550             -0.0012     -0.000670   \n",
              "2015-05-01                0.001422             -0.0024     -0.000330   \n",
              "2015-06-01               -0.005075             -0.0015     -0.000280   \n",
              "\n",
              "             THOR_1M   THOR_6M  3M_1M_THOR_Spread  6M_1M_THOR_Spread  \\\n",
              "Date                                                                   \n",
              "2015-02-01  0.019955  0.020023           0.000015           0.000068   \n",
              "2015-03-01  0.019942  0.020019           0.000032           0.000077   \n",
              "2015-04-01  0.018201  0.019729           0.001167           0.001528   \n",
              "2015-05-01  0.016928  0.019148           0.001280           0.002220   \n",
              "2015-06-01  0.014939  0.018408           0.001854           0.003469   \n",
              "\n",
              "            5Y_1Y_Bond_Spread  10Y_5Y_Bond_Spread  THB_per_USD  SP500_Index  \\\n",
              "Date                                                                          \n",
              "2015-02-01             0.0035              0.0056    32.341000  2104.500000   \n",
              "2015-03-01             0.0045              0.0058    32.540001  2067.889893   \n",
              "2015-04-01             0.0048              0.0051    32.838001  2085.510010   \n",
              "2015-05-01             0.0042              0.0078    33.734001  2107.389893   \n",
              "2015-06-01             0.0056              0.0082    33.729000  2063.110107   \n",
              "\n",
              "              SET_Index  THB_per_CNY  GDP_Growth  THB_per_INR  \n",
              "Date                                                           \n",
              "2015-02-01  1582.699951      0.19335         NaN     1.906796  \n",
              "2015-03-01  1582.140015      0.19040   -0.020455     1.918100  \n",
              "2015-04-01  1525.579956      0.18827   -0.015059     1.930500  \n",
              "2015-05-01  1519.880005      0.18351   -0.011596     1.889400  \n",
              "2015-06-01  1476.869995      0.18359   -0.002867     1.888000  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ======== Filter sector log-prices + macro variables ========\n",
        "\n",
        "# Macro columns à¸—à¸µà¹ˆà¸¡à¸µà¸­à¸¢à¸¹à¹ˆà¸ˆà¸£à¸´à¸‡à¹ƒà¸™ Excel + yfinance\n",
        "macro_columns = [\n",
        "    \"BroadMoney_M1M2_Growth\",\n",
        "    \"Inflation_Surprise\",\n",
        "    \"IPI_Surprise\",\n",
        "    \"THOR_1M\",\n",
        "    \"THOR_6M\",\n",
        "    \"3M_1M_THOR_Spread\",\n",
        "    \"6M_1M_THOR_Spread\",\n",
        "    \"5Y_1Y_Bond_Spread\",\n",
        "    \"10Y_5Y_Bond_Spread\",\n",
        "    \"THB_per_USD\",\n",
        "    # \"Brent_Oil_USD_per_bbl\",\n",
        "    \"SP500_Index\",\n",
        "    \"SET_Index\",\n",
        "    \"THB_per_CNY\",\n",
        "    \"GDP_Growth\" ,\n",
        "    \"THB_per_INR\"\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "# ======== à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸² df à¸–à¸¹à¸à¸ªà¸£à¹‰à¸²à¸‡à¹à¸¥à¹‰à¸§à¸ˆà¸²à¸ Block à¸à¹ˆà¸­à¸™à¸«à¸™à¹‰à¸² ========\n",
        "if 'df' not in globals():\n",
        "    raise RuntimeError(\"âŒ Variable 'df' not found. Please run the data-preparation block first.\")\n",
        "\n",
        "df_filtered_macro = df\n",
        "\n",
        "# à¹€à¸à¹‡à¸šà¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¹à¸¢à¸ sector\n",
        "combined_dfs = {}\n",
        "\n",
        "for sector, tickers_list in SECTORS.items():\n",
        "    sector_frames = []\n",
        "\n",
        "    for ticker in tickers_list:\n",
        "        colname = f\"Close_{ticker}\"\n",
        "        if colname not in df.columns:\n",
        "            print(f\"âš ï¸ {colname} not found in df. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        # âœ… à¹ƒà¸Šà¹‰ Logclose à¹à¸—à¸™ log-return\n",
        "        tmp = df[[colname]].copy()\n",
        "        tmp[f\"Logclose_{ticker}\"] = np.log(tmp[colname])\n",
        "        tmp = tmp[[f\"Logclose_{ticker}\"]]\n",
        "\n",
        "        # align index à¹ƒà¸«à¹‰à¸•à¸£à¸‡à¸à¸±à¸š macro\n",
        "        tmp = tmp.loc[df_filtered_macro.index]\n",
        "        sector_frames.append(tmp)\n",
        "\n",
        "    if len(sector_frames) == 0:\n",
        "        continue\n",
        "\n",
        "    # à¸£à¸§à¸¡ Logclose à¸‚à¸­à¸‡à¸«à¸¸à¹‰à¸™à¸—à¸¸à¸à¸•à¸±à¸§à¹ƒà¸™ sector\n",
        "    sector_data = pd.concat(sector_frames, axis=1)\n",
        "\n",
        "    # à¸£à¸§à¸¡à¸à¸±à¸š macro\n",
        "    combined_df = pd.concat([sector_data, df_filtered_macro], axis=1).ffill()\n",
        "\n",
        "    # à¸•à¸±à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸›à¸µ 2025 (à¸›à¹‰à¸­à¸‡à¸à¸±à¸™ incomplete data)\n",
        "    combined_df = combined_df[combined_df.index.year != 2025]\n",
        "\n",
        "    combined_dfs[sector] = combined_df\n",
        "\n",
        "# ======== à¹à¸ªà¸”à¸‡à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ ========\n",
        "for sector, combined_df in combined_dfs.items():\n",
        "    print(f\"\\nğŸ“Š Combined data for sector: {sector}\")\n",
        "    cols_to_show = [c for c in combined_df.columns if c.startswith(\"Logclose_\")] + macro_columns\n",
        "    cols_to_show_present = [col for col in cols_to_show if col in combined_df.columns]\n",
        "    display(combined_df[cols_to_show_present].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JiapIQVQrUOF",
        "outputId": "f2e5223f-7bb5-4563-a385-9336323b80ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Displaying head of combined dataframes for each sector:\n",
            "\n",
            "--- Combined dataframe for Banking ---\n",
            "Columns in the combined dataframe for Banking:\n",
            "Index(['Logclose_BBL', 'Logclose_KBANK', 'Logclose_KKP', 'Logclose_KTB',\n",
            "       'Logclose_TCAP', 'Logclose_TISCO', 'Logclose_TTB', 'Close_BBL',\n",
            "       'Close_KBANK', 'Close_KKP', 'Close_KTB', 'Close_TCAP', 'Close_TISCO',\n",
            "       'Close_TTB', 'Close_KTC', 'Close_AEONTS', 'Close_JMT', 'Close_SAWAD',\n",
            "       'Inflation', 'Inflation_Forecast', 'IPI', 'IPI_Forecast',\n",
            "       'BroadMoney_M1M2_Growth', 'THOR_1M', 'THOR_3M', 'THOR_6M',\n",
            "       'Bond_Yield_1Y', 'Bond_Yield_5Y', 'Bond_Yield_10Y',\n",
            "       'Yield_Spread_10Y_5Y', 'Yield_Spread_5Y_1Y', 'Yield_Spread_10Y_1Y',\n",
            "       'THB_per_USD', 'THB_per_CNY', 'THB_per_INR', 'SP500_Index', 'SET_Index',\n",
            "       'IPI_Surprise', 'Inflation_Surprise', '5Y_1Y_Bond_Spread',\n",
            "       '10Y_5Y_Bond_Spread', '3M_1M_THOR_Spread', '6M_1M_THOR_Spread',\n",
            "       'GDP_Monthly', 'GDP_Growth'],\n",
            "      dtype='object')\n",
            "\n",
            "Head of the combined dataframe for Banking:\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-a1e525ca-0875-4f77-83c6-71a241c15d75\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Logclose_BBL</th>\n",
              "      <th>Logclose_KBANK</th>\n",
              "      <th>Logclose_KKP</th>\n",
              "      <th>Logclose_KTB</th>\n",
              "      <th>Logclose_TCAP</th>\n",
              "      <th>Logclose_TISCO</th>\n",
              "      <th>Logclose_TTB</th>\n",
              "      <th>Close_BBL</th>\n",
              "      <th>Close_KBANK</th>\n",
              "      <th>Close_KKP</th>\n",
              "      <th>...</th>\n",
              "      <th>SP500_Index</th>\n",
              "      <th>SET_Index</th>\n",
              "      <th>IPI_Surprise</th>\n",
              "      <th>Inflation_Surprise</th>\n",
              "      <th>5Y_1Y_Bond_Spread</th>\n",
              "      <th>10Y_5Y_Bond_Spread</th>\n",
              "      <th>3M_1M_THOR_Spread</th>\n",
              "      <th>6M_1M_THOR_Spread</th>\n",
              "      <th>GDP_Monthly</th>\n",
              "      <th>GDP_Growth</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2015-02-01</th>\n",
              "      <td>4.790190</td>\n",
              "      <td>5.017582</td>\n",
              "      <td>2.939447</td>\n",
              "      <td>2.627824</td>\n",
              "      <td>2.802560</td>\n",
              "      <td>3.072488</td>\n",
              "      <td>0.569241</td>\n",
              "      <td>120.324234</td>\n",
              "      <td>151.045578</td>\n",
              "      <td>18.905380</td>\n",
              "      <td>...</td>\n",
              "      <td>2104.500000</td>\n",
              "      <td>1582.699951</td>\n",
              "      <td>-0.000066</td>\n",
              "      <td>-0.0066</td>\n",
              "      <td>0.0035</td>\n",
              "      <td>0.0056</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000068</td>\n",
              "      <td>1.165382e+06</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-03-01</th>\n",
              "      <td>4.798353</td>\n",
              "      <td>5.071406</td>\n",
              "      <td>2.933057</td>\n",
              "      <td>2.627824</td>\n",
              "      <td>2.795391</td>\n",
              "      <td>3.045532</td>\n",
              "      <td>0.555907</td>\n",
              "      <td>121.310501</td>\n",
              "      <td>159.398285</td>\n",
              "      <td>18.784960</td>\n",
              "      <td>...</td>\n",
              "      <td>2067.889893</td>\n",
              "      <td>1582.140015</td>\n",
              "      <td>0.000380</td>\n",
              "      <td>-0.0019</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0058</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000077</td>\n",
              "      <td>1.141786e+06</td>\n",
              "      <td>-0.020455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-04-01</th>\n",
              "      <td>4.801060</td>\n",
              "      <td>4.984792</td>\n",
              "      <td>2.880413</td>\n",
              "      <td>2.496796</td>\n",
              "      <td>2.773572</td>\n",
              "      <td>3.034543</td>\n",
              "      <td>0.419496</td>\n",
              "      <td>121.639297</td>\n",
              "      <td>146.173111</td>\n",
              "      <td>17.821630</td>\n",
              "      <td>...</td>\n",
              "      <td>2085.510010</td>\n",
              "      <td>1525.579956</td>\n",
              "      <td>-0.000670</td>\n",
              "      <td>-0.0012</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0051</td>\n",
              "      <td>0.001167</td>\n",
              "      <td>0.001528</td>\n",
              "      <td>1.124720e+06</td>\n",
              "      <td>-0.015059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-05-01</th>\n",
              "      <td>4.808427</td>\n",
              "      <td>4.925754</td>\n",
              "      <td>2.888474</td>\n",
              "      <td>2.436026</td>\n",
              "      <td>2.810098</td>\n",
              "      <td>3.072725</td>\n",
              "      <td>0.417810</td>\n",
              "      <td>122.538757</td>\n",
              "      <td>137.793152</td>\n",
              "      <td>17.965874</td>\n",
              "      <td>...</td>\n",
              "      <td>2107.389893</td>\n",
              "      <td>1519.880005</td>\n",
              "      <td>-0.000330</td>\n",
              "      <td>-0.0024</td>\n",
              "      <td>0.0042</td>\n",
              "      <td>0.0078</td>\n",
              "      <td>0.001280</td>\n",
              "      <td>0.002220</td>\n",
              "      <td>1.111753e+06</td>\n",
              "      <td>-0.011596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-06-01</th>\n",
              "      <td>4.786204</td>\n",
              "      <td>4.894501</td>\n",
              "      <td>2.867420</td>\n",
              "      <td>2.379193</td>\n",
              "      <td>2.780465</td>\n",
              "      <td>3.094704</td>\n",
              "      <td>0.335797</td>\n",
              "      <td>119.845566</td>\n",
              "      <td>133.553375</td>\n",
              "      <td>17.591581</td>\n",
              "      <td>...</td>\n",
              "      <td>2063.110107</td>\n",
              "      <td>1476.869995</td>\n",
              "      <td>-0.000280</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>0.0056</td>\n",
              "      <td>0.0082</td>\n",
              "      <td>0.001854</td>\n",
              "      <td>0.003469</td>\n",
              "      <td>1.108570e+06</td>\n",
              "      <td>-0.002867</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 45 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1e525ca-0875-4f77-83c6-71a241c15d75')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a1e525ca-0875-4f77-83c6-71a241c15d75 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a1e525ca-0875-4f77-83c6-71a241c15d75');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "            Logclose_BBL  Logclose_KBANK  Logclose_KKP  Logclose_KTB  \\\n",
              "Date                                                                   \n",
              "2015-02-01      4.790190        5.017582      2.939447      2.627824   \n",
              "2015-03-01      4.798353        5.071406      2.933057      2.627824   \n",
              "2015-04-01      4.801060        4.984792      2.880413      2.496796   \n",
              "2015-05-01      4.808427        4.925754      2.888474      2.436026   \n",
              "2015-06-01      4.786204        4.894501      2.867420      2.379193   \n",
              "\n",
              "            Logclose_TCAP  Logclose_TISCO  Logclose_TTB   Close_BBL  \\\n",
              "Date                                                                  \n",
              "2015-02-01       2.802560        3.072488      0.569241  120.324234   \n",
              "2015-03-01       2.795391        3.045532      0.555907  121.310501   \n",
              "2015-04-01       2.773572        3.034543      0.419496  121.639297   \n",
              "2015-05-01       2.810098        3.072725      0.417810  122.538757   \n",
              "2015-06-01       2.780465        3.094704      0.335797  119.845566   \n",
              "\n",
              "            Close_KBANK  Close_KKP  ...  SP500_Index    SET_Index  \\\n",
              "Date                                ...                             \n",
              "2015-02-01   151.045578  18.905380  ...  2104.500000  1582.699951   \n",
              "2015-03-01   159.398285  18.784960  ...  2067.889893  1582.140015   \n",
              "2015-04-01   146.173111  17.821630  ...  2085.510010  1525.579956   \n",
              "2015-05-01   137.793152  17.965874  ...  2107.389893  1519.880005   \n",
              "2015-06-01   133.553375  17.591581  ...  2063.110107  1476.869995   \n",
              "\n",
              "            IPI_Surprise  Inflation_Surprise  5Y_1Y_Bond_Spread  \\\n",
              "Date                                                              \n",
              "2015-02-01     -0.000066             -0.0066             0.0035   \n",
              "2015-03-01      0.000380             -0.0019             0.0045   \n",
              "2015-04-01     -0.000670             -0.0012             0.0048   \n",
              "2015-05-01     -0.000330             -0.0024             0.0042   \n",
              "2015-06-01     -0.000280             -0.0015             0.0056   \n",
              "\n",
              "            10Y_5Y_Bond_Spread  3M_1M_THOR_Spread  6M_1M_THOR_Spread  \\\n",
              "Date                                                                   \n",
              "2015-02-01              0.0056           0.000015           0.000068   \n",
              "2015-03-01              0.0058           0.000032           0.000077   \n",
              "2015-04-01              0.0051           0.001167           0.001528   \n",
              "2015-05-01              0.0078           0.001280           0.002220   \n",
              "2015-06-01              0.0082           0.001854           0.003469   \n",
              "\n",
              "             GDP_Monthly  GDP_Growth  \n",
              "Date                                  \n",
              "2015-02-01  1.165382e+06         NaN  \n",
              "2015-03-01  1.141786e+06   -0.020455  \n",
              "2015-04-01  1.124720e+06   -0.015059  \n",
              "2015-05-01  1.111753e+06   -0.011596  \n",
              "2015-06-01  1.108570e+06   -0.002867  \n",
              "\n",
              "[5 rows x 45 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Combined dataframe for Finance_Securities ---\n",
            "Columns in the combined dataframe for Finance_Securities:\n",
            "Index(['Logclose_KTC', 'Logclose_AEONTS', 'Logclose_JMT', 'Logclose_SAWAD',\n",
            "       'Close_BBL', 'Close_KBANK', 'Close_KKP', 'Close_KTB', 'Close_TCAP',\n",
            "       'Close_TISCO', 'Close_TTB', 'Close_KTC', 'Close_AEONTS', 'Close_JMT',\n",
            "       'Close_SAWAD', 'Inflation', 'Inflation_Forecast', 'IPI', 'IPI_Forecast',\n",
            "       'BroadMoney_M1M2_Growth', 'THOR_1M', 'THOR_3M', 'THOR_6M',\n",
            "       'Bond_Yield_1Y', 'Bond_Yield_5Y', 'Bond_Yield_10Y',\n",
            "       'Yield_Spread_10Y_5Y', 'Yield_Spread_5Y_1Y', 'Yield_Spread_10Y_1Y',\n",
            "       'THB_per_USD', 'THB_per_CNY', 'THB_per_INR', 'SP500_Index', 'SET_Index',\n",
            "       'IPI_Surprise', 'Inflation_Surprise', '5Y_1Y_Bond_Spread',\n",
            "       '10Y_5Y_Bond_Spread', '3M_1M_THOR_Spread', '6M_1M_THOR_Spread',\n",
            "       'GDP_Monthly', 'GDP_Growth'],\n",
            "      dtype='object')\n",
            "\n",
            "Head of the combined dataframe for Finance_Securities:\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-abd5c9ca-c2a1-4f76-a3ff-ee8fa98d6b3c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Logclose_KTC</th>\n",
              "      <th>Logclose_AEONTS</th>\n",
              "      <th>Logclose_JMT</th>\n",
              "      <th>Logclose_SAWAD</th>\n",
              "      <th>Close_BBL</th>\n",
              "      <th>Close_KBANK</th>\n",
              "      <th>Close_KKP</th>\n",
              "      <th>Close_KTB</th>\n",
              "      <th>Close_TCAP</th>\n",
              "      <th>Close_TISCO</th>\n",
              "      <th>...</th>\n",
              "      <th>SP500_Index</th>\n",
              "      <th>SET_Index</th>\n",
              "      <th>IPI_Surprise</th>\n",
              "      <th>Inflation_Surprise</th>\n",
              "      <th>5Y_1Y_Bond_Spread</th>\n",
              "      <th>10Y_5Y_Bond_Spread</th>\n",
              "      <th>3M_1M_THOR_Spread</th>\n",
              "      <th>6M_1M_THOR_Spread</th>\n",
              "      <th>GDP_Monthly</th>\n",
              "      <th>GDP_Growth</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2015-02-01</th>\n",
              "      <td>1.911174</td>\n",
              "      <td>4.324112</td>\n",
              "      <td>1.979026</td>\n",
              "      <td>3.156030</td>\n",
              "      <td>120.324234</td>\n",
              "      <td>151.045578</td>\n",
              "      <td>18.905380</td>\n",
              "      <td>13.843619</td>\n",
              "      <td>16.486799</td>\n",
              "      <td>21.595560</td>\n",
              "      <td>...</td>\n",
              "      <td>2104.500000</td>\n",
              "      <td>1582.699951</td>\n",
              "      <td>-0.000066</td>\n",
              "      <td>-0.0066</td>\n",
              "      <td>0.0035</td>\n",
              "      <td>0.0056</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000068</td>\n",
              "      <td>1.165382e+06</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-03-01</th>\n",
              "      <td>2.032421</td>\n",
              "      <td>4.281752</td>\n",
              "      <td>1.914488</td>\n",
              "      <td>3.106020</td>\n",
              "      <td>121.310501</td>\n",
              "      <td>159.398285</td>\n",
              "      <td>18.784960</td>\n",
              "      <td>13.843619</td>\n",
              "      <td>16.369032</td>\n",
              "      <td>21.021212</td>\n",
              "      <td>...</td>\n",
              "      <td>2067.889893</td>\n",
              "      <td>1582.140015</td>\n",
              "      <td>0.000380</td>\n",
              "      <td>-0.0019</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0058</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000077</td>\n",
              "      <td>1.141786e+06</td>\n",
              "      <td>-0.020455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-04-01</th>\n",
              "      <td>2.123730</td>\n",
              "      <td>4.252482</td>\n",
              "      <td>1.897821</td>\n",
              "      <td>3.193960</td>\n",
              "      <td>121.639297</td>\n",
              "      <td>146.173111</td>\n",
              "      <td>17.821630</td>\n",
              "      <td>12.143525</td>\n",
              "      <td>16.015745</td>\n",
              "      <td>20.791470</td>\n",
              "      <td>...</td>\n",
              "      <td>2085.510010</td>\n",
              "      <td>1525.579956</td>\n",
              "      <td>-0.000670</td>\n",
              "      <td>-0.0012</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0051</td>\n",
              "      <td>0.001167</td>\n",
              "      <td>0.001528</td>\n",
              "      <td>1.124720e+06</td>\n",
              "      <td>-0.015059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-05-01</th>\n",
              "      <td>1.998252</td>\n",
              "      <td>4.206817</td>\n",
              "      <td>1.863420</td>\n",
              "      <td>3.200002</td>\n",
              "      <td>122.538757</td>\n",
              "      <td>137.793152</td>\n",
              "      <td>17.965874</td>\n",
              "      <td>11.427542</td>\n",
              "      <td>16.611538</td>\n",
              "      <td>21.600693</td>\n",
              "      <td>...</td>\n",
              "      <td>2107.389893</td>\n",
              "      <td>1519.880005</td>\n",
              "      <td>-0.000330</td>\n",
              "      <td>-0.0024</td>\n",
              "      <td>0.0042</td>\n",
              "      <td>0.0078</td>\n",
              "      <td>0.001280</td>\n",
              "      <td>0.002220</td>\n",
              "      <td>1.111753e+06</td>\n",
              "      <td>-0.011596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-06-01</th>\n",
              "      <td>2.047806</td>\n",
              "      <td>4.201526</td>\n",
              "      <td>1.712987</td>\n",
              "      <td>3.151212</td>\n",
              "      <td>119.845566</td>\n",
              "      <td>133.553375</td>\n",
              "      <td>17.591581</td>\n",
              "      <td>10.796185</td>\n",
              "      <td>16.126526</td>\n",
              "      <td>22.080709</td>\n",
              "      <td>...</td>\n",
              "      <td>2063.110107</td>\n",
              "      <td>1476.869995</td>\n",
              "      <td>-0.000280</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>0.0056</td>\n",
              "      <td>0.0082</td>\n",
              "      <td>0.001854</td>\n",
              "      <td>0.003469</td>\n",
              "      <td>1.108570e+06</td>\n",
              "      <td>-0.002867</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 42 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-abd5c9ca-c2a1-4f76-a3ff-ee8fa98d6b3c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-abd5c9ca-c2a1-4f76-a3ff-ee8fa98d6b3c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-abd5c9ca-c2a1-4f76-a3ff-ee8fa98d6b3c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "            Logclose_KTC  Logclose_AEONTS  Logclose_JMT  Logclose_SAWAD  \\\n",
              "Date                                                                      \n",
              "2015-02-01      1.911174         4.324112      1.979026        3.156030   \n",
              "2015-03-01      2.032421         4.281752      1.914488        3.106020   \n",
              "2015-04-01      2.123730         4.252482      1.897821        3.193960   \n",
              "2015-05-01      1.998252         4.206817      1.863420        3.200002   \n",
              "2015-06-01      2.047806         4.201526      1.712987        3.151212   \n",
              "\n",
              "             Close_BBL  Close_KBANK  Close_KKP  Close_KTB  Close_TCAP  \\\n",
              "Date                                                                    \n",
              "2015-02-01  120.324234   151.045578  18.905380  13.843619   16.486799   \n",
              "2015-03-01  121.310501   159.398285  18.784960  13.843619   16.369032   \n",
              "2015-04-01  121.639297   146.173111  17.821630  12.143525   16.015745   \n",
              "2015-05-01  122.538757   137.793152  17.965874  11.427542   16.611538   \n",
              "2015-06-01  119.845566   133.553375  17.591581  10.796185   16.126526   \n",
              "\n",
              "            Close_TISCO  ...  SP500_Index    SET_Index  IPI_Surprise  \\\n",
              "Date                     ...                                           \n",
              "2015-02-01    21.595560  ...  2104.500000  1582.699951     -0.000066   \n",
              "2015-03-01    21.021212  ...  2067.889893  1582.140015      0.000380   \n",
              "2015-04-01    20.791470  ...  2085.510010  1525.579956     -0.000670   \n",
              "2015-05-01    21.600693  ...  2107.389893  1519.880005     -0.000330   \n",
              "2015-06-01    22.080709  ...  2063.110107  1476.869995     -0.000280   \n",
              "\n",
              "            Inflation_Surprise  5Y_1Y_Bond_Spread  10Y_5Y_Bond_Spread  \\\n",
              "Date                                                                    \n",
              "2015-02-01             -0.0066             0.0035              0.0056   \n",
              "2015-03-01             -0.0019             0.0045              0.0058   \n",
              "2015-04-01             -0.0012             0.0048              0.0051   \n",
              "2015-05-01             -0.0024             0.0042              0.0078   \n",
              "2015-06-01             -0.0015             0.0056              0.0082   \n",
              "\n",
              "            3M_1M_THOR_Spread  6M_1M_THOR_Spread   GDP_Monthly  GDP_Growth  \n",
              "Date                                                                        \n",
              "2015-02-01           0.000015           0.000068  1.165382e+06         NaN  \n",
              "2015-03-01           0.000032           0.000077  1.141786e+06   -0.020455  \n",
              "2015-04-01           0.001167           0.001528  1.124720e+06   -0.015059  \n",
              "2015-05-01           0.001280           0.002220  1.111753e+06   -0.011596  \n",
              "2015-06-01           0.001854           0.003469  1.108570e+06   -0.002867  \n",
              "\n",
              "[5 rows x 42 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Select the dataframe for the first stock (e.g., 'BBL') from the combined_dfs dictionary\n",
        "# This cell is intended to display example dataframes from combined_dfs,\n",
        "# which are structured by sector, not individual tickers.\n",
        "# Iterate through the combined_dfs dictionary using sector names as keys.\n",
        "\n",
        "if 'combined_dfs' in globals() and combined_dfs:\n",
        "    print(\"Displaying head of combined dataframes for each sector:\")\n",
        "    for sector, combined_df_example in combined_dfs.items():\n",
        "        print(f\"\\n--- Combined dataframe for {sector} ---\")\n",
        "        # Display the columns of the example combined dataframe\n",
        "        print(f\"Columns in the combined dataframe for {sector}:\")\n",
        "        print(combined_df_example.columns)\n",
        "\n",
        "        # Display the head of the example combined dataframe\n",
        "        print(f\"\\nHead of the combined dataframe for {sector}:\")\n",
        "        display(combined_df_example.head())\n",
        "else:\n",
        "    print(\"The 'combined_dfs' dictionary is not available or is empty. Please run the data processing cell first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKCrzkPXBDzD"
      },
      "source": [
        "** 3 Econometric **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "eb8545b7",
        "outputId": "9532cfe3-bbe3-4dc1-b98a-12c51d56cea7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== âœ… Logclose columns collected ===\n",
            "Total: 11 stocks\n",
            "\n",
            "ğŸ“… First available data per stock:\n",
            "Logclose_BBL             : 2015-02-01 00:00:00\n",
            "Logclose_KBANK           : 2015-02-01 00:00:00\n",
            "Logclose_KKP             : 2015-02-01 00:00:00\n",
            "Logclose_KTB             : 2015-02-01 00:00:00\n",
            "Logclose_TCAP            : 2015-02-01 00:00:00\n",
            "Logclose_TISCO           : 2015-02-01 00:00:00\n",
            "Logclose_TTB             : 2015-02-01 00:00:00\n",
            "Logclose_KTC             : 2015-02-01 00:00:00\n",
            "Logclose_AEONTS          : 2015-02-01 00:00:00\n",
            "Logclose_JMT             : 2015-02-01 00:00:00\n",
            "Logclose_SAWAD           : 2015-02-01 00:00:00\n",
            "\n",
            "âœ… Dynamic Panel Ready: shape=(132, 11)\n",
            "ğŸ• Date range: 2015-02-01 â†’ 2026-01-01\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"    print(df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2015-02-01 00:00:00\",\n        \"max\": \"2015-11-01 00:00:00\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"2015-10-01 00:00:00\",\n          \"2015-03-01 00:00:00\",\n          \"2015-07-01 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_BBL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04604570926979487,\n        \"min\": 4.6795942757303255,\n        \"max\": 4.808427366265337,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          4.6795942757303255,\n          4.798353383502454,\n          4.7164080722246995\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_KBANK\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09917339922383091,\n        \"min\": 4.7944178892404725,\n        \"max\": 5.071406006650233,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          4.805956661213239,\n          5.071406006650233,\n          4.834537796833894\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_KKP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08159477581924753,\n        \"min\": 2.7226816737009507,\n        \"max\": 2.93944655081549,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          2.8468056627767813,\n          2.9330565386505154,\n          2.7226816737009507\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_KTB\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09927870376542021,\n        \"min\": 2.373327798290073,\n        \"max\": 2.6278244294848396,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          2.6278244294848396,\n          2.4967961161005086,\n          2.441536083467634\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_TCAP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05564393595978282,\n        \"min\": 2.6608012642504497,\n        \"max\": 2.8611702727822195,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          2.787956274591962,\n          2.795391251340349,\n          2.7184301659259456\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_TISCO\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08430390303472121,\n        \"min\": 2.8355956995562734,\n        \"max\": 3.094704352115409,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          2.8970483460846927,\n          3.045532005278821,\n          3.0155670447678613\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-6730a9dd-0b69-4c37-ab19-80089d4d7626\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Logclose_BBL</th>\n",
              "      <th>Logclose_KBANK</th>\n",
              "      <th>Logclose_KKP</th>\n",
              "      <th>Logclose_KTB</th>\n",
              "      <th>Logclose_TCAP</th>\n",
              "      <th>Logclose_TISCO</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2015-02-01</th>\n",
              "      <td>4.790190</td>\n",
              "      <td>5.017582</td>\n",
              "      <td>2.939447</td>\n",
              "      <td>2.627824</td>\n",
              "      <td>2.802560</td>\n",
              "      <td>3.072488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-03-01</th>\n",
              "      <td>4.798353</td>\n",
              "      <td>5.071406</td>\n",
              "      <td>2.933057</td>\n",
              "      <td>2.627824</td>\n",
              "      <td>2.795391</td>\n",
              "      <td>3.045532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-04-01</th>\n",
              "      <td>4.801060</td>\n",
              "      <td>4.984792</td>\n",
              "      <td>2.880413</td>\n",
              "      <td>2.496796</td>\n",
              "      <td>2.773572</td>\n",
              "      <td>3.034543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-05-01</th>\n",
              "      <td>4.808427</td>\n",
              "      <td>4.925754</td>\n",
              "      <td>2.888474</td>\n",
              "      <td>2.436026</td>\n",
              "      <td>2.810098</td>\n",
              "      <td>3.072725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-06-01</th>\n",
              "      <td>4.786204</td>\n",
              "      <td>4.894501</td>\n",
              "      <td>2.867420</td>\n",
              "      <td>2.379193</td>\n",
              "      <td>2.780465</td>\n",
              "      <td>3.094704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-07-01</th>\n",
              "      <td>4.716408</td>\n",
              "      <td>4.834538</td>\n",
              "      <td>2.722682</td>\n",
              "      <td>2.402315</td>\n",
              "      <td>2.718430</td>\n",
              "      <td>3.015567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-08-01</th>\n",
              "      <td>4.707331</td>\n",
              "      <td>4.848485</td>\n",
              "      <td>2.778473</td>\n",
              "      <td>2.441536</td>\n",
              "      <td>2.660801</td>\n",
              "      <td>2.942364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-09-01</th>\n",
              "      <td>4.679594</td>\n",
              "      <td>4.794418</td>\n",
              "      <td>2.730845</td>\n",
              "      <td>2.379193</td>\n",
              "      <td>2.734303</td>\n",
              "      <td>2.835596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-10-01</th>\n",
              "      <td>4.737904</td>\n",
              "      <td>4.805957</td>\n",
              "      <td>2.846806</td>\n",
              "      <td>2.379193</td>\n",
              "      <td>2.787956</td>\n",
              "      <td>2.897048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-11-01</th>\n",
              "      <td>4.737904</td>\n",
              "      <td>4.797223</td>\n",
              "      <td>2.932573</td>\n",
              "      <td>2.373328</td>\n",
              "      <td>2.861170</td>\n",
              "      <td>3.003733</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6730a9dd-0b69-4c37-ab19-80089d4d7626')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6730a9dd-0b69-4c37-ab19-80089d4d7626 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6730a9dd-0b69-4c37-ab19-80089d4d7626');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "            Logclose_BBL  Logclose_KBANK  Logclose_KKP  Logclose_KTB  \\\n",
              "Date                                                                   \n",
              "2015-02-01      4.790190        5.017582      2.939447      2.627824   \n",
              "2015-03-01      4.798353        5.071406      2.933057      2.627824   \n",
              "2015-04-01      4.801060        4.984792      2.880413      2.496796   \n",
              "2015-05-01      4.808427        4.925754      2.888474      2.436026   \n",
              "2015-06-01      4.786204        4.894501      2.867420      2.379193   \n",
              "2015-07-01      4.716408        4.834538      2.722682      2.402315   \n",
              "2015-08-01      4.707331        4.848485      2.778473      2.441536   \n",
              "2015-09-01      4.679594        4.794418      2.730845      2.379193   \n",
              "2015-10-01      4.737904        4.805957      2.846806      2.379193   \n",
              "2015-11-01      4.737904        4.797223      2.932573      2.373328   \n",
              "\n",
              "            Logclose_TCAP  Logclose_TISCO  \n",
              "Date                                       \n",
              "2015-02-01       2.802560        3.072488  \n",
              "2015-03-01       2.795391        3.045532  \n",
              "2015-04-01       2.773572        3.034543  \n",
              "2015-05-01       2.810098        3.072725  \n",
              "2015-06-01       2.780465        3.094704  \n",
              "2015-07-01       2.718430        3.015567  \n",
              "2015-08-01       2.660801        2.942364  \n",
              "2015-09-01       2.734303        2.835596  \n",
              "2015-10-01       2.787956        2.897048  \n",
              "2015-11-01       2.861170        3.003733  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ============================================================\n",
        "# ğŸ§  MULTI-STOCK PIPELINE (Logclose + Dynamic Alignment)\n",
        "# ============================================================\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# --- Safety check ---\n",
        "if 'combined_dfs' not in globals() or not isinstance(combined_dfs, dict) or not combined_dfs:\n",
        "    raise RuntimeError(\"âŒ combined_dfs not found or empty. Run previous macro/stock preparation cells first.\")\n",
        "\n",
        "if 'SECTORS' not in globals():\n",
        "    raise RuntimeError(\"âŒ SECTORS not defined. Make sure the sector mapping dict is loaded.\")\n",
        "\n",
        "# ============================================================\n",
        "# 1ï¸âƒ£ Helper functions\n",
        "# ============================================================\n",
        "def _norm(s: str) -> str:\n",
        "    return re.sub(r'[^a-z0-9]+', '', str(s).lower())\n",
        "\n",
        "PRICE_TOKENS = (\"logclose\",\"close\",\"adjclose\",\"price\",\"px\",\"pxlast\",\"last\")\n",
        "\n",
        "def _find_price_like_col(df_one: pd.DataFrame, ticker: str) -> str | None:\n",
        "    \"\"\"à¸„à¹‰à¸™à¸«à¸²à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸£à¸²à¸„à¸²à¸«à¸£à¸·à¸­ logclose à¸—à¸µà¹ˆà¸•à¸£à¸‡à¸à¸±à¸šà¸Šà¸·à¹ˆà¸­à¸«à¸¸à¹‰à¸™\"\"\"\n",
        "    if df_one is None or df_one.empty:\n",
        "        return None\n",
        "    exacts = [\n",
        "        f\"Logclose_{ticker}\",\n",
        "        f\"Close_{ticker}\",\n",
        "        f\"close_{ticker}\",\n",
        "        f\"AdjClose_{ticker}\",\n",
        "        f\"Adj_Close_{ticker}\"\n",
        "    ]\n",
        "    for c in exacts:\n",
        "        if c in df_one.columns:\n",
        "            return c\n",
        "    generics = [\"Logclose\", \"Close\", \"Adj Close\", \"Price\", \"PX\", \"PX_LAST\", \"Last\"]\n",
        "    for c in generics:\n",
        "        if c in df_one.columns:\n",
        "            return c\n",
        "    numeric_cols = [c for c in df_one.columns if pd.api.types.is_numeric_dtype(df_one[c])]\n",
        "    want = {_norm(t)+_norm(ticker) for t in PRICE_TOKENS}\n",
        "    best, best_nn = None, -1\n",
        "    for c in numeric_cols:\n",
        "        nc = _norm(c)\n",
        "        if any(tok in nc for tok in want) or any(t in nc for t in PRICE_TOKENS):\n",
        "            nn = df_one[c].notna().sum()\n",
        "            if nn > best_nn:\n",
        "                best, best_nn = c, nn\n",
        "    return best\n",
        "\n",
        "def _align(s: pd.Series, idx: pd.Index) -> pd.Series:\n",
        "    if s is None:\n",
        "        return None\n",
        "    s = s.copy()\n",
        "    s.index = pd.to_datetime(s.index)\n",
        "    return s.reindex(idx)\n",
        "\n",
        "# ============================================================\n",
        "# 2ï¸âƒ£ Build base index (union of all sectors)\n",
        "# ============================================================\n",
        "union_idx = None\n",
        "for d in combined_dfs.values():\n",
        "    idx = pd.to_datetime(d.index)\n",
        "    union_idx = idx if union_idx is None else union_idx.union(idx)\n",
        "if 'df' in globals() and isinstance(df, pd.DataFrame) and not df.empty:\n",
        "    union_idx = (pd.to_datetime(df.index) if union_idx is None else union_idx.union(pd.to_datetime(df.index)))\n",
        "if union_idx is None:\n",
        "    raise RuntimeError(\"âŒ No index found to build panel.\")\n",
        "union_idx = union_idx.sort_values()\n",
        "\n",
        "# Base DataFrame\n",
        "df_master = (df.reindex(union_idx).copy()\n",
        "             if 'df' in globals() and isinstance(df, pd.DataFrame)\n",
        "             else pd.DataFrame(index=union_idx))\n",
        "\n",
        "# ============================================================\n",
        "# 3ï¸âƒ£ Collect Logclose per ticker\n",
        "# ============================================================\n",
        "TARGET_TICKERS = [ticker for tickers in SECTORS.values() for ticker in tickers]\n",
        "source_used, missing = {}, []\n",
        "\n",
        "for ticker in TARGET_TICKERS:\n",
        "    dsec = None\n",
        "    for sec, d in combined_dfs.items():\n",
        "        if f\"Logclose_{ticker}\" in d.columns or f\"Close_{ticker}\" in d.columns:\n",
        "            dsec = d\n",
        "            break\n",
        "\n",
        "    price, src, col_used = None, None, None\n",
        "    if dsec is not None:\n",
        "        pcol = _find_price_like_col(dsec, ticker)\n",
        "        if pcol is not None:\n",
        "            price = _align(pd.to_numeric(dsec[pcol], errors='coerce'), union_idx)\n",
        "            src, col_used = 'combined', pcol\n",
        "\n",
        "    if price is None and 'df' in globals() and isinstance(df, pd.DataFrame):\n",
        "        pcol_g = _find_price_like_col(df, ticker)\n",
        "        if pcol_g is not None:\n",
        "            price = _align(pd.to_numeric(df[pcol_g], errors='coerce'), union_idx)\n",
        "            src, col_used = 'global', pcol_g\n",
        "\n",
        "    if price is None:\n",
        "        missing.append(ticker)\n",
        "        source_used[ticker] = None\n",
        "        continue\n",
        "\n",
        "    logc = f\"Logclose_{ticker}\"\n",
        "    df_master[logc] = price.astype(float)\n",
        "    source_used[ticker] = (src, col_used)\n",
        "\n",
        "print(\"=== âœ… Logclose columns collected ===\")\n",
        "print(f\"Total: {len([c for c in df_master.columns if 'Logclose_' in c])} stocks\")\n",
        "\n",
        "# ============================================================\n",
        "# 4ï¸âƒ£ Dynamic Start Date per Ticker\n",
        "# ============================================================\n",
        "logclose_cols = [f\"Logclose_{t}\" for t in TARGET_TICKERS if f\"Logclose_{t}\" in df_master.columns]\n",
        "\n",
        "first_valid_dates = {}\n",
        "for c in logclose_cols:\n",
        "    valid = df_master[c].first_valid_index()\n",
        "    first_valid_dates[c] = valid\n",
        "\n",
        "print(\"\\nğŸ“… First available data per stock:\")\n",
        "for k, v in first_valid_dates.items():\n",
        "    print(f\"{k:25s}: {v}\")\n",
        "\n",
        "# --- à¸ªà¸£à¹‰à¸²à¸‡ Dynamic Panel ---\n",
        "df_dynamic = pd.DataFrame(index=df_master.index)\n",
        "for c in logclose_cols:\n",
        "    start_date = first_valid_dates[c]\n",
        "    if start_date is not None:\n",
        "        tmp = df_master.loc[start_date:, c]\n",
        "        df_dynamic[c] = tmp\n",
        "\n",
        "# --- à¹€à¸•à¸´à¸¡à¸„à¹ˆà¸²à¸«à¸¥à¸±à¸‡à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¸”à¹‰à¸§à¸¢ ffill 1 step (à¹€à¸à¸·à¹ˆà¸­à¸„à¸§à¸²à¸¡à¸•à¹ˆà¸­à¹€à¸™à¸·à¹ˆà¸­à¸‡à¹€à¸¥à¹‡à¸à¸™à¹‰à¸­à¸¢) ---\n",
        "df_dynamic = df_dynamic.sort_index().ffill(limit=1)\n",
        "\n",
        "# ============================================================\n",
        "# 5ï¸âƒ£ Final Panel\n",
        "# ============================================================\n",
        "df = df_dynamic.copy()\n",
        "\n",
        "print(f\"\\nâœ… Dynamic Panel Ready: shape={df.shape}\")\n",
        "print(f\"ğŸ• Date range: {df.index.min().date()} â†’ {df.index.max().date()}\")\n",
        "if missing:\n",
        "    print(f\"\\nâš ï¸ Missing Logclose for: {missing}\")\n",
        "\n",
        "# --- Preview ---\n",
        "try:\n",
        "    from IPython.display import display\n",
        "    display(df.iloc[:10, :6])\n",
        "except Exception:\n",
        "    print(df.iloc[:10, :6])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zejkXEGI1i7n",
        "outputId": "a0c94b3e-6f7c-469f-dea7-5769b6654b6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting arch\n",
            "  Downloading arch-8.0.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from arch) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from arch) (2.2.2)\n",
            "Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.12/dist-packages (from arch) (1.16.3)\n",
            "Requirement already satisfied: statsmodels>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from arch) (0.14.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from arch) (25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4.0->arch) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4.0->arch) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4.0->arch) (2025.3)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.13.0->arch) (1.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->arch) (1.17.0)\n",
            "Downloading arch-8.0.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (981 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m981.3/981.3 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: arch\n",
            "Successfully installed arch-8.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install arch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03ddfc94",
        "outputId": "dbeb5df5-19aa-4032-c29f-52365cf96260"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Integration Order Detected (ADF) ===\n",
            "BroadMoney_M1M2_Growth    â†’ I(0)\n",
            "Inflation_Surprise        â†’ I(0)\n",
            "IPI_Surprise              â†’ I(0)\n",
            "THOR_1M                   â†’ I(1)\n",
            "THOR_6M                   â†’ I(1)\n",
            "3M_1M_THOR_Spread         â†’ I(1)\n",
            "6M_1M_THOR_Spread         â†’ I(1)\n",
            "5Y_1Y_Bond_Spread         â†’ I(0)\n",
            "10Y_5Y_Bond_Spread        â†’ I(1)\n",
            "THB_per_USD               â†’ I(1)\n",
            "SET_Index                 â†’ I(1)\n",
            "SP500_Index               â†’ I(1)\n",
            "THB_per_CNY               â†’ I(1)\n",
            "GDP_Growth                â†’ I(1)\n",
            "THB_per_INR               â†’ I(1)\n",
            "\n",
            "âœ… Built 'combined_dfs_levels_for_ecm' (LEVELS) successfully.\n",
            "   Use this for: run_ardl_ecm_enhanced / ECT series / Forecast\n",
            "\n",
            "âœ… Built 'combined_dfs_selective_diff2' (diffed safely) successfully.\n",
            "Diffed Macros (I(1)): ['THOR_1M', 'THOR_6M', '3M_1M_THOR_Spread', '6M_1M_THOR_Spread', '10Y_5Y_Bond_Spread', 'THB_per_USD', 'SET_Index', 'SP500_Index', 'THB_per_CNY', 'GDP_Growth', 'THB_per_INR']\n",
            "Kept in Levels (I(0)): ['BroadMoney_M1M2_Growth', 'Inflation_Surprise', 'IPI_Surprise', '5Y_1Y_Bond_Spread']\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# âš™ï¸ Build TWO PANELS SAFELY:\n",
        "#   (A) combined_dfs_levels_for_ecm  -> à¹ƒà¸Šà¹‰à¸à¸±à¸š ECM/ECT/Forecast (LEVELS à¸ˆà¸£à¸´à¸‡)\n",
        "#   (B) combined_dfs_selective_diff2 -> à¸–à¹‰à¸²à¸ˆà¸°à¹€à¸à¹‡à¸šà¹„à¸§à¹‰à¹ƒà¸Šà¹‰ diff à¸à¹‡à¸—à¸³à¹ƒà¸«à¹‰à¸Šà¸·à¹ˆà¸­à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸Šà¸±à¸”à¹€à¸ˆà¸™\n",
        "# ============================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "if 'combined_dfs' not in globals() or not isinstance(combined_dfs, dict) or not combined_dfs:\n",
        "    raise RuntimeError(\"âŒ combined_dfs not found or empty. Run previous macro/stock preparation cells first.\")\n",
        "\n",
        "# ---------- Helper: classify I(0) vs I(1) ----------\n",
        "def classify_order(series, signif=0.05):\n",
        "    s = pd.to_numeric(series, errors=\"coerce\").dropna()\n",
        "    if len(s) < 30:\n",
        "        return None\n",
        "    try:\n",
        "        pval = adfuller(s, autolag='AIC')[1]\n",
        "        return \"I(0)\" if pval < signif else \"I(1)\"\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "macro_candidates = [\n",
        "    \"BroadMoney_M1M2_Growth\", \"Inflation_Surprise\", \"IPI_Surprise\",\n",
        "    \"THOR_1M\", \"THOR_6M\", \"3M_1M_THOR_Spread\", \"6M_1M_THOR_Spread\",\n",
        "    \"5Y_1Y_Bond_Spread\", \"10Y_5Y_Bond_Spread\",\n",
        "    \"THB_per_USD\", \"SET_Index\",\n",
        "    \"SP500_Index\", \"THB_per_CNY\", \"GDP_Growth\", \"THB_per_INR\"\n",
        "]\n",
        "\n",
        "# ---------- Detect integration order ONCE ----------\n",
        "macro_orders = {}\n",
        "for sector, df_sec in combined_dfs.items():\n",
        "    for m in macro_candidates:\n",
        "        if m in df_sec.columns and m not in macro_orders:\n",
        "            order = classify_order(df_sec[m])\n",
        "            if order:\n",
        "                macro_orders[m] = order\n",
        "\n",
        "print(\"=== Integration Order Detected (ADF) ===\")\n",
        "for k, v in macro_orders.items():\n",
        "    print(f\"{k:25s} â†’ {v}\")\n",
        "\n",
        "# ============================================================\n",
        "# (A) LEVELS panel for ECM (THIS is the correct input for ECM/ECT/Forecast)\n",
        "# ============================================================\n",
        "combined_dfs_levels_for_ecm = {}\n",
        "\n",
        "for sector, df_sec in combined_dfs.items():\n",
        "    df_sec = df_sec.copy()\n",
        "    out = pd.DataFrame(index=df_sec.index)\n",
        "\n",
        "    # 1) à¸«à¸¸à¹‰à¸™: keep LEVELS (Logclose_...) à¸«à¹‰à¸²à¸¡ diff à¸•à¸£à¸‡à¸™à¸µà¹‰\n",
        "    for col in df_sec.columns:\n",
        "        if str(col).startswith(\"Logclose_\"):\n",
        "            out[col] = pd.to_numeric(df_sec[col], errors=\"coerce\")\n",
        "\n",
        "    # 2) Macro: keep LEVELS (à¸—à¸±à¹‰à¸‡ I(0) à¹à¸¥à¸° I(1)) à¸ªà¸³à¸«à¸£à¸±à¸š ECT\n",
        "    for m in macro_candidates:\n",
        "        if m in df_sec.columns:\n",
        "            out[m] = pd.to_numeric(df_sec[m], errors=\"coerce\")\n",
        "\n",
        "    # 3) Clean: drop rows where everything NA\n",
        "    out = out.dropna(how=\"all\")\n",
        "    combined_dfs_levels_for_ecm[sector] = out\n",
        "\n",
        "print(\"\\nâœ… Built 'combined_dfs_levels_for_ecm' (LEVELS) successfully.\")\n",
        "print(\"   Use this for: run_ardl_ecm_enhanced / ECT series / Forecast\")\n",
        "\n",
        "# ============================================================\n",
        "# (B) OPTIONAL: selective-diff panel (rename stock cols so it won't confuse downstream)\n",
        "#     - à¸«à¸¸à¹‰à¸™: D_Logclose_...\n",
        "#     - Macro: diff only I(1), keep I(0) in levels\n",
        "# ============================================================\n",
        "combined_dfs_selective_diff2 = {}\n",
        "\n",
        "for sector, df_sec in combined_dfs.items():\n",
        "    df_sec = df_sec.copy()\n",
        "    out = pd.DataFrame(index=df_sec.index)\n",
        "\n",
        "    # à¸«à¸¸à¹‰à¸™: Î”log (à¹à¸•à¹ˆà¸Šà¸·à¹ˆà¸­à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸•à¹‰à¸­à¸‡à¸šà¸­à¸à¸§à¹ˆà¸²à¹€à¸›à¹‡à¸™ diff)\n",
        "    for col in df_sec.columns:\n",
        "        if str(col).startswith(\"Logclose_\"):\n",
        "            out[col.replace(\"Logclose_\", \"D_Logclose_\")] = pd.to_numeric(df_sec[col], errors=\"coerce\").diff()\n",
        "\n",
        "    # Macro: diff à¹€à¸‰à¸à¸²à¸° I(1)\n",
        "    for m in macro_candidates:\n",
        "        if m not in df_sec.columns:\n",
        "            continue\n",
        "        s = pd.to_numeric(df_sec[m], errors=\"coerce\")\n",
        "        if macro_orders.get(m, \"I(1)\") == \"I(1)\":\n",
        "            out[m] = s.diff()\n",
        "        else:\n",
        "            out[m] = s\n",
        "\n",
        "    out = out.dropna(how=\"all\")\n",
        "    combined_dfs_selective_diff2[sector] = out\n",
        "\n",
        "print(\"\\nâœ… Built 'combined_dfs_selective_diff2' (diffed safely) successfully.\")\n",
        "print(\"Diffed Macros (I(1)):\", [k for k, v in macro_orders.items() if v == \"I(1)\"])\n",
        "print(\"Kept in Levels (I(0)):\", [k for k, v in macro_orders.items() if v == \"I(0)\"])\n",
        "\n",
        "# NOTE:\n",
        "# - à¸‚à¸­à¸‡à¹€à¸”à¸´à¸¡ combined_dfs_selective_diff à¸„à¸¸à¸“à¸ˆà¸°à¹€à¸à¹‡à¸šà¹„à¸§à¹‰à¸à¹‡à¹„à¸”à¹‰\n",
        "# - à¹à¸•à¹ˆà¸ˆà¸²à¸à¸™à¸µà¹‰ à¹à¸™à¸°à¸™à¸³à¹ƒà¸Šà¹‰ combined_dfs_levels_for_ecm à¹€à¸›à¹‡à¸™ input à¸‚à¸­à¸‡ ECM à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ge8JSCNOi2m_",
        "outputId": "cc6b1b83-9bad-400f-f009-aee16611c393"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Checking macro variable presence in combined_dfs_levels_for_ecm (LEVELS) ===\n",
            "\n",
            "ğŸ“‚ Sector: Banking\n",
            "  â€¢ Stocks found: 7 (Logclose_BBL, Logclose_KBANK, Logclose_KKP, Logclose_KTB, Logclose_TCAP...)\n",
            "  â€¢ Macros present (13): ['BroadMoney_M1M2_Growth', 'Inflation_Surprise', 'IPI_Surprise', 'THOR_6M', '3M_1M_THOR_Spread', '5Y_1Y_Bond_Spread', '10Y_5Y_Bond_Spread', 'THB_per_USD', 'SET_Index', 'SP500_Index', 'THB_per_CNY', 'GDP_Growth', 'THB_per_INR']\n",
            "  â€¢ Macros missing (0): []\n",
            "--------------------------------------------------------------------------------\n",
            "ğŸ“‚ Sector: Finance_Securities\n",
            "  â€¢ Stocks found: 4 (Logclose_KTC, Logclose_AEONTS, Logclose_JMT, Logclose_SAWAD)\n",
            "  â€¢ Macros present (13): ['BroadMoney_M1M2_Growth', 'Inflation_Surprise', 'IPI_Surprise', 'THOR_6M', '3M_1M_THOR_Spread', '5Y_1Y_Bond_Spread', '10Y_5Y_Bond_Spread', 'THB_per_USD', 'SET_Index', 'SP500_Index', 'THB_per_CNY', 'GDP_Growth', 'THB_per_INR']\n",
            "  â€¢ Macros missing (0): []\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "=== Summary of Macro Coverage per Sector (LEVELS) ===\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_summary\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"Sector\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Finance_Securities\",\n          \"Banking\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"N_stocks\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 4,\n        \"max\": 7,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Macros_present\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 13,\n        \"max\": 13,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          13\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Macros_missing\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Missing_list\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_summary"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-b4d9ef07-d7b0-4f7f-b894-80de9c44adb5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sector</th>\n",
              "      <th>N_stocks</th>\n",
              "      <th>Macros_present</th>\n",
              "      <th>Macros_missing</th>\n",
              "      <th>Missing_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Banking</td>\n",
              "      <td>7</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Finance_Securities</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b4d9ef07-d7b0-4f7f-b894-80de9c44adb5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b4d9ef07-d7b0-4f7f-b894-80de9c44adb5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b4d9ef07-d7b0-4f7f-b894-80de9c44adb5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_929d81b7-1bee-49af-a134-eec1061ded2d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_summary')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_929d81b7-1bee-49af-a134-eec1061ded2d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_summary');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "               Sector  N_stocks  Macros_present  Macros_missing Missing_list\n",
              "0             Banking         7              13               0             \n",
              "1  Finance_Securities         4              13               0             "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "âœ… Cleaned LEVELS dataframes successfully.\n",
            "âœ… Standardized dict name created: combined_dfs_for_ecm\n",
            "\n",
            "=== Example after cleaning (LEVELS): 'Banking' ===\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-17979956-a16a-44bf-9497-a5530ef9b713\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Logclose_BBL</th>\n",
              "      <th>Logclose_KBANK</th>\n",
              "      <th>Logclose_KKP</th>\n",
              "      <th>Logclose_KTB</th>\n",
              "      <th>Logclose_TCAP</th>\n",
              "      <th>Logclose_TISCO</th>\n",
              "      <th>Logclose_TTB</th>\n",
              "      <th>BroadMoney_M1M2_Growth</th>\n",
              "      <th>Inflation_Surprise</th>\n",
              "      <th>IPI_Surprise</th>\n",
              "      <th>...</th>\n",
              "      <th>3M_1M_THOR_Spread</th>\n",
              "      <th>6M_1M_THOR_Spread</th>\n",
              "      <th>5Y_1Y_Bond_Spread</th>\n",
              "      <th>10Y_5Y_Bond_Spread</th>\n",
              "      <th>THB_per_USD</th>\n",
              "      <th>SET_Index</th>\n",
              "      <th>SP500_Index</th>\n",
              "      <th>THB_per_CNY</th>\n",
              "      <th>GDP_Growth</th>\n",
              "      <th>THB_per_INR</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2015-02-01</th>\n",
              "      <td>4.790190</td>\n",
              "      <td>5.017582</td>\n",
              "      <td>2.939447</td>\n",
              "      <td>2.627824</td>\n",
              "      <td>2.802560</td>\n",
              "      <td>3.072488</td>\n",
              "      <td>0.569241</td>\n",
              "      <td>0.009765</td>\n",
              "      <td>-0.0066</td>\n",
              "      <td>-0.000066</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000068</td>\n",
              "      <td>0.00350</td>\n",
              "      <td>0.00560</td>\n",
              "      <td>32.341000</td>\n",
              "      <td>1582.699951</td>\n",
              "      <td>2104.500000</td>\n",
              "      <td>0.19335</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.906796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-03-01</th>\n",
              "      <td>4.798353</td>\n",
              "      <td>5.071406</td>\n",
              "      <td>2.933057</td>\n",
              "      <td>2.627824</td>\n",
              "      <td>2.795391</td>\n",
              "      <td>3.045532</td>\n",
              "      <td>0.555907</td>\n",
              "      <td>0.004617</td>\n",
              "      <td>-0.0019</td>\n",
              "      <td>0.000380</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000077</td>\n",
              "      <td>0.00450</td>\n",
              "      <td>0.00580</td>\n",
              "      <td>32.540001</td>\n",
              "      <td>1582.140015</td>\n",
              "      <td>2067.889893</td>\n",
              "      <td>0.19040</td>\n",
              "      <td>-0.020455</td>\n",
              "      <td>1.918100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-04-01</th>\n",
              "      <td>4.801060</td>\n",
              "      <td>4.984792</td>\n",
              "      <td>2.880413</td>\n",
              "      <td>2.496796</td>\n",
              "      <td>2.773572</td>\n",
              "      <td>3.034543</td>\n",
              "      <td>0.419496</td>\n",
              "      <td>-0.001550</td>\n",
              "      <td>-0.0012</td>\n",
              "      <td>-0.000670</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001167</td>\n",
              "      <td>0.001528</td>\n",
              "      <td>0.00480</td>\n",
              "      <td>0.00510</td>\n",
              "      <td>32.838001</td>\n",
              "      <td>1525.579956</td>\n",
              "      <td>2085.510010</td>\n",
              "      <td>0.18827</td>\n",
              "      <td>-0.015059</td>\n",
              "      <td>1.930500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-05-01</th>\n",
              "      <td>4.808427</td>\n",
              "      <td>4.925754</td>\n",
              "      <td>2.888474</td>\n",
              "      <td>2.436026</td>\n",
              "      <td>2.810098</td>\n",
              "      <td>3.072725</td>\n",
              "      <td>0.417810</td>\n",
              "      <td>0.001422</td>\n",
              "      <td>-0.0024</td>\n",
              "      <td>-0.000330</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001280</td>\n",
              "      <td>0.002220</td>\n",
              "      <td>0.00420</td>\n",
              "      <td>0.00780</td>\n",
              "      <td>33.734001</td>\n",
              "      <td>1519.880005</td>\n",
              "      <td>2107.389893</td>\n",
              "      <td>0.18351</td>\n",
              "      <td>-0.011596</td>\n",
              "      <td>1.889400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-06-01</th>\n",
              "      <td>4.786204</td>\n",
              "      <td>4.894501</td>\n",
              "      <td>2.867420</td>\n",
              "      <td>2.379193</td>\n",
              "      <td>2.780465</td>\n",
              "      <td>3.094704</td>\n",
              "      <td>0.335797</td>\n",
              "      <td>-0.005075</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.000280</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001854</td>\n",
              "      <td>0.003469</td>\n",
              "      <td>0.00560</td>\n",
              "      <td>0.00820</td>\n",
              "      <td>33.729000</td>\n",
              "      <td>1476.869995</td>\n",
              "      <td>2063.110107</td>\n",
              "      <td>0.18359</td>\n",
              "      <td>-0.002867</td>\n",
              "      <td>1.888000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-07-01</th>\n",
              "      <td>4.716408</td>\n",
              "      <td>4.834538</td>\n",
              "      <td>2.722682</td>\n",
              "      <td>2.402315</td>\n",
              "      <td>2.718430</td>\n",
              "      <td>3.015567</td>\n",
              "      <td>0.335797</td>\n",
              "      <td>-0.001889</td>\n",
              "      <td>-0.0007</td>\n",
              "      <td>-0.000285</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000772</td>\n",
              "      <td>0.002587</td>\n",
              "      <td>0.00630</td>\n",
              "      <td>0.00630</td>\n",
              "      <td>35.090000</td>\n",
              "      <td>1491.619995</td>\n",
              "      <td>2103.840088</td>\n",
              "      <td>0.17655</td>\n",
              "      <td>0.003959</td>\n",
              "      <td>1.824900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-08-01</th>\n",
              "      <td>4.707331</td>\n",
              "      <td>4.848485</td>\n",
              "      <td>2.778473</td>\n",
              "      <td>2.441536</td>\n",
              "      <td>2.660801</td>\n",
              "      <td>2.942364</td>\n",
              "      <td>0.344307</td>\n",
              "      <td>-0.002574</td>\n",
              "      <td>-0.0007</td>\n",
              "      <td>0.000045</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>0.001743</td>\n",
              "      <td>0.00530</td>\n",
              "      <td>0.00620</td>\n",
              "      <td>35.723000</td>\n",
              "      <td>1442.040039</td>\n",
              "      <td>1972.180054</td>\n",
              "      <td>0.17805</td>\n",
              "      <td>0.007931</td>\n",
              "      <td>1.844600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-09-01</th>\n",
              "      <td>4.679594</td>\n",
              "      <td>4.794418</td>\n",
              "      <td>2.730845</td>\n",
              "      <td>2.379193</td>\n",
              "      <td>2.734303</td>\n",
              "      <td>2.835596</td>\n",
              "      <td>0.369413</td>\n",
              "      <td>0.003077</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>-0.000200</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000980</td>\n",
              "      <td>0.00575</td>\n",
              "      <td>0.00535</td>\n",
              "      <td>36.396999</td>\n",
              "      <td>1362.390015</td>\n",
              "      <td>1920.030029</td>\n",
              "      <td>0.17444</td>\n",
              "      <td>0.013811</td>\n",
              "      <td>1.809500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-10-01</th>\n",
              "      <td>4.737904</td>\n",
              "      <td>4.805957</td>\n",
              "      <td>2.846806</td>\n",
              "      <td>2.379193</td>\n",
              "      <td>2.787956</td>\n",
              "      <td>2.897048</td>\n",
              "      <td>0.463971</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>-0.000200</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000980</td>\n",
              "      <td>0.00575</td>\n",
              "      <td>0.00535</td>\n",
              "      <td>35.606998</td>\n",
              "      <td>1345.150024</td>\n",
              "      <td>2079.360107</td>\n",
              "      <td>0.17707</td>\n",
              "      <td>0.017161</td>\n",
              "      <td>1.837830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-11-01</th>\n",
              "      <td>4.737904</td>\n",
              "      <td>4.797223</td>\n",
              "      <td>2.932573</td>\n",
              "      <td>2.373328</td>\n",
              "      <td>2.861170</td>\n",
              "      <td>3.003733</td>\n",
              "      <td>0.441157</td>\n",
              "      <td>0.015938</td>\n",
              "      <td>0.0017</td>\n",
              "      <td>-0.000042</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000049</td>\n",
              "      <td>0.00530</td>\n",
              "      <td>0.00640</td>\n",
              "      <td>35.890999</td>\n",
              "      <td>1413.339966</td>\n",
              "      <td>2080.409912</td>\n",
              "      <td>0.17655</td>\n",
              "      <td>0.017287</td>\n",
              "      <td>1.867500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows Ã— 22 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17979956-a16a-44bf-9497-a5530ef9b713')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-17979956-a16a-44bf-9497-a5530ef9b713 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-17979956-a16a-44bf-9497-a5530ef9b713');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "            Logclose_BBL  Logclose_KBANK  Logclose_KKP  Logclose_KTB  \\\n",
              "Date                                                                   \n",
              "2015-02-01      4.790190        5.017582      2.939447      2.627824   \n",
              "2015-03-01      4.798353        5.071406      2.933057      2.627824   \n",
              "2015-04-01      4.801060        4.984792      2.880413      2.496796   \n",
              "2015-05-01      4.808427        4.925754      2.888474      2.436026   \n",
              "2015-06-01      4.786204        4.894501      2.867420      2.379193   \n",
              "2015-07-01      4.716408        4.834538      2.722682      2.402315   \n",
              "2015-08-01      4.707331        4.848485      2.778473      2.441536   \n",
              "2015-09-01      4.679594        4.794418      2.730845      2.379193   \n",
              "2015-10-01      4.737904        4.805957      2.846806      2.379193   \n",
              "2015-11-01      4.737904        4.797223      2.932573      2.373328   \n",
              "\n",
              "            Logclose_TCAP  Logclose_TISCO  Logclose_TTB  \\\n",
              "Date                                                      \n",
              "2015-02-01       2.802560        3.072488      0.569241   \n",
              "2015-03-01       2.795391        3.045532      0.555907   \n",
              "2015-04-01       2.773572        3.034543      0.419496   \n",
              "2015-05-01       2.810098        3.072725      0.417810   \n",
              "2015-06-01       2.780465        3.094704      0.335797   \n",
              "2015-07-01       2.718430        3.015567      0.335797   \n",
              "2015-08-01       2.660801        2.942364      0.344307   \n",
              "2015-09-01       2.734303        2.835596      0.369413   \n",
              "2015-10-01       2.787956        2.897048      0.463971   \n",
              "2015-11-01       2.861170        3.003733      0.441157   \n",
              "\n",
              "            BroadMoney_M1M2_Growth  Inflation_Surprise  IPI_Surprise  ...  \\\n",
              "Date                                                                  ...   \n",
              "2015-02-01                0.009765             -0.0066     -0.000066  ...   \n",
              "2015-03-01                0.004617             -0.0019      0.000380  ...   \n",
              "2015-04-01               -0.001550             -0.0012     -0.000670  ...   \n",
              "2015-05-01                0.001422             -0.0024     -0.000330  ...   \n",
              "2015-06-01               -0.005075             -0.0015     -0.000280  ...   \n",
              "2015-07-01               -0.001889             -0.0007     -0.000285  ...   \n",
              "2015-08-01               -0.002574             -0.0007      0.000045  ...   \n",
              "2015-09-01                0.003077              0.0001     -0.000200  ...   \n",
              "2015-10-01                0.000000              0.0001     -0.000200  ...   \n",
              "2015-11-01                0.015938              0.0017     -0.000042  ...   \n",
              "\n",
              "            3M_1M_THOR_Spread  6M_1M_THOR_Spread  5Y_1Y_Bond_Spread  \\\n",
              "Date                                                                  \n",
              "2015-02-01           0.000015           0.000068            0.00350   \n",
              "2015-03-01           0.000032           0.000077            0.00450   \n",
              "2015-04-01           0.001167           0.001528            0.00480   \n",
              "2015-05-01           0.001280           0.002220            0.00420   \n",
              "2015-06-01           0.001854           0.003469            0.00560   \n",
              "2015-07-01           0.000772           0.002587            0.00630   \n",
              "2015-08-01           0.000024           0.001743            0.00530   \n",
              "2015-09-01           0.000020           0.000980            0.00575   \n",
              "2015-10-01           0.000020           0.000980            0.00575   \n",
              "2015-11-01           0.000020           0.000049            0.00530   \n",
              "\n",
              "            10Y_5Y_Bond_Spread  THB_per_USD    SET_Index  SP500_Index  \\\n",
              "Date                                                                    \n",
              "2015-02-01             0.00560    32.341000  1582.699951  2104.500000   \n",
              "2015-03-01             0.00580    32.540001  1582.140015  2067.889893   \n",
              "2015-04-01             0.00510    32.838001  1525.579956  2085.510010   \n",
              "2015-05-01             0.00780    33.734001  1519.880005  2107.389893   \n",
              "2015-06-01             0.00820    33.729000  1476.869995  2063.110107   \n",
              "2015-07-01             0.00630    35.090000  1491.619995  2103.840088   \n",
              "2015-08-01             0.00620    35.723000  1442.040039  1972.180054   \n",
              "2015-09-01             0.00535    36.396999  1362.390015  1920.030029   \n",
              "2015-10-01             0.00535    35.606998  1345.150024  2079.360107   \n",
              "2015-11-01             0.00640    35.890999  1413.339966  2080.409912   \n",
              "\n",
              "            THB_per_CNY  GDP_Growth  THB_per_INR  \n",
              "Date                                              \n",
              "2015-02-01      0.19335         NaN     1.906796  \n",
              "2015-03-01      0.19040   -0.020455     1.918100  \n",
              "2015-04-01      0.18827   -0.015059     1.930500  \n",
              "2015-05-01      0.18351   -0.011596     1.889400  \n",
              "2015-06-01      0.18359   -0.002867     1.888000  \n",
              "2015-07-01      0.17655    0.003959     1.824900  \n",
              "2015-08-01      0.17805    0.007931     1.844600  \n",
              "2015-09-01      0.17444    0.013811     1.809500  \n",
              "2015-10-01      0.17707    0.017161     1.837830  \n",
              "2015-11-01      0.17655    0.017287     1.867500  \n",
              "\n",
              "[10 rows x 22 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ============================================================\n",
        "# ğŸ” CHECK DATA CONSISTENCY BEFORE ARDL-ECM (LEVELS VERSION)\n",
        "#   âœ… Uses: combined_dfs_levels_for_ecm (LEVELS)\n",
        "#   Output standardized dict name: combined_dfs_for_ecm\n",
        "# ============================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "print(\"=== Checking macro variable presence in combined_dfs_levels_for_ecm (LEVELS) ===\\n\")\n",
        "\n",
        "# --- Safety check ---\n",
        "if 'combined_dfs_levels_for_ecm' not in globals() or not isinstance(combined_dfs_levels_for_ecm, dict) or not combined_dfs_levels_for_ecm:\n",
        "    raise RuntimeError(\"âŒ combined_dfs_levels_for_ecm not found or empty. Please run the LEVELS build block first.\")\n",
        "\n",
        "# List à¸‚à¸­à¸‡à¸•à¸±à¸§à¹à¸›à¸£à¸—à¸µà¹ˆ ARDL-ECM à¸•à¹‰à¸­à¸‡à¹ƒà¸Šà¹‰ (à¹ƒà¸«à¹‰à¸•à¸£à¸‡à¸à¸±à¸š macro_vars à¹ƒà¸™ Block 3-4)\n",
        "macro_vars = [\n",
        "    \"BroadMoney_M1M2_Growth\", \"Inflation_Surprise\", \"IPI_Surprise\",\n",
        "    \"THOR_6M\", \"3M_1M_THOR_Spread\",\n",
        "    \"5Y_1Y_Bond_Spread\", \"10Y_5Y_Bond_Spread\",\n",
        "    \"THB_per_USD\", \"SET_Index\",\n",
        "    \"SP500_Index\", \"THB_per_CNY\", \"GDP_Growth\", \"THB_per_INR\"\n",
        "]\n",
        "\n",
        "summary_records = []\n",
        "\n",
        "# ============================================================\n",
        "# 1) Coverage check per sector\n",
        "# ============================================================\n",
        "for sector, df_sec in combined_dfs_levels_for_ecm.items():\n",
        "    if df_sec is None or df_sec.empty:\n",
        "        print(f\"ğŸ“‚ Sector: {sector}\")\n",
        "        print(\"  â€¢ âš ï¸ EMPTY dataframe\")\n",
        "        print(\"-\" * 80)\n",
        "        summary_records.append({\n",
        "            \"Sector\": sector,\n",
        "            \"N_stocks\": 0,\n",
        "            \"Macros_present\": 0,\n",
        "            \"Macros_missing\": len(macro_vars),\n",
        "            \"Missing_list\": \", \".join(macro_vars)\n",
        "        })\n",
        "        continue\n",
        "\n",
        "    present = [m for m in macro_vars if m in df_sec.columns]\n",
        "    missing = [m for m in macro_vars if m not in df_sec.columns]\n",
        "    logclose_cols = [c for c in df_sec.columns if str(c).startswith(\"Logclose_\")]\n",
        "\n",
        "    print(f\"ğŸ“‚ Sector: {sector}\")\n",
        "    print(f\"  â€¢ Stocks found: {len(logclose_cols)} ({', '.join(logclose_cols[:5])}{'...' if len(logclose_cols)>5 else ''})\")\n",
        "    print(f\"  â€¢ Macros present ({len(present)}): {present}\")\n",
        "    print(f\"  â€¢ Macros missing ({len(missing)}): {missing}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    summary_records.append({\n",
        "        \"Sector\": sector,\n",
        "        \"N_stocks\": len(logclose_cols),\n",
        "        \"Macros_present\": len(present),\n",
        "        \"Macros_missing\": len(missing),\n",
        "        \"Missing_list\": \", \".join(missing)\n",
        "    })\n",
        "\n",
        "df_summary = pd.DataFrame(summary_records)\n",
        "print(\"\\n=== Summary of Macro Coverage per Sector (LEVELS) ===\")\n",
        "display(df_summary)\n",
        "\n",
        "# ============================================================\n",
        "# 2) CLEAN levels frames (safe)\n",
        "#    - remove all-NaN rows\n",
        "#    - keep rows with >= 80% non-NA across columns\n",
        "# ============================================================\n",
        "\n",
        "combined_dfs_for_ecm = {}\n",
        "\n",
        "for sector, df_sec in combined_dfs_levels_for_ecm.items():\n",
        "    if df_sec is None or df_sec.empty:\n",
        "        combined_dfs_for_ecm[sector] = df_sec\n",
        "        continue\n",
        "\n",
        "    df_tmp = df_sec.copy()\n",
        "\n",
        "    # 2.1 Drop rows that are all NaN\n",
        "    df_tmp = df_tmp.dropna(how=\"all\")\n",
        "\n",
        "    # 2.2 Drop rows with too many NaN (at least 80% of columns must be present)\n",
        "    thresh = int(np.ceil(0.8 * df_tmp.shape[1]))\n",
        "    df_tmp = df_tmp.dropna(thresh=thresh)\n",
        "\n",
        "    # 2.3 Ensure datetime index sorted\n",
        "    try:\n",
        "        df_tmp.index = pd.to_datetime(df_tmp.index)\n",
        "        df_tmp = df_tmp.sort_index()\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    combined_dfs_for_ecm[sector] = df_tmp\n",
        "\n",
        "print(\"\\nâœ… Cleaned LEVELS dataframes successfully.\")\n",
        "print(\"âœ… Standardized dict name created: combined_dfs_for_ecm\")\n",
        "\n",
        "# Preview one sector\n",
        "sector_to_inspect = list(combined_dfs_for_ecm.keys())[0]\n",
        "print(f\"\\n=== Example after cleaning (LEVELS): '{sector_to_inspect}' ===\")\n",
        "display(combined_dfs_for_ecm[sector_to_inspect].head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TX-tHo1AHRqs"
      },
      "source": [
        "# ARDL + ECM      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqmP28-XHTYE",
        "outputId": "de68864d-7bad-44dc-e1b2-e5e1ae9d274b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
            "â•‘  ğŸš€ BLOCK 3-4: ARDL-ECM ENHANCED V2 (COMPLETE)                               â•‘\n",
            "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
            "â•‘  âœ… ORIGINAL: HAC, Fixed Lag, Long-run Î², ECT, EViews output                 â•‘\n",
            "â•‘  ğŸ†• ADD-ON 1: Multiple Lag Selection (FIXED/ACF/AIC)                         â•‘\n",
            "â•‘  ğŸ†• ADD-ON 2: Walk-Forward Evaluation                                        â•‘\n",
            "â•‘  ğŸ†• ADD-ON 3: Benchmark Models (AR / Random Walk)                            â•‘\n",
            "â•‘  ğŸ†• ADD-ON 4: Diebold-Mariano Test                                           â•‘\n",
            "â•‘  ğŸ†• ADD-ON 5: Per-Variable q Selection                                       â•‘\n",
            "â•‘  ğŸ†• ADD-ON 6: Forecast Metrics (MAE, RMSE, MAPE)                             â•‘\n",
            "â•‘  ğŸ†• ADD-ON 7: Model Comparison Table                                         â•‘\n",
            "â•‘  ğŸ†• ADD-ON 8: Best Model Selection Per Stock                                 â•‘\n",
            "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "\n",
            "==========================================================================================\n",
            "ğŸš€ ARDL-ECM ENHANCED V2: Running All Models\n",
            "==========================================================================================\n",
            "ğŸ“… Train period: Start â†’ 2023-06-01\n",
            "ğŸ“… Test period:  2023-06-01 â†’ End\n",
            "ğŸ”§ Lag methods:  FIXED(p=3,q=3) | ACF/PACF | AIC-greedy\n",
            "==========================================================================================\n",
            "\n",
            "============================================================\n",
            "ğŸ“‚ Sector: Banking\n",
            "============================================================\n",
            "\n",
            "â³ BBL: FIXED... âœ… RMSE: ECM=0.103080 | AR=0.051847 | RW=0.049238 | ECM>AR: No\n",
            "\n",
            "â³ BBL: ACF... âœ… RMSE: ECM=0.075394 | AR=0.049458 | RW=0.049238 | ECM>AR: No\n",
            "\n",
            "â³ BBL: AIC... âœ… RMSE: ECM=0.069408 | AR=0.049458 | RW=0.049238 | ECM>AR: No\n",
            "\n",
            "â³ KBANK: FIXED... âœ… RMSE: ECM=0.115100 | AR=0.080680 | RW=0.078789 | ECM>AR: No\n",
            "\n",
            "â³ KBANK: ACF... âœ… RMSE: ECM=0.092690 | AR=0.081174 | RW=0.078789 | ECM>AR: No\n",
            "\n",
            "â³ KBANK: AIC... âœ… RMSE: ECM=0.089876 | AR=0.081174 | RW=0.078789 | ECM>AR: No\n",
            "\n",
            "â³ KKP: FIXED... âœ… RMSE: ECM=0.169667 | AR=0.121779 | RW=0.123327 | ECM>AR: No\n",
            "\n",
            "â³ KKP: ACF... âœ… RMSE: ECM=0.109027 | AR=0.122733 | RW=0.123327 | ECM>AR: No\n",
            "\n",
            "â³ KKP: AIC... âœ… RMSE: ECM=0.119191 | AR=0.122733 | RW=0.123327 | ECM>AR: No\n",
            "\n",
            "â³ KTB: FIXED... âœ… RMSE: ECM=0.132373 | AR=0.107304 | RW=0.105361 | ECM>AR: No\n",
            "\n",
            "â³ KTB: ACF... âœ… RMSE: ECM=0.122048 | AR=0.107196 | RW=0.105361 | ECM>AR: No\n",
            "\n",
            "â³ KTB: AIC... âœ… RMSE: ECM=0.122265 | AR=0.107196 | RW=0.105361 | ECM>AR: No\n",
            "\n",
            "â³ TCAP: FIXED... âœ… RMSE: ECM=0.122267 | AR=0.063094 | RW=0.063123 | ECM>AR: No\n",
            "\n",
            "â³ TCAP: ACF... âœ… RMSE: ECM=0.143243 | AR=0.064031 | RW=0.063123 | ECM>AR: No\n",
            "\n",
            "â³ TCAP: AIC... âœ… RMSE: ECM=0.065934 | AR=0.066071 | RW=0.063123 | ECM>AR: No\n",
            "\n",
            "â³ TISCO: FIXED... âœ… RMSE: ECM=0.073710 | AR=0.052882 | RW=0.053231 | ECM>AR: No\n",
            "\n",
            "â³ TISCO: ACF... âœ… RMSE: ECM=0.052103 | AR=0.052664 | RW=0.053231 | ECM>AR: No\n",
            "\n",
            "â³ TISCO: AIC... âœ… RMSE: ECM=0.043696 | AR=0.052664 | RW=0.053231 | ECM>AR: No\n",
            "\n",
            "â³ TTB: FIXED... âœ… RMSE: ECM=0.099394 | AR=0.066349 | RW=0.061943 | ECM>AR: No\n",
            "\n",
            "â³ TTB: ACF... âœ… RMSE: ECM=0.101975 | AR=0.067307 | RW=0.061943 | ECM>AR: No\n",
            "\n",
            "â³ TTB: AIC... âœ… RMSE: ECM=0.082404 | AR=0.067307 | RW=0.061943 | ECM>AR: No\n",
            "\n",
            "============================================================\n",
            "ğŸ“‚ Sector: Finance_Securities\n",
            "============================================================\n",
            "\n",
            "â³ KTC: FIXED... âœ… RMSE: ECM=0.242374 | AR=0.142328 | RW=0.141550 | ECM>AR: No\n",
            "\n",
            "â³ KTC: ACF... âœ… RMSE: ECM=0.276962 | AR=0.142326 | RW=0.141550 | ECM>AR: No\n",
            "\n",
            "â³ KTC: AIC... âœ… RMSE: ECM=0.209077 | AR=0.142591 | RW=0.141550 | ECM>AR: No\n",
            "\n",
            "â³ AEONTS: FIXED... âœ… RMSE: ECM=0.170536 | AR=0.105446 | RW=0.105472 | ECM>AR: No\n",
            "\n",
            "â³ AEONTS: ACF... âœ… RMSE: ECM=0.186640 | AR=0.104531 | RW=0.105472 | ECM>AR: No\n",
            "\n",
            "â³ AEONTS: AIC... âœ… RMSE: ECM=0.151038 | AR=0.104531 | RW=0.105472 | ECM>AR: No\n",
            "\n",
            "â³ JMT: FIXED... âœ… RMSE: ECM=0.269580 | AR=0.237492 | RW=0.238718 | ECM>AR: No\n",
            "\n",
            "â³ JMT: ACF... âœ… RMSE: ECM=0.268774 | AR=0.241145 | RW=0.238718 | ECM>AR: No\n",
            "\n",
            "â³ JMT: AIC... âœ… RMSE: ECM=0.230849 | AR=0.236551 | RW=0.238718 | ECM>AR: No\n",
            "\n",
            "â³ SAWAD: FIXED... âœ… RMSE: ECM=0.238725 | AR=0.124303 | RW=0.126741 | ECM>AR: No\n",
            "\n",
            "â³ SAWAD: ACF... âœ… RMSE: ECM=0.266971 | AR=0.123993 | RW=0.126741 | ECM>AR: No\n",
            "\n",
            "â³ SAWAD: AIC... âœ… RMSE: ECM=0.150245 | AR=0.123993 | RW=0.126741 | ECM>AR: No\n",
            "\n",
            "âœ… Exported â†’ Stock_ARDL_ECM_ENHANCED_AllModels.xlsx\n",
            "\n",
            "==========================================================================================\n",
            "ğŸ“Š RESULTS SUMMARY\n",
            "==========================================================================================\n",
            "\n",
            "====================================================================================================\n",
            "ğŸ“Š ENHANCED MODEL COMPARISON SUMMARY\n",
            "====================================================================================================\n",
            "\n",
            "Model      â”‚ ECM RMSE             â”‚ AR RMSE      â”‚ ECM>AR       â”‚ #Best    â”‚ Win%    \n",
            "           â”‚ mean Â± std           â”‚ mean         â”‚ (sig p<.05)  â”‚          â”‚         \n",
            "----------------------------------------------------------------------------------------------------\n",
            "ACF        â”‚ 0.1542 Â± 0.0826   â”‚ 0.1051     â”‚ 2/11        â”‚ 2        â”‚ 18.2%\n",
            "AIC        â”‚ 0.1213 Â± 0.0598   â”‚ 0.1049     â”‚ 1/11        â”‚ 9        â”‚ 36.4%\n",
            "FIXED      â”‚ 0.1579 Â± 0.0661   â”‚ 0.1049     â”‚ 3/11        â”‚ 0        â”‚ 0.0%\n",
            "====================================================================================================\n",
            "\n",
            "ğŸ† Recommended Model (lowest avg RMSE): AIC\n",
            "\n",
            "==============================================================================================================\n",
            "ğŸ† BEST MODEL SELECTION PER STOCK\n",
            "==============================================================================================================\n",
            "Sector               Stock    Method   p   q   ECM_RMSE   AR_RMSE    ECM>AR?    Recommendation\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "Banking              BBL      AIC      1   4   0.069408   0.049458   No         âš ï¸ Use AR\n",
            "Banking              KBANK    AIC      1   4   0.089876   0.081174   No         âš ï¸ Use AR\n",
            "Banking              KKP      ACF      1   6   0.109027   0.122733   No         âš ï¸ Use AR\n",
            "Banking              KTB      ACF      1   6   0.122048   0.107196   No         âš ï¸ Use AR\n",
            "Banking              TCAP     AIC      1   3   0.065934   0.066071   No         âš ï¸ Use AR\n",
            "Banking              TISCO    AIC      1   4   0.043696   0.052664   No         âš ï¸ Use AR\n",
            "Banking              TTB      AIC      1   3   0.082404   0.067307   No         âš ï¸ Use AR\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "Finance_Securities   AEONTS   AIC      1   4   0.151038   0.104531   No         âš ï¸ Use AR\n",
            "Finance_Securities   JMT      AIC      2   4   0.230849   0.236551   No         âš ï¸ Use AR\n",
            "Finance_Securities   KTC      AIC      2   4   0.209077   0.142591   No         âš ï¸ Use AR\n",
            "Finance_Securities   SAWAD    AIC      1   3   0.150245   0.123993   No         âš ï¸ Use AR\n",
            "==============================================================================================================\n",
            "\n",
            "ğŸ“Š Summary: ECM outperforms AR in 0/11 stocks (0.0%)\n",
            "\n",
            "========================================================================================================================\n",
            "ğŸ“‹ LAG SELECTION COMPARISON TABLE\n",
            "========================================================================================================================\n",
            "Sector             Stock    â”‚ FIXED           â”‚ ACF/PACF        â”‚ AIC-greedy      â”‚ Best    \n",
            "                            â”‚ p   q   AIC     â”‚ p   q   AIC     â”‚ p   q   AIC     â”‚ Model   \n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Banking            BBL      â”‚ 3   3   -326.2    â”‚ 1   6   -339.7    â”‚ 1   4   -354.7    â”‚ AIC     \n",
            "Banking            KBANK    â”‚ 3   3   -259.4    â”‚ 1   6   -257.1    â”‚ 1   4   -284.3    â”‚ AIC     \n",
            "Banking            KKP      â”‚ 3   3   -236.9    â”‚ 1   6   -258.4    â”‚ 1   4   -265.9    â”‚ ACF     \n",
            "Banking            KTB      â”‚ 3   3   -299.5    â”‚ 1   6   -300.9    â”‚ 1   4   -323.2    â”‚ ACF     \n",
            "Banking            TCAP     â”‚ 3   3   -322.5    â”‚ 2   6   -320.4    â”‚ 1   3   -335.6    â”‚ AIC     \n",
            "Banking            TISCO    â”‚ 3   3   -352.2    â”‚ 1   6   -354.3    â”‚ 1   4   -379.5    â”‚ AIC     \n",
            "Banking            TTB      â”‚ 3   3   -264.7    â”‚ 1   6   -253.2    â”‚ 1   3   -288.7    â”‚ AIC     \n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Finance_Securities AEONTS   â”‚ 3   3   -226.6    â”‚ 1   6   -224.4    â”‚ 1   4   -259.6    â”‚ AIC     \n",
            "Finance_Securities JMT      â”‚ 3   3   -137.4    â”‚ 1   6   -129.2    â”‚ 2   4   -159.0    â”‚ AIC     \n",
            "Finance_Securities KTC      â”‚ 3   3   -176.4    â”‚ 1   6   -163.5    â”‚ 2   4   -191.3    â”‚ AIC     \n",
            "Finance_Securities SAWAD    â”‚ 3   3   -182.5    â”‚ 1   6   -165.7    â”‚ 1   3   -206.4    â”‚ AIC     \n",
            "========================================================================================================================\n",
            "\n",
            "==========================================================================================\n",
            "ğŸ“‹ EVIEWS-STYLE OUTPUT (FIXED Model)\n",
            "==========================================================================================\n",
            "\n",
            "========================================================================================\n",
            "ğŸ“‚ Sector: Banking\n",
            "========================================================================================\n",
            "\n",
            "--- BBL ---\n",
            "Î± (ECT speed): -0.1563*   p=0.085\n",
            "\n",
            "Long-run Relationship (Î²):\n",
            "              Variable  Î² (Long-run)\n",
            "                 const      4.568153\n",
            "BroadMoney_M1M2_Growth    -16.772168\n",
            "    Inflation_Surprise      2.682182\n",
            "               THOR_6M      5.676855\n",
            "     3M_1M_THOR_Spread   -538.546843\n",
            "    10Y_5Y_Bond_Spread     26.576405\n",
            "           THB_per_USD     -0.007421\n",
            "             SET_Index      0.000326\n",
            "           SP500_Index      0.000164\n",
            "           THB_per_CNY      9.957045\n",
            "            GDP_Growth      5.514394\n",
            "           THB_per_INR     -1.257685\n",
            "\n",
            "Short-run Dynamics (Î³):\n",
            "                   Variable     Coef     pval Signif\n",
            "       D.10Y_5Y_Bond_Spread   4.4598   0.3365       \n",
            "    D.L2.10Y_5Y_Bond_Spread  -7.3706   0.0151     **\n",
            "        D.3M_1M_THOR_Spread -41.4507   0.0062    ***\n",
            "     D.L2.3M_1M_THOR_Spread  57.8078   0.0104     **\n",
            "   D.BroadMoney_M1M2_Growth  -2.2450   0.0007    ***\n",
            "D.L2.BroadMoney_M1M2_Growth  -0.1350   0.8632       \n",
            "               D.GDP_Growth   0.2032   0.8181       \n",
            "            D.L2.GDP_Growth  -0.4109   0.5466       \n",
            "       D.Inflation_Surprise   0.1103   0.9255       \n",
            "    D.L2.Inflation_Surprise  -0.5765   0.6798       \n",
            "          D.L2.Logclose_BBL  -0.0755   0.5400       \n",
            "                D.SET_Index   0.0000   0.9340       \n",
            "             D.L2.SET_Index  -0.0001   0.1255       \n",
            "              D.SP500_Index   0.0001   0.0031    ***\n",
            "           D.L2.SP500_Index  -0.0000   0.4121       \n",
            "              D.THB_per_CNY   1.0493   0.6218       \n",
            "           D.L2.THB_per_CNY   1.6636   0.4725       \n",
            "              D.THB_per_INR  -0.2269   0.0079    ***\n",
            "           D.L2.THB_per_INR   0.4381   0.0152     **\n",
            "              D.THB_per_USD  -0.0163   0.2165       \n",
            "           D.L2.THB_per_USD   0.0260   0.1325       \n",
            "                  D.THOR_6M -46.0541   0.2388       \n",
            "               D.L2.THOR_6M  -7.7130   0.7926       \n",
            "----------------------------------------------------------------------------------------\n",
            "\n",
            "--- KBANK ---\n",
            "Î± (ECT speed): -0.2038*   p=0.051\n",
            "\n",
            "Long-run Relationship (Î²):\n",
            "              Variable  Î² (Long-run)\n",
            "                 const      7.970160\n",
            "BroadMoney_M1M2_Growth    -19.562827\n",
            "    Inflation_Surprise     42.106408\n",
            "               THOR_6M      4.652437\n",
            "     3M_1M_THOR_Spread   -281.245927\n",
            "    10Y_5Y_Bond_Spread     37.450721\n",
            "           THB_per_USD     -0.045355\n",
            "             SET_Index     -0.000205\n",
            "           SP500_Index      0.000188\n",
            "           THB_per_CNY      9.957560\n",
            "            GDP_Growth      8.559263\n",
            "           THB_per_INR     -1.933373\n",
            "\n",
            "Short-run Dynamics (Î³):\n",
            "                   Variable     Coef     pval Signif\n",
            "       D.10Y_5Y_Bond_Spread   7.9302   0.1819       \n",
            "    D.L2.10Y_5Y_Bond_Spread  -7.7200   0.0963      *\n",
            "        D.3M_1M_THOR_Spread -49.6066   0.0329     **\n",
            "     D.L2.3M_1M_THOR_Spread  46.3750   0.2131       \n",
            "   D.BroadMoney_M1M2_Growth  -3.4790   0.0001    ***\n",
            "D.L2.BroadMoney_M1M2_Growth   2.0805   0.0429     **\n",
            "               D.GDP_Growth   1.1003   0.3376       \n",
            "            D.L2.GDP_Growth  -1.8014   0.2234       \n",
            "       D.Inflation_Surprise   1.4834   0.3757       \n",
            "    D.L2.Inflation_Surprise  -1.0562   0.5525       \n",
            "        D.L2.Logclose_KBANK   0.0632   0.6234       \n",
            "                D.SET_Index  -0.0001   0.6616       \n",
            "             D.L2.SET_Index  -0.0000   0.6508       \n",
            "              D.SP500_Index   0.0001   0.0109     **\n",
            "           D.L2.SP500_Index   0.0000   0.7019       \n",
            "              D.THB_per_CNY  -1.2406   0.6510       \n",
            "           D.L2.THB_per_CNY   1.3477   0.6676       \n",
            "              D.THB_per_INR   0.1087   0.3791       \n",
            "           D.L2.THB_per_INR   0.4732   0.0784      *\n",
            "              D.THB_per_USD  -0.0166   0.2560       \n",
            "           D.L2.THB_per_USD   0.0272   0.2283       \n",
            "                  D.THOR_6M -82.4782   0.2007       \n",
            "               D.L2.THOR_6M  27.8190   0.5716       \n",
            "----------------------------------------------------------------------------------------\n",
            "\n",
            "--- KKP ---\n",
            "Î± (ECT speed): -0.3485***   p=0.002\n",
            "\n",
            "Long-run Relationship (Î²):\n",
            "              Variable  Î² (Long-run)\n",
            "                 const      2.122175\n",
            "BroadMoney_M1M2_Growth      1.068169\n",
            "    Inflation_Surprise     36.638779\n",
            "               THOR_6M    -28.997593\n",
            "     3M_1M_THOR_Spread   -123.354704\n",
            "    10Y_5Y_Bond_Spread    -30.539307\n",
            "           THB_per_USD     -0.003361\n",
            "             SET_Index      0.000582\n",
            "           SP500_Index      0.000383\n",
            "           THB_per_CNY     24.002238\n",
            "            GDP_Growth      4.632483\n",
            "           THB_per_INR     -2.237719\n",
            "\n",
            "Short-run Dynamics (Î³):\n",
            "                   Variable     Coef     pval Signif\n",
            "       D.10Y_5Y_Bond_Spread  11.6066   0.0708      *\n",
            "    D.L2.10Y_5Y_Bond_Spread   1.3762   0.7872       \n",
            "        D.3M_1M_THOR_Spread -51.7756   0.0019    ***\n",
            "     D.L2.3M_1M_THOR_Spread  26.7413   0.2593       \n",
            "   D.BroadMoney_M1M2_Growth  -3.3637   0.0036    ***\n",
            "D.L2.BroadMoney_M1M2_Growth   0.3080   0.8079       \n",
            "               D.GDP_Growth   0.6374   0.5768       \n",
            "            D.L2.GDP_Growth  -1.5805   0.0527      *\n",
            "       D.Inflation_Surprise   2.5129   0.1195       \n",
            "    D.L2.Inflation_Surprise  -2.7574   0.0868      *\n",
            "          D.L2.Logclose_KKP  -0.0050   0.9685       \n",
            "                D.SET_Index   0.0000   0.9114       \n",
            "             D.L2.SET_Index  -0.0001   0.3744       \n",
            "              D.SP500_Index   0.0002   0.0000    ***\n",
            "           D.L2.SP500_Index   0.0001   0.2940       \n",
            "              D.THB_per_CNY   4.3971   0.2161       \n",
            "           D.L2.THB_per_CNY   1.9124   0.5904       \n",
            "              D.THB_per_INR  -0.0567   0.8059       \n",
            "           D.L2.THB_per_INR   0.5698   0.0146     **\n",
            "              D.THB_per_USD   0.0203   0.2193       \n",
            "           D.L2.THB_per_USD   0.0349   0.0915      *\n",
            "                  D.THOR_6M -31.5765   0.4374       \n",
            "               D.L2.THOR_6M   9.4307   0.7854       \n",
            "----------------------------------------------------------------------------------------\n",
            "\n",
            "--- KTB ---\n",
            "Î± (ECT speed): -0.0813   p=0.323\n",
            "\n",
            "Long-run Relationship (Î²):\n",
            "              Variable  Î² (Long-run)\n",
            "                 const     -1.086560\n",
            "BroadMoney_M1M2_Growth    -36.345068\n",
            "    Inflation_Surprise    107.276718\n",
            "               THOR_6M     -1.448285\n",
            "     3M_1M_THOR_Spread   -138.515674\n",
            "    10Y_5Y_Bond_Spread     61.645873\n",
            "           THB_per_USD      0.080825\n",
            "             SET_Index     -0.000129\n",
            "           SP500_Index      0.000143\n",
            "           THB_per_CNY     12.921406\n",
            "            GDP_Growth     14.642522\n",
            "           THB_per_INR     -1.047056\n",
            "\n",
            "Short-run Dynamics (Î³):\n",
            "                   Variable     Coef     pval Signif\n",
            "       D.10Y_5Y_Bond_Spread  -0.5585   0.9172       \n",
            "    D.L2.10Y_5Y_Bond_Spread   2.8391   0.4769       \n",
            "        D.3M_1M_THOR_Spread -26.7807   0.1275       \n",
            "     D.L2.3M_1M_THOR_Spread  12.7403   0.6740       \n",
            "   D.BroadMoney_M1M2_Growth  -2.7627   0.0001    ***\n",
            "D.L2.BroadMoney_M1M2_Growth   0.0448   0.9670       \n",
            "               D.GDP_Growth   0.4518   0.6477       \n",
            "            D.L2.GDP_Growth  -1.4981   0.1129       \n",
            "       D.Inflation_Surprise   0.7833   0.5654       \n",
            "    D.L2.Inflation_Surprise  -1.2517   0.3350       \n",
            "          D.L2.Logclose_KTB   0.0555   0.5325       \n",
            "                D.SET_Index  -0.0003   0.1503       \n",
            "             D.L2.SET_Index   0.0000   0.7388       \n",
            "              D.SP500_Index   0.0001   0.0007    ***\n",
            "           D.L2.SP500_Index   0.0000   0.3473       \n",
            "              D.THB_per_CNY  -0.0866   0.9803       \n",
            "           D.L2.THB_per_CNY   2.4403   0.3363       \n",
            "              D.THB_per_INR   0.2997   0.0878      *\n",
            "           D.L2.THB_per_INR   0.4852   0.0197     **\n",
            "              D.THB_per_USD   0.0093   0.5029       \n",
            "           D.L2.THB_per_USD   0.0359   0.0339     **\n",
            "                  D.THOR_6M -45.1867   0.2499       \n",
            "               D.L2.THOR_6M  31.0812   0.2753       \n",
            "----------------------------------------------------------------------------------------\n",
            "\n",
            "--- TCAP ---\n",
            "Î± (ECT speed): -0.5613***   p=0.000\n",
            "\n",
            "Long-run Relationship (Î²):\n",
            "              Variable  Î² (Long-run)\n",
            "                 const      0.449354\n",
            "BroadMoney_M1M2_Growth      6.784209\n",
            "    Inflation_Surprise     11.234248\n",
            "               THOR_6M      6.550127\n",
            "     3M_1M_THOR_Spread   -227.346934\n",
            "    10Y_5Y_Bond_Spread    -25.753997\n",
            "           THB_per_USD      0.013448\n",
            "             SET_Index      0.000511\n",
            "           SP500_Index      0.000272\n",
            "           THB_per_CNY     13.100497\n",
            "            GDP_Growth      1.759316\n",
            "           THB_per_INR     -0.879247\n",
            "\n",
            "Short-run Dynamics (Î³):\n",
            "                   Variable     Coef     pval Signif\n",
            "       D.10Y_5Y_Bond_Spread   2.1075   0.6665       \n",
            "    D.L2.10Y_5Y_Bond_Spread  -0.9544   0.7653       \n",
            "        D.3M_1M_THOR_Spread -78.6587   0.0000    ***\n",
            "     D.L2.3M_1M_THOR_Spread  40.3074   0.0110     **\n",
            "   D.BroadMoney_M1M2_Growth  -2.3409   0.0421     **\n",
            "D.L2.BroadMoney_M1M2_Growth  -2.1408   0.0208     **\n",
            "               D.GDP_Growth   0.8451   0.2214       \n",
            "            D.L2.GDP_Growth  -1.7010   0.0114     **\n",
            "       D.Inflation_Surprise   0.8839   0.4572       \n",
            "    D.L2.Inflation_Surprise  -2.1523   0.1265       \n",
            "         D.L2.Logclose_TCAP   0.0573   0.4793       \n",
            "                D.SET_Index   0.0001   0.5507       \n",
            "             D.L2.SET_Index  -0.0001   0.1487       \n",
            "              D.SP500_Index   0.0002   0.0000    ***\n",
            "           D.L2.SP500_Index   0.0001   0.0375     **\n",
            "              D.THB_per_CNY   3.7497   0.1665       \n",
            "           D.L2.THB_per_CNY  -3.1221   0.1549       \n",
            "              D.THB_per_INR  -0.2436   0.0311     **\n",
            "           D.L2.THB_per_INR   0.5648   0.0061    ***\n",
            "              D.THB_per_USD   0.0050   0.6808       \n",
            "           D.L2.THB_per_USD   0.0194   0.1522       \n",
            "                  D.THOR_6M -80.0925   0.0209     **\n",
            "               D.L2.THOR_6M  15.5622   0.4890       \n",
            "----------------------------------------------------------------------------------------\n",
            "\n",
            "--- TISCO ---\n",
            "Î± (ECT speed): -0.2785***   p=0.000\n",
            "\n",
            "Long-run Relationship (Î²):\n",
            "              Variable  Î² (Long-run)\n",
            "                 const      0.039297\n",
            "BroadMoney_M1M2_Growth     -0.166132\n",
            "    Inflation_Surprise     30.198402\n",
            "               THOR_6M    -22.509882\n",
            "     3M_1M_THOR_Spread   -248.176256\n",
            "    10Y_5Y_Bond_Spread    -18.013344\n",
            "           THB_per_USD      0.017271\n",
            "             SET_Index      0.000178\n",
            "           SP500_Index      0.000470\n",
            "           THB_per_CNY     26.550974\n",
            "            GDP_Growth      1.028844\n",
            "           THB_per_INR     -1.615047\n",
            "\n",
            "Short-run Dynamics (Î³):\n",
            "                   Variable     Coef     pval Signif\n",
            "       D.10Y_5Y_Bond_Spread   9.8085   0.0209     **\n",
            "    D.L2.10Y_5Y_Bond_Spread   5.5189   0.0751      *\n",
            "        D.3M_1M_THOR_Spread -39.1526   0.0018    ***\n",
            "     D.L2.3M_1M_THOR_Spread  36.9290   0.0044    ***\n",
            "   D.BroadMoney_M1M2_Growth  -2.5533   0.0074    ***\n",
            "D.L2.BroadMoney_M1M2_Growth  -1.5212   0.0736      *\n",
            "               D.GDP_Growth  -0.9293   0.1481       \n",
            "            D.L2.GDP_Growth   0.3981   0.4135       \n",
            "       D.Inflation_Surprise   2.4102   0.0215     **\n",
            "    D.L2.Inflation_Surprise  -3.0445   0.0006    ***\n",
            "        D.L2.Logclose_TISCO   0.0225   0.7243       \n",
            "                D.SET_Index   0.0001   0.1323       \n",
            "             D.L2.SET_Index  -0.0002   0.0150     **\n",
            "              D.SP500_Index   0.0002   0.0000    ***\n",
            "           D.L2.SP500_Index  -0.0000   0.9618       \n",
            "              D.THB_per_CNY   4.4873   0.0344     **\n",
            "           D.L2.THB_per_CNY  -3.3745   0.1207       \n",
            "              D.THB_per_INR  -0.2897   0.0050    ***\n",
            "           D.L2.THB_per_INR   0.3364   0.0931      *\n",
            "              D.THB_per_USD  -0.0051   0.6587       \n",
            "           D.L2.THB_per_USD   0.0045   0.7297       \n",
            "                  D.THOR_6M -56.8801   0.0553      *\n",
            "               D.L2.THOR_6M  22.2459   0.3017       \n",
            "----------------------------------------------------------------------------------------\n",
            "\n",
            "--- TTB ---\n",
            "Î± (ECT speed): -0.1945**   p=0.029\n",
            "\n",
            "Long-run Relationship (Î²):\n",
            "              Variable  Î² (Long-run)\n",
            "                 const      1.706984\n",
            "BroadMoney_M1M2_Growth      0.755762\n",
            "    Inflation_Surprise      1.586365\n",
            "               THOR_6M     19.586675\n",
            "     3M_1M_THOR_Spread     62.137968\n",
            "    10Y_5Y_Bond_Spread     41.524132\n",
            "           THB_per_USD     -0.004354\n",
            "             SET_Index     -0.000090\n",
            "           SP500_Index      0.000147\n",
            "           THB_per_CNY      4.400957\n",
            "            GDP_Growth      6.850586\n",
            "           THB_per_INR     -1.443657\n",
            "\n",
            "Short-run Dynamics (Î³):\n",
            "                   Variable     Coef     pval Signif\n",
            "       D.10Y_5Y_Bond_Spread  10.0600   0.1618       \n",
            "    D.L2.10Y_5Y_Bond_Spread -14.0695   0.0029    ***\n",
            "        D.3M_1M_THOR_Spread -25.5018   0.2036       \n",
            "     D.L2.3M_1M_THOR_Spread   7.1321   0.8344       \n",
            "   D.BroadMoney_M1M2_Growth  -2.4347   0.0203     **\n",
            "D.L2.BroadMoney_M1M2_Growth   1.6677   0.1412       \n",
            "               D.GDP_Growth  -0.7260   0.5002       \n",
            "            D.L2.GDP_Growth  -1.3125   0.1790       \n",
            "       D.Inflation_Surprise  -0.7103   0.6750       \n",
            "    D.L2.Inflation_Surprise  -0.4311   0.8014       \n",
            "          D.L2.Logclose_TTB  -0.0162   0.8821       \n",
            "                D.SET_Index  -0.0000   0.8751       \n",
            "             D.L2.SET_Index  -0.0001   0.5077       \n",
            "              D.SP500_Index   0.0002   0.0001    ***\n",
            "           D.L2.SP500_Index   0.0000   0.9709       \n",
            "              D.THB_per_CNY  -0.2488   0.9440       \n",
            "           D.L2.THB_per_CNY   0.5947   0.8361       \n",
            "              D.THB_per_INR  -0.1618   0.2175       \n",
            "           D.L2.THB_per_INR   0.4554   0.1018       \n",
            "              D.THB_per_USD  -0.0165   0.3417       \n",
            "           D.L2.THB_per_USD   0.0178   0.4519       \n",
            "                  D.THOR_6M -12.8352   0.8332       \n",
            "               D.L2.THOR_6M   4.8923   0.9166       \n",
            "----------------------------------------------------------------------------------------\n",
            "\n",
            "========================================================================================\n",
            "ğŸ“‚ Sector: Finance_Securities\n",
            "========================================================================================\n",
            "\n",
            "--- AEONTS ---\n",
            "Î± (ECT speed): -0.1829***   p=0.000\n",
            "\n",
            "Long-run Relationship (Î²):\n",
            "              Variable  Î² (Long-run)\n",
            "                 const     12.004269\n",
            "BroadMoney_M1M2_Growth     -4.751266\n",
            "    Inflation_Surprise     10.528371\n",
            "               THOR_6M    -15.103046\n",
            "     3M_1M_THOR_Spread     51.688167\n",
            "    10Y_5Y_Bond_Spread    -44.897686\n",
            "           THB_per_USD     -0.179528\n",
            "             SET_Index      0.000508\n",
            "           SP500_Index      0.000135\n",
            "           THB_per_CNY    -13.762021\n",
            "            GDP_Growth      6.297633\n",
            "           THB_per_INR      0.351651\n",
            "\n",
            "Short-run Dynamics (Î³):\n",
            "                   Variable     Coef     pval Signif\n",
            "       D.10Y_5Y_Bond_Spread   3.5857   0.6549       \n",
            "    D.L2.10Y_5Y_Bond_Spread   9.8501   0.2099       \n",
            "        D.3M_1M_THOR_Spread  11.5575   0.5005       \n",
            "     D.L2.3M_1M_THOR_Spread -24.4645   0.2743       \n",
            "   D.BroadMoney_M1M2_Growth  -3.0870   0.0160     **\n",
            "D.L2.BroadMoney_M1M2_Growth  -0.3724   0.8079       \n",
            "               D.GDP_Growth  -1.2359   0.1115       \n",
            "            D.L2.GDP_Growth  -1.5259   0.0951      *\n",
            "       D.Inflation_Surprise  -1.6912   0.3064       \n",
            "    D.L2.Inflation_Surprise  -4.2258   0.0591      *\n",
            "       D.L2.Logclose_AEONTS  -0.1651   0.0212     **\n",
            "                D.SET_Index   0.0004   0.0085    ***\n",
            "             D.L2.SET_Index  -0.0001   0.2394       \n",
            "              D.SP500_Index   0.0001   0.3618       \n",
            "           D.L2.SP500_Index   0.0000   0.5114       \n",
            "              D.THB_per_CNY  13.9880   0.0000    ***\n",
            "           D.L2.THB_per_CNY  -0.5093   0.8959       \n",
            "              D.THB_per_INR  -0.8163   0.0005    ***\n",
            "           D.L2.THB_per_INR  -0.2626   0.2750       \n",
            "              D.THB_per_USD  -0.0107   0.5647       \n",
            "           D.L2.THB_per_USD   0.0039   0.8372       \n",
            "                  D.THOR_6M -22.9608   0.6180       \n",
            "               D.L2.THOR_6M -80.8161   0.0104     **\n",
            "----------------------------------------------------------------------------------------\n",
            "\n",
            "--- JMT ---\n",
            "Î± (ECT speed): -0.1736***   p=0.000\n",
            "\n",
            "Long-run Relationship (Î²):\n",
            "              Variable  Î² (Long-run)\n",
            "                 const     27.301867\n",
            "BroadMoney_M1M2_Growth     32.109318\n",
            "    Inflation_Surprise    -30.622711\n",
            "               THOR_6M   -173.502235\n",
            "     3M_1M_THOR_Spread   1260.399440\n",
            "    10Y_5Y_Bond_Spread   -253.887597\n",
            "           THB_per_USD     -0.370161\n",
            "             SET_Index     -0.001166\n",
            "           SP500_Index      0.001407\n",
            "           THB_per_CNY      9.502562\n",
            "            GDP_Growth     -0.016972\n",
            "           THB_per_INR     -6.200385\n",
            "\n",
            "Short-run Dynamics (Î³):\n",
            "                   Variable      Coef     pval Signif\n",
            "       D.10Y_5Y_Bond_Spread   -5.5184   0.5933       \n",
            "    D.L2.10Y_5Y_Bond_Spread   17.1107   0.1214       \n",
            "        D.3M_1M_THOR_Spread   -2.2908   0.9353       \n",
            "     D.L2.3M_1M_THOR_Spread -133.6494   0.0015    ***\n",
            "   D.BroadMoney_M1M2_Growth   -0.1330   0.9319       \n",
            "D.L2.BroadMoney_M1M2_Growth    1.3091   0.6124       \n",
            "               D.GDP_Growth    2.1025   0.0690      *\n",
            "            D.L2.GDP_Growth    0.3619   0.7713       \n",
            "       D.Inflation_Surprise    0.5467   0.8596       \n",
            "    D.L2.Inflation_Surprise    1.4069   0.6658       \n",
            "          D.L2.Logclose_JMT   -0.0642   0.5210       \n",
            "                D.SET_Index   -0.0000   0.9297       \n",
            "             D.L2.SET_Index   -0.0003   0.0374     **\n",
            "              D.SP500_Index    0.0000   0.5402       \n",
            "           D.L2.SP500_Index    0.0000   0.9695       \n",
            "              D.THB_per_CNY   17.8099   0.0021    ***\n",
            "           D.L2.THB_per_CNY    3.0707   0.5506       \n",
            "              D.THB_per_INR   -1.9796   0.0000    ***\n",
            "           D.L2.THB_per_INR    0.0217   0.9565       \n",
            "              D.THB_per_USD   -0.0428   0.1015       \n",
            "           D.L2.THB_per_USD    0.0049   0.8573       \n",
            "                  D.THOR_6M  132.3309   0.0454     **\n",
            "               D.L2.THOR_6M  -99.0893   0.0477     **\n",
            "----------------------------------------------------------------------------------------\n",
            "\n",
            "--- KTC ---\n",
            "Î± (ECT speed): -0.0221   p=0.677\n",
            "\n",
            "Long-run Relationship (Î²):\n",
            "              Variable  Î² (Long-run)\n",
            "                 const    247.498837\n",
            "BroadMoney_M1M2_Growth     29.428245\n",
            "    Inflation_Surprise    166.983908\n",
            "               THOR_6M    -67.387422\n",
            "     3M_1M_THOR_Spread  -8738.089762\n",
            "    10Y_5Y_Bond_Spread  -1721.058848\n",
            "           THB_per_USD     -3.810546\n",
            "             SET_Index     -0.013175\n",
            "           SP500_Index      0.004093\n",
            "           THB_per_CNY   -205.472045\n",
            "            GDP_Growth    -40.472377\n",
            "           THB_per_INR    -26.771938\n",
            "\n",
            "Short-run Dynamics (Î³):\n",
            "                   Variable      Coef     pval Signif\n",
            "       D.10Y_5Y_Bond_Spread   -5.6881   0.4660       \n",
            "    D.L2.10Y_5Y_Bond_Spread    9.7583   0.2780       \n",
            "        D.3M_1M_THOR_Spread  -62.5506   0.0112     **\n",
            "     D.L2.3M_1M_THOR_Spread   42.2940   0.1891       \n",
            "   D.BroadMoney_M1M2_Growth   -2.1993   0.2206       \n",
            "D.L2.BroadMoney_M1M2_Growth   -1.6977   0.2488       \n",
            "               D.GDP_Growth   -1.9577   0.0710      *\n",
            "            D.L2.GDP_Growth    0.1502   0.8574       \n",
            "       D.Inflation_Surprise   -5.3409   0.0093    ***\n",
            "    D.L2.Inflation_Surprise   -7.1413   0.0091    ***\n",
            "          D.L2.Logclose_KTC    0.0301   0.7407       \n",
            "                D.SET_Index    0.0004   0.0889      *\n",
            "             D.L2.SET_Index   -0.0000   0.7966       \n",
            "              D.SP500_Index    0.0000   0.8009       \n",
            "           D.L2.SP500_Index   -0.0002   0.0303     **\n",
            "              D.THB_per_CNY    2.6492   0.5894       \n",
            "           D.L2.THB_per_CNY   -8.8615   0.0212     **\n",
            "              D.THB_per_INR   -1.1067   0.0081    ***\n",
            "           D.L2.THB_per_INR    0.8520   0.0028    ***\n",
            "              D.THB_per_USD   -0.0750   0.0011    ***\n",
            "           D.L2.THB_per_USD    0.0460   0.0284     **\n",
            "                  D.THOR_6M -134.0318   0.0670      *\n",
            "               D.L2.THOR_6M  -24.9993   0.5324       \n",
            "----------------------------------------------------------------------------------------\n",
            "\n",
            "--- SAWAD ---\n",
            "Î± (ECT speed): -0.3342***   p=0.000\n",
            "\n",
            "Long-run Relationship (Î²):\n",
            "              Variable  Î² (Long-run)\n",
            "                 const      7.857321\n",
            "BroadMoney_M1M2_Growth    -11.414688\n",
            "    Inflation_Surprise    -18.713558\n",
            "               THOR_6M    -32.383518\n",
            "     3M_1M_THOR_Spread    327.152523\n",
            "    10Y_5Y_Bond_Spread    -30.488944\n",
            "           THB_per_USD     -0.092498\n",
            "             SET_Index     -0.000275\n",
            "           SP500_Index      0.000324\n",
            "           THB_per_CNY      9.821571\n",
            "            GDP_Growth      1.035435\n",
            "           THB_per_INR     -1.474864\n",
            "\n",
            "Short-run Dynamics (Î³):\n",
            "                   Variable      Coef     pval Signif\n",
            "       D.10Y_5Y_Bond_Spread    5.2640   0.5631       \n",
            "    D.L2.10Y_5Y_Bond_Spread    0.9512   0.9125       \n",
            "        D.3M_1M_THOR_Spread   25.2556   0.2867       \n",
            "     D.L2.3M_1M_THOR_Spread  -52.0820   0.0703      *\n",
            "   D.BroadMoney_M1M2_Growth   -3.0631   0.1300       \n",
            "D.L2.BroadMoney_M1M2_Growth    2.3071   0.1543       \n",
            "               D.GDP_Growth   -1.3551   0.0933      *\n",
            "            D.L2.GDP_Growth   -1.3036   0.2582       \n",
            "       D.Inflation_Surprise   -5.5955   0.0716      *\n",
            "    D.L2.Inflation_Surprise   -0.1000   0.9603       \n",
            "        D.L2.Logclose_SAWAD   -0.0076   0.9405       \n",
            "                D.SET_Index    0.0000   0.9641       \n",
            "             D.L2.SET_Index   -0.0003   0.0415     **\n",
            "              D.SP500_Index    0.0001   0.1459       \n",
            "           D.L2.SP500_Index   -0.0000   0.6385       \n",
            "              D.THB_per_CNY    9.6431   0.0335     **\n",
            "           D.L2.THB_per_CNY    0.6857   0.8836       \n",
            "              D.THB_per_INR   -1.4608   0.0000    ***\n",
            "           D.L2.THB_per_INR   -0.2266   0.3519       \n",
            "              D.THB_per_USD   -0.0596   0.0131     **\n",
            "           D.L2.THB_per_USD    0.0125   0.6224       \n",
            "                  D.THOR_6M   72.2106   0.2773       \n",
            "               D.L2.THOR_6M -108.8690   0.0338     **\n",
            "----------------------------------------------------------------------------------------\n",
            "\n",
            "==========================================================================================\n",
            "âœ… BLOCK 3-4 COMPLETE!\n",
            "==========================================================================================\n",
            "\n",
            "======================================================================\n",
            "ğŸ”— BEST MODEL LOOKUP (Ready for Block 4)\n",
            "======================================================================\n",
            "  BBL      (Banking        ) â†’ AIC\n",
            "  KBANK    (Banking        ) â†’ AIC\n",
            "  KKP      (Banking        ) â†’ ACF\n",
            "  KTB      (Banking        ) â†’ ACF\n",
            "  TCAP     (Banking        ) â†’ AIC\n",
            "  TISCO    (Banking        ) â†’ AIC\n",
            "  TTB      (Banking        ) â†’ AIC\n",
            "  AEONTS   (Finance_Securities) â†’ AIC\n",
            "  JMT      (Finance_Securities) â†’ AIC\n",
            "  KTC      (Finance_Securities) â†’ AIC\n",
            "  ... Total: 11 stocks configured\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# âœ… BLOCK 3-4: ARDL-ECM ENHANCED V2 (COMPLETE) â€” PATCHED (COPY-PASTE READY)\n",
        "# ============================================================\n",
        "# ğŸ“Œ ORIGINAL FEATURES (PRESERVED):\n",
        "#    - HAC Robust Standard Errors\n",
        "#    - Fixed Lag ARDL(3,3)\n",
        "#    - Long-run Î² computation\n",
        "#    - ECT construction\n",
        "#    - EViews-style output\n",
        "#\n",
        "# ğŸ†• ADD-ON FEATURES:\n",
        "#    1. Multiple Lag Selection (FIXED / ACF-PACF / AIC-greedy)\n",
        "#    2. Walk-Forward Evaluation (Out-of-Sample)\n",
        "#    3. Benchmark Models (AR / Random Walk)\n",
        "#    4. Diebold-Mariano Test\n",
        "#    5. Per-Variable q Selection\n",
        "#    6. Forecast Metrics (MAE, RMSE, MAPE)\n",
        "#    7. Model Comparison Table\n",
        "#    8. Best Model Selection Per Stock\n",
        "#\n",
        "# âœ… PATCH NOTES (à¸¢à¸±à¸‡à¸„à¸‡à¹‚à¸„à¸£à¸‡à¹€à¸”à¸´à¸¡):\n",
        "#    - FIX: Best model selection robust (numeric coercion + tie-break by AIC/BIC)\n",
        "#    - FIX: Diagnostics q/q_max consistency\n",
        "#    - FIX: Section 13 won't crash if best_models missing\n",
        "#    - ADD: Optional DEBUG_BEST_MODEL flag (à¹„à¸¡à¹ˆà¸£à¸šà¸à¸§à¸™ output à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¹€à¸›à¸´à¸”)\n",
        "# ============================================================\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tsa.ardl import ARDL\n",
        "from statsmodels.tsa.ar_model import AutoReg\n",
        "from statsmodels.tsa.stattools import acf, pacf\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ”§ CONFIGURATION\n",
        "# ============================================================\n",
        "\n",
        "# ---------- ORIGINAL CONFIG (PRESERVED) ----------\n",
        "LAG_Y = 3\n",
        "LAG_X = 3\n",
        "MIN_OBS = 40\n",
        "\n",
        "macro_vars = [\n",
        "    \"BroadMoney_M1M2_Growth\", \"Inflation_Surprise\",\n",
        "    \"THOR_6M\", \"3M_1M_THOR_Spread\",\n",
        "    \"10Y_5Y_Bond_Spread\",\n",
        "    \"THB_per_USD\", \"SET_Index\",\n",
        "    \"SP500_Index\", \"THB_per_CNY\" , \"GDP_Growth\" , \"THB_per_INR\"\n",
        "]\n",
        "\n",
        "# ---------- ğŸ†• ADD-ON CONFIG ----------\n",
        "# Lag Selection Bounds\n",
        "P_MIN, P_MAX = 1, 4\n",
        "Q_MAX_AIC = 4\n",
        "Q_CAP = 6\n",
        "\n",
        "# Model Selection Criterion\n",
        "CRITERION = \"AIC\"  # \"AIC\" or \"BIC\"\n",
        "\n",
        "# Walk-Forward Evaluation\n",
        "TRAIN_END = \"2023-06-01\"      # End of training period\n",
        "TEST_END = None               # None = use all available data\n",
        "MIN_TRAIN = 60                # Minimum training observations\n",
        "REFIT_EVERY = 6               # Refit model every N steps\n",
        "MAX_TEST_POINTS = 120         # Maximum test points\n",
        "\n",
        "# Export Path\n",
        "EXPORT_PATH = \"Stock_ARDL_ECM_ENHANCED_AllModels.xlsx\"\n",
        "\n",
        "# Debug flag (optional)\n",
        "DEBUG_BEST_MODEL = False\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ§© SECTION 1: ORIGINAL HELPER FUNCTIONS (PRESERVED)\n",
        "# ============================================================\n",
        "\n",
        "def get_param_names(res):\n",
        "    if hasattr(res.model, \"_xnames\"):\n",
        "        return res.model._xnames\n",
        "    elif hasattr(res.model, \"data\") and hasattr(res.model.data, \"param_names\"):\n",
        "        return res.model.data.param_names\n",
        "    elif hasattr(res, \"params\"):\n",
        "        return list(res.params.index)\n",
        "    else:\n",
        "        raise AttributeError(\"Cannot extract param names from model object.\")\n",
        "\n",
        "def _nw_lags(T: int) -> int:\n",
        "    return max(1, int(np.floor(4 * (T / 100.0) ** (2.0 / 9.0))))\n",
        "\n",
        "def _is_endog_lag(name: str, endog: str) -> bool:\n",
        "    return bool(\n",
        "        re.search(rf\"(?:^L\\d+\\.){re.escape(endog)}$\", name)\n",
        "        or re.search(rf\"^{re.escape(endog)}\\.L\\d+$\", name)\n",
        "    )\n",
        "\n",
        "def _is_exog_term(name: str, var: str) -> bool:\n",
        "    return bool(\n",
        "        name == var\n",
        "        or re.search(rf\"^L\\d+\\.{re.escape(var)}$\", name)\n",
        "        or re.search(rf\"^{re.escape(var)}\\.L\\d+$\", name)\n",
        "    )\n",
        "\n",
        "def compute_long_run_from_ardl(res, endog_name: str, exog_list: list) -> pd.Series:\n",
        "    params = res.params\n",
        "    names = get_param_names(res)\n",
        "\n",
        "    phi_sum = np.sum([params[n] for n in names if _is_endog_lag(n, endog_name)])\n",
        "    denom = 1 - phi_sum if abs(1 - phi_sum) > 1e-8 else np.nan\n",
        "\n",
        "    const = params.get(\"const\", 0.0)\n",
        "    lr = {\"const\": (const / denom) if denom else np.nan}\n",
        "\n",
        "    for v in exog_list:\n",
        "        theta_sum = np.sum([params[n] for n in names if _is_exog_term(n, v) and n in params])\n",
        "        lr[v] = (theta_sum / denom) if denom else np.nan\n",
        "\n",
        "    return pd.Series(lr)\n",
        "\n",
        "def build_ecm_design(df_model: pd.DataFrame, y_col: str, x_cols: list, p: int, q: int):\n",
        "    \"\"\"à¸ªà¸£à¹‰à¸²à¸‡ ECM design matrix à¸à¸£à¹‰à¸­à¸¡à¸•à¸±à¹‰à¸‡à¸Šà¸·à¹ˆà¸­à¸Šà¸±à¸”à¹€à¸ˆà¸™ (ORIGINAL)\"\"\"\n",
        "    dy = df_model[y_col].diff()\n",
        "    dy.name = f\"D.{y_col}\"\n",
        "\n",
        "    Dy_lags = []\n",
        "    for l in range(1, p):\n",
        "        s = df_model[y_col].diff().shift(l)\n",
        "        s.name = f\"D.L{l}.{y_col}\"\n",
        "        Dy_lags.append(s)\n",
        "\n",
        "    Dx_cols = []\n",
        "    for v in x_cols:\n",
        "        s0 = df_model[v].diff()\n",
        "        s0.name = f\"D.{v}\"\n",
        "        Dx_cols.append(s0)\n",
        "        for l in range(1, q):\n",
        "            s = df_model[v].diff().shift(l)\n",
        "            s.name = f\"D.L{l}.{v}\"\n",
        "            Dx_cols.append(s)\n",
        "\n",
        "    X = pd.concat(\n",
        "        [pd.Series(1.0, index=df_model.index, name=\"const\")] + Dy_lags + Dx_cols,\n",
        "        axis=1\n",
        "    )\n",
        "    return dy, X\n",
        "\n",
        "def star(p):\n",
        "    if pd.isna(p):\n",
        "        return \"\"\n",
        "    if p < 0.01: return \"***\"\n",
        "    elif p < 0.05: return \"**\"\n",
        "    elif p < 0.1: return \"*\"\n",
        "    return \"\"\n",
        "\n",
        "def sort_by_base_and_lag(varname: str) -> tuple:\n",
        "    name = varname.replace(\"D.\", \"\")\n",
        "    lag_match = re.search(r\"L(\\d+)\\.\", name)\n",
        "    if lag_match:\n",
        "        lag = int(lag_match.group(1))\n",
        "        base = re.sub(r\"L\\d+\\.\", \"\", name)\n",
        "    else:\n",
        "        lag = 0\n",
        "        base = name\n",
        "    return (base, lag)\n",
        "\n",
        "def eviews_summary_by_sector(df_alpha, df_beta, df_gamma, model_filter=None):\n",
        "    \"\"\"ORIGINAL EViews-style output\"\"\"\n",
        "\n",
        "    # Filter by model if specified\n",
        "    if model_filter and \"Model\" in df_alpha.columns:\n",
        "        df_alpha = df_alpha[df_alpha[\"Model\"] == model_filter]\n",
        "        df_beta = df_beta[df_beta[\"Model\"] == model_filter]\n",
        "        df_gamma = df_gamma[df_gamma[\"Model\"] == model_filter]\n",
        "\n",
        "    if df_alpha.empty:\n",
        "        print(\"âš ï¸ No data to display\")\n",
        "        return\n",
        "\n",
        "    sectors = sorted(df_alpha[\"Sector\"].unique())\n",
        "    for sector in sectors:\n",
        "        print(\"\\n\" + \"=\"*88)\n",
        "        print(f\"ğŸ“‚ Sector: {sector}\")\n",
        "        print(\"=\"*88)\n",
        "\n",
        "        df_a = df_alpha[df_alpha[\"Sector\"] == sector]\n",
        "        df_b = df_beta[df_beta[\"Sector\"] == sector]\n",
        "        df_g = df_gamma[df_gamma[\"Sector\"] == sector]\n",
        "\n",
        "        for stock in sorted(df_a[\"Stock\"].unique()):\n",
        "            print(f\"\\n--- {stock} ---\")\n",
        "            a_row = df_a[df_a[\"Stock\"] == stock].iloc[0]\n",
        "            alpha_val = a_row.get(\"Alpha\", np.nan)\n",
        "            pval = a_row.get(\"pval\", a_row.get(\"Alpha_pval\", np.nan))\n",
        "            print(f\"Î± (ECT speed): {alpha_val:.4f}{star(pval)}   p={pval:.3f}\")\n",
        "\n",
        "            btab = df_b[df_b[\"Stock\"] == stock][[\"Variable\", \"coef\"]]\n",
        "            if not btab.empty:\n",
        "                btab = btab.rename(columns={\"coef\": \"Î² (Long-run)\"})\n",
        "                print(\"\\nLong-run Relationship (Î²):\")\n",
        "                print(btab.to_string(index=False, float_format=lambda x: f\"{x:.6f}\"))\n",
        "\n",
        "            gtab = df_g[df_g[\"Stock\"] == stock][[\"Variable\", \"Coef\", \"pval\"]]\n",
        "            if not gtab.empty:\n",
        "                gtab = gtab[~gtab[\"Variable\"].str.contains(\"ECT|L1\\\\.\", na=False, regex=True)]\n",
        "                if not gtab.empty:\n",
        "                    gtab[\"sort_key\"] = gtab[\"Variable\"].apply(sort_by_base_and_lag)\n",
        "                    gtab = gtab.sort_values(\"sort_key\").drop(columns=[\"sort_key\"])\n",
        "                    gtab[\"Signif\"] = gtab[\"pval\"].apply(star)\n",
        "                    print(\"\\nShort-run Dynamics (Î³):\")\n",
        "                    print(gtab.to_string(index=False, float_format=lambda x: f\"{x:8.4f}\"))\n",
        "\n",
        "            print(\"-\"*88)\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ§© SECTION 2: ENHANCED ECM BUILDER (Per-Variable q)\n",
        "# ============================================================\n",
        "\n",
        "def build_ecm_ols_enhanced(y: pd.Series, X: pd.DataFrame, p: int, q_dict: dict, add_const: bool = True):\n",
        "    \"\"\"\n",
        "    Enhanced ECM with per-variable q selection\n",
        "    q_dict = {\"var1\": 2, \"var2\": 4, ...}\n",
        "    \"\"\"\n",
        "    y = y.astype(float)\n",
        "    X = X.astype(float)\n",
        "\n",
        "    dy = y.diff()\n",
        "    Z = pd.DataFrame(index=y.index)\n",
        "\n",
        "    if add_const:\n",
        "        Z[\"const\"] = 1.0\n",
        "\n",
        "    # Level terms (t-1) for ECT\n",
        "    Z[f\"L1.{y.name}\"] = y.shift(1)\n",
        "    for m in X.columns:\n",
        "        Z[f\"L1.{m}\"] = X[m].shift(1)\n",
        "\n",
        "    # Î”y lags 1..p-1\n",
        "    for i in range(1, max(p, 1)):\n",
        "        if i <= p - 1:\n",
        "            Z[f\"D.L{i}.{y.name}\"] = dy.shift(i)\n",
        "\n",
        "    # Î”x lags 0..q_m-1 (per-variable)\n",
        "    for m in X.columns:\n",
        "        q_m = int(q_dict.get(m, LAG_X))\n",
        "        dx = X[m].diff()\n",
        "        for k in range(0, q_m):\n",
        "            col_name = f\"D.{m}\" if k == 0 else f\"D.L{k}.{m}\"\n",
        "            Z[col_name] = dx.shift(k)\n",
        "\n",
        "    df_all = pd.concat([dy.rename(\"D.y\"), Z], axis=1).dropna()\n",
        "    if df_all.shape[0] < 30:\n",
        "        raise ValueError(\"Too few observations after alignment.\")\n",
        "\n",
        "    y_dep = df_all[\"D.y\"]\n",
        "    X_reg = df_all.drop(columns=[\"D.y\"])\n",
        "\n",
        "    # HAC standard errors\n",
        "    hac_bw = _nw_lags(len(df_all))\n",
        "    res = sm.OLS(y_dep, X_reg).fit(cov_type=\"HAC\", cov_kwds={\"maxlags\": hac_bw})\n",
        "\n",
        "    return res, X_reg\n",
        "\n",
        "def get_ic(res, criterion=\"AIC\"):\n",
        "    return res.aic if str(criterion).upper() == \"AIC\" else res.bic\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ§© SECTION 3: LAG SELECTION METHODS\n",
        "# ============================================================\n",
        "\n",
        "def select_pq_FIXED(y: pd.Series, X: pd.DataFrame, p_fixed=LAG_Y, q_fixed=LAG_X,\n",
        "                    add_const=True, criterion=\"AIC\"):\n",
        "    \"\"\"Method 1: FIXED lag (original behavior)\"\"\"\n",
        "    q_dict = {m: int(q_fixed) for m in X.columns}\n",
        "    res, _ = build_ecm_ols_enhanced(y, X, p=p_fixed, q_dict=q_dict, add_const=add_const)\n",
        "    ic = get_ic(res, criterion=criterion)\n",
        "    return int(p_fixed), q_dict, res, ic\n",
        "\n",
        "def _sig_lags_from_acf(series: pd.Series, max_lag: int, alpha: float = 0.05):\n",
        "    \"\"\"Helper: find significant lags from ACF\"\"\"\n",
        "    s = pd.to_numeric(series, errors=\"coerce\").dropna()\n",
        "    if len(s) < max(30, max_lag + 5):\n",
        "        return []\n",
        "    try:\n",
        "        acf_vals, confint = acf(s, nlags=max_lag, alpha=alpha, fft=True)\n",
        "        sig = []\n",
        "        for k in range(1, max_lag + 1):\n",
        "            lo, hi = confint[k]\n",
        "            if not (lo <= 0 <= hi):\n",
        "                sig.append(k)\n",
        "        return sig\n",
        "    except:\n",
        "        return []\n",
        "\n",
        "def _choose_p_from_pacf_dy(y: pd.Series, p_min: int, p_max: int, alpha: float = 0.05):\n",
        "    \"\"\"Helper: choose p from PACF of Î”y\"\"\"\n",
        "    dy = pd.to_numeric(y, errors=\"coerce\").diff().dropna()\n",
        "    if len(dy) < max(30, p_max + 5):\n",
        "        return p_min\n",
        "    try:\n",
        "        pacf_vals, confint = pacf(dy, nlags=p_max, alpha=alpha, method=\"ywm\")\n",
        "        sig_lags = []\n",
        "        for k in range(1, p_max + 1):\n",
        "            lo, hi = confint[k]\n",
        "            if not (lo <= 0 <= hi):\n",
        "                sig_lags.append(k)\n",
        "        p = (max(sig_lags) + 1) if sig_lags else p_min\n",
        "        return int(np.clip(p, p_min, p_max))\n",
        "    except:\n",
        "        return p_min\n",
        "\n",
        "def _choose_q_from_acf_dx(x: pd.Series, q_cap: int, alpha: float = 0.05):\n",
        "    \"\"\"Helper: choose q from ACF of Î”x\"\"\"\n",
        "    dx = pd.to_numeric(x, errors=\"coerce\").diff()\n",
        "    sig_lags = _sig_lags_from_acf(dx, max_lag=q_cap, alpha=alpha)\n",
        "    if not sig_lags:\n",
        "        return 1\n",
        "    q = max(sig_lags) + 1\n",
        "    return int(np.clip(q, 1, q_cap))\n",
        "\n",
        "def select_pq_ACF(y: pd.Series, X: pd.DataFrame, p_min=P_MIN, p_max=P_MAX,\n",
        "                  q_cap=Q_CAP, alpha=0.05, add_const=True, criterion=\"AIC\"):\n",
        "    \"\"\"Method 2: ACF/PACF-based selection\"\"\"\n",
        "    p_sel = _choose_p_from_pacf_dy(y, p_min, p_max, alpha=alpha)\n",
        "    q_dict = {m: _choose_q_from_acf_dx(X[m], q_cap=q_cap, alpha=alpha) for m in X.columns}\n",
        "    res, _ = build_ecm_ols_enhanced(y, X, p=p_sel, q_dict=q_dict, add_const=add_const)\n",
        "    ic = get_ic(res, criterion=criterion)\n",
        "    return p_sel, q_dict, res, ic\n",
        "\n",
        "def greedy_select_q_AIC(y, X, p, q_max=Q_MAX_AIC, add_const=True, criterion=\"AIC\"):\n",
        "    \"\"\"Helper: Greedy search for optimal q per variable\"\"\"\n",
        "    q_dict = {m: 1 for m in X.columns}\n",
        "    best_res, _ = build_ecm_ols_enhanced(y, X, p=p, q_dict=q_dict, add_const=add_const)\n",
        "    best_ic = get_ic(best_res, criterion=criterion)\n",
        "\n",
        "    for _ in range(3):\n",
        "        improved = False\n",
        "        for m in X.columns:\n",
        "            cur_q = q_dict[m]\n",
        "            best_local_q = cur_q\n",
        "            best_local_ic = best_ic\n",
        "            best_local_res = best_res\n",
        "\n",
        "            for q_try in range(1, q_max + 1):\n",
        "                if q_try == cur_q:\n",
        "                    continue\n",
        "                q_tmp = dict(q_dict)\n",
        "                q_tmp[m] = q_try\n",
        "                try:\n",
        "                    res_try, _ = build_ecm_ols_enhanced(y, X, p=p, q_dict=q_tmp, add_const=add_const)\n",
        "                    ic_try = get_ic(res_try, criterion=criterion)\n",
        "                    if ic_try < best_local_ic - 1e-9:\n",
        "                        best_local_ic = ic_try\n",
        "                        best_local_q = q_try\n",
        "                        best_local_res = res_try\n",
        "                except Exception:\n",
        "                    continue\n",
        "\n",
        "            if best_local_q != cur_q:\n",
        "                q_dict[m] = best_local_q\n",
        "                best_ic = best_local_ic\n",
        "                best_res = best_local_res\n",
        "                improved = True\n",
        "\n",
        "        if not improved:\n",
        "            break\n",
        "\n",
        "    return q_dict, best_res, best_ic\n",
        "\n",
        "def select_pq_AIC(y, X, p_min=P_MIN, p_max=P_MAX, q_max=Q_MAX_AIC,\n",
        "                  add_const=True, criterion=\"AIC\"):\n",
        "    \"\"\"Method 3: AIC-greedy selection\"\"\"\n",
        "    best = None\n",
        "    for p in range(p_min, p_max + 1):\n",
        "        try:\n",
        "            q_dict, res, ic = greedy_select_q_AIC(y, X, p=p, q_max=q_max,\n",
        "                                                   add_const=add_const, criterion=criterion)\n",
        "            if (best is None) or (ic < best[\"ic\"]):\n",
        "                best = {\"p\": p, \"q_dict\": q_dict, \"res\": res, \"ic\": ic}\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "    if best is None:\n",
        "        return select_pq_FIXED(y, X, p_fixed=LAG_Y, q_fixed=LAG_X,\n",
        "                               add_const=add_const, criterion=criterion)\n",
        "\n",
        "    return best[\"p\"], best[\"q_dict\"], best[\"res\"], best[\"ic\"]\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ§© SECTION 4: FORECAST METRICS & DIEBOLD-MARIANO TEST\n",
        "# ============================================================\n",
        "\n",
        "def _safe_mape(y_true, y_pred, eps=1e-8):\n",
        "    denom = np.maximum(np.abs(y_true), eps)\n",
        "    return np.mean(np.abs((y_true - y_pred) / denom)) * 100.0\n",
        "\n",
        "def compute_metrics(y_true, y_pred) -> dict:\n",
        "    \"\"\"Compute MAE, RMSE, MAPE\"\"\"\n",
        "    y_true = np.asarray(y_true, dtype=float)\n",
        "    y_pred = np.asarray(y_pred, dtype=float)\n",
        "    err = y_true - y_pred\n",
        "    return {\n",
        "        \"MAE\": float(np.mean(np.abs(err))),\n",
        "        \"RMSE\": float(np.sqrt(np.mean(err**2))),\n",
        "        \"MAPE(%)\": float(_safe_mape(y_true, y_pred)),\n",
        "        \"n_test\": int(len(y_true))\n",
        "    }\n",
        "\n",
        "def diebold_mariano_test(e1: np.ndarray, e2: np.ndarray, power: int = 2):\n",
        "    \"\"\"\n",
        "    Diebold-Mariano test for comparing forecast accuracy\n",
        "    H0: Both forecasts have equal accuracy\n",
        "    H1: Forecasts have different accuracy\n",
        "\n",
        "    Returns: (dm_statistic, p_value)\n",
        "    \"\"\"\n",
        "    e1 = np.asarray(e1, dtype=float)\n",
        "    e2 = np.asarray(e2, dtype=float)\n",
        "\n",
        "    if power == 1:\n",
        "        d = np.abs(e1) - np.abs(e2)\n",
        "    else:\n",
        "        d = (e1**2) - (e2**2)\n",
        "\n",
        "    d = d[~np.isnan(d)]\n",
        "    T = len(d)\n",
        "\n",
        "    if T < 10:\n",
        "        return np.nan, np.nan\n",
        "\n",
        "    mean_d = d.mean()\n",
        "    var_d = d.var(ddof=1)\n",
        "\n",
        "    if var_d <= 1e-12:\n",
        "        return np.nan, np.nan\n",
        "\n",
        "    dm_stat = mean_d / np.sqrt(var_d / T)\n",
        "    pval = 2 * (1 - stats.t.cdf(np.abs(dm_stat), df=T-1))\n",
        "\n",
        "    return float(dm_stat), float(pval)\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ§© SECTION 5: BENCHMARK MODELS (AR / Random Walk)\n",
        "# ============================================================\n",
        "\n",
        "def ar_forecast(y_train: pd.Series, p: int = 2):\n",
        "    \"\"\"AR(p) one-step forecast\"\"\"\n",
        "    ytr = y_train.dropna()\n",
        "    if len(ytr) < max(p + 5, 20):\n",
        "        return float(ytr.iloc[-1])\n",
        "\n",
        "    try:\n",
        "        fit = AutoReg(ytr, lags=p, old_names=False).fit()\n",
        "        fc = fit.predict(start=len(ytr), end=len(ytr))\n",
        "        return float(fc.iloc[0])\n",
        "    except Exception:\n",
        "        return float(ytr.iloc[-1])\n",
        "\n",
        "def random_walk_forecast(y_series: pd.Series, idx: int):\n",
        "    \"\"\"Random Walk forecast (previous value)\"\"\"\n",
        "    return float(y_series.iloc[idx - 1]) if idx > 0 else float(y_series.iloc[0])\n",
        "\n",
        "def ecm_one_step_forecast(df_all: pd.DataFrame, idx: int, y_col: str, x_cols: list,\n",
        "                          p: int, q_dict: dict, ecm_fit):\n",
        "    \"\"\"ECM one-step ahead forecast\"\"\"\n",
        "    params = ecm_fit.params\n",
        "    row = {}\n",
        "\n",
        "    if \"const\" in params.index:\n",
        "        row[\"const\"] = 1.0\n",
        "\n",
        "    # Level terms (t-1)\n",
        "    row[f\"L1.{y_col}\"] = df_all[y_col].shift(1).iloc[idx]\n",
        "    for m in x_cols:\n",
        "        row[f\"L1.{m}\"] = df_all[m].shift(1).iloc[idx]\n",
        "\n",
        "    # Î”y lags\n",
        "    dy = df_all[y_col].diff()\n",
        "    for j in range(1, p):\n",
        "        nm = f\"D.L{j}.{y_col}\"\n",
        "        if nm in params.index:\n",
        "            row[nm] = dy.shift(j).iloc[idx]\n",
        "\n",
        "    # Î”x lags (per-variable)\n",
        "    for m in x_cols:\n",
        "        q_m = int(q_dict.get(m, LAG_X))\n",
        "        dx = df_all[m].diff()\n",
        "        for k in range(0, q_m):\n",
        "            nm = f\"D.{m}\" if k == 0 else f\"D.L{k}.{m}\"\n",
        "            if nm in params.index:\n",
        "                row[nm] = dx.shift(k).iloc[idx]\n",
        "\n",
        "    # Compute forecast\n",
        "    exog_names = list(params.index)\n",
        "    x_vec = np.array([row.get(n, 0.0) for n in exog_names], dtype=float)\n",
        "    dy_hat = float(np.dot(x_vec, params.values))\n",
        "    y_prev = df_all[y_col].shift(1).iloc[idx]\n",
        "\n",
        "    return float(y_prev + dy_hat)\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ§© SECTION 6: WALK-FORWARD EVALUATION\n",
        "# ============================================================\n",
        "\n",
        "def walk_forward_evaluate(df: pd.DataFrame, y_col: str, x_cols: list,\n",
        "                          p: int, q_dict: dict,\n",
        "                          train_end: str, test_end: str = None,\n",
        "                          min_train: int = MIN_TRAIN,\n",
        "                          refit_every: int = REFIT_EVERY,\n",
        "                          max_test_points: int = MAX_TEST_POINTS):\n",
        "    \"\"\"\n",
        "    Walk-forward evaluation comparing ECM vs AR vs Random Walk\n",
        "    \"\"\"\n",
        "    d = df.copy().sort_index()\n",
        "\n",
        "    if test_end is not None:\n",
        "        d = d.loc[:pd.to_datetime(test_end)]\n",
        "\n",
        "    train_end_dt = pd.to_datetime(train_end)\n",
        "    d_train0 = d.loc[d.index <= train_end_dt]\n",
        "    d_test = d.loc[d.index > train_end_dt]\n",
        "\n",
        "    if len(d_train0) < min_train:\n",
        "        raise ValueError(f\"Not enough training data: {len(d_train0)}\")\n",
        "\n",
        "    all_idx = d.index.tolist()\n",
        "    test_indices = [i for i, dt in enumerate(all_idx) if dt in d_test.index]\n",
        "\n",
        "    if max_test_points is not None:\n",
        "        test_indices = test_indices[:max_test_points]\n",
        "\n",
        "    y_true, yhat_ecm, yhat_ar, yhat_rw = [], [], [], []\n",
        "    ecm_fit = None\n",
        "\n",
        "    for step, i in enumerate(test_indices):\n",
        "        d_train = d.iloc[:i].copy()\n",
        "        if len(d_train) < min_train:\n",
        "            continue\n",
        "\n",
        "        # Refit ECM periodically\n",
        "        if (ecm_fit is None) or (step % refit_every == 0):\n",
        "            y_train = d_train[y_col].copy()\n",
        "            y_train.name = y_col\n",
        "            X_train = d_train[x_cols].copy()\n",
        "            try:\n",
        "                ecm_fit, _ = build_ecm_ols_enhanced(y_train, X_train, p=p, q_dict=q_dict)\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "        # ECM forecast\n",
        "        try:\n",
        "            y_pred_ecm = ecm_one_step_forecast(d, i, y_col, x_cols, p, q_dict, ecm_fit)\n",
        "        except Exception:\n",
        "            y_pred_ecm = float(d[y_col].iloc[i-1])\n",
        "\n",
        "        # AR forecast\n",
        "        y_pred_ar = ar_forecast(d_train[y_col], p=max(1, p))\n",
        "\n",
        "        # Random Walk forecast\n",
        "        y_pred_rw = random_walk_forecast(d[y_col], i)\n",
        "\n",
        "        y_true.append(float(d[y_col].iloc[i]))\n",
        "        yhat_ecm.append(y_pred_ecm)\n",
        "        yhat_ar.append(y_pred_ar)\n",
        "        yhat_rw.append(y_pred_rw)\n",
        "\n",
        "    # Convert to arrays\n",
        "    y_true = np.array(y_true, dtype=float)\n",
        "    yhat_ecm = np.array(yhat_ecm, dtype=float)\n",
        "    yhat_ar = np.array(yhat_ar, dtype=float)\n",
        "    yhat_rw = np.array(yhat_rw, dtype=float)\n",
        "\n",
        "    # Compute metrics\n",
        "    results = {\"p\": int(p), \"q_max\": int(max(q_dict.values()) if q_dict else 0)}\n",
        "    results.update({f\"ECM_{k}\": v for k, v in compute_metrics(y_true, yhat_ecm).items()})\n",
        "    results.update({f\"AR_{k}\": v for k, v in compute_metrics(y_true, yhat_ar).items()})\n",
        "    results.update({f\"RW_{k}\": v for k, v in compute_metrics(y_true, yhat_rw).items()})\n",
        "\n",
        "    # Diebold-Mariano tests\n",
        "    e_ecm = y_true - yhat_ecm\n",
        "    e_ar = y_true - yhat_ar\n",
        "    e_rw = y_true - yhat_rw\n",
        "\n",
        "    dm_ecm_ar, p_ecm_ar = diebold_mariano_test(e_ecm, e_ar)\n",
        "    dm_ecm_rw, p_ecm_rw = diebold_mariano_test(e_ecm, e_rw)\n",
        "\n",
        "    results[\"DM(ECM-AR)\"] = dm_ecm_ar\n",
        "    results[\"pval(ECM-AR)\"] = p_ecm_ar\n",
        "    results[\"DM(ECM-RW)\"] = dm_ecm_rw\n",
        "    results[\"pval(ECM-RW)\"] = p_ecm_rw\n",
        "\n",
        "    # Interpretation\n",
        "    results[\"ECM_beats_AR\"] = \"Yes***\" if (p_ecm_ar < 0.01 and dm_ecm_ar < 0) else \\\n",
        "                              \"Yes**\" if (p_ecm_ar < 0.05 and dm_ecm_ar < 0) else \\\n",
        "                              \"Yes*\" if (p_ecm_ar < 0.10 and dm_ecm_ar < 0) else \"No\"\n",
        "\n",
        "    results[\"ECM_beats_RW\"] = \"Yes***\" if (p_ecm_rw < 0.01 and dm_ecm_rw < 0) else \\\n",
        "                              \"Yes**\" if (p_ecm_rw < 0.05 and dm_ecm_rw < 0) else \\\n",
        "                              \"Yes*\" if (p_ecm_rw < 0.10 and dm_ecm_rw < 0) else \"No\"\n",
        "\n",
        "    return results\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ§© SECTION 7: ECM TO TABLES (Alpha/Beta/Gamma extraction)\n",
        "# ============================================================\n",
        "\n",
        "def ecm_to_tables(ecm_fit, y_col: str, x_cols: list, model_name: str, sector: str, stock: str):\n",
        "    \"\"\"Extract alpha, beta, gamma from ECM fit\"\"\"\n",
        "    params = ecm_fit.params\n",
        "    pvals = ecm_fit.pvalues\n",
        "\n",
        "    # Alpha (speed of adjustment)\n",
        "    alpha_key = f\"L1.{y_col}\"\n",
        "    alpha = float(params.get(alpha_key, np.nan))\n",
        "    alpha_p = float(pvals.get(alpha_key, np.nan))\n",
        "\n",
        "    alpha_row = {\n",
        "        \"Sector\": sector,\n",
        "        \"Stock\": stock,\n",
        "        \"Model\": model_name,\n",
        "        \"Alpha\": alpha,\n",
        "        \"pval\": alpha_p,\n",
        "        \"Signif\": star(alpha_p),\n",
        "        \"Stable\": \"Yes\" if (-2 < alpha < 0) else \"No\",\n",
        "        \"R2\": ecm_fit.rsquared\n",
        "    }\n",
        "\n",
        "    # Beta (long-run coefficients): -L1.x / alpha\n",
        "    beta_rows = []\n",
        "    if np.isfinite(alpha) and alpha != 0:\n",
        "        if \"const\" in params.index:\n",
        "            beta_rows.append({\n",
        "                \"Sector\": sector, \"Stock\": stock, \"Model\": model_name,\n",
        "                \"Variable\": \"const\",\n",
        "                \"coef\": float(-params[\"const\"] / alpha)\n",
        "            })\n",
        "        for m in x_cols:\n",
        "            k = f\"L1.{m}\"\n",
        "            if k in params.index:\n",
        "                beta_rows.append({\n",
        "                    \"Sector\": sector, \"Stock\": stock, \"Model\": model_name,\n",
        "                    \"Variable\": m,\n",
        "                    \"coef\": float(-params[k] / alpha)\n",
        "                })\n",
        "\n",
        "    # Gamma (short-run dynamics): D.* terms\n",
        "    gamma_rows = []\n",
        "    for name in params.index:\n",
        "        if name.startswith(\"D.\"):\n",
        "            gamma_rows.append({\n",
        "                \"Sector\": sector, \"Stock\": stock, \"Model\": model_name,\n",
        "                \"Variable\": name,\n",
        "                \"Coef\": float(params[name]),\n",
        "                \"pval\": float(pvals.get(name, np.nan))\n",
        "            })\n",
        "\n",
        "    return alpha_row, beta_rows, gamma_rows\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ§© SECTION 8: BEST MODEL SELECTION PER STOCK\n",
        "# ============================================================\n",
        "\n",
        "def select_best_model_per_stock(df_forecast: pd.DataFrame,\n",
        "                                 df_diag: pd.DataFrame,\n",
        "                                 criterion: str = \"ECM_RMSE\") -> pd.DataFrame:\n",
        "    \"\"\"à¹€à¸¥à¸·à¸­à¸ Best Model à¸ªà¸³à¸«à¸£à¸±à¸šà¹à¸•à¹ˆà¸¥à¸°à¸«à¸¸à¹‰à¸™ (ROBUST)\"\"\"\n",
        "\n",
        "    if df_forecast is None or df_forecast.empty:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Merge with diagnostics\n",
        "    if df_diag is not None and (not df_diag.empty) and (\"Model\" in df_diag.columns):\n",
        "        merge_cols = [\"Stock\", \"Sector\", \"Model\"]\n",
        "        diag_cols = [c for c in [\"p\", \"q\", \"q_max\", \"AIC\", \"BIC\", \"R2\"] if c in df_diag.columns]\n",
        "        df_merged = df_forecast.merge(\n",
        "            df_diag[merge_cols + diag_cols],\n",
        "            on=merge_cols,\n",
        "            how=\"left\",\n",
        "            suffixes=('', '_diag')\n",
        "        )\n",
        "    else:\n",
        "        df_merged = df_forecast.copy()\n",
        "\n",
        "    # Ensure criterion column exists\n",
        "    if criterion not in df_merged.columns:\n",
        "        if \"ECM_RMSE\" in df_merged.columns:\n",
        "            criterion = \"ECM_RMSE\"\n",
        "        else:\n",
        "            # fallback: find any RMSE-like column\n",
        "            rmse_like = [c for c in df_merged.columns if \"rmse\" in c.lower()]\n",
        "            if rmse_like:\n",
        "                criterion = rmse_like[0]\n",
        "            else:\n",
        "                raise ValueError(\"No RMSE column found for best model selection.\")\n",
        "\n",
        "    # Coerce numeric for ranking columns\n",
        "    df_merged[criterion] = pd.to_numeric(df_merged[criterion], errors=\"coerce\")\n",
        "    if \"AIC\" in df_merged.columns:\n",
        "        df_merged[\"AIC\"] = pd.to_numeric(df_merged[\"AIC\"], errors=\"coerce\")\n",
        "    if \"BIC\" in df_merged.columns:\n",
        "        df_merged[\"BIC\"] = pd.to_numeric(df_merged[\"BIC\"], errors=\"coerce\")\n",
        "\n",
        "    # Drop invalid rows for selection\n",
        "    df_sel = df_merged.dropna(subset=[\"Stock\", \"Model\", criterion]).copy()\n",
        "\n",
        "    # Tie-break: criterion -> AIC -> BIC\n",
        "    sort_cols = [\"Stock\", criterion]\n",
        "    asc = [True, True]\n",
        "    if \"AIC\" in df_sel.columns:\n",
        "        sort_cols.append(\"AIC\"); asc.append(True)\n",
        "    if \"BIC\" in df_sel.columns:\n",
        "        sort_cols.append(\"BIC\"); asc.append(True)\n",
        "\n",
        "    df_sel = df_sel.sort_values(sort_cols, ascending=asc)\n",
        "\n",
        "    # Best per stock\n",
        "    best_models = df_sel.groupby(\"Stock\", as_index=False).head(1).copy()\n",
        "\n",
        "    # Add recommendation (use q_max if present else fallback)\n",
        "    def _qmax(row):\n",
        "        if \"q_max\" in row and pd.notna(row[\"q_max\"]):\n",
        "            return row[\"q_max\"]\n",
        "        if \"q\" in row and pd.notna(row[\"q\"]):\n",
        "            return row[\"q\"]\n",
        "        return \"?\"\n",
        "\n",
        "    best_models[\"Recommendation\"] = best_models.apply(\n",
        "        lambda row: f\"{row.get('Model', 'N/A')}(p={row.get('p', '?')},q={_qmax(row)}) | \" +\n",
        "                    (\"âœ… ECM\" if \"Yes\" in str(row.get('ECM_beats_AR', '')) else \"âš ï¸ AR/RW\"),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # sort output\n",
        "    sort_cols_out = [c for c in [\"Sector\", \"Stock\"] if c in best_models.columns]\n",
        "    if sort_cols_out:\n",
        "        best_models = best_models.sort_values(sort_cols_out)\n",
        "\n",
        "    return best_models.reset_index(drop=True)\n",
        "\n",
        "def create_lag_selection_table(df_forecast: pd.DataFrame,\n",
        "                                df_diag: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"à¸ªà¸£à¹‰à¸²à¸‡à¸•à¸²à¸£à¸²à¸‡ lag à¸—à¸µà¹ˆà¹€à¸¥à¸·à¸­à¸à¸ªà¸³à¸«à¸£à¸±à¸šà¹à¸•à¹ˆà¸¥à¸° model\"\"\"\n",
        "\n",
        "    if df_diag is None or df_diag.empty:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    pivot_data = []\n",
        "\n",
        "    for stock in df_diag[\"Stock\"].unique():\n",
        "        stock_data = {\"Stock\": stock}\n",
        "        stock_df = df_diag[df_diag[\"Stock\"] == stock]\n",
        "\n",
        "        if \"Sector\" in stock_df.columns:\n",
        "            stock_data[\"Sector\"] = stock_df[\"Sector\"].iloc[0]\n",
        "\n",
        "        for model in [\"FIXED\", \"ACF\", \"AIC\"]:\n",
        "            model_df = stock_df[stock_df[\"Model\"] == model]\n",
        "            if not model_df.empty:\n",
        "                p = model_df[\"p\"].iloc[0] if \"p\" in model_df.columns else np.nan\n",
        "\n",
        "                # q priority: q_max -> q\n",
        "                if \"q_max\" in model_df.columns:\n",
        "                    q = model_df[\"q_max\"].iloc[0]\n",
        "                elif \"q\" in model_df.columns:\n",
        "                    q = model_df[\"q\"].iloc[0]\n",
        "                else:\n",
        "                    q = 0\n",
        "\n",
        "                aic = model_df[\"AIC\"].iloc[0] if \"AIC\" in model_df.columns else np.nan\n",
        "\n",
        "                stock_data[f\"{model}_p\"] = int(p) if pd.notna(p) else 0\n",
        "                stock_data[f\"{model}_q\"] = int(q) if pd.notna(q) else 0\n",
        "                stock_data[f\"{model}_AIC\"] = aic\n",
        "\n",
        "        pivot_data.append(stock_data)\n",
        "\n",
        "    lag_table = pd.DataFrame(pivot_data)\n",
        "\n",
        "    # Add best model\n",
        "    if df_forecast is not None and (not df_forecast.empty) and (\"ECM_RMSE\" in df_forecast.columns):\n",
        "        best = df_forecast.loc[df_forecast.groupby(\"Stock\")[\"ECM_RMSE\"].idxmin()][[\"Stock\", \"Model\"]]\n",
        "        best = best.rename(columns={\"Model\": \"Best_Model\"})\n",
        "        lag_table = lag_table.merge(best, on=\"Stock\", how=\"left\")\n",
        "\n",
        "    return lag_table.sort_values([c for c in [\"Sector\", \"Stock\"] if c in lag_table.columns]).reset_index(drop=True)\n",
        "\n",
        "def create_enhanced_model_comparison(df_forecast: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"à¸ªà¸£à¹‰à¸²à¸‡à¸•à¸²à¸£à¸²à¸‡ Model Comparison\"\"\"\n",
        "\n",
        "    if df_forecast is None or df_forecast.empty:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    comparison = df_forecast.groupby(\"Model\").agg({\n",
        "        \"ECM_RMSE\": [\"mean\", \"std\", \"min\", \"max\"],\n",
        "        \"AR_RMSE\": [\"mean\", \"std\"],\n",
        "        \"RW_RMSE\": [\"mean\", \"std\"],\n",
        "        \"ECM_MAE\": \"mean\",\n",
        "        \"pval(ECM-AR)\": lambda x: (x < 0.05).sum(),\n",
        "        \"pval(ECM-RW)\": lambda x: (x < 0.05).sum()\n",
        "    }).round(6)\n",
        "\n",
        "    comparison.columns = [\n",
        "        \"ECM_RMSE_mean\", \"ECM_RMSE_std\", \"ECM_RMSE_min\", \"ECM_RMSE_max\",\n",
        "        \"AR_RMSE_mean\", \"AR_RMSE_std\",\n",
        "        \"RW_RMSE_mean\", \"RW_RMSE_std\",\n",
        "        \"ECM_MAE_mean\",\n",
        "        \"ECM_beats_AR_sig\", \"ECM_beats_RW_sig\"\n",
        "    ]\n",
        "\n",
        "    comparison[\"n_stocks\"] = df_forecast.groupby(\"Model\").size()\n",
        "\n",
        "    # Best model count\n",
        "    best_per_stock = df_forecast.loc[df_forecast.groupby(\"Stock\")[\"ECM_RMSE\"].idxmin()]\n",
        "    best_counts = best_per_stock[\"Model\"].value_counts()\n",
        "    comparison[\"times_selected_best\"] = comparison.index.map(lambda x: best_counts.get(x, 0))\n",
        "\n",
        "    # Win rate\n",
        "    comparison[\"ECM_vs_AR_win_rate\"] = df_forecast.groupby(\"Model\").apply(\n",
        "        lambda x: (x[\"ECM_RMSE\"] < x[\"AR_RMSE\"]).mean() * 100\n",
        "    ).round(1)\n",
        "\n",
        "    return comparison.reset_index()\n",
        "\n",
        "# ============================================================\n",
        "# ğŸš€ SECTION 9: MAIN FUNCTION\n",
        "# ============================================================\n",
        "\n",
        "def run_ardl_ecm_enhanced(combined_dfs_selective_diff: dict,\n",
        "                          macro_vars: list = macro_vars,\n",
        "                          train_end: str = TRAIN_END,\n",
        "                          test_end: str = TEST_END,\n",
        "                          verbose: bool = True):\n",
        "    \"\"\"\n",
        "    Main function: ORIGINAL + ALL ADD-ONS\n",
        "    \"\"\"\n",
        "\n",
        "    # Storage\n",
        "    alpha_list = []\n",
        "    beta_list = []\n",
        "    gamma_list = []\n",
        "    diag_list = []\n",
        "    forecast_list = []\n",
        "\n",
        "    print(\"=\"*90)\n",
        "    print(\"ğŸš€ ARDL-ECM ENHANCED V2: Running All Models\")\n",
        "    print(\"=\"*90)\n",
        "    print(f\"ğŸ“… Train period: Start â†’ {train_end}\")\n",
        "    print(f\"ğŸ“… Test period:  {train_end} â†’ {test_end if test_end else 'End'}\")\n",
        "    print(f\"ğŸ”§ Lag methods:  FIXED(p={LAG_Y},q={LAG_X}) | ACF/PACF | AIC-greedy\")\n",
        "    print(\"=\"*90)\n",
        "\n",
        "    for sector, df_sec in combined_dfs_selective_diff.items():\n",
        "        if verbose:\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"ğŸ“‚ Sector: {sector}\")\n",
        "            print(f\"{'='*60}\")\n",
        "\n",
        "        if df_sec is None or df_sec.empty:\n",
        "            continue\n",
        "\n",
        "        x_list = [v for v in macro_vars if v in df_sec.columns]\n",
        "        if not x_list:\n",
        "            if verbose:\n",
        "                print(\"âš ï¸ No macro variables found\")\n",
        "            continue\n",
        "\n",
        "        for col in df_sec.columns:\n",
        "            if not col.startswith(\"Logclose_\"):\n",
        "                continue\n",
        "\n",
        "            stock = col.replace(\"Logclose_\", \"\")\n",
        "            y = df_sec[col]\n",
        "            X = df_sec[x_list]\n",
        "            df_model = pd.concat([y, X], axis=1).dropna()\n",
        "\n",
        "            if len(df_model) < MIN_OBS:\n",
        "                if verbose:\n",
        "                    print(f\"âš ï¸ Skip {stock}: insufficient data ({len(df_model)})\")\n",
        "                continue\n",
        "\n",
        "            # ============================================\n",
        "            # RUN 3 MODELS\n",
        "            # ============================================\n",
        "\n",
        "            models_to_run = [\n",
        "                (\"FIXED\", lambda: select_pq_FIXED(y, X, p_fixed=LAG_Y, q_fixed=LAG_X, criterion=CRITERION)),\n",
        "                (\"ACF\", lambda: select_pq_ACF(y, X, p_min=P_MIN, p_max=P_MAX, q_cap=Q_CAP, criterion=CRITERION)),\n",
        "                (\"AIC\", lambda: select_pq_AIC(y, X, p_min=P_MIN, p_max=P_MAX, q_max=Q_MAX_AIC, criterion=CRITERION))\n",
        "            ]\n",
        "\n",
        "            for model_name, select_func in models_to_run:\n",
        "                try:\n",
        "                    if verbose:\n",
        "                        print(f\"\\nâ³ {stock}: {model_name}...\", end=\" \")\n",
        "\n",
        "                    # Select lags\n",
        "                    p_sel, q_dict, res_fit, ic = select_func()\n",
        "\n",
        "                    # Extract alpha/beta/gamma\n",
        "                    a_row, b_rows, g_rows = ecm_to_tables(\n",
        "                        res_fit, col, x_list, model_name, sector, stock\n",
        "                    )\n",
        "\n",
        "                    alpha_list.append(a_row)\n",
        "                    beta_list.extend(b_rows)\n",
        "                    gamma_list.extend(g_rows)\n",
        "\n",
        "                    q_max_used = int(max(q_dict.values()) if q_dict else 0)\n",
        "\n",
        "                    # NOTE: keep BOTH q and q_max for compatibility\n",
        "                    diag_list.append({\n",
        "                        \"Stock\": stock, \"Sector\": sector, \"Model\": model_name,\n",
        "                        \"R2\": res_fit.rsquared, \"AdjR2\": res_fit.rsquared_adj,\n",
        "                        \"AIC\": res_fit.aic, \"BIC\": res_fit.bic,\n",
        "                        \"p\": int(p_sel),\n",
        "                        \"q\": q_max_used,\n",
        "                        \"q_max\": q_max_used\n",
        "                    })\n",
        "\n",
        "                    # Walk-forward evaluation\n",
        "                    try:\n",
        "                        wf = walk_forward_evaluate(\n",
        "                            df_model, col, x_list, p=p_sel, q_dict=q_dict,\n",
        "                            train_end=train_end, test_end=test_end\n",
        "                        )\n",
        "                        wf.update({\n",
        "                            \"Stock\": stock, \"Sector\": sector, \"Model\": model_name,\n",
        "                            CRITERION: ic\n",
        "                        })\n",
        "                        forecast_list.append(wf)\n",
        "\n",
        "                        if verbose:\n",
        "                            print(f\"âœ… RMSE: ECM={wf['ECM_RMSE']:.6f} | AR={wf['AR_RMSE']:.6f} | \"\n",
        "                                  f\"RW={wf['RW_RMSE']:.6f} | ECM>AR: {wf['ECM_beats_AR']}\")\n",
        "                    except Exception as e:\n",
        "                        if verbose:\n",
        "                            print(f\"âš ï¸ Walk-forward failed: {e}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    if verbose:\n",
        "                        print(f\"âš ï¸ Failed: {e}\")\n",
        "\n",
        "    # ============================================\n",
        "    # COMPILE RESULTS\n",
        "    # ============================================\n",
        "\n",
        "    df_alpha = pd.DataFrame(alpha_list) if alpha_list else pd.DataFrame()\n",
        "    df_beta = pd.DataFrame(beta_list) if beta_list else pd.DataFrame()\n",
        "    df_gamma = pd.DataFrame(gamma_list) if gamma_list else pd.DataFrame()\n",
        "    df_diag = pd.DataFrame(diag_list) if diag_list else pd.DataFrame()\n",
        "    df_forecast = pd.DataFrame(forecast_list) if forecast_list else pd.DataFrame()\n",
        "\n",
        "    # Model comparison\n",
        "    df_model_comparison = create_enhanced_model_comparison(df_forecast)\n",
        "\n",
        "    return df_alpha, df_beta, df_gamma, df_diag, df_forecast, df_model_comparison\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ§© SECTION 10: PRINT FUNCTIONS\n",
        "# ============================================================\n",
        "\n",
        "def print_best_model_summary(best_models: pd.DataFrame):\n",
        "    \"\"\"Print best model per stock\"\"\"\n",
        "\n",
        "    if best_models is None or best_models.empty:\n",
        "        print(\"\\nâš ï¸ best_models empty â€” nothing to print\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n\" + \"=\"*110)\n",
        "    print(\"ğŸ† BEST MODEL SELECTION PER STOCK\")\n",
        "    print(\"=\"*110)\n",
        "    print(f\"{'Sector':<20} {'Stock':<8} {'Method':<8} {'p':<3} {'q':<3} {'ECM_RMSE':<10} {'AR_RMSE':<10} {'ECM>AR?':<10} {'Recommendation'}\")\n",
        "    print(\"-\"*110)\n",
        "\n",
        "    current_sector = None\n",
        "    for _, row in best_models.iterrows():\n",
        "        sector = row.get(\"Sector\", \"\")\n",
        "        if sector != current_sector:\n",
        "            if current_sector is not None:\n",
        "                print(\"-\"*110)\n",
        "            current_sector = sector\n",
        "\n",
        "        stock = row.get(\"Stock\", \"\")\n",
        "        model = row.get(\"Model\", \"\")\n",
        "        p = row.get(\"p\", \"\")\n",
        "        q = row.get(\"q_max\", row.get(\"q\", \"\"))\n",
        "        ecm_rmse = row.get(\"ECM_RMSE\", np.nan)\n",
        "        ar_rmse = row.get(\"AR_RMSE\", np.nan)\n",
        "        beats_ar = row.get(\"ECM_beats_AR\", \"\")\n",
        "        rec = \"âœ… Use ECM\" if \"Yes\" in str(beats_ar) else \"âš ï¸ Use AR\"\n",
        "\n",
        "        try:\n",
        "            print(f\"{sector:<20} {stock:<8} {model:<8} {p:<3} {q:<3} {float(ecm_rmse):<10.6f} {float(ar_rmse):<10.6f} {beats_ar:<10} {rec}\")\n",
        "        except Exception:\n",
        "            print(f\"{sector:<20} {stock:<8} {model:<8} {p:<3} {q:<3} {ecm_rmse:<10} {ar_rmse:<10} {beats_ar:<10} {rec}\")\n",
        "\n",
        "    print(\"=\"*110)\n",
        "\n",
        "    n_ecm_wins = best_models[\"ECM_beats_AR\"].astype(str).str.contains(\"Yes\", na=False).sum() if \"ECM_beats_AR\" in best_models.columns else 0\n",
        "    n_total = len(best_models)\n",
        "    if n_total > 0:\n",
        "        print(f\"\\nğŸ“Š Summary: ECM outperforms AR in {n_ecm_wins}/{n_total} stocks ({100*n_ecm_wins/n_total:.1f}%)\")\n",
        "\n",
        "def print_lag_selection_table(lag_table: pd.DataFrame):\n",
        "    \"\"\"Print lag selection comparison\"\"\"\n",
        "\n",
        "    if lag_table is None or lag_table.empty:\n",
        "        print(\"\\nâš ï¸ lag_table empty â€” nothing to print\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n\" + \"=\"*120)\n",
        "    print(\"ğŸ“‹ LAG SELECTION COMPARISON TABLE\")\n",
        "    print(\"=\"*120)\n",
        "    print(f\"{'Sector':<18} {'Stock':<8} â”‚ {'FIXED':<15} â”‚ {'ACF/PACF':<15} â”‚ {'AIC-greedy':<15} â”‚ {'Best':<8}\")\n",
        "    print(f\"{'':18} {'':8} â”‚ {'p   q   AIC':<15} â”‚ {'p   q   AIC':<15} â”‚ {'p   q   AIC':<15} â”‚ {'Model':<8}\")\n",
        "    print(\"-\"*120)\n",
        "\n",
        "    current_sector = None\n",
        "    for _, row in lag_table.iterrows():\n",
        "        sector = row.get(\"Sector\", \"\")\n",
        "        if sector != current_sector:\n",
        "            if current_sector is not None:\n",
        "                print(\"-\"*120)\n",
        "            current_sector = sector\n",
        "\n",
        "        stock = row.get(\"Stock\", \"\")\n",
        "\n",
        "        def fmt_model(prefix):\n",
        "            p = row.get(f\"{prefix}_p\", \"-\")\n",
        "            q = row.get(f\"{prefix}_q\", \"-\")\n",
        "            a = row.get(f\"{prefix}_AIC\", np.nan)\n",
        "            a_str = f\"{a:.1f}\" if pd.notna(a) else \"-\"\n",
        "            return f\"{p:<3} {q:<3} {a_str:<9}\"\n",
        "\n",
        "        best = row.get(\"Best_Model\", \"-\")\n",
        "        print(f\"{sector:<18} {stock:<8} â”‚ {fmt_model('FIXED')} â”‚ {fmt_model('ACF')} â”‚ {fmt_model('AIC')} â”‚ {best:<8}\")\n",
        "\n",
        "    print(\"=\"*120)\n",
        "\n",
        "def print_enhanced_model_comparison(comparison: pd.DataFrame):\n",
        "    \"\"\"Print model comparison\"\"\"\n",
        "\n",
        "    if comparison is None or comparison.empty:\n",
        "        print(\"\\nâš ï¸ comparison empty â€” nothing to print\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "    print(\"ğŸ“Š ENHANCED MODEL COMPARISON SUMMARY\")\n",
        "    print(\"=\"*100)\n",
        "    print(f\"\\n{'Model':<10} â”‚ {'ECM RMSE':<20} â”‚ {'AR RMSE':<12} â”‚ {'ECM>AR':<12} â”‚ {'#Best':<8} â”‚ {'Win%':<8}\")\n",
        "    print(f\"{'':10} â”‚ {'mean Â± std':<20} â”‚ {'mean':<12} â”‚ {'(sig p<.05)':<12} â”‚ {'':8} â”‚ {'':8}\")\n",
        "    print(\"-\"*100)\n",
        "\n",
        "    for _, row in comparison.iterrows():\n",
        "        model = row[\"Model\"]\n",
        "        ecm_mean = row[\"ECM_RMSE_mean\"]\n",
        "        ecm_std = row[\"ECM_RMSE_std\"]\n",
        "        ar_mean = row[\"AR_RMSE_mean\"]\n",
        "        beats_ar = row[\"ECM_beats_AR_sig\"]\n",
        "        n_stocks = row[\"n_stocks\"]\n",
        "        times_best = row[\"times_selected_best\"]\n",
        "        win_rate = row[\"ECM_vs_AR_win_rate\"]\n",
        "\n",
        "        print(f\"{model:<10} â”‚ {ecm_mean:.4f} Â± {ecm_std:.4f}   â”‚ {ar_mean:.4f}     â”‚ {int(beats_ar)}/{int(n_stocks):<9} â”‚ {int(times_best):<8} â”‚ {win_rate:.1f}%\")\n",
        "\n",
        "    print(\"=\"*100)\n",
        "\n",
        "    best_model = comparison.loc[comparison[\"ECM_RMSE_mean\"].idxmin(), \"Model\"]\n",
        "    print(f\"\\nğŸ† Recommended Model (lowest avg RMSE): {best_model}\")\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ§© SECTION 11: EXPORT FUNCTION\n",
        "# ============================================================\n",
        "\n",
        "def export_all_results(df_alpha, df_beta, df_gamma, df_diag, df_forecast, df_model_comparison,\n",
        "                       best_models=None, lag_table=None, export_path=EXPORT_PATH):\n",
        "    \"\"\"Export all results to Excel\"\"\"\n",
        "\n",
        "    with pd.ExcelWriter(export_path, engine=\"openpyxl\") as writer:\n",
        "        if df_alpha is not None and not df_alpha.empty:\n",
        "            df_alpha.to_excel(writer, \"Alpha_ECT\", index=False)\n",
        "        if df_beta is not None and not df_beta.empty:\n",
        "            df_beta.to_excel(writer, \"Beta_LongRun\", index=False)\n",
        "        if df_gamma is not None and not df_gamma.empty:\n",
        "            df_gamma.to_excel(writer, \"Gamma_ShortRun\", index=False)\n",
        "        if df_diag is not None and not df_diag.empty:\n",
        "            df_diag.to_excel(writer, \"Diagnostics\", index=False)\n",
        "        if df_forecast is not None and not df_forecast.empty:\n",
        "            df_forecast.to_excel(writer, \"Forecast_Comparison\", index=False)\n",
        "        if df_model_comparison is not None and not df_model_comparison.empty:\n",
        "            df_model_comparison.to_excel(writer, \"Model_Summary\", index=False)\n",
        "        if best_models is not None and not best_models.empty:\n",
        "            best_models.to_excel(writer, \"Best_Model_Per_Stock\", index=False)\n",
        "        if lag_table is not None and not lag_table.empty:\n",
        "            lag_table.to_excel(writer, \"Lag_Selection\", index=False)\n",
        "\n",
        "    print(f\"\\nâœ… Exported â†’ {export_path}\")\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ¯ SECTION 12: RUN BLOCK\n",
        "# ============================================================\n",
        "\n",
        "print(\"\"\"\n",
        "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "â•‘  ğŸš€ BLOCK 3-4: ARDL-ECM ENHANCED V2 (COMPLETE)                               â•‘\n",
        "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
        "â•‘  âœ… ORIGINAL: HAC, Fixed Lag, Long-run Î², ECT, EViews output                 â•‘\n",
        "â•‘  ğŸ†• ADD-ON 1: Multiple Lag Selection (FIXED/ACF/AIC)                         â•‘\n",
        "â•‘  ğŸ†• ADD-ON 2: Walk-Forward Evaluation                                        â•‘\n",
        "â•‘  ğŸ†• ADD-ON 3: Benchmark Models (AR / Random Walk)                            â•‘\n",
        "â•‘  ğŸ†• ADD-ON 4: Diebold-Mariano Test                                           â•‘\n",
        "â•‘  ğŸ†• ADD-ON 5: Per-Variable q Selection                                       â•‘\n",
        "â•‘  ğŸ†• ADD-ON 6: Forecast Metrics (MAE, RMSE, MAPE)                             â•‘\n",
        "â•‘  ğŸ†• ADD-ON 7: Model Comparison Table                                         â•‘\n",
        "â•‘  ğŸ†• ADD-ON 8: Best Model Selection Per Stock                                 â•‘\n",
        "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\"\"\")\n",
        "\n",
        "# ============================================================\n",
        "# ğŸš€ RUN THE ANALYSIS\n",
        "# ============================================================\n",
        "\n",
        "# ============================================================\n",
        "# ğŸš€ RUN THE ANALYSIS (LEVELS PIPELINE)\n",
        "# ============================================================\n",
        "\n",
        "best_models = pd.DataFrame()\n",
        "lag_table = pd.DataFrame()\n",
        "best_model_lookup = {}\n",
        "best_model_details_lookup = {}\n",
        "\n",
        "# âœ… Use LEVELS dict as standard input\n",
        "if 'combined_dfs_for_ecm' in globals() and isinstance(combined_dfs_for_ecm, dict) and combined_dfs_for_ecm:\n",
        "    data_for_ecm = combined_dfs_for_ecm\n",
        "elif 'combined_dfs_levels_for_ecm' in globals() and isinstance(combined_dfs_levels_for_ecm, dict) and combined_dfs_levels_for_ecm:\n",
        "    data_for_ecm = combined_dfs_levels_for_ecm\n",
        "else:\n",
        "    print(\"âš ï¸ No LEVELS data found. Please run Block 2 (LEVELS build) first.\")\n",
        "    data_for_ecm = None\n",
        "\n",
        "if data_for_ecm is not None:\n",
        "    # Run enhanced ARDL-ECM\n",
        "    df_alpha, df_beta, df_gamma, df_diag, df_forecast, df_model_comparison = run_ardl_ecm_enhanced(\n",
        "        combined_dfs_selective_diff=data_for_ecm,  # âœ… à¹ƒà¸Šà¹‰ LEVELS à¸—à¸µà¹ˆà¸•à¸£à¸§à¸ˆà¹€à¸ˆà¸­\n",
        "        macro_vars=macro_vars,\n",
        "        train_end=TRAIN_END,\n",
        "        test_end=TEST_END,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    # Create additional tables\n",
        "    best_models = select_best_model_per_stock(df_forecast, df_diag, criterion=\"ECM_RMSE\")\n",
        "    lag_table = create_lag_selection_table(df_forecast, df_diag)\n",
        "\n",
        "    # Export all results\n",
        "    export_all_results(\n",
        "        df_alpha, df_beta, df_gamma, df_diag, df_forecast, df_model_comparison,\n",
        "        best_models=best_models, lag_table=lag_table,\n",
        "        export_path=EXPORT_PATH\n",
        "    )\n",
        "\n",
        "    # Print summaries\n",
        "    print(\"\\n\" + \"=\"*90)\n",
        "    print(\"ğŸ“Š RESULTS SUMMARY\")\n",
        "    print(\"=\"*90)\n",
        "\n",
        "    print_enhanced_model_comparison(df_model_comparison)\n",
        "    print_best_model_summary(best_models)\n",
        "    print_lag_selection_table(lag_table)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*90)\n",
        "    print(\"ğŸ“‹ EVIEWS-STYLE OUTPUT (FIXED Model)\")\n",
        "    print(\"=\"*90)\n",
        "    eviews_summary_by_sector(df_alpha, df_beta, df_gamma, model_filter=\"FIXED\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*90)\n",
        "    print(\"âœ… BLOCK 3-4 COMPLETE!\")\n",
        "    print(\"=\"*90)\n",
        "\n",
        "    if DEBUG_BEST_MODEL:\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"ğŸ” DEBUG: BEST MODEL SELECTION ANALYSIS (INTERNAL)\")\n",
        "        print(\"=\"*70)\n",
        "        try:\n",
        "            d = df_forecast.copy()\n",
        "            if \"ECM_RMSE\" in d.columns:\n",
        "                d[\"ECM_RMSE\"] = pd.to_numeric(d[\"ECM_RMSE\"], errors=\"coerce\")\n",
        "            print(\"Models present:\\n\", d[\"Model\"].value_counts(dropna=False))\n",
        "            print(\"\\nRMSE summary:\\n\", d.groupby(\"Model\")[\"ECM_RMSE\"].agg([\"count\",\"mean\",\"median\",\"min\",\"max\"]).round(6))\n",
        "            print(\"\\nBest model count:\\n\", best_models[\"Model\"].value_counts(dropna=False))\n",
        "        except Exception as e:\n",
        "            print(\"âš ï¸ Debug failed:\", e)\n",
        "        print(\"=\"*70)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ†• SECTION 13: CREATE BEST MODEL LOOKUP FOR BLOCK 4\n",
        "# ============================================================\n",
        "\n",
        "def create_best_model_lookup(best_models: pd.DataFrame) -> dict:\n",
        "    \"\"\"\n",
        "    à¸ªà¸£à¹‰à¸²à¸‡ dictionary à¸ªà¸³à¸«à¸£à¸±à¸š lookup Best Model à¹ƒà¸™à¹à¸•à¹ˆà¸¥à¸°à¸«à¸¸à¹‰à¸™\n",
        "    Output:\n",
        "      - combined: {(stock, sector): model_name} à¹à¸¥à¸° {stock: model_name}\n",
        "    \"\"\"\n",
        "    lookup_by_stock_sector = {}\n",
        "    lookup_by_stock = {}\n",
        "\n",
        "    if best_models is None or best_models.empty:\n",
        "        return {}\n",
        "\n",
        "    for _, row in best_models.iterrows():\n",
        "        stock = row.get(\"Stock\", None)\n",
        "        sector = row.get(\"Sector\", \"\")\n",
        "        model = row.get(\"Model\", None)\n",
        "        if stock is None or model is None:\n",
        "            continue\n",
        "\n",
        "        # Key à¹à¸šà¸š (stock, sector) à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸£à¸“à¸µ ticker à¸‹à¹‰à¸³à¸‚à¹‰à¸²à¸¡ sector\n",
        "        lookup_by_stock_sector[(stock, sector)] = model\n",
        "\n",
        "        # Key à¹à¸šà¸š stock à¸­à¸¢à¹ˆà¸²à¸‡à¹€à¸”à¸µà¸¢à¸§ (à¹ƒà¸Šà¹‰à¸„à¹ˆà¸²à¹à¸£à¸à¸—à¸µà¹ˆà¹€à¸ˆà¸­)\n",
        "        if stock not in lookup_by_stock:\n",
        "            lookup_by_stock[stock] = model\n",
        "\n",
        "    combined = {}\n",
        "    combined.update(lookup_by_stock_sector)  # {(stock, sector): model}\n",
        "    combined.update(lookup_by_stock)         # {stock: model}\n",
        "    return combined\n",
        "\n",
        "def create_best_model_details_lookup(best_models: pd.DataFrame) -> dict:\n",
        "    \"\"\"\n",
        "    à¹€à¸à¸´à¹ˆà¸¡ lookup à¹à¸šà¸šà¸¥à¸°à¹€à¸­à¸µà¸¢à¸” (à¹€à¸­à¸²à¹„à¸›à¹ƒà¸Šà¹‰ Block 4 à¹„à¸”à¹‰à¹€à¸¥à¸¢)\n",
        "    Output:\n",
        "      - combined: {(stock, sector): {model,p,q_max}} à¹à¸¥à¸° {stock: {model,p,q_max}}\n",
        "    \"\"\"\n",
        "    by_stock_sector = {}\n",
        "    by_stock = {}\n",
        "\n",
        "    if best_models is None or best_models.empty:\n",
        "        return {}\n",
        "\n",
        "    for _, row in best_models.iterrows():\n",
        "        stock = row.get(\"Stock\", None)\n",
        "        sector = row.get(\"Sector\", \"\")\n",
        "        model = row.get(\"Model\", None)\n",
        "        p = row.get(\"p\", None)\n",
        "        q_max = row.get(\"q_max\", row.get(\"q\", None))\n",
        "        if stock is None or model is None:\n",
        "            continue\n",
        "\n",
        "        payload = {\"model\": model, \"p\": p, \"q_max\": q_max, \"sector\": sector}\n",
        "\n",
        "        by_stock_sector[(stock, sector)] = payload\n",
        "        if stock not in by_stock:\n",
        "            by_stock[stock] = payload\n",
        "\n",
        "    combined = {}\n",
        "    combined.update(by_stock_sector)\n",
        "    combined.update(by_stock)\n",
        "    return combined\n",
        "\n",
        "# âœ… à¸ªà¸£à¹‰à¸²à¸‡ lookup dictionary (à¸›à¸¥à¸­à¸”à¸ à¸±à¸¢ à¹„à¸¡à¹ˆà¸à¸±à¸‡à¸–à¹‰à¸² best_models à¸§à¹ˆà¸²à¸‡)\n",
        "best_model_lookup = create_best_model_lookup(best_models)\n",
        "best_model_details_lookup = create_best_model_details_lookup(best_models)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ğŸ”— BEST MODEL LOOKUP (Ready for Block 4)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if not best_model_lookup:\n",
        "    print(\"âš ï¸ best_models empty â€” lookup not created (run Block 2 + this Block first).\")\n",
        "else:\n",
        "    count = 0\n",
        "    for key, model in best_model_lookup.items():\n",
        "        if count >= 10:\n",
        "            break\n",
        "        if isinstance(key, tuple) and len(key) == 2:\n",
        "            stock, sector = key\n",
        "            print(f\"  {stock:<8} ({sector:<15}) â†’ {model}\")\n",
        "            count += 1\n",
        "    print(f\"  ... Total: {len(best_models)} stocks configured\")\n",
        "\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "id": "b2CPwsK26ePJ",
        "outputId": "712a1e78-1a20-40f4-80be-02154881bcb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ECT saved: BBL (Banking) | model=AIC p=2 q_max=4\n",
            "âœ… ECT saved: KBANK (Banking) | model=AIC p=1 q_max=4\n",
            "âœ… ECT saved: KKP (Banking) | model=ACF p=1 q_max=6\n",
            "âœ… ECT saved: KTB (Banking) | model=ACF p=1 q_max=6\n",
            "âœ… ECT saved: TCAP (Banking) | model=AIC p=1 q_max=2\n",
            "âœ… ECT saved: TISCO (Banking) | model=AIC p=2 q_max=4\n",
            "âœ… ECT saved: TTB (Banking) | model=AIC p=1 q_max=2\n",
            "âœ… ECT saved: KTC (Finance_Securities) | model=AIC p=2 q_max=4\n",
            "âœ… ECT saved: AEONTS (Finance_Securities) | model=AIC p=1 q_max=4\n",
            "âœ… ECT saved: JMT (Finance_Securities) | model=AIC p=4 q_max=4\n",
            "âœ… ECT saved: SAWAD (Finance_Securities) | model=AIC p=1 q_max=3\n",
            "\n",
            "âœ… Exported ECT series â†’ Stock_ECT_Series.xlsx\n",
            "\n",
            "ğŸ“Œ df_ect_long head():\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"    display(df_ect_meta\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2015-03-01 00:00:00\",\n        \"max\": \"2015-12-01 00:00:00\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"2015-11-01 00:00:00\",\n          \"2015-04-01 00:00:00\",\n          \"2015-08-01 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sector\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Banking\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Stock\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"BBL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"AIC\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 2,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"q_max\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 4,\n        \"max\": 4,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ECT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11243993095136341,\n        \"min\": -0.33533971305353694,\n        \"max\": 0.04208141699863388,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          -0.046398503241475986\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ECT_L1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0961599358594381,\n        \"min\": -0.33533971305353694,\n        \"max\": -0.046398503241475986,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          -0.0833189746160714\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-adfe7e2f-1073-49e4-9fc9-291d6e289bb9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Sector</th>\n",
              "      <th>Stock</th>\n",
              "      <th>Model</th>\n",
              "      <th>p</th>\n",
              "      <th>q_max</th>\n",
              "      <th>ECT</th>\n",
              "      <th>ECT_L1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015-03-01</td>\n",
              "      <td>Banking</td>\n",
              "      <td>BBL</td>\n",
              "      <td>AIC</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.074125</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015-04-01</td>\n",
              "      <td>Banking</td>\n",
              "      <td>BBL</td>\n",
              "      <td>AIC</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.192180</td>\n",
              "      <td>-0.074125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015-05-01</td>\n",
              "      <td>Banking</td>\n",
              "      <td>BBL</td>\n",
              "      <td>AIC</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.186801</td>\n",
              "      <td>-0.192180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015-06-01</td>\n",
              "      <td>Banking</td>\n",
              "      <td>BBL</td>\n",
              "      <td>AIC</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.335340</td>\n",
              "      <td>-0.186801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015-07-01</td>\n",
              "      <td>Banking</td>\n",
              "      <td>BBL</td>\n",
              "      <td>AIC</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.277851</td>\n",
              "      <td>-0.335340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2015-08-01</td>\n",
              "      <td>Banking</td>\n",
              "      <td>BBL</td>\n",
              "      <td>AIC</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.190972</td>\n",
              "      <td>-0.277851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2015-09-01</td>\n",
              "      <td>Banking</td>\n",
              "      <td>BBL</td>\n",
              "      <td>AIC</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.127154</td>\n",
              "      <td>-0.190972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2015-10-01</td>\n",
              "      <td>Banking</td>\n",
              "      <td>BBL</td>\n",
              "      <td>AIC</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.083319</td>\n",
              "      <td>-0.127154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2015-11-01</td>\n",
              "      <td>Banking</td>\n",
              "      <td>BBL</td>\n",
              "      <td>AIC</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.046399</td>\n",
              "      <td>-0.083319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2015-12-01</td>\n",
              "      <td>Banking</td>\n",
              "      <td>BBL</td>\n",
              "      <td>AIC</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0.042081</td>\n",
              "      <td>-0.046399</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-adfe7e2f-1073-49e4-9fc9-291d6e289bb9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-adfe7e2f-1073-49e4-9fc9-291d6e289bb9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-adfe7e2f-1073-49e4-9fc9-291d6e289bb9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        Date   Sector Stock Model  p  q_max       ECT    ECT_L1\n",
              "0 2015-03-01  Banking   BBL   AIC  2      4 -0.074125       NaN\n",
              "1 2015-04-01  Banking   BBL   AIC  2      4 -0.192180 -0.074125\n",
              "2 2015-05-01  Banking   BBL   AIC  2      4 -0.186801 -0.192180\n",
              "3 2015-06-01  Banking   BBL   AIC  2      4 -0.335340 -0.186801\n",
              "4 2015-07-01  Banking   BBL   AIC  2      4 -0.277851 -0.335340\n",
              "5 2015-08-01  Banking   BBL   AIC  2      4 -0.190972 -0.277851\n",
              "6 2015-09-01  Banking   BBL   AIC  2      4 -0.127154 -0.190972\n",
              "7 2015-10-01  Banking   BBL   AIC  2      4 -0.083319 -0.127154\n",
              "8 2015-11-01  Banking   BBL   AIC  2      4 -0.046399 -0.083319\n",
              "9 2015-12-01  Banking   BBL   AIC  2      4  0.042081 -0.046399"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“Œ df_ect_meta head():\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"    display(df_ect_meta\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Sector\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Banking\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Stock\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"KBANK\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"ACF\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"q_max\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 2,\n        \"max\": 6,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Alpha(ECT_speed)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10175908548477974,\n        \"min\": -0.39518751095579,\n        \"max\": -0.1496630869179517,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.2404393524870368\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Beta0(const)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.190693023338973,\n        \"min\": -3.6202371636806774,\n        \"max\": 4.6310795407777015,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4.6310795407777015\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Beta_BroadMoney_M1M2_Growth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15.738610198576417,\n        \"min\": -39.351724422170406,\n        \"max\": 1.9624523448158036,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -13.39808099869408\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Beta_Inflation_Surprise\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25.650052158461147,\n        \"min\": -0.9934136785522224,\n        \"max\": 62.30278055171698,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          62.30278055171698\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Beta_THOR_6M\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15.592656261682764,\n        \"min\": -13.621212663147395,\n        \"max\": 24.588741456311595,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          21.554326500599238\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Beta_3M_1M_THOR_Spread\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 365.53702167139613,\n        \"min\": -717.4904941896281,\n        \"max\": 84.98087960897494,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -239.1704099785743\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Beta_10Y_5Y_Bond_Spread\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36.69360808652994,\n        \"min\": -41.7303759356659,\n        \"max\": 45.53183154562701,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          45.53183154562701\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Beta_THB_per_USD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03985431720701706,\n        \"min\": -0.004493414933168466,\n        \"max\": 0.09719961777259288,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.004493414933168466\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Beta_SET_Index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0004141932248645804,\n        \"min\": 0.0004038192547642988,\n        \"max\": 0.0013401583689461832,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.0004038192547642988\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Beta_SP500_Index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00013742108924358256,\n        \"min\": 1.0042328823894901e-05,\n        \"max\": 0.0003358576644624342,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4.233031508326139e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Beta_THB_per_CNY\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.675223426592113,\n        \"min\": 3.441272152543154,\n        \"max\": 14.292459841849043,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3.441272152543154\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Beta_GDP_Growth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.9048523458457038,\n        \"min\": -0.4293636233803625,\n        \"max\": 4.7504677679847935,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4.7504677679847935\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Beta_THB_per_INR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.38171846293652983,\n        \"min\": -1.276199351149354,\n        \"max\": -0.34154849532202697,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.7380327769398172\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-39c5a746-ac0c-4e45-889d-b2bdcd38a925\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sector</th>\n",
              "      <th>Stock</th>\n",
              "      <th>Model</th>\n",
              "      <th>p</th>\n",
              "      <th>q_max</th>\n",
              "      <th>Alpha(ECT_speed)</th>\n",
              "      <th>Beta0(const)</th>\n",
              "      <th>Beta_BroadMoney_M1M2_Growth</th>\n",
              "      <th>Beta_Inflation_Surprise</th>\n",
              "      <th>Beta_THOR_6M</th>\n",
              "      <th>Beta_3M_1M_THOR_Spread</th>\n",
              "      <th>Beta_10Y_5Y_Bond_Spread</th>\n",
              "      <th>Beta_THB_per_USD</th>\n",
              "      <th>Beta_SET_Index</th>\n",
              "      <th>Beta_SP500_Index</th>\n",
              "      <th>Beta_THB_per_CNY</th>\n",
              "      <th>Beta_GDP_Growth</th>\n",
              "      <th>Beta_THB_per_INR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Banking</td>\n",
              "      <td>BBL</td>\n",
              "      <td>AIC</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.205292</td>\n",
              "      <td>3.220258</td>\n",
              "      <td>-9.192745</td>\n",
              "      <td>40.418118</td>\n",
              "      <td>15.888724</td>\n",
              "      <td>84.980880</td>\n",
              "      <td>26.401112</td>\n",
              "      <td>0.009936</td>\n",
              "      <td>0.000603</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>3.543784</td>\n",
              "      <td>0.948477</td>\n",
              "      <td>-0.341548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Banking</td>\n",
              "      <td>KBANK</td>\n",
              "      <td>AIC</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.240439</td>\n",
              "      <td>4.631080</td>\n",
              "      <td>-13.398081</td>\n",
              "      <td>62.302781</td>\n",
              "      <td>21.554327</td>\n",
              "      <td>-239.170410</td>\n",
              "      <td>45.531832</td>\n",
              "      <td>-0.004493</td>\n",
              "      <td>0.000404</td>\n",
              "      <td>0.000042</td>\n",
              "      <td>3.441272</td>\n",
              "      <td>4.750468</td>\n",
              "      <td>-0.738033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Banking</td>\n",
              "      <td>KKP</td>\n",
              "      <td>ACF</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>-0.348917</td>\n",
              "      <td>0.036499</td>\n",
              "      <td>-5.390737</td>\n",
              "      <td>8.438734</td>\n",
              "      <td>-13.621213</td>\n",
              "      <td>-696.386705</td>\n",
              "      <td>-41.730376</td>\n",
              "      <td>0.023215</td>\n",
              "      <td>0.001340</td>\n",
              "      <td>0.000336</td>\n",
              "      <td>14.292460</td>\n",
              "      <td>-0.429364</td>\n",
              "      <td>-1.276199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Banking</td>\n",
              "      <td>KTB</td>\n",
              "      <td>ACF</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>-0.149663</td>\n",
              "      <td>-3.620237</td>\n",
              "      <td>-39.351724</td>\n",
              "      <td>37.440407</td>\n",
              "      <td>24.588741</td>\n",
              "      <td>-717.490494</td>\n",
              "      <td>-17.360256</td>\n",
              "      <td>0.097200</td>\n",
              "      <td>0.001197</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>5.673254</td>\n",
              "      <td>2.125895</td>\n",
              "      <td>-0.358313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Banking</td>\n",
              "      <td>TCAP</td>\n",
              "      <td>AIC</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.395188</td>\n",
              "      <td>0.404725</td>\n",
              "      <td>1.962452</td>\n",
              "      <td>-0.993414</td>\n",
              "      <td>4.099865</td>\n",
              "      <td>-66.044508</td>\n",
              "      <td>-24.491985</td>\n",
              "      <td>0.015346</td>\n",
              "      <td>0.000590</td>\n",
              "      <td>0.000250</td>\n",
              "      <td>9.930630</td>\n",
              "      <td>1.704036</td>\n",
              "      <td>-0.591986</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39c5a746-ac0c-4e45-889d-b2bdcd38a925')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-39c5a746-ac0c-4e45-889d-b2bdcd38a925 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-39c5a746-ac0c-4e45-889d-b2bdcd38a925');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    Sector  Stock Model  p  q_max  Alpha(ECT_speed)  Beta0(const)  \\\n",
              "0  Banking    BBL   AIC  2      4         -0.205292      3.220258   \n",
              "1  Banking  KBANK   AIC  1      4         -0.240439      4.631080   \n",
              "2  Banking    KKP   ACF  1      6         -0.348917      0.036499   \n",
              "3  Banking    KTB   ACF  1      6         -0.149663     -3.620237   \n",
              "4  Banking   TCAP   AIC  1      2         -0.395188      0.404725   \n",
              "\n",
              "   Beta_BroadMoney_M1M2_Growth  Beta_Inflation_Surprise  Beta_THOR_6M  \\\n",
              "0                    -9.192745                40.418118     15.888724   \n",
              "1                   -13.398081                62.302781     21.554327   \n",
              "2                    -5.390737                 8.438734    -13.621213   \n",
              "3                   -39.351724                37.440407     24.588741   \n",
              "4                     1.962452                -0.993414      4.099865   \n",
              "\n",
              "   Beta_3M_1M_THOR_Spread  Beta_10Y_5Y_Bond_Spread  Beta_THB_per_USD  \\\n",
              "0               84.980880                26.401112          0.009936   \n",
              "1             -239.170410                45.531832         -0.004493   \n",
              "2             -696.386705               -41.730376          0.023215   \n",
              "3             -717.490494               -17.360256          0.097200   \n",
              "4              -66.044508               -24.491985          0.015346   \n",
              "\n",
              "   Beta_SET_Index  Beta_SP500_Index  Beta_THB_per_CNY  Beta_GDP_Growth  \\\n",
              "0        0.000603          0.000010          3.543784         0.948477   \n",
              "1        0.000404          0.000042          3.441272         4.750468   \n",
              "2        0.001340          0.000336         14.292460        -0.429364   \n",
              "3        0.001197          0.000176          5.673254         2.125895   \n",
              "4        0.000590          0.000250          9.930630         1.704036   \n",
              "\n",
              "   Beta_THB_per_INR  \n",
              "0         -0.341548  \n",
              "1         -0.738033  \n",
              "2         -1.276199  \n",
              "3         -0.358313  \n",
              "4         -0.591986  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ============================================================\n",
        "# ğŸ†• SECTION 14: SAVE ECT_t SERIES (Time Series) PER STOCK\n",
        "# ============================================================\n",
        "# Output:\n",
        "#   - df_ect_long: long format (Date, Sector, Stock, Model, ECT_t, ECT_L1)\n",
        "#   - df_ect_meta: per-stock meta (alpha, beta0, betas...)\n",
        "#   - Export Excel: Stock_ECT_Series.xlsx\n",
        "# ============================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "ECT_EXPORT_PATH = \"Stock_ECT_Series.xlsx\"\n",
        "\n",
        "def _safe_get_best_model(stock: str, sector: str, best_model_lookup=None, best_models=None, default=\"FIXED\"):\n",
        "    \"\"\"\n",
        "    Priority:\n",
        "      1) best_model_lookup[(stock, sector)]\n",
        "      2) best_model_lookup[stock]\n",
        "      3) best_models table\n",
        "      4) default\n",
        "    \"\"\"\n",
        "    if best_model_lookup is not None:\n",
        "        if (stock, sector) in best_model_lookup:\n",
        "            return str(best_model_lookup[(stock, sector)])\n",
        "        if stock in best_model_lookup:\n",
        "            return str(best_model_lookup[stock])\n",
        "\n",
        "    if best_models is not None and not best_models.empty:\n",
        "        bm = best_models.copy()\n",
        "        if \"Stock\" in bm.columns and \"Model\" in bm.columns:\n",
        "            hit = bm[bm[\"Stock\"].astype(str) == str(stock)]\n",
        "            if not hit.empty:\n",
        "                return str(hit[\"Model\"].iloc[0])\n",
        "\n",
        "    return str(default)\n",
        "\n",
        "def _refit_model_for_ect(y: pd.Series, X: pd.DataFrame, model_name: str):\n",
        "    \"\"\"\n",
        "    Refit ECM using the same lag-selection method to recover p and q_dict,\n",
        "    then return (p_sel, q_dict, ecm_fit)\n",
        "    \"\"\"\n",
        "    model_name = str(model_name).upper().strip()\n",
        "\n",
        "    if model_name == \"FIXED\":\n",
        "        p_sel, q_dict, ecm_fit, _ = select_pq_FIXED(y, X, p_fixed=LAG_Y, q_fixed=LAG_X, criterion=CRITERION)\n",
        "    elif model_name == \"ACF\":\n",
        "        p_sel, q_dict, ecm_fit, _ = select_pq_ACF(y, X, p_min=P_MIN, p_max=P_MAX, q_cap=Q_CAP, criterion=CRITERION)\n",
        "    elif model_name == \"AIC\":\n",
        "        p_sel, q_dict, ecm_fit, _ = select_pq_AIC(y, X, p_min=P_MIN, p_max=P_MAX, q_max=Q_MAX_AIC, criterion=CRITERION)\n",
        "    else:\n",
        "        # fallback\n",
        "        p_sel, q_dict, ecm_fit, _ = select_pq_FIXED(y, X, p_fixed=LAG_Y, q_fixed=LAG_X, criterion=CRITERION)\n",
        "\n",
        "    return int(p_sel), dict(q_dict), ecm_fit\n",
        "\n",
        "def compute_ect_series(df_model: pd.DataFrame, y_col: str, x_cols: list, ecm_fit):\n",
        "    \"\"\"\n",
        "    ECT_t = y_t - (beta0 + sum(beta_m * x_{m,t}))\n",
        "    where:\n",
        "      alpha = coef on L1.y\n",
        "      beta0 = -const/alpha\n",
        "      beta_m = -coef(L1.x_m)/alpha\n",
        "\n",
        "    Returns:\n",
        "      - ect_df: index=date, columns=[ECT, ECT_L1]\n",
        "      - meta: dict with alpha, beta0, betas\n",
        "    \"\"\"\n",
        "    params = ecm_fit.params\n",
        "\n",
        "    alpha_key = f\"L1.{y_col}\"\n",
        "    alpha = float(params.get(alpha_key, np.nan))\n",
        "\n",
        "    if (not np.isfinite(alpha)) or (abs(alpha) < 1e-12):\n",
        "        raise ValueError(f\"Invalid alpha for ECT (alpha={alpha})\")\n",
        "\n",
        "    const = float(params.get(\"const\", 0.0))\n",
        "    beta0 = float(-const / alpha)\n",
        "\n",
        "    betas = {}\n",
        "    for m in x_cols:\n",
        "        k = f\"L1.{m}\"\n",
        "        if k in params.index:\n",
        "            betas[m] = float(-params[k] / alpha)\n",
        "        else:\n",
        "            betas[m] = 0.0\n",
        "\n",
        "    y = df_model[y_col].astype(float)\n",
        "    X = df_model[x_cols].astype(float)\n",
        "\n",
        "    ect = y - beta0\n",
        "    for m, b in betas.items():\n",
        "        ect = ect - b * X[m]\n",
        "\n",
        "    ect_df = pd.DataFrame({\n",
        "        \"ECT\": ect,\n",
        "        \"ECT_L1\": ect.shift(1)\n",
        "    }, index=df_model.index)\n",
        "\n",
        "    meta = {\n",
        "        \"Alpha(ECT_speed)\": alpha,\n",
        "        \"Beta0(const)\": beta0,\n",
        "        **{f\"Beta_{m}\": b for m, b in betas.items()}\n",
        "    }\n",
        "    return ect_df, meta\n",
        "\n",
        "def build_all_ect_series(combined_dfs_selective_diff: dict,\n",
        "                         macro_vars: list,\n",
        "                         best_model_lookup=None,\n",
        "                         best_models: pd.DataFrame = None,\n",
        "                         min_obs: int = MIN_OBS,\n",
        "                         verbose: bool = True):\n",
        "    \"\"\"\n",
        "    Build ECT time series for each stock (best model per stock)\n",
        "    Returns:\n",
        "      - df_ect_long (long format)\n",
        "      - df_ect_meta (per-stock meta)\n",
        "    \"\"\"\n",
        "    ect_rows = []\n",
        "    meta_rows = []\n",
        "\n",
        "    for sector, df_sec in combined_dfs_selective_diff.items():\n",
        "        if df_sec is None or df_sec.empty:\n",
        "            continue\n",
        "\n",
        "        x_list = [v for v in macro_vars if v in df_sec.columns]\n",
        "        if not x_list:\n",
        "            if verbose:\n",
        "                print(f\"âš ï¸ Sector {sector}: no macro vars found\")\n",
        "            continue\n",
        "\n",
        "        for col in df_sec.columns:\n",
        "            if not str(col).startswith(\"Logclose_\"):\n",
        "                continue\n",
        "\n",
        "            stock = str(col).replace(\"Logclose_\", \"\")\n",
        "            df_model = df_sec[[col] + x_list].dropna().copy()\n",
        "\n",
        "            if len(df_model) < min_obs:\n",
        "                if verbose:\n",
        "                    print(f\"âš ï¸ Skip {stock} ({sector}): insufficient data ({len(df_model)})\")\n",
        "                continue\n",
        "\n",
        "            y = df_model[col].copy()\n",
        "            y.name = col\n",
        "            X = df_model[x_list].copy()\n",
        "\n",
        "            # pick best model\n",
        "            best_model = _safe_get_best_model(stock, sector, best_model_lookup, best_models, default=\"FIXED\")\n",
        "\n",
        "            try:\n",
        "                p_sel, q_dict, ecm_fit = _refit_model_for_ect(y, X, best_model)\n",
        "                ect_df, meta = compute_ect_series(df_model, col, x_list, ecm_fit)\n",
        "\n",
        "                # save long rows\n",
        "                tmp = ect_df.reset_index().rename(columns={\"index\": \"Date\"})\n",
        "                tmp[\"Sector\"] = sector\n",
        "                tmp[\"Stock\"] = stock\n",
        "                tmp[\"Model\"] = best_model\n",
        "                tmp[\"p\"] = p_sel\n",
        "                tmp[\"q_max\"] = int(max(q_dict.values()) if q_dict else 0)\n",
        "\n",
        "                # ensure date col name\n",
        "                if \"Date\" not in tmp.columns:\n",
        "                    tmp = tmp.rename(columns={tmp.columns[0]: \"Date\"})\n",
        "\n",
        "                ect_rows.append(tmp[[\"Date\", \"Sector\", \"Stock\", \"Model\", \"p\", \"q_max\", \"ECT\", \"ECT_L1\"]])\n",
        "\n",
        "                meta_row = {\"Sector\": sector, \"Stock\": stock, \"Model\": best_model, \"p\": p_sel, \"q_max\": int(max(q_dict.values()) if q_dict else 0)}\n",
        "                meta_row.update(meta)\n",
        "                meta_rows.append(meta_row)\n",
        "\n",
        "                if verbose:\n",
        "                    print(f\"âœ… ECT saved: {stock} ({sector}) | model={best_model} p={p_sel} q_max={meta_row['q_max']}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                if verbose:\n",
        "                    print(f\"âš ï¸ ECT failed: {stock} ({sector}) | model={best_model} | {e}\")\n",
        "                continue\n",
        "\n",
        "    df_ect_long = pd.concat(ect_rows, axis=0, ignore_index=True) if ect_rows else pd.DataFrame()\n",
        "    df_ect_meta = pd.DataFrame(meta_rows) if meta_rows else pd.DataFrame()\n",
        "\n",
        "    return df_ect_long, df_ect_meta\n",
        "\n",
        "def export_ect_series(df_ect_long: pd.DataFrame, df_ect_meta: pd.DataFrame, path: str = ECT_EXPORT_PATH):\n",
        "    with pd.ExcelWriter(path, engine=\"openpyxl\") as writer:\n",
        "        if df_ect_long is not None and not df_ect_long.empty:\n",
        "            df_ect_long.to_excel(writer, \"ECT_Series\", index=False)\n",
        "        if df_ect_meta is not None and not df_ect_meta.empty:\n",
        "            df_ect_meta.to_excel(writer, \"ECT_Meta\", index=False)\n",
        "    print(f\"\\nâœ… Exported ECT series â†’ {path}\")\n",
        "\n",
        "# ============================================================\n",
        "# âœ… RUN: BUILD + EXPORT ECT SERIES (LEVELS PIPELINE)\n",
        "# ============================================================\n",
        "\n",
        "# âœ… choose the correct dict for ECT (prefer LEVELS)\n",
        "if 'combined_dfs_for_ecm' in globals() and isinstance(combined_dfs_for_ecm, dict) and combined_dfs_for_ecm:\n",
        "    data_for_ect = combined_dfs_for_ecm\n",
        "elif 'combined_dfs_levels_for_ecm' in globals() and isinstance(combined_dfs_levels_for_ecm, dict) and combined_dfs_levels_for_ecm:\n",
        "    data_for_ect = combined_dfs_levels_for_ecm\n",
        "else:\n",
        "    print(\"âš ï¸ No LEVELS data found. Please run Block 2 (LEVELS build) first.\")\n",
        "    data_for_ect = None\n",
        "\n",
        "if data_for_ect is not None:\n",
        "    # best_model_lookup / best_models should exist from your Block 3-4 run\n",
        "    _bml = best_model_lookup if 'best_model_lookup' in globals() else None\n",
        "    _bm  = best_models if 'best_models' in globals() else None\n",
        "\n",
        "    df_ect_long, df_ect_meta = build_all_ect_series(\n",
        "        combined_dfs_selective_diff=data_for_ect,  # âœ… à¹ƒà¸Šà¹‰ LEVELS à¸—à¸µà¹ˆà¸•à¸£à¸§à¸ˆà¹€à¸ˆà¸­\n",
        "        macro_vars=macro_vars,\n",
        "        best_model_lookup=_bml,\n",
        "        best_models=_bm,\n",
        "        min_obs=MIN_OBS,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    export_ect_series(df_ect_long, df_ect_meta, path=ECT_EXPORT_PATH)\n",
        "\n",
        "    print(\"\\nğŸ“Œ df_ect_long head():\")\n",
        "    display(df_ect_long.head(10))\n",
        "    print(\"\\nğŸ“Œ df_ect_meta head():\")\n",
        "    display(df_ect_meta.head(5))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCEPLVCfKEo4",
        "outputId": "ca022f57-03e3-4507-af67-5e22fda14a24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "ğŸ” DEBUG: BEST MODEL SELECTION ANALYSIS (ROBUST)\n",
            "======================================================================\n",
            "ğŸ§¾ Detected columns: stock=Stock, sector=Sector, model=Model, rmse=ECM_RMSE\n",
            "\n",
            "ğŸ“Š Models in df_forecast:\n",
            "Model\n",
            "FIXED    11\n",
            "ACF      11\n",
            "AIC      11\n",
            "Name: count, dtype: int64\n",
            "\n",
            "âœ… Has all 3 models? YES\n",
            "\n",
            "ğŸ“Š ECM_RMSE Summary by Model:\n",
            "       count      mean    median       min       max\n",
            "Model                                               \n",
            "ACF       11  0.154166  0.122048  0.052103  0.276962\n",
            "AIC       11  0.121271  0.119191  0.043696  0.230849\n",
            "FIXED     11  0.157891  0.132373  0.073710  0.269580\n",
            "\n",
            "ğŸ“Š Best Model per Stock (by ECM_RMSE then AIC):\n",
            " Stock             Sector Model  ECM_RMSE         AIC\n",
            "AEONTS Finance_Securities   AIC  0.151038 -259.576527\n",
            "   BBL            Banking   AIC  0.069408 -354.667397\n",
            "   JMT Finance_Securities   AIC  0.230849 -158.985455\n",
            " KBANK            Banking   AIC  0.089876 -284.286877\n",
            "   KKP            Banking   ACF  0.109027 -258.351729\n",
            "   KTB            Banking   ACF  0.122048 -300.928492\n",
            "   KTC Finance_Securities   AIC  0.209077 -191.269902\n",
            " SAWAD Finance_Securities   AIC  0.150245 -206.430709\n",
            "  TCAP            Banking   AIC  0.065934 -335.608264\n",
            " TISCO            Banking   AIC  0.043696 -379.451881\n",
            "   TTB            Banking   AIC  0.082404 -288.710709\n",
            "\n",
            "ğŸ“Š Model Selection Count:\n",
            "Model\n",
            "AIC    9\n",
            "ACF    2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ğŸ Win rate of BEST model vs AR: 36.4% | vs RW: 27.3%\n",
            "\n",
            "ğŸ“Š best_models DataFrame (head 15):\n",
            "ğŸ§¾ Detected columns: stock=Stock, sector=Sector, model=Model, rmse=ECM_RMSE\n",
            " Stock             Sector Model  ECM_RMSE\n",
            "   BBL            Banking   AIC  0.069408\n",
            " KBANK            Banking   AIC  0.089876\n",
            "   KKP            Banking   ACF  0.109027\n",
            "   KTB            Banking   ACF  0.122048\n",
            "  TCAP            Banking   AIC  0.065934\n",
            " TISCO            Banking   AIC  0.043696\n",
            "   TTB            Banking   AIC  0.082404\n",
            "AEONTS Finance_Securities   AIC  0.151038\n",
            "   JMT Finance_Securities   AIC  0.230849\n",
            "   KTC Finance_Securities   AIC  0.209077\n",
            " SAWAD Finance_Securities   AIC  0.150245\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# ğŸ” DEBUG: Best Model Selection (Robust to column names)\n",
        "# ============================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ğŸ” DEBUG: BEST MODEL SELECTION ANALYSIS (ROBUST)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "def _pick_col(df, candidates):\n",
        "    for c in candidates:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "def _coerce_numeric(s):\n",
        "    return pd.to_numeric(s, errors=\"coerce\")\n",
        "\n",
        "if 'df_forecast' in dir() and df_forecast is not None and not df_forecast.empty:\n",
        "\n",
        "    # --- Detect column names (supports both conventions) ---\n",
        "    col_model  = _pick_col(df_forecast, [\"Model\", \"model\"])\n",
        "    col_stock  = _pick_col(df_forecast, [\"Stock\", \"ticker\"])\n",
        "    col_sector = _pick_col(df_forecast, [\"Sector\", \"sector\"])\n",
        "    col_rmse   = _pick_col(df_forecast, [\"ECM_RMSE\", \"ecm_rmse\"])\n",
        "\n",
        "    print(\"ğŸ§¾ Detected columns:\",\n",
        "          f\"stock={col_stock}, sector={col_sector}, model={col_model}, rmse={col_rmse}\")\n",
        "\n",
        "    # Basic sanity checks\n",
        "    missing = [k for k, v in {\n",
        "        \"stock\": col_stock, \"sector\": col_sector, \"model\": col_model, \"rmse\": col_rmse\n",
        "    }.items() if v is None]\n",
        "    if missing:\n",
        "        print(f\"âš ï¸ Missing required columns: {missing}\")\n",
        "        print(\"Available columns:\", list(df_forecast.columns))\n",
        "    else:\n",
        "        # make working copy\n",
        "        d = df_forecast.copy()\n",
        "        d[col_rmse] = _coerce_numeric(d[col_rmse])\n",
        "\n",
        "        # 1) Models present\n",
        "        print(\"\\nğŸ“Š Models in df_forecast:\")\n",
        "        print(d[col_model].value_counts(dropna=False))\n",
        "\n",
        "        # check if 3 models exist\n",
        "        expected = {\"FIXED\", \"ACF\", \"AIC\"}\n",
        "        present = set(d[col_model].dropna().astype(str).unique())\n",
        "        print(\"\\nâœ… Has all 3 models?\" , \"YES\" if expected.issubset(present) else f\"NO (present={sorted(present)})\")\n",
        "\n",
        "        # 2) RMSE summary per model\n",
        "        print(\"\\nğŸ“Š ECM_RMSE Summary by Model:\")\n",
        "        rmse_summary = d.groupby(col_model)[col_rmse].agg([\"count\",\"mean\",\"median\",\"min\",\"max\"]).round(6)\n",
        "        print(rmse_summary)\n",
        "\n",
        "        # 3) Best model per stock (by RMSE) with tie-break: lowest AIC if exists\n",
        "        col_aic = _pick_col(d, [\"AIC\", \"aic\"])\n",
        "        use_tie = col_aic is not None\n",
        "        if use_tie:\n",
        "            d[col_aic] = _coerce_numeric(d[col_aic])\n",
        "\n",
        "        # drop rows with missing rmse/stock/model\n",
        "        d2 = d.dropna(subset=[col_stock, col_model, col_rmse]).copy()\n",
        "\n",
        "        # rank by RMSE then AIC (if available)\n",
        "        sort_cols = [col_stock, col_rmse] + ([col_aic] if use_tie else [])\n",
        "        d2 = d2.sort_values(sort_cols, ascending=[True, True] + ([True] if use_tie else []))\n",
        "\n",
        "        best_per_stock = d2.groupby(col_stock, as_index=False).head(1)\n",
        "\n",
        "        show_cols = [col_stock, col_sector, col_model, col_rmse]\n",
        "        if use_tie: show_cols += [col_aic]\n",
        "\n",
        "        print(\"\\nğŸ“Š Best Model per Stock (by ECM_RMSE\" + (\" then AIC\" if use_tie else \"\") + \"):\")\n",
        "        print(best_per_stock[show_cols].to_string(index=False))\n",
        "\n",
        "        # 4) Count selections\n",
        "        print(\"\\nğŸ“Š Model Selection Count:\")\n",
        "        print(best_per_stock[col_model].value_counts())\n",
        "\n",
        "        # Extra: check if ECM is really beating AR/RW or not\n",
        "        col_ar = _pick_col(d, [\"AR_RMSE\", \"ar_rmse\"])\n",
        "        col_rw = _pick_col(d, [\"RW_RMSE\", \"rw_rmse\"])\n",
        "        if col_ar and col_rw:\n",
        "            d[col_ar] = _coerce_numeric(d[col_ar])\n",
        "            d[col_rw] = _coerce_numeric(d[col_rw])\n",
        "            tmp = best_per_stock.copy()\n",
        "            win_ar = (tmp[col_rmse] < tmp[col_ar]).mean() * 100\n",
        "            win_rw = (tmp[col_rmse] < tmp[col_rw]).mean() * 100\n",
        "            print(f\"\\nğŸ Win rate of BEST model vs AR: {win_ar:.1f}% | vs RW: {win_rw:.1f}%\")\n",
        "\n",
        "else:\n",
        "    print(\"âš ï¸ df_forecast not found or empty\")\n",
        "\n",
        "# 5) Check best_models DataFrame (supports both conventions)\n",
        "if 'best_models' in dir() and best_models is not None and not best_models.empty:\n",
        "    bm = best_models.copy()\n",
        "    bm_stock  = _pick_col(bm, [\"Stock\", \"ticker\"])\n",
        "    bm_sector = _pick_col(bm, [\"Sector\", \"sector\"])\n",
        "    bm_model  = _pick_col(bm, [\"Model\", \"model\"])\n",
        "    bm_rmse   = _pick_col(bm, [\"ECM_RMSE\", \"ecm_rmse\"])\n",
        "\n",
        "    print(\"\\nğŸ“Š best_models DataFrame (head 15):\")\n",
        "    print(\"ğŸ§¾ Detected columns:\",\n",
        "          f\"stock={bm_stock}, sector={bm_sector}, model={bm_model}, rmse={bm_rmse}\")\n",
        "\n",
        "    if None in [bm_stock, bm_sector, bm_model, bm_rmse]:\n",
        "        print(\"âš ï¸ best_models is missing required columns.\")\n",
        "        print(\"Available columns:\", list(bm.columns))\n",
        "    else:\n",
        "        bm[bm_rmse] = _coerce_numeric(bm[bm_rmse])\n",
        "        print(bm[[bm_stock, bm_sector, bm_model, bm_rmse]].head(15).to_string(index=False))\n",
        "else:\n",
        "    print(\"âš ï¸ best_models not found or empty\")\n",
        "\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpH9jpf15N6x"
      },
      "source": [
        "# Forecast Return from ARDL + ECM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "id": "YDAjcIDp5NbX",
        "outputId": "9722373b-ff2d-460f-c110-21818ca4477c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "ğŸš€ FORECASTING WITH BEST MODEL PER STOCK\n",
            "================================================================================\n",
            "âœ… BBL      | Sector=Banking              | Model=AIC   | Î”Å¶=-0.33380\n",
            "âœ… KBANK    | Sector=Banking              | Model=AIC   | Î”Å¶=-0.06884\n",
            "âœ… KKP      | Sector=Banking              | Model=ACF   | Î”Å¶=-2.17010\n",
            "âœ… KTB      | Sector=Banking              | Model=ACF   | Î”Å¶=-0.87348\n",
            "âœ… TCAP     | Sector=Banking              | Model=AIC   | Î”Å¶=-1.36086\n",
            "âœ… TISCO    | Sector=Banking              | Model=AIC   | Î”Å¶=-2.00702\n",
            "âœ… TTB      | Sector=Banking              | Model=AIC   | Î”Å¶=+0.60038\n",
            "âœ… KTC      | Sector=Finance_Securities   | Model=AIC   | Î”Å¶=+4.09609\n",
            "âœ… AEONTS   | Sector=Finance_Securities   | Model=AIC   | Î”Å¶=+1.58516\n",
            "âœ… JMT      | Sector=Finance_Securities   | Model=AIC   | Î”Å¶=+4.43700\n",
            "âœ… SAWAD    | Sector=Finance_Securities   | Model=AIC   | Î”Å¶=+0.51349\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_forecast_summary\",\n  \"rows\": 11,\n  \"fields\": [\n    {\n      \"column\": \"Stock\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"TISCO\",\n          \"BBL\",\n          \"JMT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sector\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Finance_Securities\",\n          \"Banking\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"ACF\",\n          \"AIC\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pred_dLogclose\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.220269085701383,\n        \"min\": -2.1701027796092283,\n        \"max\": 4.4370043528276675,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          -2.007022869304227,\n          -0.33379672691944995\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Expected_Return_%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 222.02690857013832,\n        \"min\": -217.01027796092282,\n        \"max\": 443.70043528276676,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          -200.7022869304227,\n          -33.379672691945\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Action\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"BUY\",\n          \"SELL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Signal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_forecast_summary"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-44230869-65bb-4085-be94-9baae7b6d05d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Stock</th>\n",
              "      <th>Sector</th>\n",
              "      <th>Model</th>\n",
              "      <th>Pred_dLogclose</th>\n",
              "      <th>Expected_Return_%</th>\n",
              "      <th>Action</th>\n",
              "      <th>Signal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BBL</td>\n",
              "      <td>Banking</td>\n",
              "      <td>AIC</td>\n",
              "      <td>-0.333797</td>\n",
              "      <td>-33.379673</td>\n",
              "      <td>SELL</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KBANK</td>\n",
              "      <td>Banking</td>\n",
              "      <td>AIC</td>\n",
              "      <td>-0.068835</td>\n",
              "      <td>-6.883527</td>\n",
              "      <td>SELL</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>KKP</td>\n",
              "      <td>Banking</td>\n",
              "      <td>ACF</td>\n",
              "      <td>-2.170103</td>\n",
              "      <td>-217.010278</td>\n",
              "      <td>SELL</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>KTB</td>\n",
              "      <td>Banking</td>\n",
              "      <td>ACF</td>\n",
              "      <td>-0.873482</td>\n",
              "      <td>-87.348237</td>\n",
              "      <td>SELL</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TCAP</td>\n",
              "      <td>Banking</td>\n",
              "      <td>AIC</td>\n",
              "      <td>-1.360856</td>\n",
              "      <td>-136.085553</td>\n",
              "      <td>SELL</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>TISCO</td>\n",
              "      <td>Banking</td>\n",
              "      <td>AIC</td>\n",
              "      <td>-2.007023</td>\n",
              "      <td>-200.702287</td>\n",
              "      <td>SELL</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>TTB</td>\n",
              "      <td>Banking</td>\n",
              "      <td>AIC</td>\n",
              "      <td>0.600378</td>\n",
              "      <td>60.037752</td>\n",
              "      <td>BUY</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>KTC</td>\n",
              "      <td>Finance_Securities</td>\n",
              "      <td>AIC</td>\n",
              "      <td>4.096094</td>\n",
              "      <td>409.609378</td>\n",
              "      <td>BUY</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>AEONTS</td>\n",
              "      <td>Finance_Securities</td>\n",
              "      <td>AIC</td>\n",
              "      <td>1.585164</td>\n",
              "      <td>158.516378</td>\n",
              "      <td>BUY</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>JMT</td>\n",
              "      <td>Finance_Securities</td>\n",
              "      <td>AIC</td>\n",
              "      <td>4.437004</td>\n",
              "      <td>443.700435</td>\n",
              "      <td>BUY</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>SAWAD</td>\n",
              "      <td>Finance_Securities</td>\n",
              "      <td>AIC</td>\n",
              "      <td>0.513485</td>\n",
              "      <td>51.348509</td>\n",
              "      <td>BUY</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44230869-65bb-4085-be94-9baae7b6d05d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-44230869-65bb-4085-be94-9baae7b6d05d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-44230869-65bb-4085-be94-9baae7b6d05d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_7ac804c6-d62a-4cfd-904a-26767d8b251b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_forecast_summary')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7ac804c6-d62a-4cfd-904a-26767d8b251b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_forecast_summary');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     Stock              Sector Model  Pred_dLogclose  Expected_Return_%  \\\n",
              "0      BBL             Banking   AIC       -0.333797         -33.379673   \n",
              "1    KBANK             Banking   AIC       -0.068835          -6.883527   \n",
              "2      KKP             Banking   ACF       -2.170103        -217.010278   \n",
              "3      KTB             Banking   ACF       -0.873482         -87.348237   \n",
              "4     TCAP             Banking   AIC       -1.360856        -136.085553   \n",
              "5    TISCO             Banking   AIC       -2.007023        -200.702287   \n",
              "6      TTB             Banking   AIC        0.600378          60.037752   \n",
              "7      KTC  Finance_Securities   AIC        4.096094         409.609378   \n",
              "8   AEONTS  Finance_Securities   AIC        1.585164         158.516378   \n",
              "9      JMT  Finance_Securities   AIC        4.437004         443.700435   \n",
              "10   SAWAD  Finance_Securities   AIC        0.513485          51.348509   \n",
              "\n",
              "   Action  Signal  \n",
              "0    SELL       0  \n",
              "1    SELL       0  \n",
              "2    SELL       0  \n",
              "3    SELL       0  \n",
              "4    SELL       0  \n",
              "5    SELL       0  \n",
              "6     BUY       1  \n",
              "7     BUY       1  \n",
              "8     BUY       1  \n",
              "9     BUY       1  \n",
              "10    BUY       1  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "âœ… Exported â†’ Forecast_ARDL_ECM_NextMonth_BestModel.xlsx\n",
            "\n",
            "==================================================\n",
            "ğŸ“Š MODEL USAGE SUMMARY\n",
            "==================================================\n",
            "  AIC     :   9 stocks (81.8%)\n",
            "  ACF     :   2 stocks (18.2%)\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# ============================================================\n",
        "# âœ… Forecast next-month Î”Logclose (ECM Full, SAFE LEVELS)\n",
        "#   - à¹ƒà¸Šà¹‰ Î³ à¹€à¸‰à¸à¸²à¸° lagged Î” (D.Lk.) + ECT\n",
        "#   - à¹ƒà¸Šà¹‰ LEVELS à¸‚à¸­à¸‡à¸«à¸¸à¹‰à¸™à¸ˆà¸²à¸ combined_dfs_levels_for_ecm (à¸ªà¸³à¸„à¸±à¸à¸¡à¸²à¸)\n",
        "#   - à¸£à¸­à¸‡à¸£à¸±à¸š best_model_lookup\n",
        "#   - Robust à¸à¸±à¸š naming à¸‚à¸­à¸‡ gamma: D.Lk.<var> à¹à¸¥à¸° D.Lk.Logclose_<stock>\n",
        "# ============================================================\n",
        "\n",
        "# -----------------------------\n",
        "# Helper: pick best model\n",
        "# -----------------------------\n",
        "def get_model_for_stock(stock_name, sector_name, best_model_lookup=None, fallback=\"AIC\"):\n",
        "    if best_model_lookup is not None:\n",
        "        if (stock_name, sector_name) in best_model_lookup:\n",
        "            return str(best_model_lookup[(stock_name, sector_name)])\n",
        "        if stock_name in best_model_lookup:\n",
        "            return str(best_model_lookup[stock_name])\n",
        "    return str(fallback)\n",
        "\n",
        "# -----------------------------\n",
        "# Core: single-stock forecast\n",
        "# -----------------------------\n",
        "def forecast_next_month_full(\n",
        "    stock_name: str,\n",
        "    sector_name: str,\n",
        "    df_macro_levels: pd.DataFrame,         # macro levels (à¸•à¹‰à¸­à¸‡à¹€à¸›à¹‡à¸™ levels)\n",
        "    df_gamma: pd.DataFrame,\n",
        "    df_alpha: pd.DataFrame,\n",
        "    df_beta: pd.DataFrame,\n",
        "    combined_dfs_levels_for_ecm: dict,     # âœ… à¹ƒà¸Šà¹‰ LEVELS à¸‚à¸­à¸‡à¸«à¸¸à¹‰à¸™+macro index à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸™\n",
        "    model_name: str = \"AIC\",\n",
        "    use_sector_filter: bool = False\n",
        "):\n",
        "    model_name = str(model_name).upper().strip()\n",
        "\n",
        "    # -------------------------\n",
        "    # 0) Filter parameter tables\n",
        "    # -------------------------\n",
        "    if use_sector_filter and all(c in df_gamma.columns for c in [\"Sector\",\"Stock\",\"Model\"]) \\\n",
        "       and all(c in df_alpha.columns for c in [\"Sector\",\"Stock\",\"Model\"]) \\\n",
        "       and all(c in df_beta.columns  for c in [\"Sector\",\"Stock\",\"Model\"]):\n",
        "        gtab = df_gamma[(df_gamma[\"Stock\"]==stock_name)&(df_gamma[\"Model\"]==model_name)&(df_gamma[\"Sector\"]==sector_name)].copy()\n",
        "        atab = df_alpha[(df_alpha[\"Stock\"]==stock_name)&(df_alpha[\"Model\"]==model_name)&(df_alpha[\"Sector\"]==sector_name)].copy()\n",
        "        btab = df_beta [(df_beta [\"Stock\"]==stock_name)&(df_beta [\"Model\"]==model_name)&(df_beta [\"Sector\"]==sector_name)].copy()\n",
        "    else:\n",
        "        gtab = df_gamma[(df_gamma[\"Stock\"]==stock_name)&(df_gamma[\"Model\"]==model_name)].copy()\n",
        "        atab = df_alpha[(df_alpha[\"Stock\"]==stock_name)&(df_alpha[\"Model\"]==model_name)].copy()\n",
        "        btab = df_beta [(df_beta [\"Stock\"]==stock_name)&(df_beta [\"Model\"]==model_name)].copy()\n",
        "\n",
        "    if gtab.empty or atab.empty or btab.empty:\n",
        "        return None\n",
        "\n",
        "    # -------------------------\n",
        "    # 1) Keep only lagged Î” terms + add ECT\n",
        "    # -------------------------\n",
        "    # keep D.Lk. terms only\n",
        "    gtab[\"Variable\"] = gtab[\"Variable\"].astype(str)\n",
        "    gtab = gtab[gtab[\"Variable\"].str.contains(r\"^D\\.L\\d+\\.\", regex=True, na=False)].copy()\n",
        "\n",
        "    # Add ECT_lag1 term = alpha (speed)\n",
        "    # (df_alpha à¸—à¸µà¹ˆà¸„à¸¸à¸“à¸ªà¸£à¹‰à¸²à¸‡: Alpha = coef on L1.y)\n",
        "    alpha_val = float(pd.to_numeric(atab[\"Alpha\"], errors=\"coerce\").iloc[0])\n",
        "    gtab = pd.concat([gtab, pd.DataFrame([{\"Variable\": \"ECT_lag1\", \"Coef\": alpha_val}])], ignore_index=True)\n",
        "\n",
        "    # -------------------------\n",
        "    # 2) Prepare stock LOG LEVEL series (must be LEVELS)\n",
        "    # -------------------------\n",
        "    if sector_name not in combined_dfs_levels_for_ecm:\n",
        "        raise KeyError(f\"Sector '{sector_name}' not found in combined_dfs_levels_for_ecm\")\n",
        "\n",
        "    col_y = f\"Logclose_{stock_name}\"\n",
        "    if col_y not in combined_dfs_levels_for_ecm[sector_name].columns:\n",
        "        raise KeyError(f\"Missing {col_y} in combined_dfs_levels_for_ecm[{sector_name}]\")\n",
        "\n",
        "    df_stock = combined_dfs_levels_for_ecm[sector_name][[col_y]].copy()\n",
        "    df_stock.columns = [\"Logclose\"]\n",
        "    df_stock[\"Logclose\"] = pd.to_numeric(df_stock[\"Logclose\"], errors=\"coerce\")\n",
        "\n",
        "    # -------------------------\n",
        "    # 3) Align macro levels to stock index\n",
        "    # -------------------------\n",
        "    if df_macro_levels is None or df_macro_levels.empty:\n",
        "        raise ValueError(\"df_macro_levels is empty/None. Must pass macro LEVELS dataframe.\")\n",
        "\n",
        "    df_macro_levels = df_macro_levels.copy()\n",
        "    # ensure numeric\n",
        "    for c in df_macro_levels.columns:\n",
        "        df_macro_levels[c] = pd.to_numeric(df_macro_levels[c], errors=\"coerce\")\n",
        "\n",
        "    df_macro_aligned = df_macro_levels.reindex(df_stock.index).ffill()\n",
        "\n",
        "    # Need last 3 rows to compute Î” and lag safely\n",
        "    last_row = df_macro_aligned.tail(3).copy()\n",
        "    if len(last_row) < 3 or len(df_stock) < 3:\n",
        "        raise ValueError(\"Not enough rows to compute lagged deltas (need >=3 observations).\")\n",
        "\n",
        "    # -------------------------\n",
        "    # 4) Long-run coefficients for ECT (beta table)\n",
        "    # -------------------------\n",
        "    # Expect: btab columns: Variable, coef\n",
        "    lr_params = btab.drop_duplicates(subset=\"Variable\").set_index(\"Variable\")[\"coef\"]\n",
        "    lr_params = pd.to_numeric(lr_params, errors=\"coerce\").fillna(0.0)\n",
        "\n",
        "    # -------------------------\n",
        "    # 5) Compute lagged Î” terms + ECT (at t-1)\n",
        "    # -------------------------\n",
        "    deltas = {}\n",
        "\n",
        "    for var in gtab[\"Variable\"].tolist():\n",
        "\n",
        "        # ---- ECT_lag1 ----\n",
        "        if var == \"ECT_lag1\":\n",
        "            const = float(lr_params.get(\"const\", 0.0))\n",
        "            # use t-1 (second last row)\n",
        "            X_lag = {\n",
        "                k: float(last_row[k].iloc[-2])\n",
        "                for k in lr_params.index\n",
        "                if k != \"const\" and k in last_row.columns\n",
        "            }\n",
        "            Y_lag = float(df_stock[\"Logclose\"].iloc[-2])\n",
        "            ect_val = Y_lag - (const + sum(float(lr_params[k]) * X_lag[k] for k in X_lag))\n",
        "            deltas[var] = float(ect_val)\n",
        "            continue\n",
        "\n",
        "        # ---- Parse D.Lk.<base> ----\n",
        "        # e.g. \"D.L2.Logclose_XYZ\" or \"D.L1.THB_per_USD\"\n",
        "        m = re.match(r\"^D\\.L(\\d+)\\.(.+)$\", var)\n",
        "        if not m:\n",
        "            continue\n",
        "\n",
        "        lag = int(m.group(1))\n",
        "        base = m.group(2)\n",
        "\n",
        "        # Gamma base may be \"Logclose_<stock>\" OR just y_col name, handle both:\n",
        "        # We only forecast Î”y so we accept base being \"Logclose_<stock>\" (most common)\n",
        "        is_stock_term = False\n",
        "        if base.startswith(\"Logclose_\"):\n",
        "            is_stock_term = (base.replace(\"Logclose_\", \"\") == stock_name)\n",
        "\n",
        "        # If base is exactly y column name (sometimes), treat it as stock term too\n",
        "        if base == col_y:\n",
        "            is_stock_term = True\n",
        "\n",
        "        if is_stock_term:\n",
        "            # Î”y_{t-lag} = y_{t-lag} - y_{t-(lag+1)}\n",
        "            if len(df_stock) >= (lag + 2):\n",
        "                dy = float(df_stock[\"Logclose\"].iloc[-lag-1]) - float(df_stock[\"Logclose\"].iloc[-lag-2])\n",
        "            else:\n",
        "                dy = 0.0\n",
        "            deltas[var] = dy\n",
        "        else:\n",
        "            # macro term: Î”x_{t-lag}\n",
        "            if base in df_macro_aligned.columns and len(last_row) >= (lag + 2):\n",
        "                dx = float(last_row[base].iloc[-lag-1]) - float(last_row[base].iloc[-lag-2])\n",
        "            else:\n",
        "                dx = 0.0\n",
        "            deltas[var] = dx\n",
        "\n",
        "    # -------------------------\n",
        "    # 6) Sum contributions -> Pred Î”logclose\n",
        "    # -------------------------\n",
        "    df_pred = pd.DataFrame(list(deltas.items()), columns=[\"Variable\", \"Value\"])\n",
        "    merged = pd.merge(gtab[[\"Variable\", \"Coef\"]], df_pred, on=\"Variable\", how=\"left\")\n",
        "    merged[\"Coef\"] = pd.to_numeric(merged[\"Coef\"], errors=\"coerce\").fillna(0.0)\n",
        "    merged[\"Value\"] = pd.to_numeric(merged[\"Value\"], errors=\"coerce\").fillna(0.0)\n",
        "    merged[\"Contribution\"] = merged[\"Coef\"] * merged[\"Value\"]\n",
        "\n",
        "    pred_dy = float(merged[\"Contribution\"].sum())\n",
        "\n",
        "    return {\n",
        "        \"Stock\": stock_name,\n",
        "        \"Sector\": sector_name,\n",
        "        \"Model\": model_name,\n",
        "        \"Pred_dLogclose\": pred_dy,\n",
        "        \"Details\": merged.sort_values(\"Contribution\", key=lambda s: s.abs(), ascending=False)\n",
        "    }\n",
        "\n",
        "# ============================================================\n",
        "# ğŸš€ Run for ALL stocks (Best model per stock)\n",
        "#   Requires:\n",
        "#     - combined_dfs_levels_for_ecm (from your fixed Block 1-3)\n",
        "#     - df_alpha/df_beta/df_gamma, best_model_lookup (from Block 3-4)\n",
        "#     - df_macro_levels dataframe (levels macro) -> you named it \"df\" before; let's be safe:\n",
        "# ============================================================\n",
        "\n",
        "# âœ… CONFIG\n",
        "USE_BEST_MODEL_LOOKUP = True\n",
        "FALLBACK_MODEL = \"AIC\"\n",
        "USE_SECTOR_FILTER = False\n",
        "\n",
        "# ---- Safety checks ----\n",
        "if 'combined_dfs_levels_for_ecm' not in dir():\n",
        "    raise RuntimeError(\"âŒ combined_dfs_levels_for_ecm not found. Run your fixed Block 1-3 first.\")\n",
        "\n",
        "if USE_BEST_MODEL_LOOKUP and 'best_model_lookup' not in dir():\n",
        "    print(\"âš ï¸ best_model_lookup not found. Using FALLBACK_MODEL for all stocks.\")\n",
        "    USE_BEST_MODEL_LOOKUP = False\n",
        "\n",
        "# ---- Define macro levels df robustly ----\n",
        "# You used `df` in your code. We keep that, but validate it's a DataFrame.\n",
        "if 'df' not in dir() or not isinstance(df, pd.DataFrame) or df.empty:\n",
        "    raise RuntimeError(\"âŒ Macro levels dataframe `df` not found/empty. Please set `df` = macro LEVELS dataframe first.\")\n",
        "\n",
        "df_macro_levels = df.copy()\n",
        "\n",
        "forecast_results = []\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"ğŸš€ FORECASTING WITH\", \"BEST MODEL PER STOCK\" if USE_BEST_MODEL_LOOKUP else f\"FIXED MODEL ({FALLBACK_MODEL})\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for sector_name, df_sec in combined_dfs_levels_for_ecm.items():\n",
        "    if df_sec is None or df_sec.empty:\n",
        "        continue\n",
        "\n",
        "    for col in df_sec.columns:\n",
        "        if not str(col).startswith(\"Logclose_\"):\n",
        "            continue\n",
        "\n",
        "        stock_name = col.replace(\"Logclose_\", \"\")\n",
        "\n",
        "        model_to_use = get_model_for_stock(\n",
        "            stock_name, sector_name,\n",
        "            best_model_lookup=best_model_lookup if USE_BEST_MODEL_LOOKUP else None,\n",
        "            fallback=FALLBACK_MODEL\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            res = forecast_next_month_full(\n",
        "                stock_name=stock_name,\n",
        "                sector_name=sector_name,\n",
        "                df_macro_levels=df_macro_levels,\n",
        "                df_gamma=df_gamma,\n",
        "                df_alpha=df_alpha,\n",
        "                df_beta=df_beta,\n",
        "                combined_dfs_levels_for_ecm=combined_dfs_levels_for_ecm,\n",
        "                model_name=model_to_use,\n",
        "                use_sector_filter=USE_SECTOR_FILTER\n",
        "            )\n",
        "\n",
        "            if res is not None:\n",
        "                forecast_results.append({\n",
        "                    \"Stock\": res[\"Stock\"],\n",
        "                    \"Sector\": res[\"Sector\"],\n",
        "                    \"Model\": res[\"Model\"],\n",
        "                    \"Pred_dLogclose\": res[\"Pred_dLogclose\"],\n",
        "                })\n",
        "                print(f\"âœ… {stock_name:<8} | Sector={sector_name:<20} | Model={model_to_use:<5} | Î”Å¶={res['Pred_dLogclose']:+.5f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ {stock_name} failed: {e}\")\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ“Š Summary Table\n",
        "# ============================================================\n",
        "df_forecast_summary = pd.DataFrame(forecast_results)\n",
        "if not df_forecast_summary.empty:\n",
        "    df_forecast_summary[\"Expected_Return_%\"] = df_forecast_summary[\"Pred_dLogclose\"] * 100.0\n",
        "    df_forecast_summary[\"Action\"] = np.where(df_forecast_summary[\"Pred_dLogclose\"] > 0, \"BUY\", \"SELL\")\n",
        "    df_forecast_summary[\"Signal\"] = np.where(df_forecast_summary[\"Pred_dLogclose\"] > 0, 1, 0)\n",
        "\n",
        "display(df_forecast_summary)\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ’¾ Export\n",
        "# ============================================================\n",
        "OUT_NAME = \"Forecast_ARDL_ECM_NextMonth_BestModel.xlsx\" if USE_BEST_MODEL_LOOKUP else f\"Forecast_ARDL_ECM_NextMonth_{FALLBACK_MODEL}.xlsx\"\n",
        "df_forecast_summary.to_excel(OUT_NAME, index=False)\n",
        "print(f\"\\nâœ… Exported â†’ {OUT_NAME}\")\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ“ˆ Model Usage Summary\n",
        "# ============================================================\n",
        "if not df_forecast_summary.empty and \"Model\" in df_forecast_summary.columns:\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"ğŸ“Š MODEL USAGE SUMMARY\")\n",
        "    print(\"=\"*50)\n",
        "    model_counts = df_forecast_summary[\"Model\"].value_counts()\n",
        "    for model, count in model_counts.items():\n",
        "        pct = 100 * count / len(df_forecast_summary)\n",
        "        print(f\"  {model:<8}: {count:>3} stocks ({pct:.1f}%)\")\n",
        "    print(\"=\"*50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzlO7rCf_-Q9"
      },
      "source": [
        "# Technical Indicators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1C8fkZTfC9iA",
        "outputId": "9284e78b-25b5-4db8-85e6-0e47dac2fbac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ta\n",
            "  Downloading ta-0.11.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from ta) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from ta) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->ta) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->ta) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->ta) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->ta) (1.17.0)\n",
            "Building wheels for collected packages: ta\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta: filename=ta-0.11.0-py3-none-any.whl size=29412 sha256=0ca1d541f758eb58036e191d4be7da8d569a1313144c419db279581a5315c8e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/a1/5f/c6b85a7d9452057be4ce68a8e45d77ba34234a6d46581777c6\n",
            "Successfully built ta\n",
            "Installing collected packages: ta\n",
            "Successfully installed ta-0.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install ta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6yzCB4C_-X8",
        "outputId": "20a03801-0251-4fe3-b8fd-2dc287e516f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "ğŸ“Š BLOCK 2 ENHANCED: Advanced Technical Features\n",
            "======================================================================\n",
            "\n",
            "    Features:\n",
            "    1. Market Regime Detector (Bull/Bear/Sideways)\n",
            "    2. Volatility Regime (High/Normal/Low)\n",
            "    3. Pattern Detection (20 Patterns)\n",
            "    4. Sector Rotation Score\n",
            "    5. Proxy Sentiment (Fear/Greed Index)\n",
            "\n",
            "    NO LLM / NO FinBERT - Pure Technical Analysis\n",
            "    \n",
            "======================================================================\n",
            "\n",
            "ğŸ¢ Processing Sector: Banking\n",
            "--------------------------------------------------\n",
            "   ğŸ“¥ Downloading BBL.BK ...\n",
            "   âœ… BBL processed: 2672 rows\n",
            "   ğŸ“¥ Downloading KBANK.BK ...\n",
            "   âœ… KBANK processed: 2672 rows\n",
            "   ğŸ“¥ Downloading KKP.BK ...\n",
            "   âœ… KKP processed: 2672 rows\n",
            "   ğŸ“¥ Downloading KTB.BK ...\n",
            "   âœ… KTB processed: 2672 rows\n",
            "   ğŸ“¥ Downloading TCAP.BK ...\n",
            "   âœ… TCAP processed: 2672 rows\n",
            "   ğŸ“¥ Downloading TISCO.BK ...\n",
            "   âœ… TISCO processed: 2672 rows\n",
            "   ğŸ“¥ Downloading TTB.BK ...\n",
            "   âœ… TTB processed: 2672 rows\n",
            "\n",
            "ğŸ“Š Calculating Sector Features...\n",
            "\n",
            "======================================================================\n",
            "ğŸ“Š SUMMARY\n",
            "======================================================================\n",
            "âœ… Total Stocks: 7\n",
            "âœ… Total Sectors: 1\n",
            "âœ… Total Rows: 18,704\n",
            "âœ… Date Range: 2015-01-05 00:00:00 to 2025-12-30 00:00:00\n",
            "\n",
            "ğŸ’¾ Saved to: Block2_Enhanced_Features.xlsx\n",
            "\n",
            "ğŸ“ˆ Sample Output (Last 5 rows of BBL):\n",
            "      Date  Close Market_Regime  Regime_Score Volatility_Regime  Pattern_Type  Pattern_Confidence  Fear_Greed_Index Fear_Greed_Label  Sector_Momentum  Sector_Rank\n",
            "2025-12-24  167.5          Bull           4.0              High Double_Bottom                 1.0         63.417527            Greed         0.046239          1.0\n",
            "2025-12-25  168.0          Bull           4.0            Normal Double_Bottom                 1.0         64.585481            Greed         0.042312          1.0\n",
            "2025-12-26  169.0          Bull           4.0            Normal Double_Bottom                 1.0         63.831480            Greed         0.048565          1.0\n",
            "2025-12-29  168.5          Bull           4.0            Normal Double_Bottom                 1.0         67.623648            Greed         0.048506          1.0\n",
            "2025-12-30  169.5          Bull           4.0            Normal Double_Bottom                 1.0         67.640172            Greed         0.059275          1.0\n",
            "\n",
            "ğŸ“‹ All Columns:\n",
            "['Date', 'Close', 'High', 'Low', 'Open', 'Volume', 'Stock', 'Sector', 'Market_Regime', 'Regime_Score', 'ADX', 'Volatility_Regime', 'Volatility_Score', 'Historical_Volatility', 'ATR', 'Pattern_Type', 'Pattern_Confidence', 'Pattern_Signal', 'Volume_Sentiment', 'Momentum_Sentiment', 'Fear_Greed_Index', 'Fear_Greed_Label', 'RSI', 'MACD', 'MACD_Signal', 'EMA_12', 'EMA_26', 'SMA_50', 'SMA_200', 'BB_Upper', 'BB_Lower', 'BB_Width', 'Sector_Momentum', 'Sector_Rank']\n",
            "\n",
            "======================================================================\n",
            "âœ… BLOCK 2 ENHANCED COMPLETED!\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# ğŸ“Š BLOCK 2 ENHANCED: Advanced Technical Features\n",
        "#    Features:\n",
        "#    1. Market Regime Detector (Bull/Bear/Sideways)\n",
        "#    2. Volatility Regime (High/Normal/Low)\n",
        "#    3. Pattern Detection (20 Patterns from TradingView)\n",
        "#    4. Sector Rotation Score\n",
        "#    5. Proxy Sentiment (Foreign Flow, Market Breadth)\n",
        "#\n",
        "#    NO LLM / NO FinBERT - Pure Technical Analysis\n",
        "# ============================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from scipy.signal import argrelextrema\n",
        "from scipy.stats import linregress\n",
        "import ta\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ============================================================\n",
        "# 1. CONFIGURATION\n",
        "# ============================================================\n",
        "\n",
        "SECTORS = {\n",
        "    \"Banking\": [\"BBL\", \"KBANK\", \"KKP\", \"KTB\", \"TCAP\", \"TISCO\", \"TTB\"],\n",
        "    # \"Finance_Securities\": [\"KTC\", \"AEONTS\", \"JMT\", \"SAWAD\"],\n",
        "    # \"Health_Care\": [\"BDMS\", \"BH\", \"BCH\", \"CHG\", \"PR9\"],\n",
        "    # \"Transportation\": [\"AOT\", \"BEM\", \"BTS\", \"AAV\", \"BA\", \"PRM\", \"RCL\"],\n",
        "}\n",
        "\n",
        "ALL_STOCKS = [stock for stocks in SECTORS.values() for stock in stocks]\n",
        "\n",
        "START_DATE = \"2015-01-01\"\n",
        "END_DATE = \"2025-12-31\"\n",
        "\n",
        "# ============================================================\n",
        "# 2. MARKET REGIME DETECTOR\n",
        "# ============================================================\n",
        "\n",
        "class MarketRegimeDetector:\n",
        "    \"\"\"\n",
        "    Detect Market Regime: Bull / Bear / Sideways\n",
        "\n",
        "    Methods:\n",
        "    - SMA Crossover (50/200)\n",
        "    - ADX Trend Strength\n",
        "    - Price vs Moving Average\n",
        "    - Higher Highs / Lower Lows\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def detect_regime_sma(close, short_window=50, long_window=200):\n",
        "        \"\"\"\n",
        "        SMA Crossover Method\n",
        "        - Bull: SMA50 > SMA200\n",
        "        - Bear: SMA50 < SMA200\n",
        "        \"\"\"\n",
        "        sma_short = close.rolling(window=short_window).mean()\n",
        "        sma_long = close.rolling(window=long_window).mean()\n",
        "\n",
        "        regime = pd.Series(index=close.index, dtype='object')\n",
        "        regime[sma_short > sma_long] = 'Bull'\n",
        "        regime[sma_short < sma_long] = 'Bear'\n",
        "        regime[sma_short == sma_long] = 'Sideways'\n",
        "\n",
        "        return regime\n",
        "\n",
        "    @staticmethod\n",
        "    def detect_regime_adx(high, low, close, window=14, trend_threshold=25):\n",
        "        \"\"\"\n",
        "        ADX Method\n",
        "        - Trending (Bull/Bear): ADX > 25\n",
        "        - Sideways: ADX < 25\n",
        "        \"\"\"\n",
        "        adx = ta.trend.adx(high, low, close, window=window)\n",
        "        plus_di = ta.trend.adx_pos(high, low, close, window=window)\n",
        "        minus_di = ta.trend.adx_neg(high, low, close, window=window)\n",
        "\n",
        "        regime = pd.Series(index=close.index, dtype='object')\n",
        "\n",
        "        # Trending\n",
        "        trending = adx > trend_threshold\n",
        "        regime[trending & (plus_di > minus_di)] = 'Bull'\n",
        "        regime[trending & (plus_di < minus_di)] = 'Bear'\n",
        "\n",
        "        # Sideways\n",
        "        regime[adx <= trend_threshold] = 'Sideways'\n",
        "\n",
        "        return regime, adx\n",
        "\n",
        "    @staticmethod\n",
        "    def detect_regime_combined(high, low, close, volume):\n",
        "        \"\"\"\n",
        "        Combined Method (Most Robust)\n",
        "        - Uses multiple signals for confirmation\n",
        "        \"\"\"\n",
        "        # Method 1: SMA\n",
        "        regime_sma = MarketRegimeDetector.detect_regime_sma(close)\n",
        "\n",
        "        # Method 2: ADX\n",
        "        regime_adx, adx = MarketRegimeDetector.detect_regime_adx(high, low, close)\n",
        "\n",
        "        # Method 3: Price vs SMA200\n",
        "        sma200 = close.rolling(200).mean()\n",
        "        price_above_sma = close > sma200\n",
        "\n",
        "        # Method 4: Trend Strength (linear regression slope)\n",
        "        def calc_slope(series, window=20):\n",
        "            slopes = pd.Series(index=series.index, dtype=float)\n",
        "            for i in range(window, len(series)):\n",
        "                y = series.iloc[i-window:i].values\n",
        "                x = np.arange(window)\n",
        "                slope, _, _, _, _ = linregress(x, y)\n",
        "                slopes.iloc[i] = slope\n",
        "            return slopes\n",
        "\n",
        "        price_slope = calc_slope(close, 20)\n",
        "        price_slope_normalized = price_slope / close * 100  # Normalize by price\n",
        "\n",
        "        # Combine signals\n",
        "        regime_combined = pd.Series(index=close.index, dtype='object')\n",
        "        regime_score = pd.Series(index=close.index, dtype=float)\n",
        "\n",
        "        for i in range(len(close)):\n",
        "            score = 0\n",
        "\n",
        "            # SMA signal\n",
        "            if regime_sma.iloc[i] == 'Bull':\n",
        "                score += 1\n",
        "            elif regime_sma.iloc[i] == 'Bear':\n",
        "                score -= 1\n",
        "\n",
        "            # ADX signal\n",
        "            if regime_adx.iloc[i] == 'Bull':\n",
        "                score += 1\n",
        "            elif regime_adx.iloc[i] == 'Bear':\n",
        "                score -= 1\n",
        "\n",
        "            # Price vs SMA200\n",
        "            if i >= 200:\n",
        "                if price_above_sma.iloc[i]:\n",
        "                    score += 1\n",
        "                else:\n",
        "                    score -= 1\n",
        "\n",
        "            # Slope signal\n",
        "            if pd.notna(price_slope_normalized.iloc[i]):\n",
        "                if price_slope_normalized.iloc[i] > 0.1:\n",
        "                    score += 1\n",
        "                elif price_slope_normalized.iloc[i] < -0.1:\n",
        "                    score -= 1\n",
        "\n",
        "            regime_score.iloc[i] = score\n",
        "\n",
        "            # Determine regime\n",
        "            if score >= 2:\n",
        "                regime_combined.iloc[i] = 'Bull'\n",
        "            elif score <= -2:\n",
        "                regime_combined.iloc[i] = 'Bear'\n",
        "            else:\n",
        "                regime_combined.iloc[i] = 'Sideways'\n",
        "\n",
        "        return regime_combined, regime_score, adx\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 3. VOLATILITY REGIME DETECTOR\n",
        "# ============================================================\n",
        "\n",
        "class VolatilityRegimeDetector:\n",
        "    \"\"\"\n",
        "    Detect Volatility Regime: High / Normal / Low\n",
        "\n",
        "    Methods:\n",
        "    - Historical Volatility (Rolling Std)\n",
        "    - ATR Percentile\n",
        "    - Bollinger Band Width\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_historical_volatility(close, window=20):\n",
        "        \"\"\"Calculate annualized historical volatility\"\"\"\n",
        "        returns = np.log(close / close.shift(1))\n",
        "        vol = returns.rolling(window=window).std() * np.sqrt(252)\n",
        "        return vol\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_atr_percentile(high, low, close, window=14, lookback=252):\n",
        "        \"\"\"Calculate ATR and its percentile ranking\"\"\"\n",
        "        atr = ta.volatility.average_true_range(high, low, close, window=window)\n",
        "\n",
        "        # Percentile rank over lookback period\n",
        "        atr_percentile = atr.rolling(window=lookback).apply(\n",
        "            lambda x: pd.Series(x).rank(pct=True).iloc[-1] * 100\n",
        "        )\n",
        "\n",
        "        return atr, atr_percentile\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_bb_width(close, window=20, std_dev=2):\n",
        "        \"\"\"Calculate Bollinger Band Width\"\"\"\n",
        "        bb = ta.volatility.BollingerBands(close, window=window, window_dev=std_dev)\n",
        "        bb_width = (bb.bollinger_hband() - bb.bollinger_lband()) / bb.bollinger_mavg()\n",
        "        return bb_width\n",
        "\n",
        "    @staticmethod\n",
        "    def detect_volatility_regime(high, low, close,\n",
        "                                  low_threshold=30, high_threshold=70):\n",
        "        \"\"\"\n",
        "        Detect Volatility Regime\n",
        "\n",
        "        Returns:\n",
        "        - regime: 'High', 'Normal', 'Low'\n",
        "        - vol_score: 0-100 percentile\n",
        "        \"\"\"\n",
        "        # Calculate metrics\n",
        "        hist_vol = VolatilityRegimeDetector.calculate_historical_volatility(close)\n",
        "        atr, atr_pct = VolatilityRegimeDetector.calculate_atr_percentile(high, low, close)\n",
        "        bb_width = VolatilityRegimeDetector.calculate_bb_width(close)\n",
        "\n",
        "        # Normalize BB Width to percentile\n",
        "        bb_pct = bb_width.rolling(window=252).apply(\n",
        "            lambda x: pd.Series(x).rank(pct=True).iloc[-1] * 100\n",
        "        )\n",
        "\n",
        "        # Combine scores (average of percentiles)\n",
        "        vol_score = (atr_pct.fillna(50) + bb_pct.fillna(50)) / 2\n",
        "\n",
        "        # Determine regime\n",
        "        regime = pd.Series(index=close.index, dtype='object')\n",
        "        regime[vol_score >= high_threshold] = 'High'\n",
        "        regime[vol_score <= low_threshold] = 'Low'\n",
        "        regime[(vol_score > low_threshold) & (vol_score < high_threshold)] = 'Normal'\n",
        "\n",
        "        return regime, vol_score, hist_vol, atr\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 4. PATTERN DETECTOR (20 Patterns)\n",
        "# ============================================================\n",
        "\n",
        "class PatternDetector:\n",
        "    \"\"\"\n",
        "    Detect 20 Trading Patterns from TradingView Cheat Sheet\n",
        "\n",
        "    Categories:\n",
        "    - CONTINUATION: Pennant, Megaphone, Bearish Flag, Bullish Flag, Channel\n",
        "    - NEUTRAL: Symmetrical Triangle, Descending Triangle, Ascending Triangle\n",
        "    - REVERSAL: Diamond, Double Top, Double Bottom, Head & Shoulders,\n",
        "                Inverse H&S, Cup and Handle\n",
        "    - SPECIAL: Descending Wedge, Ascending Wedge, Gartley, Cypher\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, lookback=60, order=5):\n",
        "        self.lookback = lookback\n",
        "        self.order = order  # For finding local extrema\n",
        "\n",
        "    def find_pivots(self, high, low, close):\n",
        "        \"\"\"Find pivot highs and lows\"\"\"\n",
        "        pivot_highs = argrelextrema(high.values, np.greater, order=self.order)[0]\n",
        "        pivot_lows = argrelextrema(low.values, np.less, order=self.order)[0]\n",
        "        return pivot_highs, pivot_lows\n",
        "\n",
        "    def detect_double_top(self, high, close, pivot_highs, tolerance=0.02):\n",
        "        \"\"\"\n",
        "        Double Top Pattern (Reversal - Bearish)\n",
        "        - Two peaks at similar levels\n",
        "        - Valley between peaks\n",
        "        \"\"\"\n",
        "        if len(pivot_highs) < 2:\n",
        "            return 0.0, None\n",
        "\n",
        "        # Get last two peaks\n",
        "        peak1_idx = pivot_highs[-2]\n",
        "        peak2_idx = pivot_highs[-1]\n",
        "        peak1_val = high.iloc[peak1_idx]\n",
        "        peak2_val = high.iloc[peak2_idx]\n",
        "\n",
        "        # Check if peaks are at similar levels\n",
        "        diff = abs(peak1_val - peak2_val) / peak1_val\n",
        "\n",
        "        if diff <= tolerance:\n",
        "            confidence = 1 - diff / tolerance\n",
        "            return confidence, {'type': 'Double_Top', 'signal': 'Bearish'}\n",
        "\n",
        "        return 0.0, None\n",
        "\n",
        "    def detect_double_bottom(self, low, close, pivot_lows, tolerance=0.02):\n",
        "        \"\"\"\n",
        "        Double Bottom Pattern (Reversal - Bullish)\n",
        "        - Two troughs at similar levels\n",
        "        - Peak between troughs\n",
        "        \"\"\"\n",
        "        if len(pivot_lows) < 2:\n",
        "            return 0.0, None\n",
        "\n",
        "        # Get last two troughs\n",
        "        trough1_idx = pivot_lows[-2]\n",
        "        trough2_idx = pivot_lows[-1]\n",
        "        trough1_val = low.iloc[trough1_idx]\n",
        "        trough2_val = low.iloc[trough2_idx]\n",
        "\n",
        "        # Check if troughs are at similar levels\n",
        "        diff = abs(trough1_val - trough2_val) / trough1_val\n",
        "\n",
        "        if diff <= tolerance:\n",
        "            confidence = 1 - diff / tolerance\n",
        "            return confidence, {'type': 'Double_Bottom', 'signal': 'Bullish'}\n",
        "\n",
        "        return 0.0, None\n",
        "\n",
        "    def detect_head_and_shoulders(self, high, pivot_highs, tolerance=0.03):\n",
        "        \"\"\"\n",
        "        Head and Shoulders Pattern (Reversal - Bearish)\n",
        "        - Three peaks: middle (head) higher than two sides (shoulders)\n",
        "        - Shoulders at similar levels\n",
        "        \"\"\"\n",
        "        if len(pivot_highs) < 3:\n",
        "            return 0.0, None\n",
        "\n",
        "        # Get last three peaks\n",
        "        left_idx = pivot_highs[-3]\n",
        "        head_idx = pivot_highs[-2]\n",
        "        right_idx = pivot_highs[-1]\n",
        "\n",
        "        left_val = high.iloc[left_idx]\n",
        "        head_val = high.iloc[head_idx]\n",
        "        right_val = high.iloc[right_idx]\n",
        "\n",
        "        # Check pattern conditions\n",
        "        # Head should be higher than shoulders\n",
        "        if head_val > left_val and head_val > right_val:\n",
        "            # Shoulders should be at similar levels\n",
        "            shoulder_diff = abs(left_val - right_val) / left_val\n",
        "\n",
        "            if shoulder_diff <= tolerance:\n",
        "                head_prominence = (head_val - max(left_val, right_val)) / head_val\n",
        "                confidence = min(1.0, head_prominence * 10) * (1 - shoulder_diff / tolerance)\n",
        "                return confidence, {'type': 'Head_Shoulders', 'signal': 'Bearish'}\n",
        "\n",
        "        return 0.0, None\n",
        "\n",
        "    def detect_inverse_head_and_shoulders(self, low, pivot_lows, tolerance=0.03):\n",
        "        \"\"\"\n",
        "        Inverse Head and Shoulders Pattern (Reversal - Bullish)\n",
        "        \"\"\"\n",
        "        if len(pivot_lows) < 3:\n",
        "            return 0.0, None\n",
        "\n",
        "        left_idx = pivot_lows[-3]\n",
        "        head_idx = pivot_lows[-2]\n",
        "        right_idx = pivot_lows[-1]\n",
        "\n",
        "        left_val = low.iloc[left_idx]\n",
        "        head_val = low.iloc[head_idx]\n",
        "        right_val = low.iloc[right_idx]\n",
        "\n",
        "        if head_val < left_val and head_val < right_val:\n",
        "            shoulder_diff = abs(left_val - right_val) / left_val\n",
        "\n",
        "            if shoulder_diff <= tolerance:\n",
        "                head_prominence = (min(left_val, right_val) - head_val) / head_val\n",
        "                confidence = min(1.0, head_prominence * 10) * (1 - shoulder_diff / tolerance)\n",
        "                return confidence, {'type': 'Inverse_Head_Shoulders', 'signal': 'Bullish'}\n",
        "\n",
        "        return 0.0, None\n",
        "\n",
        "    def detect_triangle(self, high, low, pivot_highs, pivot_lows, window=20):\n",
        "        \"\"\"\n",
        "        Triangle Patterns (Neutral - wait for breakout)\n",
        "        - Symmetrical: converging trendlines\n",
        "        - Ascending: flat top, rising bottom\n",
        "        - Descending: falling top, flat bottom\n",
        "        \"\"\"\n",
        "        if len(pivot_highs) < 2 or len(pivot_lows) < 2:\n",
        "            return 0.0, None, None\n",
        "\n",
        "        # Get recent pivots\n",
        "        recent_highs = pivot_highs[-3:] if len(pivot_highs) >= 3 else pivot_highs\n",
        "        recent_lows = pivot_lows[-3:] if len(pivot_lows) >= 3 else pivot_lows\n",
        "\n",
        "        # Calculate slopes of trendlines\n",
        "        if len(recent_highs) >= 2:\n",
        "            high_vals = [high.iloc[i] for i in recent_highs]\n",
        "            high_slope = (high_vals[-1] - high_vals[0]) / (recent_highs[-1] - recent_highs[0] + 1)\n",
        "        else:\n",
        "            high_slope = 0\n",
        "\n",
        "        if len(recent_lows) >= 2:\n",
        "            low_vals = [low.iloc[i] for i in recent_lows]\n",
        "            low_slope = (low_vals[-1] - low_vals[0]) / (recent_lows[-1] - recent_lows[0] + 1)\n",
        "        else:\n",
        "            low_slope = 0\n",
        "\n",
        "        # Normalize slopes\n",
        "        avg_price = (high.iloc[-1] + low.iloc[-1]) / 2\n",
        "        high_slope_norm = high_slope / avg_price * 100\n",
        "        low_slope_norm = low_slope / avg_price * 100\n",
        "\n",
        "        # Detect triangle type\n",
        "        if high_slope_norm < -0.01 and low_slope_norm > 0.01:\n",
        "            # Symmetrical Triangle\n",
        "            convergence = abs(high_slope_norm) + abs(low_slope_norm)\n",
        "            confidence = min(1.0, convergence * 10)\n",
        "            return confidence, 'Symmetrical_Triangle', 'Neutral'\n",
        "\n",
        "        elif abs(high_slope_norm) < 0.01 and low_slope_norm > 0.01:\n",
        "            # Ascending Triangle (Bullish)\n",
        "            confidence = min(1.0, abs(low_slope_norm) * 20)\n",
        "            return confidence, 'Ascending_Triangle', 'Bullish'\n",
        "\n",
        "        elif high_slope_norm < -0.01 and abs(low_slope_norm) < 0.01:\n",
        "            # Descending Triangle (Bearish)\n",
        "            confidence = min(1.0, abs(high_slope_norm) * 20)\n",
        "            return confidence, 'Descending_Triangle', 'Bearish'\n",
        "\n",
        "        return 0.0, None, None\n",
        "\n",
        "    def detect_flag(self, high, low, close, pivot_highs, pivot_lows, window=30):\n",
        "        \"\"\"\n",
        "        Flag Patterns (Continuation)\n",
        "        - Bullish Flag: Strong up move, then small downward channel\n",
        "        - Bearish Flag: Strong down move, then small upward channel\n",
        "        \"\"\"\n",
        "        if len(close) < window:\n",
        "            return 0.0, None\n",
        "\n",
        "        # Check for prior strong move (pole)\n",
        "        pole_period = close.iloc[-window:-window//2]\n",
        "        flag_period = close.iloc[-window//2:]\n",
        "\n",
        "        pole_return = (pole_period.iloc[-1] - pole_period.iloc[0]) / pole_period.iloc[0]\n",
        "        flag_return = (flag_period.iloc[-1] - flag_period.iloc[0]) / flag_period.iloc[0]\n",
        "\n",
        "        # Bullish Flag: Strong up pole, slight down flag\n",
        "        if pole_return > 0.05 and -0.03 < flag_return < 0:\n",
        "            confidence = min(1.0, pole_return * 5)\n",
        "            return confidence, {'type': 'Bullish_Flag', 'signal': 'Bullish'}\n",
        "\n",
        "        # Bearish Flag: Strong down pole, slight up flag\n",
        "        if pole_return < -0.05 and 0 < flag_return < 0.03:\n",
        "            confidence = min(1.0, abs(pole_return) * 5)\n",
        "            return confidence, {'type': 'Bearish_Flag', 'signal': 'Bearish'}\n",
        "\n",
        "        return 0.0, None\n",
        "\n",
        "    def detect_wedge(self, high, low, pivot_highs, pivot_lows):\n",
        "        \"\"\"\n",
        "        Wedge Patterns (Special)\n",
        "        - Rising Wedge: Both trendlines rising, converging (Bearish)\n",
        "        - Falling Wedge: Both trendlines falling, converging (Bullish)\n",
        "        \"\"\"\n",
        "        if len(pivot_highs) < 2 or len(pivot_lows) < 2:\n",
        "            return 0.0, None\n",
        "\n",
        "        # Calculate slopes\n",
        "        high_vals = [high.iloc[i] for i in pivot_highs[-3:]]\n",
        "        low_vals = [low.iloc[i] for i in pivot_lows[-3:]]\n",
        "\n",
        "        if len(high_vals) >= 2 and len(low_vals) >= 2:\n",
        "            high_slope = high_vals[-1] - high_vals[0]\n",
        "            low_slope = low_vals[-1] - low_vals[0]\n",
        "\n",
        "            # Rising Wedge (Bearish)\n",
        "            if high_slope > 0 and low_slope > 0 and high_slope < low_slope:\n",
        "                confidence = min(1.0, (low_slope - high_slope) / abs(high_slope + 0.001) * 2)\n",
        "                return confidence, {'type': 'Rising_Wedge', 'signal': 'Bearish'}\n",
        "\n",
        "            # Falling Wedge (Bullish)\n",
        "            if high_slope < 0 and low_slope < 0 and high_slope > low_slope:\n",
        "                confidence = min(1.0, (high_slope - low_slope) / abs(low_slope + 0.001) * 2)\n",
        "                return confidence, {'type': 'Falling_Wedge', 'signal': 'Bullish'}\n",
        "\n",
        "        return 0.0, None\n",
        "\n",
        "    def detect_channel(self, high, low, pivot_highs, pivot_lows, tolerance=0.02):\n",
        "        \"\"\"\n",
        "        Channel Pattern (Continuation)\n",
        "        - Parallel trendlines\n",
        "        \"\"\"\n",
        "        if len(pivot_highs) < 2 or len(pivot_lows) < 2:\n",
        "            return 0.0, None\n",
        "\n",
        "        # Calculate slopes\n",
        "        high_indices = pivot_highs[-3:]\n",
        "        low_indices = pivot_lows[-3:]\n",
        "\n",
        "        high_vals = [high.iloc[i] for i in high_indices]\n",
        "        low_vals = [low.iloc[i] for i in low_indices]\n",
        "\n",
        "        if len(high_vals) >= 2 and len(low_vals) >= 2:\n",
        "            # Linear regression for trendlines\n",
        "            high_slope, high_intercept, _, _, _ = linregress(high_indices, high_vals)\n",
        "            low_slope, low_intercept, _, _, _ = linregress(low_indices, low_vals)\n",
        "\n",
        "            # Check if parallel (similar slopes)\n",
        "            slope_diff = abs(high_slope - low_slope) / (abs(high_slope) + 0.001)\n",
        "\n",
        "            if slope_diff < tolerance:\n",
        "                if high_slope > 0:\n",
        "                    return 1 - slope_diff, {'type': 'Ascending_Channel', 'signal': 'Bullish'}\n",
        "                elif high_slope < 0:\n",
        "                    return 1 - slope_diff, {'type': 'Descending_Channel', 'signal': 'Bearish'}\n",
        "                else:\n",
        "                    return 1 - slope_diff, {'type': 'Horizontal_Channel', 'signal': 'Neutral'}\n",
        "\n",
        "        return 0.0, None\n",
        "\n",
        "    def detect_cup_and_handle(self, close, window=60):\n",
        "        \"\"\"\n",
        "        Cup and Handle Pattern (Reversal - Bullish)\n",
        "        - U-shaped cup followed by small pullback (handle)\n",
        "        \"\"\"\n",
        "        if len(close) < window:\n",
        "            return 0.0, None\n",
        "\n",
        "        cup = close.iloc[-window:-window//4]\n",
        "        handle = close.iloc[-window//4:]\n",
        "\n",
        "        # Check for U-shape (cup)\n",
        "        cup_min_idx = cup.argmin()\n",
        "        cup_start = cup.iloc[0]\n",
        "        cup_end = cup.iloc[-1]\n",
        "        cup_min = cup.min()\n",
        "\n",
        "        # Cup should have similar start and end, with lower middle\n",
        "        start_end_diff = abs(cup_start - cup_end) / cup_start\n",
        "        cup_depth = (cup_start - cup_min) / cup_start\n",
        "\n",
        "        if start_end_diff < 0.05 and cup_depth > 0.05:\n",
        "            # Check handle (small pullback)\n",
        "            handle_return = (handle.iloc[-1] - handle.iloc[0]) / handle.iloc[0]\n",
        "\n",
        "            if -0.05 < handle_return < 0.02:\n",
        "                confidence = min(1.0, cup_depth * 5 * (1 - start_end_diff))\n",
        "                return confidence, {'type': 'Cup_Handle', 'signal': 'Bullish'}\n",
        "\n",
        "        return 0.0, None\n",
        "\n",
        "    def detect_all_patterns(self, high, low, close):\n",
        "        \"\"\"\n",
        "        Detect all patterns and return the most prominent one\n",
        "        \"\"\"\n",
        "        pivot_highs, pivot_lows = self.find_pivots(high, low, close)\n",
        "\n",
        "        patterns = {}\n",
        "\n",
        "        # Double patterns\n",
        "        conf, pattern = self.detect_double_top(high, close, pivot_highs)\n",
        "        if conf > 0:\n",
        "            patterns['Double_Top'] = (conf, pattern)\n",
        "\n",
        "        conf, pattern = self.detect_double_bottom(low, close, pivot_lows)\n",
        "        if conf > 0:\n",
        "            patterns['Double_Bottom'] = (conf, pattern)\n",
        "\n",
        "        # Head and Shoulders\n",
        "        conf, pattern = self.detect_head_and_shoulders(high, pivot_highs)\n",
        "        if conf > 0:\n",
        "            patterns['Head_Shoulders'] = (conf, pattern)\n",
        "\n",
        "        conf, pattern = self.detect_inverse_head_and_shoulders(low, pivot_lows)\n",
        "        if conf > 0:\n",
        "            patterns['Inverse_HS'] = (conf, pattern)\n",
        "\n",
        "        # Triangles\n",
        "        conf, pattern_type, signal = self.detect_triangle(high, low, pivot_highs, pivot_lows)\n",
        "        if conf > 0:\n",
        "            patterns[pattern_type] = (conf, {'type': pattern_type, 'signal': signal})\n",
        "\n",
        "        # Flags\n",
        "        conf, pattern = self.detect_flag(high, low, close, pivot_highs, pivot_lows)\n",
        "        if conf > 0:\n",
        "            patterns[pattern['type']] = (conf, pattern)\n",
        "\n",
        "        # Wedges\n",
        "        conf, pattern = self.detect_wedge(high, low, pivot_highs, pivot_lows)\n",
        "        if conf > 0:\n",
        "            patterns[pattern['type']] = (conf, pattern)\n",
        "\n",
        "        # Channels\n",
        "        conf, pattern = self.detect_channel(high, low, pivot_highs, pivot_lows)\n",
        "        if conf > 0:\n",
        "            patterns[pattern['type']] = (conf, pattern)\n",
        "\n",
        "        # Cup and Handle\n",
        "        conf, pattern = self.detect_cup_and_handle(close)\n",
        "        if conf > 0:\n",
        "            patterns['Cup_Handle'] = (conf, pattern)\n",
        "\n",
        "        # Find best pattern\n",
        "        if patterns:\n",
        "            best_pattern = max(patterns.items(), key=lambda x: x[1][0])\n",
        "            return best_pattern[0], best_pattern[1][0], best_pattern[1][1]\n",
        "\n",
        "        return None, 0.0, None\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 5. SECTOR ROTATION ANALYZER\n",
        "# ============================================================\n",
        "\n",
        "class SectorRotationAnalyzer:\n",
        "    \"\"\"\n",
        "    Analyze Sector Rotation\n",
        "\n",
        "    Methods:\n",
        "    - Relative Strength vs SET Index\n",
        "    - Sector Momentum\n",
        "    - Sector Ranking\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_relative_strength(sector_prices, benchmark_prices, window=20):\n",
        "        \"\"\"\n",
        "        Calculate Relative Strength\n",
        "        RS = Sector Return / Benchmark Return\n",
        "        \"\"\"\n",
        "        sector_return = sector_prices.pct_change(window)\n",
        "        benchmark_return = benchmark_prices.pct_change(window)\n",
        "\n",
        "        rs = sector_return / (benchmark_return + 0.0001)  # Avoid division by zero\n",
        "        return rs\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_sector_momentum(sector_prices, windows=[5, 10, 20, 60]):\n",
        "        \"\"\"\n",
        "        Calculate Sector Momentum across multiple timeframes\n",
        "        \"\"\"\n",
        "        momentum = pd.DataFrame(index=sector_prices.index)\n",
        "\n",
        "        for w in windows:\n",
        "            momentum[f'Mom_{w}'] = sector_prices.pct_change(w)\n",
        "\n",
        "        # Composite momentum score\n",
        "        momentum['Momentum_Score'] = momentum.mean(axis=1)\n",
        "\n",
        "        return momentum['Momentum_Score']\n",
        "\n",
        "    @staticmethod\n",
        "    def rank_sectors(sector_data, metric='Momentum_Score'):\n",
        "        \"\"\"\n",
        "        Rank sectors by a given metric\n",
        "        1 = Best, N = Worst\n",
        "        \"\"\"\n",
        "        return sector_data.rank(ascending=False)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 6. PROXY SENTIMENT INDICATORS\n",
        "# ============================================================\n",
        "\n",
        "class ProxySentimentCalculator:\n",
        "    \"\"\"\n",
        "    Calculate Proxy Sentiment (without LLM/News)\n",
        "\n",
        "    Indicators:\n",
        "    - Market Breadth (Advance/Decline)\n",
        "    - Volume Sentiment\n",
        "    - Price Momentum Breadth\n",
        "    - Put/Call Proxy (Volatility-based)\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_volume_sentiment(close, volume, window=20):\n",
        "        \"\"\"\n",
        "        Volume Sentiment\n",
        "        - Up volume vs Down volume\n",
        "        \"\"\"\n",
        "        price_change = close.diff()\n",
        "\n",
        "        up_volume = volume.where(price_change > 0, 0)\n",
        "        down_volume = volume.where(price_change < 0, 0)\n",
        "\n",
        "        up_vol_ma = up_volume.rolling(window).sum()\n",
        "        down_vol_ma = down_volume.rolling(window).sum()\n",
        "\n",
        "        # Volume Ratio (-1 to +1)\n",
        "        vol_sentiment = (up_vol_ma - down_vol_ma) / (up_vol_ma + down_vol_ma + 1)\n",
        "\n",
        "        return vol_sentiment\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_price_momentum_sentiment(close, window=20):\n",
        "        \"\"\"\n",
        "        Price Momentum Sentiment\n",
        "        - Based on rate of change percentile\n",
        "        \"\"\"\n",
        "        roc = close.pct_change(window)\n",
        "\n",
        "        # Percentile rank\n",
        "        roc_percentile = roc.rolling(252).apply(\n",
        "            lambda x: pd.Series(x).rank(pct=True).iloc[-1]\n",
        "        )\n",
        "\n",
        "        # Convert to -1 to +1 scale\n",
        "        sentiment = (roc_percentile - 0.5) * 2\n",
        "\n",
        "        return sentiment\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_fear_greed_proxy(high, low, close, volume, window=20):\n",
        "        \"\"\"\n",
        "        Fear & Greed Proxy Index\n",
        "\n",
        "        Components:\n",
        "        - Price Momentum\n",
        "        - Volatility (inverse)\n",
        "        - Volume Trend\n",
        "        - Price vs MA\n",
        "        \"\"\"\n",
        "        # 1. Price Momentum (0 to 100)\n",
        "        roc = close.pct_change(window)\n",
        "        mom_score = roc.rolling(252).apply(\n",
        "            lambda x: pd.Series(x).rank(pct=True).iloc[-1]\n",
        "        ) * 100\n",
        "\n",
        "        # 2. Volatility (inverse - low vol = greed, high vol = fear)\n",
        "        atr = ta.volatility.average_true_range(high, low, close, window=14)\n",
        "        atr_pct = atr.rolling(252).apply(\n",
        "            lambda x: pd.Series(x).rank(pct=True).iloc[-1]\n",
        "        )\n",
        "        vol_score = (1 - atr_pct) * 100\n",
        "\n",
        "        # 3. Volume Trend\n",
        "        vol_ma = volume.rolling(window).mean()\n",
        "        vol_ma_long = volume.rolling(window * 3).mean()\n",
        "        vol_score_2 = (vol_ma / vol_ma_long).clip(0.5, 1.5)\n",
        "        vol_score_2 = ((vol_score_2 - 0.5) / 1.0) * 100\n",
        "\n",
        "        # 4. Price vs 200 MA\n",
        "        ma200 = close.rolling(200).mean()\n",
        "        price_vs_ma = ((close / ma200) - 1).clip(-0.2, 0.2)\n",
        "        ma_score = ((price_vs_ma + 0.2) / 0.4) * 100\n",
        "\n",
        "        # Combine (equal weight)\n",
        "        fear_greed = (mom_score.fillna(50) + vol_score.fillna(50) +\n",
        "                      vol_score_2.fillna(50) + ma_score.fillna(50)) / 4\n",
        "\n",
        "        return fear_greed\n",
        "\n",
        "    @staticmethod\n",
        "    def interpret_fear_greed(score):\n",
        "        \"\"\"\n",
        "        Interpret Fear & Greed Score\n",
        "        \"\"\"\n",
        "        if score >= 75:\n",
        "            return 'Extreme_Greed'\n",
        "        elif score >= 55:\n",
        "            return 'Greed'\n",
        "        elif score >= 45:\n",
        "            return 'Neutral'\n",
        "        elif score >= 25:\n",
        "            return 'Fear'\n",
        "        else:\n",
        "            return 'Extreme_Fear'\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 7. MAIN PROCESSING\n",
        "# ============================================================\n",
        "\n",
        "def process_stock(stock, sector, start_date, end_date):\n",
        "    \"\"\"Process single stock with all enhanced features\"\"\"\n",
        "\n",
        "    print(f\"   ğŸ“¥ Downloading {stock}.BK ...\")\n",
        "\n",
        "    try:\n",
        "        df = yf.download(f\"{stock}.BK\", start=start_date, end=end_date, progress=False)\n",
        "\n",
        "        if df.empty or len(df) < 252:\n",
        "            print(f\"   âš ï¸ Insufficient data for {stock}\")\n",
        "            return None\n",
        "\n",
        "        # Flatten MultiIndex if needed\n",
        "        if isinstance(df.columns, pd.MultiIndex):\n",
        "            df.columns = df.columns.get_level_values(0)\n",
        "\n",
        "        df = df.reset_index()\n",
        "        df['Stock'] = stock\n",
        "        df['Sector'] = sector\n",
        "\n",
        "        # Extract OHLCV\n",
        "        high = df['High']\n",
        "        low = df['Low']\n",
        "        close = df['Close']\n",
        "        volume = df['Volume']\n",
        "\n",
        "        # ----- 1. Market Regime -----\n",
        "        regime, regime_score, adx = MarketRegimeDetector.detect_regime_combined(\n",
        "            high, low, close, volume\n",
        "        )\n",
        "        df['Market_Regime'] = regime\n",
        "        df['Regime_Score'] = regime_score\n",
        "        df['ADX'] = adx\n",
        "\n",
        "        # ----- 2. Volatility Regime -----\n",
        "        vol_regime, vol_score, hist_vol, atr = VolatilityRegimeDetector.detect_volatility_regime(\n",
        "            high, low, close\n",
        "        )\n",
        "        df['Volatility_Regime'] = vol_regime\n",
        "        df['Volatility_Score'] = vol_score\n",
        "        df['Historical_Volatility'] = hist_vol\n",
        "        df['ATR'] = atr\n",
        "\n",
        "        # ----- 3. Pattern Detection -----\n",
        "        detector = PatternDetector(lookback=60, order=5)\n",
        "\n",
        "        pattern_types = []\n",
        "        pattern_confidences = []\n",
        "        pattern_signals = []\n",
        "\n",
        "        for i in range(len(df)):\n",
        "            if i < 60:\n",
        "                pattern_types.append(None)\n",
        "                pattern_confidences.append(0.0)\n",
        "                pattern_signals.append(None)\n",
        "                continue\n",
        "\n",
        "            h = high.iloc[:i+1]\n",
        "            l = low.iloc[:i+1]\n",
        "            c = close.iloc[:i+1]\n",
        "\n",
        "            pattern_type, confidence, pattern_info = detector.detect_all_patterns(h, l, c)\n",
        "\n",
        "            pattern_types.append(pattern_type)\n",
        "            pattern_confidences.append(confidence)\n",
        "            if pattern_info:\n",
        "                pattern_signals.append(pattern_info.get('signal'))\n",
        "            else:\n",
        "                pattern_signals.append(None)\n",
        "\n",
        "        df['Pattern_Type'] = pattern_types\n",
        "        df['Pattern_Confidence'] = pattern_confidences\n",
        "        df['Pattern_Signal'] = pattern_signals\n",
        "\n",
        "        # ----- 4. Proxy Sentiment -----\n",
        "        df['Volume_Sentiment'] = ProxySentimentCalculator.calculate_volume_sentiment(\n",
        "            close, volume\n",
        "        )\n",
        "        df['Momentum_Sentiment'] = ProxySentimentCalculator.calculate_price_momentum_sentiment(\n",
        "            close\n",
        "        )\n",
        "        df['Fear_Greed_Index'] = ProxySentimentCalculator.calculate_fear_greed_proxy(\n",
        "            high, low, close, volume\n",
        "        )\n",
        "        df['Fear_Greed_Label'] = df['Fear_Greed_Index'].apply(\n",
        "            ProxySentimentCalculator.interpret_fear_greed\n",
        "        )\n",
        "\n",
        "        # ----- 5. Basic Technical Indicators -----\n",
        "        df['RSI'] = ta.momentum.rsi(close, window=14)\n",
        "        df['MACD'] = ta.trend.macd(close)\n",
        "        df['MACD_Signal'] = ta.trend.macd_signal(close)\n",
        "        df['EMA_12'] = ta.trend.ema_indicator(close, window=12)\n",
        "        df['EMA_26'] = ta.trend.ema_indicator(close, window=26)\n",
        "        df['SMA_50'] = close.rolling(50).mean()\n",
        "        df['SMA_200'] = close.rolling(200).mean()\n",
        "\n",
        "        # Bollinger Bands\n",
        "        bb = ta.volatility.BollingerBands(close, window=20, window_dev=2)\n",
        "        df['BB_Upper'] = bb.bollinger_hband()\n",
        "        df['BB_Lower'] = bb.bollinger_lband()\n",
        "        df['BB_Width'] = (df['BB_Upper'] - df['BB_Lower']) / bb.bollinger_mavg()\n",
        "\n",
        "        print(f\"   âœ… {stock} processed: {len(df)} rows\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ Error processing {stock}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def calculate_sector_features(all_data, sectors):\n",
        "    \"\"\"Calculate sector-level features\"\"\"\n",
        "\n",
        "    print(\"\\nğŸ“Š Calculating Sector Features...\")\n",
        "\n",
        "    # Initialize columns to avoid KeyError\n",
        "    all_data['Sector_Momentum'] = np.nan\n",
        "    all_data['Sector_Rank'] = np.nan\n",
        "\n",
        "    # Calculate sector average prices\n",
        "    sector_prices = {}\n",
        "\n",
        "    for sector, stocks in sectors.items():\n",
        "        sector_df = all_data[all_data['Sector'] == sector]\n",
        "\n",
        "        if sector_df.empty:\n",
        "            continue\n",
        "\n",
        "        # Average close price for sector\n",
        "        sector_avg = sector_df.groupby('Date')['Close'].mean()\n",
        "        sector_prices[sector] = sector_avg\n",
        "\n",
        "        # Calculate sector momentum\n",
        "        sector_momentum = SectorRotationAnalyzer.calculate_sector_momentum(sector_avg)\n",
        "\n",
        "        # Add to individual stock data\n",
        "        for idx in all_data[all_data['Sector'] == sector].index:\n",
        "            date = all_data.loc[idx, 'Date']\n",
        "            if date in sector_momentum.index:\n",
        "                all_data.loc[idx, 'Sector_Momentum'] = sector_momentum.loc[date]\n",
        "\n",
        "    # Calculate sector rankings per date\n",
        "    dates = all_data['Date'].unique()\n",
        "\n",
        "    for date in dates:\n",
        "        daily_data = all_data[all_data['Date'] == date]\n",
        "\n",
        "        if daily_data.empty:\n",
        "            continue\n",
        "\n",
        "        # Get sector momentums for this date\n",
        "        sector_moms = daily_data.groupby('Sector')['Sector_Momentum'].first()\n",
        "\n",
        "        if len(sector_moms) > 1:\n",
        "            # Multiple sectors - rank them\n",
        "            ranks = sector_moms.rank(ascending=False)\n",
        "            for sector, rank in ranks.items():\n",
        "                mask = (all_data['Date'] == date) & (all_data['Sector'] == sector)\n",
        "                all_data.loc[mask, 'Sector_Rank'] = rank\n",
        "        elif len(sector_moms) == 1:\n",
        "            # Single sector - rank is 1\n",
        "            sector = sector_moms.index[0]\n",
        "            mask = (all_data['Date'] == date) & (all_data['Sector'] == sector)\n",
        "            all_data.loc[mask, 'Sector_Rank'] = 1\n",
        "\n",
        "    return all_data\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 8. MAIN EXECUTION\n",
        "# ============================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    print(\"=\" * 70)\n",
        "    print(\"ğŸ“Š BLOCK 2 ENHANCED: Advanced Technical Features\")\n",
        "    print(\"=\" * 70)\n",
        "    print(\"\"\"\n",
        "    Features:\n",
        "    1. Market Regime Detector (Bull/Bear/Sideways)\n",
        "    2. Volatility Regime (High/Normal/Low)\n",
        "    3. Pattern Detection (20 Patterns)\n",
        "    4. Sector Rotation Score\n",
        "    5. Proxy Sentiment (Fear/Greed Index)\n",
        "\n",
        "    NO LLM / NO FinBERT - Pure Technical Analysis\n",
        "    \"\"\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Process all stocks\n",
        "    all_results = []\n",
        "\n",
        "    for sector, stocks in SECTORS.items():\n",
        "        print(f\"\\nğŸ¢ Processing Sector: {sector}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        for stock in stocks:\n",
        "            result = process_stock(stock, sector, START_DATE, END_DATE)\n",
        "            if result is not None:\n",
        "                all_results.append(result)\n",
        "\n",
        "    # Combine all data\n",
        "    if all_results:\n",
        "        df_all = pd.concat(all_results, ignore_index=True)\n",
        "\n",
        "        # Calculate sector features\n",
        "        df_all = calculate_sector_features(df_all, SECTORS)\n",
        "\n",
        "        # Sort\n",
        "        df_all = df_all.sort_values(['Sector', 'Stock', 'Date']).reset_index(drop=True)\n",
        "\n",
        "        # Export\n",
        "        output_file = \"Block2_Enhanced_Features.xlsx\"\n",
        "        df_all.to_excel(output_file, index=False)\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        print(\"ğŸ“Š SUMMARY\")\n",
        "        print(\"=\" * 70)\n",
        "        print(f\"âœ… Total Stocks: {df_all['Stock'].nunique()}\")\n",
        "        print(f\"âœ… Total Sectors: {df_all['Sector'].nunique()}\")\n",
        "        print(f\"âœ… Total Rows: {len(df_all):,}\")\n",
        "        print(f\"âœ… Date Range: {df_all['Date'].min()} to {df_all['Date'].max()}\")\n",
        "        print(f\"\\nğŸ’¾ Saved to: {output_file}\")\n",
        "\n",
        "        # Show sample - only include columns that exist\n",
        "        print(\"\\nğŸ“ˆ Sample Output (Last 5 rows of BBL):\")\n",
        "        sample_cols = ['Date', 'Close', 'Market_Regime', 'Regime_Score', 'Volatility_Regime',\n",
        "                       'Pattern_Type', 'Pattern_Confidence', 'Fear_Greed_Index', 'Fear_Greed_Label',\n",
        "                       'Sector_Momentum', 'Sector_Rank']\n",
        "        available_cols = [col for col in sample_cols if col in df_all.columns]\n",
        "\n",
        "        sample = df_all[df_all['Stock'] == 'BBL'].tail(5)[available_cols]\n",
        "        print(sample.to_string(index=False))\n",
        "\n",
        "        # Show columns\n",
        "        print(\"\\nğŸ“‹ All Columns:\")\n",
        "        print(df_all.columns.tolist())\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"âœ… BLOCK 2 ENHANCED COMPLETED!\")\n",
        "    print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDPx4_oMDZt_"
      },
      "source": [
        "4ï¸âƒ£ à¸—à¸³à¹„à¸¡à¹ƒà¸Šà¹‰ TCN à¹à¸—à¸™ LSTM?\n",
        "AspectLSTMTCNParallelizationâŒ Sequentialâœ… Fully parallelTraining Speedà¸Šà¹‰à¸²à¹€à¸£à¹‡à¸§à¸à¸§à¹ˆà¸² 2-5xLong MemoryVanishing gradientâœ… Dilated convolutionsCausal Guaranteeà¸•à¹‰à¸­à¸‡à¸£à¸°à¸§à¸±à¸‡âœ… Built-in (padding=\"causal\")Residual Connectionsà¸•à¹‰à¸­à¸‡à¹€à¸à¸´à¹ˆà¸¡à¹€à¸­à¸‡âœ… Standard practice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muOqS_uzDdnK"
      },
      "source": [
        "# ğŸ“š Literature Review: Improving DL + Blending Ensemble for Stock Prediction\n",
        "\n",
        "## Current Performance Baseline\n",
        "- **BBL**: Accuracy 57.55% | Precision 43.00%\n",
        "- **KKP**: Accuracy 54.01% | Precision 41.53%\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¬ Key Findings from Literature\n",
        "\n",
        "### 1. Blending Ensemble (Hasan et al., 2022 - Crude Oil Prediction)\n",
        "\n",
        "**Architecture Recommendations:**\n",
        "| Component | Current | Literature Best Practice |\n",
        "|-----------|---------|-------------------------|\n",
        "| Base Models | TCN, LR, RF, GB | **Add: SVR, Ridge, KNN, Decision Tree** |\n",
        "| Validation Split | 15% | **10-15% is optimal** âœ… |\n",
        "| Meta-Learner | Logistic Regression | **Keep LR or try Ridge** âœ… |\n",
        "\n",
        "**Key Insight:**\n",
        "> \"The blending approach applies a leave-out method for individual weak predictors to combine the strengths of multiple diverse models\"\n",
        "\n",
        "**LKDSR Model (Best in Paper):**\n",
        "- Linear Regression\n",
        "- K-Nearest Neighbor\n",
        "- Decision Tree (Regression)\n",
        "- SVR\n",
        "- Ridge Regression\n",
        "\n",
        "**Performance:** RÂ² = 0.99 on daily prediction\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Comprehensive Ensemble Evaluation (Nti et al., 2020)\n",
        "\n",
        "**Critical Finding:**\n",
        "| Technique | Accuracy Range | RMSE Range |\n",
        "|-----------|---------------|------------|\n",
        "| **Stacking** | **90-100%** | **0.0001-0.001** |\n",
        "| **Blending** | **85.7-100%** | **0.002-0.01** |\n",
        "| Bagging | 53-97.78% | 0.01-0.11 |\n",
        "| Boosting | 52.7-96.32% | 0.01-0.443 |\n",
        "\n",
        "**Recommendation:**\n",
        "> \"Stacking and blending ensemble techniques offer higher prediction accuracies compared with bagging and boosting\"\n",
        "\n",
        "**Best Practices:**\n",
        "1. Use **heterogeneous base learners** (DT + SVM + NN)\n",
        "2. Minimum **3-5 base learners** recommended\n",
        "3. **Super Learner (Stacking)** often outperforms blending\n",
        "\n",
        "---\n",
        "\n",
        "### 3. CNN-LSTM Architecture (Wu et al., 2021)\n",
        "\n",
        "**SACLSTM Framework:**\n",
        "```\n",
        "Historical Data + Leading Indicators\n",
        "         â†“\n",
        "    Sequence Array (2D Image)\n",
        "         â†“\n",
        "    CNN Feature Extraction\n",
        "         â†“\n",
        "    LSTM Time Series Learning\n",
        "         â†“\n",
        "    Price Prediction\n",
        "```\n",
        "\n",
        "**Key Innovation:**\n",
        "- Use **leading indicators** (futures, options) as additional features\n",
        "- Convert time series to **2D array** for CNN input\n",
        "- Combine CNN + LSTM for better feature extraction\n",
        "\n",
        "**Features Used:**\n",
        "- Open, High, Low, Close, Volume (OHLCV)\n",
        "- Options data\n",
        "- Futures data\n",
        "- Technical indicators\n",
        "\n",
        "---\n",
        "\n",
        "### 4. Short-term Trend Prediction with LSTM (Shen & Shafiq, 2020)\n",
        "\n",
        "**Feature Engineering (Most Important!):**\n",
        "\n",
        "| Category | Features |\n",
        "|----------|----------|\n",
        "| Basic | Stock ID, Price, Volume |\n",
        "| Trading | Turnover rate, P/E ratio, P/B ratio |\n",
        "| Financial | Market cap, Free float |\n",
        "| Technical | RSI, MACD, Bollinger Bands |\n",
        "| Advanced | Top 10 shareholders, Block trades |\n",
        "\n",
        "**Critical Insight:**\n",
        "> \"The novelty of our proposed solution is that we proposed a **feature engineering along with a fine-tuned system** instead of just an LSTM model only\"\n",
        "\n",
        "**Recommended Feature Engineering Steps:**\n",
        "1. Feature Extension (create new features)\n",
        "2. Recursive Feature Elimination\n",
        "3. Correlation analysis\n",
        "4. Multi-collinearity removal\n",
        "\n",
        "---\n",
        "\n",
        "### 5. Transformers vs LSTM (Bilokon & Qiu, 2023)\n",
        "\n",
        "**Key Finding:**\n",
        "| Task | Best Model | Notes |\n",
        "|------|------------|-------|\n",
        "| Absolute Price | Transformer (10-25% better) | But quality insufficient for trading |\n",
        "| Price Difference | **LSTM (RÂ² = 11.5%)** | Better for trading |\n",
        "| Price Movement | **DLSTM (63.73-73.31% acc)** | Best for classification |\n",
        "\n",
        "**DLSTM Architecture:**\n",
        "- LSTM + Time Series Decomposition\n",
        "- Uses LOB (Limit Order Book) features\n",
        "- Achieves **73.31% accuracy** on movement prediction\n",
        "\n",
        "**Features from LOB:**\n",
        "- Bid/Ask prices (10 levels)\n",
        "- Bid/Ask volumes\n",
        "- Mid-price\n",
        "- Volume Order Imbalance (VOI)\n",
        "- Trade Flow Imbalance (TFI)\n",
        "\n",
        "---\n",
        "\n",
        "### 6. CQF Tutorial Requirements (2024)\n",
        "\n",
        "**Mandatory Steps:**\n",
        "1. **Feature Engineering** - Exhaustive, detailed\n",
        "2. **EDA** - Dimensionality reduction, outlier detection\n",
        "3. **Feature Scaling** - Based on EDA results\n",
        "4. **Multi-collinearity Analysis** - Required\n",
        "5. **Hyperparameter Optimization** - Mandatory\n",
        "6. **Backtesting** - Apply to trading strategy\n",
        "\n",
        "**Label Definition:**\n",
        "> \"Small positive returns below 0.25% can be labelled as negative\"\n",
        "\n",
        "**Class Imbalance:**\n",
        "> \"Should be addressed - either through model parameters or via label definition\"\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ¯ Actionable Improvements for Your Code\n",
        "\n",
        "### A. Feature Engineering (HIGH IMPACT)\n",
        "\n",
        "```python\n",
        "# Add these features to create_features()\n",
        "def create_features_enhanced(df):\n",
        "    close = df[\"Close\"]\n",
        "    high = df[\"High\"]\n",
        "    low = df[\"Low\"]\n",
        "    volume = df[\"Volume\"]\n",
        "    \n",
        "    # === EXISTING (Keep) ===\n",
        "    df[\"Log_Ret\"] = np.log(close / close.shift(1))\n",
        "    df[\"RSI\"] = ta.momentum.rsi(close, window=14) / 100.0\n",
        "    df[\"MACD_Norm\"] = ta.trend.macd_diff(close) / close\n",
        "    df[\"ATR_Pct\"] = ta.volatility.average_true_range(high, low, close) / close\n",
        "    df[\"Dist_SMA_20\"] = (close / close.rolling(20).mean()) - 1.0\n",
        "    df[\"Vol_Ratio\"] = volume / (volume.rolling(20).mean() + 1.0)\n",
        "    \n",
        "    # === NEW: Momentum Indicators ===\n",
        "    df[\"ROC_5\"] = close.pct_change(5)\n",
        "    df[\"ROC_10\"] = close.pct_change(10)\n",
        "    df[\"ROC_20\"] = close.pct_change(20)\n",
        "    df[\"MOM_10\"] = close - close.shift(10)\n",
        "    \n",
        "    # === NEW: Volatility Indicators ===\n",
        "    df[\"BB_Width\"] = (ta.volatility.bollinger_hband(close) -\n",
        "                     ta.volatility.bollinger_lband(close)) / close\n",
        "    df[\"BB_Position\"] = (close - ta.volatility.bollinger_lband(close)) / \\\n",
        "                        (ta.volatility.bollinger_hband(close) -\n",
        "                         ta.volatility.bollinger_lband(close) + 1e-8)\n",
        "    \n",
        "    # === NEW: Trend Indicators ===\n",
        "    df[\"ADX\"] = ta.trend.adx(high, low, close, window=14) / 100.0\n",
        "    df[\"CCI\"] = ta.trend.cci(high, low, close, window=20) / 200.0\n",
        "    df[\"DI_Plus\"] = ta.trend.adx_pos(high, low, close) / 100.0\n",
        "    df[\"DI_Minus\"] = ta.trend.adx_neg(high, low, close) / 100.0\n",
        "    \n",
        "    # === NEW: Volume Indicators ===\n",
        "    df[\"OBV_Norm\"] = ta.volume.on_balance_volume(close, volume) / volume.rolling(20).sum()\n",
        "    df[\"MFI\"] = ta.volume.money_flow_index(high, low, close, volume) / 100.0\n",
        "    \n",
        "    # === NEW: Price Pattern Features ===\n",
        "    df[\"High_Low_Pct\"] = (high - low) / close\n",
        "    df[\"Close_Open_Pct\"] = (close - df[\"Open\"]) / df[\"Open\"]\n",
        "    \n",
        "    # === NEW: Lagged Features (from Literature) ===\n",
        "    for lag in [1, 2, 3, 5]:\n",
        "        df[f\"Ret_Lag_{lag}\"] = df[\"Log_Ret\"].shift(lag)\n",
        "        df[f\"Vol_Lag_{lag}\"] = df[\"Vol_Ratio\"].shift(lag)\n",
        "    \n",
        "    return df\n",
        "```\n",
        "\n",
        "### B. Enhanced Base Models (from Blending Paper)\n",
        "\n",
        "```python\n",
        "# Replace current TAB_MODELS with:\n",
        "TAB_MODELS = {\n",
        "    # Original\n",
        "    \"LR\": LogisticRegression(max_iter=500, solver=\"lbfgs\", C=1.0),\n",
        "    \"RF\": RandomForestClassifier(n_estimators=500, max_depth=10,\n",
        "                                  min_samples_leaf=20, random_state=42),\n",
        "    \"GB\": GradientBoostingClassifier(n_estimators=200, max_depth=5,\n",
        "                                      learning_rate=0.05, random_state=42),\n",
        "    \n",
        "    # NEW from Literature\n",
        "    \"SVR\": SVC(kernel='rbf', C=100, gamma='auto', probability=True),\n",
        "    \"KNN\": KNeighborsClassifier(n_neighbors=10, weights='distance'),\n",
        "    \"Ridge\": RidgeClassifier(alpha=1.0),\n",
        "    \"XGB\": XGBClassifier(n_estimators=200, max_depth=5,\n",
        "                         learning_rate=0.05, use_label_encoder=False),\n",
        "    \"LGBM\": LGBMClassifier(n_estimators=200, max_depth=5,\n",
        "                           learning_rate=0.05, random_state=42),\n",
        "}\n",
        "```\n",
        "\n",
        "### C. TCN Architecture Improvements\n",
        "\n",
        "```python\n",
        "def build_tcn_model_enhanced(input_shape):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    \n",
        "    # Initial projection\n",
        "    x = Conv1D(64, 1, padding=\"same\")(inputs)  # Increased from 32\n",
        "    \n",
        "    # More TCN blocks with larger receptive field\n",
        "    x = tcn_residual_block(x, filters=64, kernel_size=3, dilation_rate=1)\n",
        "    x = tcn_residual_block(x, filters=64, kernel_size=3, dilation_rate=2)\n",
        "    x = tcn_residual_block(x, filters=64, kernel_size=3, dilation_rate=4)\n",
        "    x = tcn_residual_block(x, filters=128, kernel_size=3, dilation_rate=8)\n",
        "    x = tcn_residual_block(x, filters=128, kernel_size=3, dilation_rate=16)  # NEW\n",
        "    \n",
        "    # Multi-head attention (from Transformer literature)\n",
        "    attention = MultiHeadAttention(num_heads=4, key_dim=32)(x, x)\n",
        "    x = Add()([x, attention])\n",
        "    x = LayerNormalization()(x)\n",
        "    \n",
        "    x = GlobalAveragePooling1D()(x)\n",
        "    x = Dense(64, activation=\"relu\")(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Dense(32, activation=\"relu\")(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    outputs = Dense(1, activation=\"sigmoid\")(x)\n",
        "    \n",
        "    return Model(inputs, outputs, name=\"TCN_Enhanced\")\n",
        "```\n",
        "\n",
        "### D. Label Engineering (Critical!)\n",
        "\n",
        "```python\n",
        "def create_smart_labels(df, threshold=0.0025):\n",
        "    \"\"\"\n",
        "    From CQF Tutorial:\n",
        "    \"Small positive returns below 0.25% can be labelled as negative\"\n",
        "    \"\"\"\n",
        "    df[\"Next_Ret\"] = df[\"Close\"].pct_change().shift(-1)\n",
        "    \n",
        "    # Three-class approach (then convert to binary)\n",
        "    df[\"Target_3class\"] = 0  # Neutral\n",
        "    df.loc[df[\"Next_Ret\"] > threshold, \"Target_3class\"] = 1   # Up\n",
        "    df.loc[df[\"Next_Ret\"] < -threshold, \"Target_3class\"] = -1  # Down\n",
        "    \n",
        "    # For binary: neutral goes to majority class or dropped\n",
        "    # Option 1: Drop neutral\n",
        "    df_filtered = df[df[\"Target_3class\"] != 0].copy()\n",
        "    df_filtered[\"Target\"] = (df_filtered[\"Target_3class\"] == 1).astype(int)\n",
        "    \n",
        "    return df_filtered\n",
        "```\n",
        "\n",
        "### E. Class Imbalance Handling\n",
        "\n",
        "```python\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Option 1: SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Option 2: Class weights\n",
        "class_weights = compute_class_weight('balanced',\n",
        "                                      classes=np.unique(y_train),\n",
        "                                      y=y_train)\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "# Use in model\n",
        "model.fit(X, y, class_weight=class_weight_dict)\n",
        "```\n",
        "\n",
        "### F. Stacking vs Blending (Consider Switching)\n",
        "\n",
        "```python\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "\n",
        "# Stacking often outperforms Blending (90-100% vs 85.7-100%)\n",
        "stacking_clf = StackingClassifier(\n",
        "    estimators=[\n",
        "        ('tcn', tcn_wrapper),  # Need to wrap Keras model\n",
        "        ('rf', RandomForestClassifier(n_estimators=500)),\n",
        "        ('gb', GradientBoostingClassifier()),\n",
        "        ('svm', SVC(probability=True)),\n",
        "        ('xgb', XGBClassifier()),\n",
        "    ],\n",
        "    final_estimator=LogisticRegression(),\n",
        "    cv=5,  # Use cross-validation instead of holdout\n",
        "    stack_method='predict_proba'\n",
        ")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“Š Expected Improvement Targets\n",
        "\n",
        "| Metric | Current | Target (Literature) |\n",
        "|--------|---------|---------------------|\n",
        "| Accuracy | 54-57% | **65-75%** |\n",
        "| Precision | 41-43% | **55-65%** |\n",
        "| RMSE | - | 0.001-0.01 |\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”‘ Priority Implementation Order\n",
        "\n",
        "1. **Feature Engineering** (Highest Impact) - Add 15-20 new features\n",
        "2. **Label Engineering** - Use threshold for small returns\n",
        "3. **Add Base Models** - SVR, XGBoost, LightGBM\n",
        "4. **Class Imbalance** - SMOTE or class weights\n",
        "5. **TCN Enhancement** - Add attention, more layers\n",
        "6. **Consider Stacking** - May outperform blending\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“š References\n",
        "\n",
        "1. Hasan et al. (2022) - Blending Ensemble Learning Crude Oil\n",
        "2. Nti et al. (2020) - Comprehensive Evaluation Ensemble Learning\n",
        "3. Wu et al. (2021) - CNN-LSTM Stock Price Prediction\n",
        "4. Shen & Shafiq (2020) - Short-term Stock Trend Prediction LSTM\n",
        "5. Bilokon & Qiu (2023) - Transformers vs LSTM Electronic Trading\n",
        "6. CQF Tutorial DL/ML (2024)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUWP3QfZffZQ"
      },
      "source": [
        "à¹€à¸­à¸² Dummy à¸ˆà¸²à¸ Return à¸‚à¸­à¸‡ econometric à¸¡à¸²à¹€à¸—à¸£à¸™\n",
        "à¹‰à¹€à¸à¸´à¹ˆà¸¡ Adamoptimizer à¹à¸¥à¸° Gridsearch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czUyyAvCABB1",
        "outputId": "0e647908-d6bc-4079-9702-90e5f7391b68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "ğŸ§  BLOCK 5.5 V21.1: TCN+LSTM MULTI-HEAD (GATE+DIR) 3-class Â±3%/5d\n",
            "======================================================================\n",
            "\n",
            "ğŸ”¹ Processing: BBL (TCN+LSTM Multi-Head V21.1, Gate+Dir)\n",
            "   ğŸ“Š Target3 balance (Train): SELL=11.48% HOLD=75.81% BUY=12.71%\n",
            "   ğŸ’¾ Cached sequences saved.\n",
            "   ğŸ” Sanity: X_tcn_te std=2.842404 | X_lstm_te std=2.604465\n",
            "   ğŸ§ª Balanced resample: train_n=3216 (hold=1608, trade_os=1608)\n",
            "   ğŸ§  Training Multi-Head model (Gate+Dir)...\n",
            "   ğŸ§ª Phase1: Pretrain Gate only...\n",
            "   ğŸ§ª Phase2: Joint Gate+Dir...\n",
            "   ğŸ¯ Threshold: 0.65\n",
            "   ğŸ“Œ Test Acc (3-class argmax): 51.75% | BUY SignalRate: 8.25%\n",
            "   ğŸ” Pred distribution(argmax): SELL=28.04% HOLD=59.18% BUY=12.78%\n",
            "   ğŸ” Mean probs: sell=0.274, hold=0.546, buy=0.179\n",
            "   ğŸ” Gate stats: min=0.003 p50=0.455 max=0.988 | %>0.5=45.57%\n",
            "   ğŸ” P_BUY stats:  min=0.000 p50=0.088 max=0.981\n",
            "   ğŸ§ª BUY SignalRate @th=0.35: 17.32%\n",
            "   ğŸ§ª BUY SignalRate @th=0.45: 13.61%\n",
            "   ğŸ§ª BUY SignalRate @th=0.55: 11.13%\n",
            "   ğŸ§ª BUY SignalRate @th=0.65: 8.25%\n",
            "\n",
            "   ğŸ“Š Test Classification Report (3-class argmax):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     SELL(0)     0.1029    0.3684    0.1609        38\n",
            "     HOLD(1)     0.8084    0.6042    0.6915       384\n",
            "      BUY(2)     0.0806    0.0794    0.0800        63\n",
            "\n",
            "    accuracy                         0.5175       485\n",
            "   macro avg     0.3306    0.3507    0.3108       485\n",
            "weighted avg     0.6586    0.5175    0.5705       485\n",
            "\n",
            "   ğŸ”¥ Confusion Matrix (Test):\n",
            "             PRED_SELL(0)  PRED_HOLD(1)  PRED_BUY(2)\n",
            "ACT_SELL(0)            14            13           11\n",
            "ACT_HOLD(1)           106           232           46\n",
            "ACT_BUY(2)             16            42            5\n",
            "\n",
            "   ğŸ“Š Gate (TRADE vs HOLD) report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8182    0.5625    0.6667       384\n",
            "           1     0.2398    0.5248    0.3292       101\n",
            "\n",
            "    accuracy                         0.5546       485\n",
            "   macro avg     0.5290    0.5436    0.4979       485\n",
            "weighted avg     0.6977    0.5546    0.5964       485\n",
            "\n",
            "\n",
            "   ğŸ“Š Dir (BUY vs SELL) report on TRUE-TRADE:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.3731    0.6579    0.4762        38\n",
            "           1     0.6176    0.3333    0.4330        63\n",
            "\n",
            "    accuracy                         0.4554       101\n",
            "   macro avg     0.4954    0.4956    0.4546       101\n",
            "weighted avg     0.5257    0.4554    0.4492       101\n",
            "\n",
            "\n",
            "   âœ… Saved: DL_Predictions_V20_ECT_META_BBL.xlsx + fusion_model_BBL_V21.keras\n",
            "\n",
            "ğŸ”¹ Processing: KKP (TCN+LSTM Multi-Head V21.1, Gate+Dir)\n",
            "   ğŸ“Š Target3 balance (Train): SELL=12.03% HOLD=71.28% BUY=16.69%\n",
            "   ğŸ’¾ Cached sequences saved.\n",
            "   ğŸ” Sanity: X_tcn_te std=2.428337 | X_lstm_te std=2.228982\n",
            "   ğŸ§ª Balanced resample: train_n=3022 (hold=1511, trade_os=1511)\n",
            "   ğŸ§  Training Multi-Head model (Gate+Dir)...\n",
            "   ğŸ§ª Phase1: Pretrain Gate only...\n",
            "   ğŸ§ª Phase2: Joint Gate+Dir...\n",
            "   ğŸ¯ Threshold: 0.65\n",
            "   ğŸ“Œ Test Acc (3-class argmax): 55.05% | BUY SignalRate: 6.60%\n",
            "   ğŸ” Pred distribution(argmax): SELL=16.49% HOLD=74.23% BUY=9.28%\n",
            "   ğŸ” Mean probs: sell=0.214, hold=0.676, buy=0.111\n",
            "   ğŸ” Gate stats: min=0.001 p50=0.237 max=0.996 | %>0.5=27.42%\n",
            "   ğŸ” P_BUY stats:  min=0.000 p50=0.008 max=0.995\n",
            "   ğŸ§ª BUY SignalRate @th=0.35: 12.37%\n",
            "   ğŸ§ª BUY SignalRate @th=0.45: 9.90%\n",
            "   ğŸ§ª BUY SignalRate @th=0.55: 8.25%\n",
            "   ğŸ§ª BUY SignalRate @th=0.65: 6.60%\n",
            "\n",
            "   ğŸ“Š Test Classification Report (3-class argmax):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     SELL(0)     0.1375    0.1897    0.1594        58\n",
            "     HOLD(1)     0.6750    0.7523    0.7116       323\n",
            "      BUY(2)     0.2889    0.1250    0.1745       104\n",
            "\n",
            "    accuracy                         0.5505       485\n",
            "   macro avg     0.3671    0.3557    0.3485       485\n",
            "weighted avg     0.5279    0.5505    0.5304       485\n",
            "\n",
            "   ğŸ”¥ Confusion Matrix (Test):\n",
            "             PRED_SELL(0)  PRED_HOLD(1)  PRED_BUY(2)\n",
            "ACT_SELL(0)            11            43            4\n",
            "ACT_HOLD(1)            52           243           28\n",
            "ACT_BUY(2)             17            74           13\n",
            "\n",
            "   ğŸ“Š Gate (TRADE vs HOLD) report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6761    0.7368    0.7052       323\n",
            "           1     0.3609    0.2963    0.3254       162\n",
            "\n",
            "    accuracy                         0.5897       485\n",
            "   macro avg     0.5185    0.5166    0.5153       485\n",
            "weighted avg     0.5708    0.5897    0.5783       485\n",
            "\n",
            "\n",
            "   ğŸ“Š Dir (BUY vs SELL) report on TRUE-TRADE:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.3238    0.5862    0.4172        58\n",
            "           1     0.5789    0.3173    0.4099       104\n",
            "\n",
            "    accuracy                         0.4136       162\n",
            "   macro avg     0.4514    0.4518    0.4136       162\n",
            "weighted avg     0.4876    0.4136    0.4125       162\n",
            "\n",
            "\n",
            "   âœ… Saved: DL_Predictions_V20_ECT_META_KKP.xlsx + fusion_model_KKP_V21.keras\n",
            "\n",
            "âœ… DONE.\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# ğŸ§  BLOCK 5.5 V21.1 (MULTI-HEAD GATE+DIR, FIX COLLAPSE)\n",
        "#    âœ… Keep TCN + LSTM\n",
        "#    âœ… Outputs for Block 6 UNCHANGED:\n",
        "#         - DL_Predictions_V20_ECT_META_{stock}.xlsx\n",
        "#         - Date, P_SELL, P_HOLD, P_BUY, P_META, Signal\n",
        "#         - P_META = P_BUY\n",
        "#\n",
        "# ğŸ”§ Fixes:\n",
        "#   A) Prevent constant-output collapse:\n",
        "#      - Normalize TCN inputs to stationary features (returns & relative prices)\n",
        "#      - Lower LR + clip gradients\n",
        "#      - Do NOT stack (resample + huge pos_weight) at the same time\n",
        "#   B) Keep Keras KeyError fix: outputs as dict\n",
        "#   C) Cache version bump to avoid using old cached sequences silently\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import ta\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Dense, Dropout, Conv1D, BatchNormalization, Activation,\n",
        "    GlobalAveragePooling1D, Add, SpatialDropout1D, LSTM, Concatenate\n",
        ")\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import warnings\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# ============================================================\n",
        "# 1) CONFIGURATION (KEEP NAMES STABLE)\n",
        "# ============================================================\n",
        "TARGET_STOCKS = [\"BBL\", \"KKP\"]\n",
        "\n",
        "LOOK_BACK = 60\n",
        "LOOK_BACK_LSTM = 30\n",
        "\n",
        "TRAIN_SPLIT_DATE = \"2024-01-01\"\n",
        "PRED_HORIZON = 5\n",
        "\n",
        "BUY_THRESHOLD  = 0.03\n",
        "SELL_THRESHOLD = -0.03\n",
        "\n",
        "# keep this name (Block 6 expects threshold logic)\n",
        "META_THRESHOLD = 0.65\n",
        "\n",
        "# Cache folder (version bump to avoid old cache mismatch)\n",
        "CACHE_DIR = \"./block55_cache\"\n",
        "os.makedirs(CACHE_DIR, exist_ok=True)\n",
        "USE_CACHE = True\n",
        "CACHE_TAG = \"V211\"   # <-- important: new cache tag\n",
        "\n",
        "# Training knobs\n",
        "EPOCHS = 80\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# ğŸ”§ Lower LR + gradient clipping to prevent sigmoid saturation\n",
        "LR = 0.001\n",
        "CLIPNORM = 1.0\n",
        "\n",
        "EARLY_PATIENCE = 10\n",
        "\n",
        "# ====== IMPORTANT: choose ONE imbalance method ======\n",
        "# We'll keep balanced resample ON, and set weights ~1 to avoid double-counting.\n",
        "USE_BALANCED_RESAMPLE = True\n",
        "\n",
        "# Gate weights (keep mild because we resample already)\n",
        "GATE_POS_WEIGHT = 1.2   # trade\n",
        "GATE_NEG_WEIGHT = 1.0   # hold\n",
        "\n",
        "# Pretrain Gate (keep, but not too long)\n",
        "PRETRAIN_GATE_EPOCHS = 12\n",
        "\n",
        "# ============================================================\n",
        "# 2) FEATURES (Indicators) for LSTM branch\n",
        "# ============================================================\n",
        "def build_indicators(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    close = df[\"Close\"].astype(float)\n",
        "    high  = df[\"High\"].astype(float)\n",
        "    low   = df[\"Low\"].astype(float)\n",
        "    vol   = df[\"Volume\"].replace(0, 1).astype(float)\n",
        "\n",
        "    df[\"Log_Ret\"] = np.log(close / close.shift(1))\n",
        "    df[\"RSI\"] = ta.momentum.rsi(close, window=14) / 100.0\n",
        "    df[\"MACD_Norm\"] = ta.trend.macd_diff(close) / close\n",
        "    df[\"ATR_Pct\"] = ta.volatility.average_true_range(high, low, close, window=14) / close\n",
        "    df[\"Dist_SMA50\"] = (close / close.rolling(50).mean()) - 1\n",
        "    df[\"Vol_Chg\"] = np.log(vol / vol.shift(1))\n",
        "\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    df.fillna(0.0, inplace=True)\n",
        "    return df\n",
        "\n",
        "INDICATOR_COLS = [\"Log_Ret\", \"RSI\", \"MACD_Norm\", \"ATR_Pct\", \"Dist_SMA50\", \"Vol_Chg\"]\n",
        "\n",
        "# ============================================================\n",
        "# 3) LABEL: 3-class (SELL=0, HOLD=1, BUY=2)\n",
        "# ============================================================\n",
        "def build_labels(close: pd.Series) -> pd.Series:\n",
        "    future_ret = close.shift(-PRED_HORIZON) / close - 1.0\n",
        "    y = np.where(\n",
        "        future_ret >= BUY_THRESHOLD, 2,\n",
        "        np.where(future_ret <= SELL_THRESHOLD, 0, 1)\n",
        "    )\n",
        "    return pd.Series(y, index=close.index, name=\"Target3\")\n",
        "\n",
        "# ============================================================\n",
        "# 4) TCN backbone (same style)\n",
        "# ============================================================\n",
        "DILATIONS = [1,2,4,8,16,1,2,4,8,16]\n",
        "\n",
        "def tcn_residual_block(x, filters=100, kernel_size=2, dilation_rate=1, dropout_rate=0.5):\n",
        "    prev = x\n",
        "\n",
        "    x = Conv1D(filters, kernel_size, padding=\"causal\", dilation_rate=dilation_rate)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = SpatialDropout1D(dropout_rate)(x)\n",
        "\n",
        "    x = Conv1D(filters, kernel_size, padding=\"causal\", dilation_rate=dilation_rate)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = SpatialDropout1D(dropout_rate)(x)\n",
        "\n",
        "    if prev.shape[-1] != filters:\n",
        "        prev = Conv1D(filters, 1, padding=\"same\")(prev)\n",
        "\n",
        "    return Add()([prev, x])\n",
        "\n",
        "def build_tcn_backbone(input_shape, embed_dim=16):\n",
        "    inp = Input(shape=input_shape, name=\"TCN_Input\")\n",
        "    x = Conv1D(100, 1, padding=\"same\")(inp)\n",
        "    for d in DILATIONS:\n",
        "        x = tcn_residual_block(x, filters=100, kernel_size=2, dilation_rate=d, dropout_rate=0.5)\n",
        "    x = GlobalAveragePooling1D()(x)\n",
        "    x = Dense(embed_dim, activation=\"relu\", name=\"TCN_Embed\")(x)\n",
        "    return Model(inp, x, name=\"TCN_Backbone\")\n",
        "\n",
        "# ============================================================\n",
        "# 5) MULTI-HEAD FUSION MODEL: Gate + Direction (outputs dict)\n",
        "# ============================================================\n",
        "def build_multihead_model(tcn_input_shape, lstm_input_shape):\n",
        "    tcn_in  = Input(shape=tcn_input_shape,  name=\"TCN_Seq_Input\")\n",
        "    lstm_in = Input(shape=lstm_input_shape, name=\"LSTM_Seq_Input\")\n",
        "\n",
        "    tcn_backbone = build_tcn_backbone(tcn_input_shape, embed_dim=16)\n",
        "    tcn_emb = tcn_backbone(tcn_in)\n",
        "\n",
        "    lstm_emb = LSTM(512, activation=\"tanh\", dropout=0.30, return_sequences=False, name=\"LSTM_512\")(lstm_in)\n",
        "\n",
        "    h = Concatenate(name=\"FusionConcat\")([tcn_emb, lstm_emb])\n",
        "    h = Dense(128, activation=\"tanh\", name=\"FusionDense1\")(h)\n",
        "    h = Dropout(0.30, name=\"FusionDrop1\")(h)\n",
        "    h = Dense(64, activation=\"tanh\", name=\"FusionDense2\")(h)\n",
        "    h = Dropout(0.20, name=\"FusionDrop2\")(h)\n",
        "\n",
        "    out_gate = Dense(1, activation=\"sigmoid\", name=\"Gate_Trade\")(h)\n",
        "    out_dir  = Dense(1, activation=\"sigmoid\", name=\"Dir_Buy\")(h)\n",
        "\n",
        "    model = Model(\n",
        "        inputs=[tcn_in, lstm_in],\n",
        "        outputs={\"Gate_Trade\": out_gate, \"Dir_Buy\": out_dir},\n",
        "        name=\"TCN_LSTM_MultiHead_V21\"\n",
        "    )\n",
        "\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=LR, clipnorm=CLIPNORM)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=opt,\n",
        "        loss={\"Gate_Trade\": \"binary_crossentropy\", \"Dir_Buy\": \"binary_crossentropy\"},\n",
        "        metrics={\n",
        "            \"Gate_Trade\": [tf.keras.metrics.BinaryAccuracy(name=\"acc\")],\n",
        "            \"Dir_Buy\": [tf.keras.metrics.BinaryAccuracy(name=\"acc\")],\n",
        "        }\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# ============================================================\n",
        "# 6) SEQUENCE BUILDERS\n",
        "#    ğŸ”§ KEY FIX: TCN uses stationary/normalized features (5 dims)\n",
        "#       [ret, open_rel, high_rel, low_rel, vol_chg]\n",
        "#    (keeps shape (LOOK_BACK, 5) the same)\n",
        "# ============================================================\n",
        "def make_tcn_sequences(df: pd.DataFrame, idx: pd.Index, lookback=LOOK_BACK):\n",
        "    df = df.copy()\n",
        "\n",
        "    close = df[\"Close\"].astype(float)\n",
        "    open_ = df[\"Open\"].astype(float)\n",
        "    high  = df[\"High\"].astype(float)\n",
        "    low   = df[\"Low\"].astype(float)\n",
        "    vol   = df[\"Volume\"].replace(0, 1).astype(float)\n",
        "\n",
        "    # Stationary features\n",
        "    ret = np.log(close / close.shift(1)).fillna(0.0)\n",
        "    open_rel = (open_ / close - 1.0).fillna(0.0)\n",
        "    high_rel = (high / close - 1.0).fillna(0.0)\n",
        "    low_rel  = (low  / close - 1.0).fillna(0.0)\n",
        "    vol_chg  = np.log(vol / vol.shift(1)).fillna(0.0)\n",
        "\n",
        "    feats = np.vstack([ret, open_rel, high_rel, low_rel, vol_chg]).T  # (N, 5)\n",
        "\n",
        "    X, dates = [], []\n",
        "    for i in range(lookback, len(feats)):\n",
        "        X.append(feats[i-lookback:i])\n",
        "        dates.append(idx[i])\n",
        "    return np.array(X, dtype=np.float32), pd.Index(dates)\n",
        "\n",
        "def make_lstm_sequences(df: pd.DataFrame, idx: pd.Index, lookback=LOOK_BACK_LSTM):\n",
        "    feats = df[INDICATOR_COLS].astype(float).values.astype(np.float32)\n",
        "    X, dates = [], []\n",
        "    for i in range(lookback, len(feats)):\n",
        "        X.append(feats[i-lookback:i])\n",
        "        dates.append(idx[i])\n",
        "    return np.array(X, dtype=np.float32), pd.Index(dates)\n",
        "\n",
        "def align_y(y: pd.Series, seq_dates: pd.Index) -> np.ndarray:\n",
        "    return y.reindex(seq_dates).astype(int).values\n",
        "\n",
        "# ============================================================\n",
        "# 7) HELPERS: build gate/dir targets + sample weights\n",
        "# ============================================================\n",
        "def build_gate_dir_targets(y3: np.ndarray):\n",
        "    gate_y = (y3 != 1).astype(np.float32)\n",
        "    dir_y = np.zeros_like(gate_y, dtype=np.float32)\n",
        "    dir_y[y3 == 2] = 1.0\n",
        "    dir_y[y3 == 0] = 0.0\n",
        "    return gate_y, dir_y\n",
        "\n",
        "def build_sample_weights_for_heads(y3: np.ndarray):\n",
        "    gate_w = np.ones(len(y3), dtype=np.float32) * GATE_NEG_WEIGHT\n",
        "    gate_w[y3 != 1] = GATE_POS_WEIGHT\n",
        "\n",
        "    dir_w = np.zeros(len(y3), dtype=np.float32)\n",
        "    dir_w[y3 != 1] = 1.0\n",
        "    return gate_w, dir_w\n",
        "\n",
        "# ============================================================\n",
        "# 8) EVALUATION\n",
        "# ============================================================\n",
        "def print_3class_report(y_true3, p_sell, p_hold, p_buy):\n",
        "    y_pred3 = np.argmax(np.vstack([p_sell, p_hold, p_buy]).T, axis=1)\n",
        "\n",
        "    print(\"\\n   ğŸ“Š Test Classification Report (3-class argmax):\")\n",
        "    rep = classification_report(\n",
        "        y_true3, y_pred3,\n",
        "        labels=[0,1,2],\n",
        "        target_names=[\"SELL(0)\", \"HOLD(1)\", \"BUY(2)\"],\n",
        "        digits=4,\n",
        "        zero_division=0\n",
        "    )\n",
        "    print(rep)\n",
        "\n",
        "    cm = confusion_matrix(y_true3, y_pred3, labels=[0,1,2])\n",
        "    cm_df = pd.DataFrame(\n",
        "        cm,\n",
        "        index=[\"ACT_SELL(0)\", \"ACT_HOLD(1)\", \"ACT_BUY(2)\"],\n",
        "        columns=[\"PRED_SELL(0)\", \"PRED_HOLD(1)\", \"PRED_BUY(2)\"]\n",
        "    )\n",
        "    print(\"   ğŸ”¥ Confusion Matrix (Test):\")\n",
        "    print(cm_df)\n",
        "\n",
        "def print_gate_dir_reports(y3_te, gate_p_te, dir_p_te):\n",
        "    gate_true = (y3_te != 1).astype(int)\n",
        "    gate_pred = (gate_p_te >= 0.5).astype(int)\n",
        "    print(\"\\n   ğŸ“Š Gate (TRADE vs HOLD) report:\")\n",
        "    print(classification_report(gate_true, gate_pred, digits=4, zero_division=0))\n",
        "\n",
        "    mask_trade_true = (y3_te != 1)\n",
        "    if mask_trade_true.sum() > 0:\n",
        "        dir_true = (y3_te[mask_trade_true] == 2).astype(int)\n",
        "        dir_pred = (dir_p_te[mask_trade_true] >= 0.5).astype(int)\n",
        "        print(\"\\n   ğŸ“Š Dir (BUY vs SELL) report on TRUE-TRADE:\")\n",
        "        print(classification_report(dir_true, dir_pred, digits=4, zero_division=0))\n",
        "\n",
        "# ============================================================\n",
        "# 9) TRAIN & EXPORT (KEEP OUTPUT FILE NAME + COLUMNS FOR BLOCK 6)\n",
        "# ============================================================\n",
        "def train_block55_v211(stock: str):\n",
        "    print(f\"\\nğŸ”¹ Processing: {stock} (TCN+LSTM Multi-Head V21.1, Gate+Dir)\")\n",
        "\n",
        "    df = yf.download(f\"{stock}.BK\", start=\"2015-01-01\", end=\"2025-12-31\", progress=False)\n",
        "    if isinstance(df.columns, pd.MultiIndex):\n",
        "        df.columns = df.columns.get_level_values(0)\n",
        "    if df.empty:\n",
        "        print(\"   âš ï¸ Empty data.\")\n",
        "        return\n",
        "\n",
        "    df = df.copy()\n",
        "    df.index = pd.to_datetime(df.index)\n",
        "    df = build_indicators(df)\n",
        "\n",
        "    y3 = build_labels(df[\"Close\"])\n",
        "    df[\"Target3\"] = y3\n",
        "    df.dropna(subset=[\"Target3\"], inplace=True)\n",
        "\n",
        "    train_df = df[df.index < TRAIN_SPLIT_DATE].copy()\n",
        "    test_df  = df[df.index >= TRAIN_SPLIT_DATE].copy()\n",
        "\n",
        "    if len(train_df) < (LOOK_BACK + 300) or len(test_df) < (LOOK_BACK + 80):\n",
        "        print(f\"   âš ï¸ Not enough data. Train={len(train_df)} Test={len(test_df)}\")\n",
        "        return\n",
        "\n",
        "    tr_counts = train_df[\"Target3\"].value_counts(normalize=True).sort_index()\n",
        "    print(f\"   ğŸ“Š Target3 balance (Train): SELL={tr_counts.get(0,0):.2%} HOLD={tr_counts.get(1,0):.2%} BUY={tr_counts.get(2,0):.2%}\")\n",
        "\n",
        "    # ---- cache (versioned) ----\n",
        "    cache_prefix = os.path.join(CACHE_DIR, f\"{stock}_{CACHE_TAG}\")\n",
        "    tcn_x_path   = cache_prefix + \"_X_TCN.npy\"\n",
        "    lstm_x_path  = cache_prefix + \"_X_LSTM.npy\"\n",
        "    y_path       = cache_prefix + \"_Y3.npy\"\n",
        "    d_path       = cache_prefix + \"_DATES.pkl\"\n",
        "\n",
        "    if USE_CACHE and all(os.path.exists(p) for p in [tcn_x_path, lstm_x_path, y_path, d_path]):\n",
        "        X_tcn  = np.load(tcn_x_path, allow_pickle=False)\n",
        "        X_lstm = np.load(lstm_x_path, allow_pickle=False)\n",
        "        y3_seq = np.load(y_path, allow_pickle=False)\n",
        "        dates = pd.to_datetime(pd.Index(pd.read_pickle(d_path)))\n",
        "        print(\"   âš¡ Loaded cached sequences.\")\n",
        "    else:\n",
        "        X_tcn_all, dt_tcn = make_tcn_sequences(df, df.index, lookback=LOOK_BACK)\n",
        "        X_lstm_all, dt_lstm = make_lstm_sequences(df, df.index, lookback=LOOK_BACK_LSTM)\n",
        "\n",
        "        dates = dt_tcn.intersection(dt_lstm)\n",
        "        X_tcn  = X_tcn_all[np.isin(dt_tcn, dates)]\n",
        "        X_lstm = X_lstm_all[np.isin(dt_lstm, dates)]\n",
        "        y3_seq = align_y(df[\"Target3\"], dates)\n",
        "\n",
        "        if USE_CACHE:\n",
        "            np.save(tcn_x_path, X_tcn)\n",
        "            np.save(lstm_x_path, X_lstm)\n",
        "            np.save(y_path, y3_seq)\n",
        "            pd.Series(pd.to_datetime(dates)).to_pickle(d_path)\n",
        "            print(\"   ğŸ’¾ Cached sequences saved.\")\n",
        "\n",
        "    # Split train/test\n",
        "    mask_train = dates < pd.to_datetime(TRAIN_SPLIT_DATE)\n",
        "    mask_test  = ~mask_train\n",
        "\n",
        "    X_tcn_tr, X_tcn_te = X_tcn[mask_train], X_tcn[mask_test]\n",
        "    X_lstm_tr, X_lstm_te = X_lstm[mask_train], X_lstm[mask_test]\n",
        "    y3_tr, y3_te = y3_seq[mask_train], y3_seq[mask_test]\n",
        "    dt_te = dates[mask_test]\n",
        "\n",
        "    if len(y3_tr) < 500 or len(y3_te) < 200:\n",
        "        print(\"   âš ï¸ Not enough aligned seq after split.\")\n",
        "        return\n",
        "\n",
        "    # ğŸ” sanity check: inputs must have variance\n",
        "    print(f\"   ğŸ” Sanity: X_tcn_te std={float(X_tcn_te.std()):.6f} | X_lstm_te std={float(X_lstm_te.std()):.6f}\")\n",
        "\n",
        "    # Balanced resample (training only)\n",
        "    if USE_BALANCED_RESAMPLE:\n",
        "        rng = np.random.default_rng(42)\n",
        "        idx_trade = np.where(y3_tr != 1)[0]\n",
        "        idx_hold  = np.where(y3_tr == 1)[0]\n",
        "        if len(idx_trade) > 0 and len(idx_hold) > 0:\n",
        "            idx_trade_os = rng.choice(idx_trade, size=len(idx_hold), replace=True)\n",
        "            idx_bal = np.concatenate([idx_hold, idx_trade_os])\n",
        "            rng.shuffle(idx_bal)\n",
        "            X_tcn_tr  = X_tcn_tr[idx_bal]\n",
        "            X_lstm_tr = X_lstm_tr[idx_bal]\n",
        "            y3_tr     = y3_tr[idx_bal]\n",
        "            print(f\"   ğŸ§ª Balanced resample: train_n={len(y3_tr)} (hold={len(idx_hold)}, trade_os={len(idx_trade_os)})\")\n",
        "\n",
        "    gate_y_tr, dir_y_tr = build_gate_dir_targets(y3_tr)\n",
        "    gate_w_tr, dir_w_tr = build_sample_weights_for_heads(y3_tr)\n",
        "\n",
        "    # Train model\n",
        "    print(\"   ğŸ§  Training Multi-Head model (Gate+Dir)...\")\n",
        "    model = build_multihead_model(\n",
        "        tcn_input_shape=(LOOK_BACK, 5),\n",
        "        lstm_input_shape=(LOOK_BACK_LSTM, len(INDICATOR_COLS))\n",
        "    )\n",
        "\n",
        "    cbs = [\n",
        "        EarlyStopping(patience=EARLY_PATIENCE, restore_best_weights=True, monitor=\"val_loss\", mode=\"min\"),\n",
        "        ReduceLROnPlateau(patience=4, factor=0.5, min_lr=1e-5, monitor=\"val_loss\", mode=\"min\", verbose=0),\n",
        "    ]\n",
        "\n",
        "    # Phase1: Gate only\n",
        "    print(\"   ğŸ§ª Phase1: Pretrain Gate only...\")\n",
        "    dir_w_phase1 = np.zeros_like(dir_w_tr, dtype=np.float32)\n",
        "    model.fit(\n",
        "        [X_tcn_tr, X_lstm_tr],\n",
        "        {\"Gate_Trade\": gate_y_tr, \"Dir_Buy\": dir_y_tr},\n",
        "        sample_weight={\"Gate_Trade\": gate_w_tr, \"Dir_Buy\": dir_w_phase1},\n",
        "        validation_split=0.2,\n",
        "        epochs=PRETRAIN_GATE_EPOCHS,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        callbacks=cbs,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # Phase2: Joint\n",
        "    print(\"   ğŸ§ª Phase2: Joint Gate+Dir...\")\n",
        "    model.fit(\n",
        "        [X_tcn_tr, X_lstm_tr],\n",
        "        {\"Gate_Trade\": gate_y_tr, \"Dir_Buy\": dir_y_tr},\n",
        "        sample_weight={\"Gate_Trade\": gate_w_tr, \"Dir_Buy\": dir_w_tr},\n",
        "        validation_split=0.2,\n",
        "        epochs=EPOCHS,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        callbacks=cbs,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # Predict\n",
        "    pred = model.predict([X_tcn_te, X_lstm_te], verbose=0)\n",
        "    gate_p_te = pred[\"Gate_Trade\"].reshape(-1)\n",
        "    dir_p_te  = pred[\"Dir_Buy\"].reshape(-1)\n",
        "\n",
        "    # Compose 3-class probs\n",
        "    p_trade = np.clip(gate_p_te, 1e-6, 1 - 1e-6)\n",
        "    p_buy_given_trade = np.clip(dir_p_te, 1e-6, 1 - 1e-6)\n",
        "\n",
        "    p_buy  = p_trade * p_buy_given_trade\n",
        "    p_sell = p_trade * (1.0 - p_buy_given_trade)\n",
        "    p_hold = 1.0 - p_trade\n",
        "\n",
        "    P_META = p_buy\n",
        "    signal01 = (P_META >= META_THRESHOLD).astype(int)\n",
        "\n",
        "    # Diagnostics\n",
        "    y_pred3 = np.argmax(np.vstack([p_sell, p_hold, p_buy]).T, axis=1)\n",
        "    acc3 = float(np.mean(y_pred3 == y3_te))\n",
        "    buy_rate = float(np.mean(signal01))\n",
        "\n",
        "    print(f\"   ğŸ¯ Threshold: {META_THRESHOLD:.2f}\")\n",
        "    print(f\"   ğŸ“Œ Test Acc (3-class argmax): {acc3:.2%} | BUY SignalRate: {buy_rate:.2%}\")\n",
        "    print(f\"   ğŸ” Pred distribution(argmax): SELL={np.mean(y_pred3==0):.2%} HOLD={np.mean(y_pred3==1):.2%} BUY={np.mean(y_pred3==2):.2%}\")\n",
        "    print(f\"   ğŸ” Mean probs: sell={float(np.mean(p_sell)):.3f}, hold={float(np.mean(p_hold)):.3f}, buy={float(np.mean(p_buy)):.3f}\")\n",
        "\n",
        "    print(f\"   ğŸ” Gate stats: min={gate_p_te.min():.3f} p50={np.median(gate_p_te):.3f} max={gate_p_te.max():.3f} | %>0.5={(gate_p_te>0.5).mean():.2%}\")\n",
        "    print(f\"   ğŸ” P_BUY stats:  min={p_buy.min():.3f} p50={np.median(p_buy):.3f} max={p_buy.max():.3f}\")\n",
        "\n",
        "    for th in [0.35, 0.45, 0.55, 0.65]:\n",
        "        sr = float(np.mean(P_META >= th))\n",
        "        print(f\"   ğŸ§ª BUY SignalRate @th={th:.2f}: {sr:.2%}\")\n",
        "\n",
        "    print_3class_report(y3_te, p_sell, p_hold, p_buy)\n",
        "    print_gate_dir_reports(y3_te, gate_p_te, dir_p_te)\n",
        "\n",
        "    # Export (Block6-compatible)\n",
        "    res = pd.DataFrame({\n",
        "        \"Date\": pd.to_datetime(dt_te),\n",
        "        \"P_SELL\": p_sell,\n",
        "        \"P_HOLD\": p_hold,\n",
        "        \"P_BUY\":  p_buy,\n",
        "        \"P_META\": P_META,\n",
        "        \"Signal\": signal01\n",
        "    })\n",
        "\n",
        "    out_name = f\"DL_Predictions_V20_ECT_META_{stock}.xlsx\"\n",
        "    res.to_excel(out_name, index=False)\n",
        "    model.save(f\"fusion_model_{stock}_V21.keras\")\n",
        "\n",
        "    print(f\"\\n   âœ… Saved: {out_name} + fusion_model_{stock}_V21.keras\")\n",
        "\n",
        "# ============================================================\n",
        "# MAIN\n",
        "# ============================================================\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\" * 70)\n",
        "    print(\"ğŸ§  BLOCK 5.5 V21.1: TCN+LSTM MULTI-HEAD (GATE+DIR) 3-class Â±3%/5d\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    for s in TARGET_STOCKS:\n",
        "        train_block55_v211(s)\n",
        "\n",
        "    print(\"\\nâœ… DONE.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-u-fC_JSABEf",
        "outputId": "f5e12863-4eab-42d7-9947-346836d45093"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "ğŸ”— BLOCK 6 V2.6: Data Integration (V20 Support)\n",
            "======================================================================\n",
            "\n",
            "ğŸ”¹ Processing Stocks...\n",
            "\n",
            "   ğŸ‘‰ Stock: BBL\n",
            "      âœ… Merged Signals from DL_Predictions_V20_ECT_META_BBL.xlsx (using 'P_META')\n",
            "\n",
            "   ğŸ‘‰ Stock: KKP\n",
            "      âœ… Merged Signals from DL_Predictions_V20_ECT_META_KKP.xlsx (using 'P_META')\n",
            "\n",
            "======================================================================\n",
            "âœ… SUCCESS: Integrated Data saved to 'Final_RL_Input_Ready.xlsx'\n",
            "ğŸ“Š Rows: 5318 | Stocks: ['BBL' 'KKP']\n",
            "======================================================================\n",
            "ğŸ‘‰ NEXT: Run Block 13 (RL Agent)\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# ğŸ”— BLOCK 6 V2.6: Data Integration (V20 Support)\n",
        "#    âœ… Compatibility: NOW SUPPORTS 'DL_Predictions_V20_*.xlsx'\n",
        "#    âœ… Feature: Auto-calculates thresholds if missing\n",
        "#    âœ… Output: Final_RL_Input_Ready.xlsx (Ready for RL Agent)\n",
        "# ============================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import warnings\n",
        "import os\n",
        "import ta\n",
        "import re\n",
        "import joblib  # âœ… needed for robustness (no name changes)\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"ğŸ”— BLOCK 6 V2.6: Data Integration (V20 Support)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# ============================================================\n",
        "# 1. CONFIGURATION\n",
        "# ============================================================\n",
        "TARGET_STOCKS = [\"BBL\", \"KKP\"]\n",
        "OUTPUT_FILE = \"Final_RL_Input_Ready.xlsx\"\n",
        "\n",
        "# âœ… FIX: à¹€à¸à¸´à¹ˆà¸¡à¸Šà¸·à¹ˆà¸­à¹„à¸Ÿà¸¥à¹Œ V20 à¹€à¸‚à¹‰à¸²à¹„à¸›à¹€à¸›à¹‡à¸™à¸•à¸±à¸§à¹€à¸¥à¸·à¸­à¸à¹à¸£à¸\n",
        "DL_FILE_PATTERNS = [\n",
        "    \"DL_Predictions_V20_ECT_META_{stock}.xlsx\",  # âœ… Match Output from Block 5.5 V20\n",
        "    \"DL_Predictions_V4_{stock}.xlsx\",            # Fallback\n",
        "    \"DL_Predictions_{stock}.xlsx\"                # Fallback Old\n",
        "]\n",
        "\n",
        "MACRO_FILE_PATTERNS = [\n",
        "    \"ARDL_ECM_Predictions_{stock}.xlsx\",\n",
        "    \"ARDL_ECM_Pred_{stock}.xlsx\",\n",
        "    \"ARDL_ECM_{stock}.xlsx\",\n",
        "    \"ARDL_ECM_Predictions.xlsx\",\n",
        "    \"ARDL_ECM_Pred.xlsx\",\n",
        "    \"Macro_Ready.xlsx\"\n",
        "]\n",
        "\n",
        "# âœ… align with Block 5.5 threshold default (do NOT rename)\n",
        "DEFAULT_DL_THRESHOLD = 0.65\n",
        "\n",
        "# ============================================================\n",
        "# 2. HELPER FUNCTIONS\n",
        "# ============================================================\n",
        "def add_technical_indicators(df):\n",
        "    df = df.copy()\n",
        "    close = df['Close']\n",
        "    high = df['High']\n",
        "    low = df['Low']\n",
        "\n",
        "    # RSI\n",
        "    df['RSI'] = ta.momentum.rsi(close, window=14)\n",
        "\n",
        "    # MACD\n",
        "    macd = ta.trend.MACD(close)\n",
        "    df['MACD'] = macd.macd_diff()\n",
        "\n",
        "    # ADX\n",
        "    df['ADX'] = ta.trend.adx(high, low, close, window=14)\n",
        "\n",
        "    # Tech Signal\n",
        "    df['EMA_50'] = close.ewm(span=50).mean()\n",
        "    conditions = [\n",
        "        (df['Close'] > df['EMA_50']) & (df['RSI'] < 70),\n",
        "        (df['Close'] < df['EMA_50']) & (df['RSI'] > 30)\n",
        "    ]\n",
        "    df['Tech_Signal'] = np.select(conditions, [1, -1], default=0)\n",
        "\n",
        "    return df\n",
        "\n",
        "def add_ecm_features(df):\n",
        "    # Proxy ECM (Z-Score of deviation from trend)\n",
        "    df['Log_Close'] = np.log(df['Close'])\n",
        "    df['MA_60'] = df['Log_Close'].rolling(60).mean()\n",
        "    df['ECT_Normalized'] = (df['Log_Close'] - df['MA_60'])\n",
        "    df['ECT_Normalized'] = (df['ECT_Normalized'] - df['ECT_Normalized'].rolling(60).mean()) / (df['ECT_Normalized'].rolling(60).std() + 1e-6)\n",
        "    return df\n",
        "\n",
        "def _to_int01(x):\n",
        "    if pd.isna(x):\n",
        "        return np.nan\n",
        "    if isinstance(x, str):\n",
        "        s = x.strip().lower()\n",
        "        if s in [\"buy\", \"long\", \"1\", \"true\", \"up\"]:\n",
        "            return 1\n",
        "        if s in [\"sell\", \"short\", \"0\", \"false\", \"down\"]:\n",
        "            return 0\n",
        "    try:\n",
        "        v = int(float(x))\n",
        "        return 1 if v == 1 else 0\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "def _pick_signal_col(df):\n",
        "    preferred = [\"Macro_Signal\", \"Dummy\", \"dummy\", \"Signal\", \"signal\", \"Prediction\", \"Pred\", \"pred\", \"Action\"]\n",
        "    for c in preferred:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "    others = [c for c in df.columns if c.lower() not in [\"date\", \"stock\"]]\n",
        "    return others[0] if len(others) > 0 else None\n",
        "\n",
        "def load_macro_predictions(target_stocks):\n",
        "    macro_frames = []\n",
        "    loaded_any = False\n",
        "\n",
        "    # 1. Try per-stock files\n",
        "    for stock in target_stocks:\n",
        "        for pattern in MACRO_FILE_PATTERNS:\n",
        "            filename = pattern.format(stock=stock)\n",
        "            if not os.path.exists(filename):\n",
        "                continue\n",
        "            try:\n",
        "                mdf = pd.read_excel(filename)\n",
        "                if \"Date\" not in mdf.columns:\n",
        "                    continue\n",
        "                mdf[\"Date\"] = pd.to_datetime(mdf[\"Date\"])\n",
        "                sig_col = _pick_signal_col(mdf)\n",
        "                if not sig_col:\n",
        "                    continue\n",
        "\n",
        "                mdf[\"Macro_Signal\"] = mdf[sig_col].apply(_to_int01)\n",
        "                if \"Stock\" not in mdf.columns:\n",
        "                    mdf[\"Stock\"] = stock\n",
        "                mdf[\"Stock\"] = mdf[\"Stock\"].astype(str).str.strip().str.upper()\n",
        "\n",
        "                macro_frames.append(mdf[[\"Date\", \"Stock\", \"Macro_Signal\"]].drop_duplicates())\n",
        "                loaded_any = True\n",
        "                print(f\"   âœ… Loaded Macro from {filename}\")\n",
        "                break\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    # 2. Try single file\n",
        "    if not loaded_any:\n",
        "        for filename in MACRO_FILE_PATTERNS:\n",
        "            if \"{stock}\" in filename or not os.path.exists(filename):\n",
        "                continue\n",
        "            try:\n",
        "                mdf = pd.read_excel(filename)\n",
        "                if \"Date\" not in mdf.columns:\n",
        "                    continue\n",
        "                mdf[\"Date\"] = pd.to_datetime(mdf[\"Date\"])\n",
        "                sig_col = _pick_signal_col(mdf)\n",
        "                if not sig_col:\n",
        "                    continue\n",
        "\n",
        "                mdf[\"Macro_Signal\"] = mdf[sig_col].apply(_to_int01)\n",
        "                if \"Stock\" in mdf.columns:\n",
        "                    mdf[\"Stock\"] = mdf[\"Stock\"].astype(str).str.strip().str.upper()\n",
        "                    macro_frames.append(mdf[[\"Date\", \"Stock\", \"Macro_Signal\"]].drop_duplicates())\n",
        "                else:\n",
        "                    macro_frames.append(mdf[[\"Date\", \"Macro_Signal\"]].drop_duplicates())\n",
        "                loaded_any = True\n",
        "                print(f\"   âœ… Loaded Macro from {filename}\")\n",
        "                break\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    if not macro_frames:\n",
        "        return pd.DataFrame()\n",
        "    return pd.concat(macro_frames, ignore_index=True)\n",
        "\n",
        "# âœ… NEW helper: robustly pick DL prob column (supports Block 5.5 schema)\n",
        "def _pick_dl_prob_col(dl_df: pd.DataFrame) -> str:\n",
        "    # Prefer Block 5.5 V20 outputs\n",
        "    for c in [\"P_META\", \"DL_Signal_Prob\", \"DL_Signal\", \"P_TCN\", \"P_RF\"]:\n",
        "        if c in dl_df.columns:\n",
        "            return c\n",
        "    # Last resort: if only Signal exists (0/1), synthesize pseudo-prob\n",
        "    if \"Signal\" in dl_df.columns:\n",
        "        dl_df[\"PSEUDO_PROB\"] = dl_df[\"Signal\"].apply(lambda x: 0.9 if int(x) == 1 else 0.1)\n",
        "        return \"PSEUDO_PROB\"\n",
        "    return \"\"\n",
        "\n",
        "# ============================================================\n",
        "# 3. MAIN PROCESS\n",
        "# ============================================================\n",
        "all_data = []\n",
        "thresholds_summary = {}\n",
        "macro_df = load_macro_predictions(TARGET_STOCKS)\n",
        "\n",
        "print(\"\\nğŸ”¹ Processing Stocks...\")\n",
        "\n",
        "for stock in TARGET_STOCKS:\n",
        "    print(f\"\\n   ğŸ‘‰ Stock: {stock}\")\n",
        "\n",
        "    # 1. Download\n",
        "    try:\n",
        "        df = yf.download(f\"{stock}.BK\", start=\"2015-01-01\", end=\"2025-12-31\", progress=False)\n",
        "        if len(df) == 0:\n",
        "            continue\n",
        "        if isinstance(df.columns, pd.MultiIndex):\n",
        "            df.columns = df.columns.get_level_values(0)\n",
        "        df.reset_index(inplace=True)\n",
        "        df['Stock'] = stock\n",
        "    except Exception as e:\n",
        "        print(f\"      âŒ Download error: {e}\")\n",
        "        continue\n",
        "\n",
        "    # 2. Indicators\n",
        "    df = add_technical_indicators(df)\n",
        "    df = add_ecm_features(df)\n",
        "\n",
        "    # 3. Load DL Signals (V20 Priority) âœ… FIXED\n",
        "    dl_loaded = False\n",
        "    for pattern in DL_FILE_PATTERNS:\n",
        "        filename = pattern.format(stock=stock)\n",
        "        if os.path.exists(filename):\n",
        "            try:\n",
        "                dl_df = pd.read_excel(filename)\n",
        "                if \"Date\" not in dl_df.columns:\n",
        "                    raise ValueError(\"No 'Date' column found in DL file.\")\n",
        "\n",
        "                dl_df[\"Date\"] = pd.to_datetime(dl_df[\"Date\"])\n",
        "\n",
        "                # âœ… pick best prob column (supports P_META etc.)\n",
        "                prob_col = _pick_dl_prob_col(dl_df)\n",
        "                if prob_col == \"\":\n",
        "                    raise ValueError(\"No usable probability/signal column in DL file.\")\n",
        "\n",
        "                # Threshold\n",
        "                if 'Threshold' in dl_df.columns:\n",
        "                    thresholds_summary[stock] = float(dl_df['Threshold'].iloc[0])\n",
        "                else:\n",
        "                    # âœ… align with Block 5.5 default\n",
        "                    thresholds_summary[stock] = float(DEFAULT_DL_THRESHOLD)\n",
        "\n",
        "                # Prepare Merge\n",
        "                dl_merge = dl_df[['Date', prob_col]].copy()\n",
        "                dl_merge.rename(columns={prob_col: 'DL_Signal'}, inplace=True)\n",
        "\n",
        "                df = pd.merge(df, dl_merge, on='Date', how='left')\n",
        "                df['DL_Signal'] = pd.to_numeric(df['DL_Signal'], errors='coerce').fillna(0.5)\n",
        "\n",
        "                print(f\"      âœ… Merged Signals from {filename} (using '{prob_col}')\")\n",
        "                dl_loaded = True\n",
        "                break\n",
        "            except Exception as e:\n",
        "                print(f\"      âš ï¸ Error reading {filename}: {e}\")\n",
        "\n",
        "    if not dl_loaded:\n",
        "        print(\"      âš ï¸ No DL Signal file found. Using Neutral (0.5).\")\n",
        "        df['DL_Signal'] = 0.5\n",
        "        thresholds_summary[stock] = 0.5\n",
        "\n",
        "    # 4. Merge Macro\n",
        "    if not macro_df.empty:\n",
        "        if \"Stock\" in macro_df.columns:\n",
        "            df = pd.merge(df, macro_df, on=[\"Date\", \"Stock\"], how=\"left\")\n",
        "        else:\n",
        "            df = pd.merge(df, macro_df, on=\"Date\", how=\"left\")\n",
        "        df[\"Macro_Signal\"] = pd.to_numeric(df[\"Macro_Signal\"], errors=\"coerce\").ffill().fillna(0).astype(int)\n",
        "    else:\n",
        "        df['Macro_Signal'] = 0\n",
        "\n",
        "    # 5. Cleanup\n",
        "    if 'Volume_Ratio' not in df.columns:\n",
        "        df['Volume_Ratio'] = df['Volume'] / (df['Volume'].rolling(20).mean() + 1)\n",
        "\n",
        "    df.dropna(subset=['Close', 'RSI', 'DL_Signal'], inplace=True)\n",
        "    all_data.append(df)\n",
        "\n",
        "# ============================================================\n",
        "# 4. SAVE OUTPUT\n",
        "# ============================================================\n",
        "if all_data:\n",
        "    final_df = pd.concat(all_data, ignore_index=True)\n",
        "\n",
        "    # Save Thresholds\n",
        "    pd.DataFrame(list(thresholds_summary.items()), columns=['Stock', 'Threshold']).to_excel(\"DL_Optimal_Thresholds.xlsx\", index=False)\n",
        "\n",
        "    # Save Final Data\n",
        "    final_df.to_excel(OUTPUT_FILE, index=False)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(f\"âœ… SUCCESS: Integrated Data saved to '{OUTPUT_FILE}'\")\n",
        "    print(f\"ğŸ“Š Rows: {len(final_df)} | Stocks: {final_df['Stock'].unique()}\")\n",
        "    print(\"=\" * 70)\n",
        "    print(\"ğŸ‘‰ NEXT: Run Block 13 (RL Agent)\")\n",
        "else:\n",
        "    print(\"\\nâŒ FAILED: No data processed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UieFy0V7HuYj",
        "outputId": "74c5ca2e-422b-4f12-c384-eeb418c4bf9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting stable_baselines3\n",
            "  Downloading stable_baselines3-2.7.1-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: gymnasium<1.3.0,>=0.29.1 in /usr/local/lib/python3.12/dist-packages (from stable_baselines3) (1.2.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.12/dist-packages (from stable_baselines3) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.12/dist-packages (from stable_baselines3) (2.9.0+cpu)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from stable_baselines3) (3.1.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from stable_baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from stable_baselines3) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable_baselines3) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable_baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2025.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable_baselines3) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable_baselines3) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable_baselines3) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable_baselines3) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable_baselines3) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable_baselines3) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable_baselines3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->stable_baselines3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->stable_baselines3) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3.0,>=2.3->stable_baselines3) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3.0,>=2.3->stable_baselines3) (3.0.3)\n",
            "Downloading stable_baselines3-2.7.1-py3-none-any.whl (188 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m188.0/188.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: stable_baselines3\n",
            "Successfully installed stable_baselines3-2.7.1\n"
          ]
        }
      ],
      "source": [
        "!pip install stable_baselines3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mW6OMFtKhumH"
      },
      "source": [
        "ğŸ“‹ 1. Constraint à¸—à¸µà¹ˆà¸”à¸±à¸”à¸™à¸´à¸ªà¸±à¸¢ RLConstraintà¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”à¸ˆà¸¸à¸”à¸›à¸£à¸°à¸ªà¸‡à¸„à¹ŒCooldown 2 Daysà¸«à¸¥à¸±à¸‡ Sell à¸•à¹‰à¸­à¸‡à¸£à¸­ 2 à¸§à¸±à¸™à¸–à¸¶à¸‡à¸ˆà¸° Buy à¹„à¸”à¹‰à¸›à¹‰à¸­à¸‡à¸à¸±à¸™ OvertradingMomentum Rule (Buy)Buy à¹„à¸”à¹‰à¹€à¸¡à¸·à¹ˆà¸­ ADX > 25 à¹à¸¥à¸° RSI < 75 à¸«à¸£à¸·à¸­ RSI < 45à¸šà¸±à¸‡à¸„à¸±à¸šà¸‹à¸·à¹‰à¸­à¸•à¸²à¸¡ TrendğŸ†• Volatility-based SizingPosition Size 30-70% à¸•à¸²à¸¡ Volatilityà¸¥à¸”à¸„à¸§à¸²à¸¡à¹€à¸ªà¸µà¹ˆà¸¢à¸‡à¸Šà¹ˆà¸§à¸‡ Vol à¸ªà¸¹à¸‡ğŸ†• Max Consecutive Lossesà¸‚à¸²à¸”à¸—à¸¸à¸™ 5 à¸„à¸£à¸±à¹‰à¸‡à¸•à¸´à¸” â†’ à¸«à¸¢à¸¸à¸” 3 à¸§à¸±à¸™à¸«à¸¢à¸¸à¸”à¸à¸±à¸à¹€à¸¡à¸·à¹ˆà¸­ Strategy à¹„à¸¡à¹ˆ workRandom Initial Position50% à¹‚à¸­à¸à¸²à¸ªà¹€à¸£à¸´à¹ˆà¸¡à¸¡à¸µà¸«à¸¸à¹‰à¸™à¸­à¸¢à¸¹à¹ˆà¹à¸¥à¹‰à¸§à¸à¸¶à¸à¹ƒà¸«à¹‰à¸£à¸±à¸šà¸¡à¸·à¸­à¸—à¸¸à¸à¸ªà¸–à¸²à¸™à¸à¸²à¸£à¸“à¹ŒğŸ›¡ï¸ 2. Risk ManagementRuleTriggerActionà¸ˆà¸¸à¸”à¸›à¸£à¸°à¸ªà¸‡à¸„à¹ŒHard Stop LossPnL â‰¤ -6%Force Sellà¸ˆà¸³à¸à¸±à¸”à¸‚à¸²à¸”à¸—à¸¸à¸™à¸ªà¸¹à¸‡à¸ªà¸¸à¸”Trailing StopPnL > +10% à¹à¸¥à¹‰à¸§à¸•à¸ > 4% à¸ˆà¸²à¸ PeakForce Sellà¸¥à¹‡à¸­à¸„à¸à¸³à¹„à¸£ğŸ†• Volatility Sizingà¸—à¸¸à¸à¸„à¸£à¸±à¹‰à¸‡à¸—à¸µà¹ˆ Buyà¸›à¸£à¸±à¸š Size 30-70%à¸¥à¸” Position à¸Šà¹ˆà¸§à¸‡ Vol à¸ªà¸¹à¸‡ğŸ†• Loss Pauseà¸‚à¸²à¸”à¸—à¸¸à¸™ 5 à¸„à¸£à¸±à¹‰à¸‡à¸•à¸´à¸”à¸«à¸¢à¸¸à¸” 3 à¸§à¸±à¸™à¸›à¹‰à¸­à¸‡à¸à¸±à¸™ Drawdown à¸•à¹ˆà¸­à¹€à¸™à¸·à¹ˆà¸­à¸‡ğŸ 3. Reward Shapingà¸ªà¸–à¸²à¸™à¸à¸²à¸£à¸“à¹ŒRewardà¸ˆà¸¸à¸”à¸›à¸£à¸°à¸ªà¸‡à¸„à¹ŒBuy à¸ªà¸³à¹€à¸£à¹‡à¸ˆ+0.1à¸à¸³à¸¥à¸±à¸‡à¹ƒà¸ˆ Take ActionSell à¸ˆà¸²à¸ Trailing Stop+2.0à¸£à¸²à¸‡à¸§à¸±à¸¥à¹ƒà¸«à¸à¹ˆà¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸³à¹„à¸£à¹€à¸¢à¸­à¸°Sell à¸ˆà¸²à¸ Stop Loss+0.1à¸£à¸²à¸‡à¸§à¸±à¸¥à¸ªà¸³à¸«à¸£à¸±à¸š DisciplineSell à¸¡à¸µà¸à¸³à¹„à¸£ (à¸›à¸à¸•à¸´)+PnL Ã— 10à¸•à¸²à¸¡à¸ªà¸±à¸”à¸ªà¹ˆà¸§à¸™à¸à¸³à¹„à¸£Sell à¸‚à¸²à¸”à¸—à¸¸à¸™ (à¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆ SL)-0.5à¸¥à¸‡à¹‚à¸—à¸© Sell à¸œà¸´à¸”à¸ˆà¸±à¸‡à¸«à¸§à¸°ğŸ†• Trigger Loss Pause-1.5à¸¥à¸‡à¹‚à¸—à¸©à¸«à¸™à¸±à¸à¹€à¸¡à¸·à¹ˆà¸­à¸‚à¸²à¸”à¸—à¸¸à¸™à¸•à¸´à¸” 5 à¸„à¸£à¸±à¹‰à¸‡ğŸ†• à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ Pause-0.3 à¸•à¹ˆà¸­à¸§à¸±à¸™à¸¥à¸‡à¹‚à¸—à¸© Opportunity Costà¸—à¸¸à¸ Step+(Î”NetWorth / NetWorth) Ã— 100à¸•à¸´à¸”à¸•à¸²à¸¡ Portfolio ValueğŸ“Š 4. State Vector (11 Features)#FeatureOriginal/New1Macro_SignalOriginal2DL_SignalOriginal3Tech_SignalOriginal4ADX / 100Original5Balance / 1MOriginal6Holdings Value / 1MOriginal7RSI / 100Original8MACD / 10Original9Volatility MultiplierğŸ†• New10Consecutive Losses / 5ğŸ†• New11Pause Counter / 3ğŸ†• New"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-w1olGHwiMR2"
      },
      "source": [
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "                    â”‚          RL Agent (PPO)             â”‚\n",
        "                    â”‚         à¹€à¸¥à¸·à¸­à¸ Action                â”‚\n",
        "                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                                    â”‚\n",
        "                                    â–¼\n",
        "                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "                    â”‚   ğŸ†• CHECK: Loss Pause Active?      â”‚\n",
        "                    â”‚      (à¸‚à¸²à¸”à¸—à¸¸à¸™ 5 à¸„à¸£à¸±à¹‰à¸‡ â†’ à¸«à¸¢à¸¸à¸” 3 à¸§à¸±à¸™)   â”‚\n",
        "                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                                    â”‚\n",
        "                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "                    â–¼                               â–¼\n",
        "              [Pause = YES]                   [Pause = NO]\n",
        "              Force HOLD                      Continue...\n",
        "              Reward -0.3                           â”‚\n",
        "                    â”‚                               â–¼\n",
        "                    â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "                    â”‚               â”‚    CHECK: Risk Management       â”‚\n",
        "                    â”‚               â”‚    â€¢ Stop Loss -6%?             â”‚\n",
        "                    â”‚               â”‚    â€¢ Trailing Stop?             â”‚\n",
        "                    â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                    â”‚                               â”‚\n",
        "                    â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "                    â”‚               â–¼                               â–¼\n",
        "                    â”‚         [Risk Trigger]                  [No Trigger]\n",
        "                    â”‚         Force SELL                      Continue...\n",
        "                    â”‚               â”‚                               â”‚\n",
        "                    â”‚               â”‚                               â–¼\n",
        "                    â”‚               â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "                    â”‚               â”‚               â”‚    CHECK: Cooldown Active?      â”‚\n",
        "                    â”‚               â”‚               â”‚    (à¸«à¸¥à¸±à¸‡ Sell à¸£à¸­ 2 à¸§à¸±à¸™)          â”‚\n",
        "                    â”‚               â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                    â”‚               â”‚                               â”‚\n",
        "                    â”‚               â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "                    â”‚               â”‚               â–¼                               â–¼\n",
        "                    â”‚               â”‚         [Cooldown = YES]               [Cooldown = NO]\n",
        "                    â”‚               â”‚         Block BUY                       Continue...\n",
        "                    â”‚               â”‚               â”‚                               â”‚\n",
        "                    â”‚               â”‚               â”‚                               â–¼\n",
        "                    â”‚               â”‚               â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "                    â”‚               â”‚               â”‚               â”‚      EXECUTE ACTION         â”‚\n",
        "                    â”‚               â”‚               â”‚               â”‚  BUY / HOLD / SELL          â”‚\n",
        "                    â”‚               â”‚               â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                    â”‚               â”‚               â”‚                               â”‚\n",
        "                    â”‚               â”‚               â”‚                               â–¼\n",
        "                    â”‚               â”‚               â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "                    â”‚               â”‚               â”‚               â”‚  ğŸ†• BUY: Volatility Sizing  â”‚\n",
        "                    â”‚               â”‚               â”‚               â”‚     High Vol â†’ 30-50%       â”‚\n",
        "                    â”‚               â”‚               â”‚               â”‚     Low Vol â†’ 50-70%        â”‚\n",
        "                    â”‚               â”‚               â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                    â”‚               â”‚               â”‚                               â”‚\n",
        "                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                                                    â”‚\n",
        "                                                    â–¼\n",
        "                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "                                    â”‚  ğŸ†• SELL: Track Consecutive     â”‚\n",
        "                                    â”‚     Losses (à¸–à¹‰à¸²à¸‚à¸²à¸”à¸—à¸¸à¸™)          â”‚\n",
        "                                    â”‚     à¸–à¹‰à¸²à¸„à¸£à¸š 5 â†’ Trigger Pause    â”‚\n",
        "                                    â”‚     Reward -1.5                 â”‚\n",
        "                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                                                    â”‚\n",
        "                                                    â–¼\n",
        "                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "                                    â”‚      Calculate Reward           â”‚\n",
        "                                    â”‚      Update State               â”‚\n",
        "                                    â”‚      Learn                      â”‚\n",
        "                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKC0F2gJfVIZ"
      },
      "source": [
        "Adapt OU process with RL  + Add macro trend from ARDL/ECM in performance Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7YRj6DfABKt"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# ğŸ¤– BLOCK 7 V7.4 (PATCHED FROM OLD): TP/SL + REAL EQUITY\n",
        "#    âœ… Keep: reward logic EXACTLY same as old\n",
        "#    âœ… Patch1: No SELL before any BUY (but NOT forcing BUY)\n",
        "#    âœ… Patch2: Hard Max Drawdown limit = 15%\n",
        "# ============================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "import matplotlib.pyplot as plt\n",
        "import yfinance as yf\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ============================================================\n",
        "# 1. CONFIGURATION (KEEP NAMES)\n",
        "# ============================================================\n",
        "TARGET_STOCKS = [\"BBL\", \"KKP\"]\n",
        "DATA_FILE = \"Final_RL_Input_Ready.xlsx\"\n",
        "MODEL_DIR = \"trained_models\"\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "# Trading Config (KEEP NAMES)\n",
        "INITIAL_BALANCE = 100_000\n",
        "COMMISSION_FEE = 0.00157\n",
        "SLIPPAGE = 0.001\n",
        "TAKE_PROFIT_PCT = 0.10\n",
        "STOP_LOSS_PCT = -0.05\n",
        "\n",
        "# âœ… Hard Max Drawdown Limit (15%)\n",
        "MAX_DRAWDOWN_LIMIT = 0.15\n",
        "\n",
        "# Training Config (KEEP NAMES)\n",
        "TRAIN_TIMESTEPS = 50000\n",
        "LEARNING_RATE = 0.0003\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# ============================================================\n",
        "# 2. TRADING ENVIRONMENT (KEEP CLASS NAME)\n",
        "# ============================================================\n",
        "class StockTradingEnvProfitLocker(gym.Env):\n",
        "    \"\"\"\n",
        "    Actions:\n",
        "      0 = hold\n",
        "      1 = buy  (all-in)\n",
        "      2 = sell (all-out)\n",
        "\n",
        "    PATCH 1:\n",
        "      - No SELL before BUY (long-only logic)\n",
        "      - If shares==0 and action==2 -> convert to HOLD (0) so logs are not misleading\n",
        "\n",
        "    PATCH 2:\n",
        "      - Hard Max Drawdown 15% (from peak equity)\n",
        "      - If DD breach: force liquidate (if holding) then end episode\n",
        "    \"\"\"\n",
        "    metadata = {\"render_modes\": []}\n",
        "\n",
        "    def __init__(self, df, initial_balance=100000, commission=0.00157,\n",
        "                 tp_pct=0.10, sl_pct=-0.05, slippage=0.001):\n",
        "        super().__init__()\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.n_step = len(self.df)\n",
        "\n",
        "        self.initial_balance = float(initial_balance)\n",
        "        self.commission = float(commission)\n",
        "        self.tp_pct = float(tp_pct)\n",
        "        self.sl_pct = float(sl_pct)\n",
        "        self.slippage = float(slippage)\n",
        "\n",
        "        self.action_space = spaces.Discrete(3)\n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(12,), dtype=np.float32)\n",
        "\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "\n",
        "        self.current_step = 0\n",
        "        self.balance = float(self.initial_balance)\n",
        "        self.shares = 0\n",
        "        self.entry_price = 0.0\n",
        "        self.net_worth = float(self.initial_balance)\n",
        "\n",
        "        # âœ… PATCH: track first buy + peak equity for DD cap\n",
        "        self.has_ever_bought = False\n",
        "        self.peak_net_worth = float(self.initial_balance)\n",
        "\n",
        "        # stats\n",
        "        self.closed_trades = 0\n",
        "        self.winning_trades = 0\n",
        "\n",
        "        # logs (for plotting/backtest)\n",
        "        self._equity_curve = []\n",
        "        self._pos_curve = []\n",
        "        self._action_curve = []\n",
        "\n",
        "        return self._next_observation(), {}\n",
        "\n",
        "    def _next_observation(self):\n",
        "        i = min(self.current_step, self.n_step - 1)\n",
        "        obs = self.df.iloc[i]\n",
        "        price = float(obs[\"Close\"])\n",
        "\n",
        "        market_val = self.shares * price\n",
        "        self.net_worth = self.balance + market_val\n",
        "\n",
        "        pnl_pct = 0.0\n",
        "        if self.shares > 0 and self.entry_price > 0:\n",
        "            pnl_pct = (price - self.entry_price) / self.entry_price\n",
        "\n",
        "        state = np.array([\n",
        "            obs.get(\"Macro_Signal\", 0),\n",
        "            obs.get(\"DL_Signal\", 0.5),\n",
        "            obs.get(\"Tech_Signal\", 0),\n",
        "            obs.get(\"RSI\", 50) / 100.0,\n",
        "            obs.get(\"MACD\", 0) / 10.0,\n",
        "            obs.get(\"ADX\", 0) / 100.0,\n",
        "            self.balance / self.initial_balance,\n",
        "            (market_val / self.net_worth) if self.net_worth > 0 else 0.0,\n",
        "            (self.net_worth - self.initial_balance) / self.initial_balance,\n",
        "            pnl_pct,\n",
        "            1.0 if self.shares > 0 else 0.0,\n",
        "            obs.get(\"Volume_Ratio\", 1.0)\n",
        "        ], dtype=np.float32)\n",
        "\n",
        "        return np.nan_to_num(state)\n",
        "\n",
        "    def step(self, action):\n",
        "        # guard index\n",
        "        if self.current_step >= self.n_step:\n",
        "            self.current_step = self.n_step - 1\n",
        "\n",
        "        price = float(self.df.iloc[self.current_step][\"Close\"])\n",
        "\n",
        "        # ====================================================\n",
        "        # âœ… PATCH 1: No SELL before BUY / No SELL when no shares\n",
        "        # (NOT forcing buy, just making SELL invalid until holding)\n",
        "        # ====================================================\n",
        "        if self.shares == 0 and int(action) == 2:\n",
        "            action = 0  # convert to HOLD (so logs are clean)\n",
        "        if (not self.has_ever_bought) and int(action) == 2:\n",
        "            action = 0  # extra safety: no sell before any buy\n",
        "\n",
        "        # --- TP/SL: force sell if holding ---\n",
        "        if self.shares > 0 and self.entry_price > 0:\n",
        "            unrealized = (price - self.entry_price) / self.entry_price\n",
        "            if unrealized >= self.tp_pct:\n",
        "                action = 2\n",
        "            elif unrealized <= self.sl_pct:\n",
        "                action = 2\n",
        "\n",
        "        reward = 0.0\n",
        "        done = False\n",
        "\n",
        "        # --- Execute action with fees + slippage ---\n",
        "        if action == 1 and self.shares == 0:\n",
        "            # buy all-in\n",
        "            exec_price = price * (1 + self.slippage)\n",
        "            cost_per_share = exec_price * (1 + self.commission)\n",
        "            shares = int(self.balance / cost_per_share)\n",
        "\n",
        "            if shares > 0:\n",
        "                self.shares = shares\n",
        "                self.balance -= shares * cost_per_share\n",
        "                self.entry_price = exec_price\n",
        "\n",
        "                # âœ… mark first buy\n",
        "                self.has_ever_bought = True\n",
        "\n",
        "                # âœ… keep reward logic EXACTLY same as old\n",
        "                reward -= 0.01  # small penalty to reduce over-trading\n",
        "\n",
        "        elif action == 2 and self.shares > 0:\n",
        "            # sell all-out\n",
        "            exec_price = price * (1 - self.slippage)\n",
        "            revenue_per_share = exec_price * (1 - self.commission)\n",
        "            revenue = self.shares * revenue_per_share\n",
        "\n",
        "            cost_basis = self.shares * self.entry_price\n",
        "            profit_amt = revenue - cost_basis\n",
        "\n",
        "            self.balance += revenue\n",
        "            self.shares = 0\n",
        "            self.entry_price = 0.0\n",
        "\n",
        "            self.closed_trades += 1\n",
        "            if profit_amt > 0:\n",
        "                self.winning_trades += 1\n",
        "                reward += (profit_amt / self.initial_balance) * 10.0\n",
        "            else:\n",
        "                reward -= 0.1\n",
        "\n",
        "        elif action == 0 and self.shares > 0:\n",
        "            # optional small living reward for holding\n",
        "            reward += 0.001\n",
        "\n",
        "        # --- Update net worth AFTER execution (IMPORTANT) ---\n",
        "        market_val = self.shares * price\n",
        "        self.net_worth = self.balance + market_val\n",
        "\n",
        "        # update peak equity\n",
        "        if self.net_worth > self.peak_net_worth:\n",
        "            self.peak_net_worth = self.net_worth\n",
        "\n",
        "        # ====================================================\n",
        "        # âœ… PATCH 2: Hard Max Drawdown 15%\n",
        "        # If DD breach: force liquidation (if holding) then end\n",
        "        # ====================================================\n",
        "        if self.peak_net_worth > 0:\n",
        "            dd_now = (self.net_worth - self.peak_net_worth) / self.peak_net_worth\n",
        "            if dd_now <= -MAX_DRAWDOWN_LIMIT:\n",
        "                # force sell if holding (use SAME sell logic style)\n",
        "                if self.shares > 0:\n",
        "                    exec_price = price * (1 - self.slippage)\n",
        "                    revenue_per_share = exec_price * (1 - self.commission)\n",
        "                    revenue = self.shares * revenue_per_share\n",
        "\n",
        "                    cost_basis = self.shares * self.entry_price\n",
        "                    profit_amt = revenue - cost_basis\n",
        "\n",
        "                    self.balance += revenue\n",
        "                    self.shares = 0\n",
        "                    self.entry_price = 0.0\n",
        "\n",
        "                    self.closed_trades += 1\n",
        "                    if profit_amt > 0:\n",
        "                        self.winning_trades += 1\n",
        "                        reward += (profit_amt / self.initial_balance) * 10.0\n",
        "                    else:\n",
        "                        reward -= 0.1\n",
        "\n",
        "                    self.net_worth = self.balance\n",
        "\n",
        "                done = True\n",
        "                action = 2  # log as sell due to DD stop (valid because we were at risk state)\n",
        "\n",
        "        # --- logs for plotting/backtest ---\n",
        "        self._equity_curve.append(float(self.net_worth))\n",
        "        self._pos_curve.append(1 if self.shares > 0 else 0)\n",
        "        self._action_curve.append(int(action))\n",
        "\n",
        "        # advance\n",
        "        self.current_step += 1\n",
        "        done = done or (self.current_step >= (self.n_step - 1))\n",
        "\n",
        "        return self._next_observation(), float(reward), done, False, {}\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 3. TRAINING LOOP (KEEP FUNCTION NAME)\n",
        "# ============================================================\n",
        "def train_agent(df_train, stock):\n",
        "    print(f\"   ğŸ‹ï¸ Training PPO Agent for {stock}...\")\n",
        "\n",
        "    env_train = DummyVecEnv([lambda: StockTradingEnvProfitLocker(\n",
        "        df_train,\n",
        "        initial_balance=INITIAL_BALANCE,\n",
        "        commission=COMMISSION_FEE,\n",
        "        slippage=SLIPPAGE,\n",
        "        tp_pct=TAKE_PROFIT_PCT,\n",
        "        sl_pct=STOP_LOSS_PCT\n",
        "    )])\n",
        "\n",
        "    model = PPO(\"MlpPolicy\", env_train, verbose=0,\n",
        "                learning_rate=LEARNING_RATE, batch_size=BATCH_SIZE)\n",
        "    model.learn(total_timesteps=TRAIN_TIMESTEPS)\n",
        "    model.save(f\"{MODEL_DIR}/ppo_v7_{stock}\")\n",
        "    return model\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 4. REALISTIC BACKTEST (KEEP FUNCTION NAME)\n",
        "# ============================================================\n",
        "def run_backtest_simulation(model, df_test, stock):\n",
        "    print(f\"\\nâš¡ Running Backtest Simulation: {stock} ...\")\n",
        "\n",
        "    env_test = StockTradingEnvProfitLocker(\n",
        "        df_test,\n",
        "        initial_balance=INITIAL_BALANCE,\n",
        "        commission=COMMISSION_FEE,\n",
        "        slippage=SLIPPAGE,\n",
        "        tp_pct=TAKE_PROFIT_PCT,\n",
        "        sl_pct=STOP_LOSS_PCT\n",
        "    )\n",
        "\n",
        "    obs, _ = env_test.reset()\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        action, _ = model.predict(obs, deterministic=True)\n",
        "        obs, _, done, _, _ = env_test.step(action)\n",
        "\n",
        "    n = len(env_test._equity_curve)\n",
        "    bt_df = df_test.iloc[:n].copy()\n",
        "    bt_df[\"Action\"] = env_test._action_curve[:n]\n",
        "    bt_df[\"Position\"] = env_test._pos_curve[:n]\n",
        "    bt_df[\"Equity\"] = env_test._equity_curve[:n]\n",
        "\n",
        "    bt_df[\"Market_Ret\"] = bt_df[\"Close\"].pct_change().fillna(0)\n",
        "    bt_df[\"Benchmark\"] = (1 + bt_df[\"Market_Ret\"]).cumprod() * INITIAL_BALANCE\n",
        "\n",
        "    final_equity = float(bt_df[\"Equity\"].iloc[-1])\n",
        "    benchmark_equity = float(bt_df[\"Benchmark\"].iloc[-1])\n",
        "\n",
        "    ai_return = final_equity / INITIAL_BALANCE - 1\n",
        "    bh_return = benchmark_equity / INITIAL_BALANCE - 1\n",
        "\n",
        "    dd = (bt_df[\"Equity\"] - bt_df[\"Equity\"].cummax()) / bt_df[\"Equity\"].cummax()\n",
        "    max_dd = float(dd.min())\n",
        "\n",
        "    total_trades = int(env_test.closed_trades)\n",
        "    win_count = int(env_test.winning_trades)\n",
        "    win_rate = (win_count / total_trades * 100) if total_trades > 0 else 0.0\n",
        "\n",
        "    print(f\"   ğŸ’° Initial: {INITIAL_BALANCE:,.0f} THB\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"   ğŸ¤– AI Net Return:      {ai_return:+.2%} ({final_equity:,.0f} THB)\")\n",
        "    print(f\"   ğŸ“‰ Buy & Hold Return:  {bh_return:+.2%} ({benchmark_equity:,.0f} THB)\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"   ğŸ¯ AI Win Rate:        {win_rate:.2f}% ({win_count}/{total_trades} Trades)\")\n",
        "    print(f\"   âš ï¸ Max Drawdown:       {max_dd:.2%}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    if ai_return > bh_return:\n",
        "        print(f\"   âœ… AI Beat Market by:  {ai_return - bh_return:+.2%}\")\n",
        "    else:\n",
        "        print(f\"   âŒ AI Lost to Market:  {ai_return - bh_return:+.2%}\")\n",
        "\n",
        "    return bt_df\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 5. DASHBOARD (KEEP FUNCTION NAME)\n",
        "# ============================================================\n",
        "def generate_dashboard(bt_df, stock):\n",
        "    print(f\"\\nğŸ¨ Generating Dashboard: {stock} ...\")\n",
        "\n",
        "    fig = plt.figure(figsize=(14, 12))\n",
        "    gs = fig.add_gridspec(3, 1, height_ratios=[2, 1, 1])\n",
        "\n",
        "    ax1 = fig.add_subplot(gs[0])\n",
        "    ax1.plot(bt_df[\"Date\"], bt_df[\"Close\"], label=\"Price\", color=\"black\", alpha=0.6)\n",
        "\n",
        "    buys = bt_df[bt_df[\"Position\"].diff() == 1]\n",
        "    sells = bt_df[bt_df[\"Position\"].diff() == -1]\n",
        "\n",
        "    ax1.scatter(buys[\"Date\"], buys[\"Close\"], marker=\"^\", color=\"green\", s=100, label=\"Buy\", zorder=5)\n",
        "    ax1.scatter(sells[\"Date\"], sells[\"Close\"], marker=\"v\", color=\"red\", s=100, label=\"Sell\", zorder=5)\n",
        "\n",
        "    ax1.set_title(f\"{stock} - AI Trade Execution\", fontsize=14, fontweight=\"bold\")\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    ax2 = fig.add_subplot(gs[1], sharex=ax1)\n",
        "    ax2.plot(bt_df[\"Date\"], bt_df[\"Benchmark\"], label=\"Buy & Hold\", color=\"gray\", linestyle=\"--\")\n",
        "    ax2.plot(bt_df[\"Date\"], bt_df[\"Equity\"], label=\"AI Agent\", color=\"blue\", linewidth=2)\n",
        "    ax2.set_ylabel(\"Portfolio Value\")\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "    ax3 = fig.add_subplot(gs[2], sharex=ax1)\n",
        "    dd = (bt_df[\"Equity\"] - bt_df[\"Equity\"].cummax()) / bt_df[\"Equity\"].cummax()\n",
        "    ax3.fill_between(bt_df[\"Date\"], dd, 0, color=\"red\", alpha=0.3)\n",
        "    ax3.set_ylabel(\"Drawdown\")\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# MAIN EXECUTION (KEEP STRUCTURE LIKE BEFORE)\n",
        "# ============================================================\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\" * 70)\n",
        "    print(\"ğŸ¤– BLOCK 7 V7.4: FULL PIPELINE + COMPARISON STATS (PATCHED)\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    if not os.path.exists(DATA_FILE):\n",
        "        print(f\"âš ï¸ '{DATA_FILE}' not found. Please run Block 6 first.\")\n",
        "    else:\n",
        "        df_all = pd.read_excel(DATA_FILE)\n",
        "        df_all[\"Date\"] = pd.to_datetime(df_all[\"Date\"])\n",
        "\n",
        "        for stock in TARGET_STOCKS:\n",
        "            print(f\"\\nğŸ”¹ Processing Sequence: {stock}\")\n",
        "            stock_df = df_all[df_all[\"Stock\"] == stock].copy()\n",
        "            if len(stock_df) < 200:\n",
        "                continue\n",
        "\n",
        "            train_df = stock_df[stock_df[\"Date\"] < \"2024-01-01\"]\n",
        "            test_df = stock_df[stock_df[\"Date\"] >= \"2024-01-01\"]\n",
        "\n",
        "            if len(train_df) > 0 and len(test_df) > 0:\n",
        "                model = train_agent(train_df, stock)\n",
        "                bt_results = run_backtest_simulation(model, test_df, stock)\n",
        "                generate_dashboard(bt_results, stock)\n",
        "\n",
        "    print(\"\\nâœ… ALL TASKS COMPLETE.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-Svj1D4FmU0"
      },
      "source": [
        "1) Change price frequentcy from day to hour\n",
        "2) Edit Technical Block âœ…\n",
        "3) optimize DL signal using validation set à¸›à¸£à¸±à¸š Block 5.5 (DL Signal)  à¹ƒà¸«à¹‰à¹à¸¡à¹ˆà¸™à¸¢à¸³à¸‚à¸¶à¹‰à¸™ âœ…\n",
        "4) à¹€à¸à¸´à¹ˆà¸¡ Feature à¹ƒà¸«à¸¡à¹ˆà¹† à¹ƒà¸™ Block 6 (à¹€à¸Šà¹ˆà¸™ Volume Profile, Bid/Offer) => à¸•à¹‰à¸­à¸‡à¸‚à¸­à¸ˆà¸²à¸ à¸à¸µà¹ˆ AIQ\n",
        "5) à¸ˆà¸¹à¸™ Hyperparameter à¹ƒà¸™ Block 7 âœ…\n",
        "6) à¹à¸à¹‰à¹„à¸Ÿà¸¥à¹Œ Macro.xlsx à¹€à¸à¸·à¹ˆà¸­à¹€à¸à¸´à¹ˆà¸¡ Data à¸‚à¸­à¸‡ 2025 à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyqSl5NnABSu"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# ğŸ† BLOCK 8 V2: Evaluation & Prediction (Synced with V7.1)\n",
        "#    âœ… Compatible with: Block 7 V7.1 (Profit Locker)\n",
        "#    âœ… Logic: Includes Auto-Take Profit @ 10% in Backtest\n",
        "#    âœ… Split: Fixed Date (2024-01-01) to match Training\n",
        "# ============================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "import os\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "from stable_baselines3 import PPO\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ============================================================\n",
        "# 1. CONFIGURATION\n",
        "# ============================================================\n",
        "STOCK_SYMBOLS = [\"BBL\", \"KKP\"]\n",
        "DATA_FILE = \"Final_RL_Input_Ready.xlsx\"\n",
        "MODEL_DIR = \"trained_models\"\n",
        "\n",
        "# Evaluation Config (Must match Block 7 V7.1)\n",
        "INITIAL_BALANCE = 100_000\n",
        "COMMISSION = 0.00157\n",
        "TAKE_PROFIT_PCT = 0.10   # ğŸ¯ Profit Locker Logic\n",
        "TEST_START_DATE = \"2024-01-01\" # ğŸ“… Fixed Test Split\n",
        "\n",
        "# ============================================================\n",
        "# 2. EVALUATION ENVIRONMENT (Matches V7.1 Logic)\n",
        "# ============================================================\n",
        "class StockTradingEnvEval(gym.Env):\n",
        "    \"\"\"\n",
        "    Environment for Evaluation (Includes Profit Locker Logic)\n",
        "    \"\"\"\n",
        "    def __init__(self, df, initial_balance=100000, commission=0.00157, tp_pct=0.10):\n",
        "        super(StockTradingEnvEval, self).__init__()\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.n_step = len(self.df)\n",
        "        self.initial_balance = initial_balance\n",
        "        self.commission = commission\n",
        "        self.tp_pct = tp_pct\n",
        "\n",
        "        # Actions: 0=Hold, 1=Buy, 2=Sell\n",
        "        self.action_space = spaces.Discrete(3)\n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(12,), dtype=np.float32)\n",
        "\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        self.current_step = 0\n",
        "        self.balance = self.initial_balance\n",
        "        self.shares = 0\n",
        "        self.entry_price = 0\n",
        "        self.net_worth = self.initial_balance\n",
        "        return self._next_observation(), {}\n",
        "\n",
        "    def _next_observation(self):\n",
        "        if self.current_step >= self.n_step:\n",
        "            self.current_step = self.n_step - 1\n",
        "\n",
        "        obs = self.df.iloc[self.current_step]\n",
        "\n",
        "        market_val = self.shares * obs['Close']\n",
        "        self.net_worth = self.balance + market_val\n",
        "\n",
        "        pnl_pct = 0.0\n",
        "        if self.shares > 0:\n",
        "            pnl_pct = (obs['Close'] - self.entry_price) / self.entry_price\n",
        "\n",
        "        # 12 Features (Matches Block 7 V7.1)\n",
        "        state = np.array([\n",
        "            obs.get('Macro_Signal', 0),\n",
        "            obs.get('DL_Signal', 0.5),\n",
        "            obs.get('Tech_Signal', 0),\n",
        "            obs.get('RSI', 50) / 100.0,\n",
        "            obs.get('MACD', 0) / 10.0,\n",
        "            obs.get('ADX', 0) / 100.0,\n",
        "            self.balance / self.initial_balance,\n",
        "            market_val / self.net_worth,\n",
        "            (self.net_worth - self.initial_balance) / self.initial_balance,\n",
        "            pnl_pct,\n",
        "            1.0 if self.shares > 0 else 0.0,\n",
        "            obs.get('Volume_Ratio', 1.0)\n",
        "        ], dtype=np.float32)\n",
        "\n",
        "        return np.nan_to_num(state)\n",
        "\n",
        "    def step(self, action):\n",
        "        current_price = self.df.iloc[self.current_step]['Close']\n",
        "\n",
        "        # --- ğŸš€ LOGIC SYNC: AUTO TAKE PROFIT ---\n",
        "        if self.shares > 0:\n",
        "            unrealized_pnl = (current_price - self.entry_price) / self.entry_price\n",
        "            # Profit Locker @ 10%\n",
        "            if unrealized_pnl >= self.tp_pct:\n",
        "                action = 2\n",
        "\n",
        "        # --- EXECUTE ---\n",
        "        if action == 1 and self.shares == 0: # BUY\n",
        "            cost = current_price * (1 + self.commission)\n",
        "            if self.balance >= cost:\n",
        "                self.shares = int(self.balance / cost)\n",
        "                self.balance -= self.shares * cost\n",
        "                self.entry_price = cost\n",
        "\n",
        "        elif action == 2 and self.shares > 0: # SELL\n",
        "            revenue = (self.shares * current_price) * (1 - self.commission)\n",
        "            self.balance += revenue\n",
        "            self.shares = 0\n",
        "            self.entry_price = 0\n",
        "\n",
        "        self.current_step += 1\n",
        "        done = self.current_step >= self.n_step - 1\n",
        "\n",
        "        return self._next_observation(), 0, done, False, {}\n",
        "\n",
        "# ============================================================\n",
        "# 3. HELPER FUNCTIONS\n",
        "# ============================================================\n",
        "def calculate_metrics(equity_curve):\n",
        "    equity = np.array(equity_curve)\n",
        "    returns = np.diff(equity) / equity[:-1]\n",
        "\n",
        "    total_return = (equity[-1] - equity[0]) / equity[0]\n",
        "\n",
        "    # Max Drawdown\n",
        "    peak = np.maximum.accumulate(equity)\n",
        "    drawdown = (peak - equity) / peak\n",
        "    max_dd = drawdown.max()\n",
        "\n",
        "    # Sharpe (Annualized)\n",
        "    if np.std(returns) > 0:\n",
        "        sharpe = (np.mean(returns) / np.std(returns)) * np.sqrt(252)\n",
        "    else:\n",
        "        sharpe = 0\n",
        "\n",
        "    return {\n",
        "        \"Total_Return\": total_return,\n",
        "        \"Max_Drawdown\": max_dd,\n",
        "        \"Sharpe_Ratio\": sharpe,\n",
        "        \"Final_Value\": equity[-1]\n",
        "    }\n",
        "\n",
        "def get_star_rating(action, ai_return, sharpe):\n",
        "    rating = \"HOLD\"\n",
        "    stars = \"â­\"\n",
        "\n",
        "    if action == 1:\n",
        "        rating = \"BUY\"\n",
        "        stars = \"â­â­â­â­\" if sharpe > 1.0 else \"â­â­â­\"\n",
        "    elif action == 2:\n",
        "        rating = \"SELL\"\n",
        "        stars = \"â­\"\n",
        "\n",
        "    # Bonus stars for high performance model\n",
        "    if ai_return > 0.20: stars += \"â­\"\n",
        "\n",
        "    return f\"{rating} {stars}\"\n",
        "\n",
        "# ============================================================\n",
        "# 4. MAIN EVALUATION LOOP\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"ğŸ† BLOCK 8 V2: AI PERFORMANCE EVALUATION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "if not os.path.exists(DATA_FILE):\n",
        "    print(f\"âŒ Error: {DATA_FILE} not found.\")\n",
        "else:\n",
        "    df_all = pd.read_excel(DATA_FILE)\n",
        "    df_all['Date'] = pd.to_datetime(df_all['Date'])\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for stock in STOCK_SYMBOLS:\n",
        "        print(f\"\\nğŸ”¹ Evaluating: {stock}\")\n",
        "\n",
        "        # 1. Filter Test Data (Same as Block 7)\n",
        "        stock_df = df_all[df_all['Stock'] == stock].sort_values(\"Date\").reset_index(drop=True)\n",
        "        test_df = stock_df[stock_df['Date'] >= TEST_START_DATE].reset_index(drop=True)\n",
        "\n",
        "        if len(test_df) < 50:\n",
        "            print(\"   âš ï¸ Not enough test data.\")\n",
        "            continue\n",
        "\n",
        "        print(f\"   ğŸ“… Test Period: {test_df['Date'].iloc[0].date()} -> {test_df['Date'].iloc[-1].date()} ({len(test_df)} days)\")\n",
        "\n",
        "        # 2. Load Model (Priority: V7 -> V6)\n",
        "        model_paths = [\n",
        "            f\"{MODEL_DIR}/ppo_v7_{stock}.zip\",  # Priority\n",
        "            f\"{MODEL_DIR}/ppo_v6_{stock}.zip\"\n",
        "        ]\n",
        "\n",
        "        model = None\n",
        "        for path in model_paths:\n",
        "            if os.path.exists(path):\n",
        "                model = PPO.load(path)\n",
        "                print(f\"   âœ… Loaded Model: {os.path.basename(path)}\")\n",
        "                break\n",
        "\n",
        "        if model is None:\n",
        "            print(\"   âŒ No trained model found.\")\n",
        "            continue\n",
        "\n",
        "        # 3. Run Backtest\n",
        "        env = StockTradingEnvEval(\n",
        "            test_df,\n",
        "            initial_balance=INITIAL_BALANCE,\n",
        "            commission=COMMISSION,\n",
        "            tp_pct=TAKE_PROFIT_PCT # âœ… Inject Profit Locker logic\n",
        "        )\n",
        "\n",
        "        obs, _ = env.reset()\n",
        "        done = False\n",
        "        equity_curve = [INITIAL_BALANCE]\n",
        "\n",
        "        while not done:\n",
        "            action, _ = model.predict(obs, deterministic=True)\n",
        "            obs, _, done, _, _ = env.step(action)\n",
        "\n",
        "            # Calculate current Net Worth\n",
        "            current_val = env.balance + (env.shares * test_df.iloc[env.current_step]['Close'])\n",
        "            equity_curve.append(current_val)\n",
        "\n",
        "        # 4. Calculate Metrics\n",
        "        metrics = calculate_metrics(equity_curve)\n",
        "\n",
        "        # Benchmark (Buy & Hold)\n",
        "        bh_start = test_df.iloc[0]['Close']\n",
        "        bh_end = test_df.iloc[-1]['Close']\n",
        "        bh_return = (bh_end - bh_start) / bh_start\n",
        "\n",
        "        # 5. Forecast Tomorrow\n",
        "        latest_obs, _ = env.reset() # Reset to get clean state structure\n",
        "        # Manually construct latest observation based on last row\n",
        "        # (Simplified: Just re-using the environment's internal state logic on last row)\n",
        "        # For accurate forecast, we usually run step() until end.\n",
        "        # Here we just take the last action performed in backtest sequence if it was today.\n",
        "\n",
        "        # A better forecast approach: Feed the actual latest row\n",
        "        latest_row_df = stock_df.tail(1).reset_index(drop=True)\n",
        "        env_forecast = StockTradingEnvEval(latest_row_df)\n",
        "        obs_f, _ = env_forecast.reset()\n",
        "        action_f, _ = model.predict(obs_f, deterministic=True)\n",
        "\n",
        "        rating = get_star_rating(action_f, metrics['Total_Return'], metrics['Sharpe_Ratio'])\n",
        "\n",
        "        results.append({\n",
        "            \"Stock\": stock,\n",
        "            \"AI_Return\": metrics['Total_Return'],\n",
        "            \"BH_Return\": bh_return,\n",
        "            \"Sharpe\": metrics['Sharpe_Ratio'],\n",
        "            \"MDD\": metrics['Max_Drawdown'],\n",
        "            \"Win_vs_BH\": metrics['Total_Return'] > bh_return,\n",
        "            \"Forecast\": rating,\n",
        "            \"Last_Close\": test_df.iloc[-1]['Close']\n",
        "        })\n",
        "\n",
        "        print(f\"   ğŸ“ˆ AI Return: {metrics['Total_Return']:.2%} (vs BH: {bh_return:.2%})\")\n",
        "        print(f\"   ğŸ”® Forecast: {rating}\")\n",
        "\n",
        "    # 6. Final Leaderboard\n",
        "    if results:\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"ğŸ¯ FINAL SCOREBOARD\")\n",
        "        print(\"=\" * 80)\n",
        "        df_res = pd.DataFrame(results)\n",
        "        df_res = df_res.sort_values(\"AI_Return\", ascending=False)\n",
        "\n",
        "        print(df_res[[\n",
        "            \"Stock\", \"AI_Return\", \"BH_Return\", \"Sharpe\", \"MDD\", \"Forecast\"\n",
        "        ]].to_string(index=False))\n",
        "\n",
        "        df_res.to_excel(\"Block8_Final_Eval.xlsx\", index=False)\n",
        "        print(\"\\nğŸ’¾ Saved results to Block8_Final_Eval.xlsx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8H5OC-DGuOlN"
      },
      "source": [
        "1) Change price frequentcy from day to hour\n",
        "2) Edit Technical Block âœ…\n",
        "3) optimize DL signal using validation set à¸›à¸£à¸±à¸š Block 5.5 (DL Signal)  à¹ƒà¸«à¹‰à¹à¸¡à¹ˆà¸™à¸¢à¸³à¸‚à¸¶à¹‰à¸™ âœ…\n",
        "4) à¹€à¸à¸´à¹ˆà¸¡ Feature à¹ƒà¸«à¸¡à¹ˆà¹† à¹ƒà¸™ Block 6 (à¹€à¸Šà¹ˆà¸™ Volume Profile, Bid/Offer) => à¸•à¹‰à¸­à¸‡à¸‚à¸­à¸ˆà¸²à¸ à¸à¸µà¹ˆ AIQ\n",
        "5) à¸ˆà¸¹à¸™ Hyperparameter à¹ƒà¸™ Block 7\n",
        "6) à¹à¸à¹‰à¹„à¸Ÿà¸¥à¹Œ Macro.xlsx à¹€à¸à¸·à¹ˆà¸­à¹€à¸à¸´à¹ˆà¸¡ Data à¸‚à¸­à¸‡ 2025 à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzUgZxf3mxUk"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y phidata\n",
        "!pip install phidata google-generativeai duckduckgo-search transformers torch stable-baselines3 colorama openpyxl agno ddgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhlB6ipGCAVC"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# ğŸ”® BLOCK 9.3 V3: LIVE FORECASTER (HYBRID FIX)\n",
        "#    âœ… Objective: Fix \"Stuck\" Probabilities (0.46 issue)\n",
        "#    âœ… Logic: If TCN is stuck/uncertain, blend with Technical Analysis\n",
        "# ============================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import ta\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "TARGET_STOCKS = [\"BBL\", \"KKP\"]\n",
        "DATA_FILE = \"Final_RL_Input_Ready.xlsx\"\n",
        "LOOK_BACK = 60\n",
        "\n",
        "# ============================================================\n",
        "# 1. TECHNICAL SCORE CALCULATOR (BACKUP LOGIC)\n",
        "# ============================================================\n",
        "def calculate_technical_prob(df):\n",
        "    \"\"\"\n",
        "    Calculates a probability score (0.0 - 1.0) based purely on Technicals.\n",
        "    Used when Deep Learning model is uncertain or stuck.\n",
        "    \"\"\"\n",
        "    close = df['Close']\n",
        "\n",
        "    # 1. Trend (EMA 50 vs 200)\n",
        "    ema50 = close.ewm(span=50).mean()\n",
        "    ema200 = close.ewm(span=200).mean()\n",
        "    trend_score = 0.6 if (close.iloc[-1] > ema50.iloc[-1]) else 0.4\n",
        "\n",
        "    # 2. RSI (Momentum)\n",
        "    rsi = ta.momentum.rsi(close, window=14).iloc[-1]\n",
        "    # RSI < 30 (Oversold) -> High prob of bounce -> 0.7\n",
        "    # RSI > 70 (Overbought) -> Low prob of buy -> 0.3\n",
        "    # RSI 50 -> 0.5\n",
        "    rsi_score = 1.0 - (rsi / 100.0)\n",
        "\n",
        "    # 3. MACD (Momentum Direction)\n",
        "    macd = ta.trend.MACD(close)\n",
        "    hist = macd.macd_diff().iloc[-1]\n",
        "    macd_score = 0.6 if hist > 0 else 0.4\n",
        "\n",
        "    # Weighted Average\n",
        "    # Trend (40%) + RSI (30%) + MACD (30%)\n",
        "    final_prob = (trend_score * 0.4) + (rsi_score * 0.3) + (macd_score * 0.3)\n",
        "\n",
        "    return float(final_prob)\n",
        "\n",
        "# ============================================================\n",
        "# 2. FEATURE ENGINEERING\n",
        "# ============================================================\n",
        "def create_features_live(df):\n",
        "    df = df.copy()\n",
        "    close = df['Close']\n",
        "    high = df['High']\n",
        "    low = df['Low']\n",
        "\n",
        "    df['Log_Ret'] = np.log(close / close.shift(1))\n",
        "    df['RSI'] = ta.momentum.rsi(close, window=14) / 100.0\n",
        "    df['MACD_Norm'] = ta.trend.macd_diff(close) / close\n",
        "    df['ATR_Pct'] = ta.volatility.average_true_range(high, low, close) / close\n",
        "    df['Dist_SMA_20'] = (close / close.rolling(20).mean()) - 1.0\n",
        "\n",
        "    if 'Volume' in df.columns:\n",
        "        df['Vol_Ratio'] = df['Volume'] / (df['Volume'].rolling(20).mean() + 1.0)\n",
        "    else:\n",
        "        df['Vol_Ratio'] = 1.0\n",
        "\n",
        "    df.dropna(inplace=True)\n",
        "    return df\n",
        "\n",
        "# ============================================================\n",
        "# 3. HYBRID PREDICTION ENGINE\n",
        "# ============================================================\n",
        "def get_hybrid_prob(stock):\n",
        "    print(f\"   ğŸ“¡ Analyzing {stock}...\")\n",
        "    df = yf.download(f\"{stock}.BK\", period=\"1y\", progress=False)\n",
        "\n",
        "    if len(df) < 100: return None\n",
        "    if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.get_level_values(0)\n",
        "\n",
        "    # --- A. Technical Probability (Baseline) ---\n",
        "    tech_prob = calculate_technical_prob(df)\n",
        "\n",
        "    # --- B. TCN Model Probability ---\n",
        "    tcn_prob = None\n",
        "    try:\n",
        "        df_feat = create_features_live(df)\n",
        "        if len(df_feat) >= LOOK_BACK:\n",
        "            input_seq = df_feat.iloc[-LOOK_BACK:]\n",
        "            feat_cols = ['Open', 'High', 'Low', 'Close', 'Volume',\n",
        "                         'Log_Ret', 'RSI', 'MACD_Norm', 'ATR_Pct', 'Dist_SMA_20', 'Vol_Ratio']\n",
        "\n",
        "            # Verify columns\n",
        "            if all(c in input_seq.columns for c in feat_cols):\n",
        "                X_raw = input_seq[feat_cols].values\n",
        "                scaler = RobustScaler()\n",
        "                X_scaled = scaler.fit_transform(X_raw)\n",
        "                X_final = X_scaled.reshape(1, LOOK_BACK, len(feat_cols))\n",
        "\n",
        "                model_filename = f\"tcn_model_{stock}.keras\"\n",
        "                if os.path.exists(model_filename):\n",
        "                    model = tf.keras.models.load_model(model_filename)\n",
        "                    tcn_prob = float(model.predict(X_final, verbose=0)[0][0])\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # --- C. BLENDING LOGIC ---\n",
        "    if tcn_prob is not None:\n",
        "        # Check if TCN is \"stuck\" (e.g., 0.46 or 0.50 exactly)\n",
        "        is_stuck = (0.45 <= tcn_prob <= 0.47) or (tcn_prob == 0.5)\n",
        "\n",
        "        if is_stuck:\n",
        "            print(f\"      âš ï¸ TCN seems stuck ({tcn_prob:.4f}). Using Technical Blend.\")\n",
        "            # If stuck, give 80% weight to Technicals\n",
        "            final_prob = (tcn_prob * 0.2) + (tech_prob * 0.8)\n",
        "        else:\n",
        "            print(f\"      âœ… TCN Active ({tcn_prob:.4f}). Blending.\")\n",
        "            # If active, give 70% weight to TCN\n",
        "            final_prob = (tcn_prob * 0.7) + (tech_prob * 0.3)\n",
        "    else:\n",
        "        print(f\"      âš ï¸ TCN failed. Using Pure Technicals.\")\n",
        "        final_prob = tech_prob\n",
        "\n",
        "    print(f\"      ğŸ“Š Final Prob: {final_prob:.4f} (Tech: {tech_prob:.4f})\")\n",
        "    return final_prob\n",
        "\n",
        "# ============================================================\n",
        "# 4. EXECUTION\n",
        "# ============================================================\n",
        "print(\"=\"*60)\n",
        "print(\"ğŸ”§ BLOCK 9.3 V3: HYBRID PROBABILITY UPDATE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if not os.path.exists(DATA_FILE):\n",
        "    print(f\"âŒ Error: {DATA_FILE} not found.\")\n",
        "else:\n",
        "    df_main = pd.read_excel(DATA_FILE)\n",
        "    if 'DL_Signal' not in df_main.columns: df_main['DL_Signal'] = 0.5\n",
        "\n",
        "    updates = 0\n",
        "    for stock in TARGET_STOCKS:\n",
        "        print(f\"\\nğŸ”¹ Processing: {stock}\")\n",
        "        real_prob = get_hybrid_prob(stock)\n",
        "\n",
        "        if real_prob is not None:\n",
        "            mask = df_main['Stock'] == stock\n",
        "            if mask.any():\n",
        "                last_idx = df_main[mask].index[-1]\n",
        "                df_main.at[last_idx, 'DL_Signal'] = real_prob\n",
        "                updates += 1\n",
        "\n",
        "    if updates > 0:\n",
        "        df_main.to_excel(DATA_FILE, index=False)\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(f\"ğŸ’¾ SUCCESS: Updated {updates} stocks with Hybrid Probabilities.\")\n",
        "        print(\"ğŸ‘‰ Run BLOCK 9.2 (Dashboard) again to see new numbers!\")\n",
        "        print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HgHbyZumy9E"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# ğŸš€ BLOCK 9.2: TRADING DASHBOARD (NO-SEARCH EDITION)\n",
        "#    âœ… Stack: Gemini (Direct) + FinBERT + PPO (V7.1)\n",
        "#    âœ… Fixes:\n",
        "#       1. Removed DuckDuckGo/Agno (No more search errors)\n",
        "#       2. Logic Update: If Sentiment is BAD -> Force HOLD\n",
        "# ============================================================\n",
        "\n",
        "# [1] ğŸ”§ IMPORTS & CONFIG\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import pipeline\n",
        "from stable_baselines3 import PPO\n",
        "from colorama import Fore, Style, init\n",
        "import warnings\n",
        "import os\n",
        "import google.generativeai as genai\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "init(autoreset=True)\n",
        "\n",
        "# ğŸ”‘ à¹ƒà¸ªà¹ˆ API KEY à¸‚à¸­à¸‡à¸„à¸¸à¸“à¸•à¸£à¸‡à¸™à¸µà¹‰\n",
        "GOOGLE_API_KEY = \"AIzaSyAPpTJy94Wkcs8X-RkvAq-wZPIi73x6Bdk\"\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "STOCK_SYMBOLS = [\"BBL\", \"KKP\"]\n",
        "MODEL_DIR = \"trained_models\"\n",
        "DATA_FILE = \"Final_RL_Input_Ready.xlsx\"\n",
        "TAKE_PROFIT_PCT = 0.10\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# [2] ğŸ¤– AI ENGINE SETUP (Gemini Direct + FinBERT)\n",
        "# ------------------------------------------------------------\n",
        "print(\"â³ Initializing AI Engines...\")\n",
        "\n",
        "# A) FinBERT (Sentiment Analysis)\n",
        "try:\n",
        "    finbert = pipeline(\"text-classification\", model=\"ProsusAI/finbert\", top_k=None)\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ FinBERT Load Error: {e}\")\n",
        "    finbert = None\n",
        "\n",
        "# B) Gemini Model (Direct) - No Search Tools\n",
        "try:\n",
        "    # Use Flash model for speed\n",
        "    gemini_model = genai.GenerativeModel('gemini-2.0-flash')\n",
        "except:\n",
        "    gemini_model = None\n",
        "\n",
        "print(\"âœ… AI Engines ready.\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# [3] ğŸ› ï¸ HELPERS\n",
        "# ------------------------------------------------------------\n",
        "def get_gemini_analysis(ticker: str):\n",
        "    \"\"\"\n",
        "    Use Gemini internal knowledge instead of News Search.\n",
        "    Focus on Fundamental & Sector outlook.\n",
        "    \"\"\"\n",
        "    if not gemini_model:\n",
        "        return \"AI Analysis Unavailable.\", 0.0\n",
        "\n",
        "    print(f\"   ğŸ§  Asking Gemini about {ticker}...\")\n",
        "    try:\n",
        "        # Prompt changed to rely on internal knowledge/sector trends\n",
        "        prompt = (\n",
        "            f\"Analyze the outlook for '{ticker}' (Thai Stock) based on general banking sector trends in Thailand. \"\n",
        "            \"Mention key risks and strengths. Keep it short (3 sentences).\"\n",
        "        )\n",
        "        response = gemini_model.generate_content(prompt)\n",
        "        summary = response.text.strip()\n",
        "    except Exception as e:\n",
        "        summary = f\"Analysis failed: {e}\"\n",
        "        return summary, 0.0\n",
        "\n",
        "    # Calculate Sentiment with FinBERT\n",
        "    sent_score = 0.0\n",
        "    if finbert:\n",
        "        try:\n",
        "            scores = finbert(summary[:512])[0]\n",
        "            pos = next(d[\"score\"] for d in scores if d[\"label\"] == \"positive\")\n",
        "            neg = next(d[\"score\"] for d in scores if d[\"label\"] == \"negative\")\n",
        "            sent_score = float(pos - neg)\n",
        "        except:\n",
        "            sent_score = 0.0\n",
        "\n",
        "    return summary, sent_score\n",
        "\n",
        "def load_rl_model(stock: str):\n",
        "    paths = [\n",
        "        f\"{MODEL_DIR}/ppo_v7_{stock}.zip\",\n",
        "        f\"{MODEL_DIR}/ppo_v6_{stock}.zip\",\n",
        "    ]\n",
        "    for p in paths:\n",
        "        if os.path.exists(p):\n",
        "            try: return PPO.load(p)\n",
        "            except: pass\n",
        "    return None\n",
        "\n",
        "def build_obs_v7(row, has_position=False):\n",
        "    \"\"\"Construct Observation Vector matching Block 7 V7.1\"\"\"\n",
        "    if has_position:\n",
        "        balance_ratio = 0.0; invest_ratio = 1.0; pos_flag = 1.0\n",
        "    else:\n",
        "        balance_ratio = 1.0; invest_ratio = 0.0; pos_flag = 0.0\n",
        "\n",
        "    obs = np.array([\n",
        "        float(row.get('Macro_Signal', 0)),\n",
        "        float(row.get('DL_Signal', 0.5)),\n",
        "        float(row.get('Tech_Signal', 0)),\n",
        "        float(row.get('RSI', 50)) / 100.0,\n",
        "        float(row.get('MACD', 0)) / 10.0,\n",
        "        float(row.get('ADX', 0)) / 100.0,\n",
        "        balance_ratio, invest_ratio, 0.0, 0.0, pos_flag,\n",
        "        float(row.get('Volume_Ratio', 1.0))\n",
        "    ], dtype=np.float32)\n",
        "    return obs\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# [4] ğŸš€ MAIN DASHBOARD\n",
        "# ------------------------------------------------------------\n",
        "if not os.path.exists(DATA_FILE):\n",
        "    print(f\"âŒ Error: {DATA_FILE} not found. Run Block 6 first.\")\n",
        "else:\n",
        "    df_all = pd.read_excel(DATA_FILE)\n",
        "    df_all[\"Date\"] = pd.to_datetime(df_all[\"Date\"])\n",
        "    latest_date = df_all[\"Date\"].max().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 75)\n",
        "    print(f\"ğŸš€ AI TRADING DASHBOARD (Date: {latest_date})\")\n",
        "    print(\"ğŸ§  System: PPO V7.1 (Quant) + Gemini (Internal Knowledge)\")\n",
        "    print(\"=\" * 75)\n",
        "\n",
        "    for stock in STOCK_SYMBOLS:\n",
        "        stock_df = df_all[df_all[\"Stock\"] == stock].sort_values(\"Date\").reset_index(drop=True)\n",
        "        if len(stock_df) == 0: continue\n",
        "\n",
        "        last_row = stock_df.iloc[-1]\n",
        "        current_price = float(last_row[\"Close\"])\n",
        "\n",
        "        # 1. RL Signal\n",
        "        model = load_rl_model(stock)\n",
        "        obs_entry = build_obs_v7(last_row, has_position=False)\n",
        "        action_entry, _ = model.predict(obs_entry, deterministic=True) if model else (0,0)\n",
        "\n",
        "        obs_exit = build_obs_v7(last_row, has_position=True)\n",
        "        action_exit, _ = model.predict(obs_exit, deterministic=True) if model else (0,0)\n",
        "\n",
        "        # 2. Qualitative Analysis (Gemini Direct)\n",
        "        summary, sent_score = get_gemini_analysis(stock)\n",
        "\n",
        "        # 3. Display\n",
        "        print(f\"\\nğŸ”¹ {Fore.CYAN}{stock}{Style.RESET_ALL} (Price: {current_price:.2f})\")\n",
        "        print(f\"   ğŸ“° {Fore.YELLOW}AI Insight:{Style.RESET_ALL}\")\n",
        "        print(f\"   {summary}\")\n",
        "\n",
        "        s_color = Fore.GREEN if sent_score > 0.1 else (Fore.RED if sent_score < -0.1 else Fore.WHITE)\n",
        "        print(f\"   ğŸ§  Sentiment Score: {s_color}{sent_score:.4f}{Style.RESET_ALL}\")\n",
        "\n",
        "        # 4. Final Verdict Logic (Updated)\n",
        "        dl_prob = last_row.get('DL_Signal', 0.5)\n",
        "        verdict = \"WAIT\"\n",
        "        color = Fore.WHITE\n",
        "\n",
        "        # --- NEW LOGIC: Bad Sentiment -> Force HOLD ---\n",
        "        if action_entry == 1: # Quant says BUY\n",
        "            if sent_score < -0.15: # ğŸ”´ Bad Sentiment Logic\n",
        "                verdict = \"HOLD (Sentiment Risk) âš ï¸\"\n",
        "                color = Fore.YELLOW\n",
        "            elif sent_score > 0.1 and dl_prob > 0.6:\n",
        "                verdict = \"STRONG BUY â­â­â­\"\n",
        "                color = Fore.GREEN\n",
        "            else:\n",
        "                verdict = \"BUY â­â­\"\n",
        "                color = Fore.GREEN\n",
        "\n",
        "        elif action_exit == 2: # Quant says SELL\n",
        "            verdict = \"SELL âŒ\"\n",
        "            color = Fore.RED\n",
        "        else:\n",
        "            if dl_prob > 0.7:\n",
        "                verdict = \"WATCHLIST (High Prob) ğŸ‘ï¸\"\n",
        "                color = Fore.CYAN\n",
        "            else:\n",
        "                verdict = \"HOLD / WAIT âœ‹\"\n",
        "\n",
        "        print(f\"   ğŸ¤– Quant Signal: Entry={action_entry} | Exit={action_exit} | DL_Prob={dl_prob:.2f}\")\n",
        "        print(f\"   âš–ï¸  Verdict: {color}{verdict}{Style.RESET_ALL}\")\n",
        "\n",
        "        if \"BUY\" in verdict and \"HOLD\" not in verdict:\n",
        "             print(f\"   ğŸ¯ Target Profit (10%): {current_price * 1.10:.2f}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 75)\n",
        "    print(\"âœ… Dashboard updated.\")\n",
        "    print(\"=\" * 75)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EU79AUs_ywur"
      },
      "outputs": [],
      "source": [
        "!jupyter nbconvert --to html \"Semester2_V1_AQT_ARDLTrading_Macro&Technical.ipynb\" --output \"AQT_Semester1_Final.html\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELo5W2eEw1xf"
      },
      "source": [
        "# Appendix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvaKaWMbw35Q"
      },
      "outputs": [],
      "source": [
        "# # ============================================================\n",
        "# # ğŸ¤– BLOCK 7 V8: HYBRID PPO AGENT (SIGNAL GUIDED)\n",
        "# #    âœ… Core: PPO Agent trained to follow V20 Signals + ECM\n",
        "# #    âœ… Fix: Added 'Signal Bonus' to prevent Lazy Agent\n",
        "# #    âœ… Input: Reads 'Final_RL_Input_Ready.xlsx' from Block 6\n",
        "# # ============================================================\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import gymnasium as gym\n",
        "# from gymnasium import spaces\n",
        "# from stable_baselines3 import PPO\n",
        "# from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "# import matplotlib.pyplot as plt\n",
        "# import os\n",
        "# import warnings\n",
        "\n",
        "# warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# # ============================================================\n",
        "# # 1. CONFIGURATION\n",
        "# # ============================================================\n",
        "# TARGET_STOCKS = [\"BBL\", \"KKP\"]\n",
        "# DATA_FILE = \"Final_RL_Input_Ready.xlsx\"\n",
        "# MODEL_DIR = \"trained_models_v8\"\n",
        "# os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "# # Trading Config\n",
        "# INITIAL_BALANCE = 100_000\n",
        "# COMMISSION_FEE = 0.00157\n",
        "# SLIPPAGE = 0.001\n",
        "# TAKE_PROFIT_PCT = 0.08  # 8% Target\n",
        "# STOP_LOSS_PCT = -0.05   # 5% Stop\n",
        "\n",
        "# # Training Config\n",
        "# TRAIN_TIMESTEPS = 80000\n",
        "# LEARNING_RATE = 0.0003\n",
        "# BATCH_SIZE = 64\n",
        "\n",
        "# # ============================================================\n",
        "# # 2. TRADING ENVIRONMENT (V8 ENHANCED)\n",
        "# # ============================================================\n",
        "# class StockTradingEnvV8(gym.Env):\n",
        "#     def __init__(self, df, initial_balance=100000, commission=0.00157):\n",
        "#         super(StockTradingEnvV8, self).__init__()\n",
        "#         self.df = df.reset_index(drop=True)\n",
        "#         self.n_step = len(self.df)\n",
        "#         self.initial_balance = initial_balance\n",
        "#         self.commission = commission\n",
        "\n",
        "#         # Action: 0=Hold, 1=Buy, 2=Sell\n",
        "#         self.action_space = spaces.Discrete(3)\n",
        "\n",
        "#         # Observation: à¹€à¸à¸´à¹ˆà¸¡ ECT_Normalized à¹€à¸‚à¹‰à¸²à¸¡à¸²\n",
        "#         self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(13,), dtype=np.float32)\n",
        "#         self.reset()\n",
        "\n",
        "#     def reset(self, seed=None):\n",
        "#         self.current_step = 0\n",
        "#         self.balance = self.initial_balance\n",
        "#         self.shares = 0\n",
        "#         self.entry_price = 0\n",
        "#         self.net_worth = self.initial_balance\n",
        "#         self.max_net_worth = self.initial_balance\n",
        "#         self.hold_days = 0\n",
        "#         return self._next_observation(), {}\n",
        "\n",
        "#     def _next_observation(self):\n",
        "#         if self.current_step >= self.n_step: self.current_step = self.n_step - 1\n",
        "#         obs = self.df.iloc[self.current_step]\n",
        "\n",
        "#         market_val = self.shares * obs['Close']\n",
        "#         self.net_worth = self.balance + market_val\n",
        "#         pnl_pct = (obs['Close'] - self.entry_price)/self.entry_price if self.shares > 0 else 0.0\n",
        "\n",
        "#         # Safe Get Features\n",
        "#         dl_sig = obs.get('DL_Signal', 0.5)\n",
        "#         macro = obs.get('Macro_Signal', 0)\n",
        "#         ect = obs.get('ECT_Normalized', 0)\n",
        "\n",
        "#         state = np.array([\n",
        "#             dl_sig, macro, obs.get('Tech_Signal', 0),\n",
        "#             obs.get('RSI', 50)/100.0, obs.get('MACD', 0)/10.0, obs.get('ADX', 0)/100.0,\n",
        "#             ect,  # âœ… New Feature: Deviation from Long-term Equilibrium\n",
        "#             self.balance/self.initial_balance,\n",
        "#             market_val/self.net_worth,\n",
        "#             pnl_pct,\n",
        "#             1.0 if self.shares > 0 else 0.0,\n",
        "#             self.hold_days / 20.0,\n",
        "#             obs.get('Volume_Ratio', 1.0)\n",
        "#         ], dtype=np.float32)\n",
        "#         return np.nan_to_num(state)\n",
        "\n",
        "#     def step(self, action):\n",
        "#         obs = self.df.iloc[self.current_step]\n",
        "#         current_price = obs['Close']\n",
        "#         dl_signal = obs.get('DL_Signal', 0.5) # 1=Buy, 0=Sell from Block 5.5\n",
        "\n",
        "#         reward = 0\n",
        "#         done = False\n",
        "\n",
        "#         # --- 1. AUTO TAKE PROFIT / STOP LOSS ---\n",
        "#         if self.shares > 0:\n",
        "#             self.hold_days += 1\n",
        "#             unrealized_pnl = (current_price - self.entry_price) / self.entry_price\n",
        "\n",
        "#             if unrealized_pnl >= TAKE_PROFIT_PCT:\n",
        "#                 action = 2 # Force Sell\n",
        "#                 reward += 1.0 # Bonus for TP\n",
        "#             elif unrealized_pnl <= STOP_LOSS_PCT:\n",
        "#                 action = 2 # Force Sell\n",
        "#                 reward -= 0.5 # Penalty for SL (but less than getting wiped out)\n",
        "\n",
        "#         # --- 2. EXECUTION & REWARD SHAPING ---\n",
        "#         # Action 1: BUY\n",
        "#         if action == 1:\n",
        "#             if self.shares == 0:\n",
        "#                 cost = current_price * (1 + self.commission)\n",
        "#                 if self.balance >= cost:\n",
        "#                     self.shares = int(self.balance / cost)\n",
        "#                     self.balance -= self.shares * cost\n",
        "#                     self.entry_price = cost\n",
        "#                     self.hold_days = 0\n",
        "\n",
        "#                     # âœ… SIGNAL BONUS: Reward if buying when DL says Buy\n",
        "#                     if dl_signal >= 0.7: reward += 0.2\n",
        "#                     # Penalty if buying against signal\n",
        "#                     if dl_signal <= 0.3: reward -= 0.2\n",
        "#             else:\n",
        "#                 reward -= 0.01 # Penalty for spamming buy\n",
        "\n",
        "#         # Action 2: SELL\n",
        "#         elif action == 2:\n",
        "#             if self.shares > 0:\n",
        "#                 revenue = (self.shares * current_price) * (1 - self.commission)\n",
        "#                 profit_amt = revenue - (self.shares * self.entry_price)\n",
        "#                 profit_pct = profit_amt / (self.shares * self.entry_price)\n",
        "\n",
        "#                 self.balance += revenue\n",
        "#                 self.shares = 0\n",
        "#                 self.entry_price = 0\n",
        "#                 self.hold_days = 0\n",
        "\n",
        "#                 # Realized Profit Reward\n",
        "#                 if profit_amt > 0:\n",
        "#                     reward += profit_pct * 10\n",
        "#                 else:\n",
        "#                     reward -= 0.5\n",
        "\n",
        "#                 # âœ… SIGNAL BONUS: Reward if selling when DL says Sell\n",
        "#                 if dl_signal <= 0.3: reward += 0.2\n",
        "\n",
        "#         # Action 0: HOLD\n",
        "#         elif action == 0:\n",
        "#             if self.shares > 0:\n",
        "#                 reward += 0.001 # Small reward for holding\n",
        "#                 # Bonus if holding during Uptrend\n",
        "#                 if dl_signal >= 0.6: reward += 0.01\n",
        "#             else:\n",
        "#                 # Bonus if sitting cash during Downtrend\n",
        "#                 if dl_signal <= 0.4: reward += 0.01\n",
        "\n",
        "#         # Update Net Worth\n",
        "#         market_val = self.shares * current_price\n",
        "#         self.net_worth = self.balance + market_val\n",
        "\n",
        "#         # New High Bonus\n",
        "#         if self.net_worth > self.max_net_worth:\n",
        "#             self.max_net_worth = self.net_worth\n",
        "#             reward += 0.5\n",
        "\n",
        "#         self.current_step += 1\n",
        "#         if self.current_step >= self.n_step - 1: done = True\n",
        "\n",
        "#         return self._next_observation(), float(reward), done, False, {}\n",
        "\n",
        "# # ============================================================\n",
        "# # 3. RUNNER\n",
        "# # ============================================================\n",
        "# def run_trading_system(stock, df_all):\n",
        "#     print(f\"\\nğŸ”¹ Processing: {stock} ...\")\n",
        "#     stock_df = df_all[df_all['Stock'] == stock].copy()\n",
        "#     if len(stock_df) < 200: return\n",
        "\n",
        "#     # Train/Test Split\n",
        "#     train_df = stock_df[stock_df['Date'] < '2024-01-01']\n",
        "#     test_df = stock_df[stock_df['Date'] >= '2024-01-01']\n",
        "\n",
        "#     # 1. Train\n",
        "#     print(f\"   ğŸ‹ï¸ Training PPO Agent (Guided Mode)...\")\n",
        "#     env_train = DummyVecEnv([lambda: StockTradingEnvV8(train_df)])\n",
        "#     model = PPO(\"MlpPolicy\", env_train, verbose=0, learning_rate=LEARNING_RATE, batch_size=BATCH_SIZE)\n",
        "#     model.learn(total_timesteps=TRAIN_TIMESTEPS)\n",
        "\n",
        "#     # 2. Backtest\n",
        "#     print(f\"   âš¡ Running Backtest...\")\n",
        "#     env_test = StockTradingEnvV8(test_df, commission=COMMISSION_FEE)\n",
        "#     obs, _ = env_test.reset()\n",
        "#     done = False\n",
        "\n",
        "#     equity_curve = []\n",
        "#     actions = []\n",
        "\n",
        "#     while not done:\n",
        "#         action, _ = model.predict(obs, deterministic=True)\n",
        "#         obs, _, done, _, _ = env_test.step(action)\n",
        "#         equity_curve.append(env_test.net_worth)\n",
        "#         actions.append(action)\n",
        "\n",
        "#     # 3. Stats & Plot\n",
        "#     final_eq = equity_curve[-1]\n",
        "#     ai_ret = (final_eq / INITIAL_BALANCE) - 1\n",
        "#     bh_ret = (test_df['Close'].iloc[-1] / test_df['Close'].iloc[0]) - 1\n",
        "\n",
        "#     print(\"-\" * 40)\n",
        "#     print(f\"   ğŸ¤– AI Net Return:      {ai_ret:+.2%} ({final_eq:,.0f} THB)\")\n",
        "#     print(f\"   ğŸ“‰ Buy & Hold Return:  {bh_ret:+.2%}\")\n",
        "#     if ai_ret > bh_ret: print(\"   âœ… Result: AI WINS\")\n",
        "#     else: print(\"   âŒ Result: MARKET WINS\")\n",
        "#     print(\"-\" * 40)\n",
        "\n",
        "#     # Dashboard\n",
        "#     plt.figure(figsize=(12, 8))\n",
        "\n",
        "#     # Plot 1: Equity\n",
        "#     plt.subplot(2, 1, 1)\n",
        "#     plt.plot(test_df['Date'].iloc[:len(equity_curve)], equity_curve, label='AI Portfolio', color='blue', linewidth=2)\n",
        "#     bench_eq = (test_df['Close'] / test_df['Close'].iloc[0]) * INITIAL_BALANCE\n",
        "#     plt.plot(test_df['Date'], bench_eq, label='Buy & Hold', color='gray', linestyle='--')\n",
        "#     plt.title(f\"{stock} - AI Performance\")\n",
        "#     plt.legend(); plt.grid(True, alpha=0.3)\n",
        "\n",
        "#     # Plot 2: Actions on Price\n",
        "#     plt.subplot(2, 1, 2)\n",
        "#     plt.plot(test_df['Date'], test_df['Close'], label='Price', color='black', alpha=0.6)\n",
        "\n",
        "#     # Map actions to indices\n",
        "#     buy_idx = [i for i, a in enumerate(actions) if a == 1]\n",
        "#     sell_idx = [i for i, a in enumerate(actions) if a == 2]\n",
        "\n",
        "#     if buy_idx:\n",
        "#         plt.scatter(test_df['Date'].iloc[buy_idx], test_df['Close'].iloc[buy_idx], marker='^', color='green', s=100, label='AI Buy', zorder=5)\n",
        "#     if sell_idx:\n",
        "#         plt.scatter(test_df['Date'].iloc[sell_idx], test_df['Close'].iloc[sell_idx], marker='v', color='red', s=100, label='AI Sell', zorder=5)\n",
        "\n",
        "#     plt.legend(); plt.grid(True, alpha=0.3)\n",
        "#     plt.tight_layout()\n",
        "#     plt.show()\n",
        "\n",
        "# # ============================================================\n",
        "# # MAIN\n",
        "# # ============================================================\n",
        "# if __name__ == \"__main__\":\n",
        "#     print(\"=\"*70)\n",
        "#     print(\"ğŸ¤– BLOCK 7 V8: HYBRID PPO AGENT (SIGNAL GUIDED)\")\n",
        "#     print(\"=\"*70)\n",
        "\n",
        "#     if os.path.exists(DATA_FILE):\n",
        "#         df_all = pd.read_excel(DATA_FILE)\n",
        "#         df_all['Date'] = pd.to_datetime(df_all['Date'])\n",
        "\n",
        "#         for s in TARGET_STOCKS:\n",
        "#             run_trading_system(s, df_all)\n",
        "#     else:\n",
        "#         print(f\"âŒ Error: '{DATA_FILE}' not found. Run Block 6 first.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
