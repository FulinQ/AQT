{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRdkUxDEoTHL"
      },
      "source": [
        "**1 Collecting Data**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqWAq7nVFmr5"
      },
      "source": [
        "## Improve thing\n",
        "  1) Chowlin model to expand data frequency\n",
        "  2) A. à¸ªà¸£à¹‰à¸²à¸‡ Environment à¹à¸¥à¸° State Vector (à¸•à¸²à¸¡à¸«à¸±à¸§à¸‚à¹‰à¸­ 5. Method à¹ƒà¸™ Paper)à¹à¸œà¸™à¸‚à¸­à¸‡à¸„à¸¸à¸“à¸£à¸°à¸šà¸¸à¸§à¹ˆà¸²à¸ˆà¸°à¹ƒà¸Šà¹‰ Reinforcement Learning (RL) à¸‹à¸¶à¹ˆà¸‡à¸•à¹‰à¸­à¸‡à¸à¸²à¸£ \"à¸ªà¸ à¸²à¸žà¹à¸§à¸”à¸¥à¹‰à¸­à¸¡ (Environment)\" à¹ƒà¸™à¸à¸²à¸£à¸•à¸±à¸”à¸ªà¸´à¸™à¹ƒà¸ˆ à¸„à¸¸à¸“à¸•à¹‰à¸­à¸‡à¹€à¸‚à¸µà¸¢à¸™ Code à¹€à¸žà¸·à¹ˆà¸­à¸£à¸§à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸à¸ªà¸­à¸‡à¸ªà¹ˆà¸§à¸™à¹€à¸‚à¹‰à¸²à¸”à¹‰à¸§à¸¢à¸à¸±à¸™à¹€à¸›à¹‡à¸™ $S_t$:Macro Signal ($m_t$): à¹€à¸­à¸²à¸œà¸¥ Forecast à¸«à¸£à¸·à¸­à¸„à¹ˆà¸² ECT/Coefficients à¸ˆà¸²à¸à¹‚à¸¡à¹€à¸”à¸¥ ARDL-ECM à¸—à¸µà¹ˆà¸„à¸¸à¸“à¸—à¸³à¹€à¸ªà¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§à¸¡à¸²à¹€à¸›à¹‡à¸™ FeatureTechnical Signal ($b_t$): à¹€à¸­à¸²à¸„à¸§à¸²à¸¡à¸™à¹ˆà¸²à¸ˆà¸°à¹€à¸›à¹‡à¸™ ($P_{bull}, P_{bear}, P_{neutral}$) à¸«à¸£à¸·à¸­à¸ªà¸±à¸à¸à¸²à¸“à¸ˆà¸²à¸à¹‚à¸¡à¹€à¸”à¸¥ LSTM/GRU à¸¡à¸²à¹€à¸›à¹‡à¸™ FeaturePortfolio State: à¸ªà¸–à¸²à¸™à¸°à¸›à¸±à¸ˆà¸ˆà¸¸à¸šà¸±à¸™ (à¸–à¸·à¸­à¹€à¸‡à¸´à¸™à¸ªà¸”, à¸–à¸·à¸­à¸«à¸¸à¹‰à¸™, à¸•à¹‰à¸™à¸—à¸¸à¸™)à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸—à¸³: à¸ªà¸£à¹‰à¸²à¸‡ Class Environment (à¹€à¸Šà¹ˆà¸™à¸ªà¸·à¸šà¸—à¸­à¸”à¸ˆà¸²à¸ gym.Env) à¸—à¸µà¹ˆà¸£à¸±à¸šà¸„à¹ˆà¸²à¹€à¸«à¸¥à¹ˆà¸²à¸™à¸µà¹‰à¹€à¸‚à¹‰à¸²à¹„à¸›à¹ƒà¸™à¹à¸•à¹ˆà¸¥à¸° Step\n",
        "  3) B. à¸žà¸±à¸’à¸™à¸²à¸ªà¹ˆà¸§à¸™ Reinforcement Learning (PPO Algorithm)à¹ƒà¸™ Code à¸›à¸±à¸ˆà¸ˆà¸¸à¸šà¸±à¸™à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸žà¸šà¸ªà¹ˆà¸§à¸™à¸—à¸µà¹ˆà¹€à¸›à¹‡à¸™ PPO (Proximal Policy Optimization) à¸«à¸£à¸·à¸­ Agent à¸—à¸µà¹ˆà¸•à¸±à¸”à¸ªà¸´à¸™à¹ƒà¸ˆ \"à¸‹à¸·à¹‰à¸­/à¸‚à¸²à¸¢/à¸–à¸·à¸­\"Action: à¸„à¸¸à¸“à¸•à¹‰à¸­à¸‡à¸à¸³à¸«à¸™à¸” Action Space à¹€à¸›à¹‡à¸™ {Buy, Hold, Sell}Reward Function: à¹€à¸‚à¸µà¸¢à¸™à¸ªà¸¡à¸à¸²à¸£ Reward à¸•à¸²à¸¡à¹à¸œà¸™: $\\text{Reward} = \\text{Portfolio Value} - (\\lambda \\times \\text{Drawdown Penalty})$Implementation: à¹ƒà¸Šà¹‰ Library à¹€à¸Šà¹ˆà¸™ stable-baselines3 à¸«à¸£à¸·à¸­ rllib à¹€à¸žà¸·à¹ˆà¸­à¸ªà¸£à¹‰à¸²à¸‡ PPO Agent à¹à¸¥à¹‰à¸§à¸ªà¸±à¹ˆà¸‡ Train à¸”à¹‰à¸§à¸¢ Environment à¸—à¸µà¹ˆà¸ªà¸£à¹‰à¸²à¸‡à¹ƒà¸™à¸‚à¹‰à¸­ A\n",
        "  4) C. à¹€à¸žà¸´à¹ˆà¸¡à¹‚à¸¡à¹€à¸”à¸¥ CNN (Optional à¸•à¸²à¸¡à¹à¸œà¸™)\n",
        "à¹ƒà¸™à¹à¸œà¸™à¸£à¸°à¸šà¸¸à¸§à¹ˆà¸²à¸ˆà¸°à¹ƒà¸Šà¹‰ CNN (Convolutional Neural Networks) à¸£à¹ˆà¸§à¸¡à¸à¸±à¸š LSTM à¹€à¸žà¸·à¹ˆà¸­à¸ˆà¸±à¸š Pattern à¸à¸£à¸²à¸Ÿ à¹à¸•à¹ˆà¹ƒà¸™ Code à¸žà¸šà¹à¸„à¹ˆ LSTM/GRU\n",
        "\n",
        "\n",
        "5) D. à¸à¸²à¸£à¸£à¸§à¸¡à¸£à¸°à¸šà¸šà¹à¸¥à¸° Backtesting (Phase 4)\n",
        "Rolling Window Training: à¸•à¹‰à¸­à¸‡à¹€à¸‚à¸µà¸¢à¸™ Loop à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¹‚à¸¡à¹€à¸”à¸¥ Train à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸›à¸µ 2010-2024 à¹à¸¥à¸° Test à¸›à¸µ 2025 (Out-of-sample)\n",
        "\n",
        "Performance Metrics: Code à¸›à¸±à¸ˆà¸ˆà¸¸à¸šà¸±à¸™à¸­à¸²à¸ˆà¸ˆà¸°à¸§à¸±à¸”à¹à¸„à¹ˆà¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³ (Accuracy/MSE) à¸‚à¸­à¸‡à¸à¸²à¸£à¸—à¸³à¸™à¸²à¸¢à¸£à¸²à¸„à¸² à¹à¸•à¹ˆà¸•à¸²à¸¡à¹à¸œà¸™à¸„à¸¸à¸“à¸•à¹‰à¸­à¸‡à¸§à¸±à¸” Trading Performance à¸‚à¸­à¸‡à¸šà¸­à¸— à¹„à¸”à¹‰à¹à¸à¹ˆ:\n",
        "\n",
        "Cumulative Return (à¸à¸³à¹„à¸£à¸ªà¸°à¸ªà¸¡)\n",
        "\n",
        "Sharpe Ratio (à¸œà¸¥à¸•à¸­à¸šà¹à¸—à¸™à¹€à¸—à¸µà¸¢à¸šà¸„à¸§à¸²à¸¡à¹€à¸ªà¸µà¹ˆà¸¢à¸‡)\n",
        "\n",
        "Maximum Drawdown (à¸à¸²à¸£à¸‚à¸²à¸”à¸—à¸¸à¸™à¸ªà¸¹à¸‡à¸ªà¸¸à¸”)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m32krxZ3oYCD",
        "outputId": "6ac023bf-b59d-4faf-aafa-37a6cecc341b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fredapi in /usr/local/lib/python3.12/dist-packages (0.5.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from fredapi) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas->fredapi) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->fredapi) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->fredapi) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->fredapi) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->fredapi) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# !pip install fredapi\n",
        "import os\n",
        "os.chdir()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZOQsga5cvLN"
      },
      "source": [
        "| Component               | Description                                    | Paper                 |\n",
        "| ----------------------- | ---------------------------------------------- | --------------------- |\n",
        "| Proxy selection         | Dynamic Factor / PCA on macro dataset          | Stock & Watson (2002) |\n",
        "| Temporal disaggregation | Chow-Lin linear regression                     | Chow & Lin (1971)     |\n",
        "| Extrapolation           | AR(1) residual correction (Fernandez model)    | Fernandez (1981)      |\n",
        "| Ratio preservation      | Denton (1971) for % variables (e.g., Debt/GDP) | Denton (1971)         |\n",
        "\n",
        "ðŸ“˜ Academic Framework (à¸ªà¸³à¸«à¸£à¸±à¸š citation à¹ƒà¸™ report)\n",
        "\n",
        "Chow & Lin (1971) â€“ Best Linear Unbiased Interpolation by Related Series\n",
        "\n",
        "Stock & Watson (2002) â€“ Macroeconomic Forecasting Using Diffusion Indexes\n",
        "\n",
        "Mariano & Murasawa (2003) â€“ A New Coincident Index of Business Cycles Based on Monthly and Quarterly Series\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38oP341GrfFn"
      },
      "source": [
        "GDP Data\n",
        "(https://)https://lookerstudio.google.com/u/0/reporting/52a283c8-91f9-4b35-8157-2b2b42312602/page/p_l7cxsbayvc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhTALLCnoY74",
        "outputId": "803a138e-535f-47de-aaf9-e024c45066ea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-4088842435.py:112: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker_yf, start=START, end=END, interval=\"1mo\")['Close']\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-4088842435.py:112: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker_yf, start=START, end=END, interval=\"1mo\")['Close']\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-4088842435.py:112: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker_yf, start=START, end=END, interval=\"1mo\")['Close']\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-4088842435.py:112: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker_yf, start=START, end=END, interval=\"1mo\")['Close']\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-4088842435.py:112: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker_yf, start=START, end=END, interval=\"1mo\")['Close']\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-4088842435.py:112: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker_yf, start=START, end=END, interval=\"1mo\")['Close']\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-4088842435.py:112: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker_yf, start=START, end=END, interval=\"1mo\")['Close']\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-4088842435.py:112: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker_yf, start=START, end=END, interval=\"1mo\")['Close']\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-4088842435.py:112: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker_yf, start=START, end=END, interval=\"1mo\")['Close']\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-4088842435.py:112: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker_yf, start=START, end=END, interval=\"1mo\")['Close']\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-4088842435.py:112: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker_yf, start=START, end=END, interval=\"1mo\")['Close']\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-4088842435.py:134: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  fx_thb_usd = yf.download(\"THB=X\", start=START, end=END, interval=\"1mo\")[\"Close\"]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-4088842435.py:138: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  fx_thb_cny = yf.download(\"THBCNY=X\", start=START, end=END, interval=\"1mo\")[\"Close\"]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-4088842435.py:142: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  brent_data = yf.download(\"BZ=F\", start=START, end=END, interval=\"1mo\")[\"Close\"]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-4088842435.py:146: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  crb_data = yf.download(\"^CRB\", start=START, end=END, interval=\"1mo\")[\"Close\"]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['^CRB']: YFPricesMissingError('possibly delisted; no price data found  (1mo 2013-01-01 -> 2026-01-13)')\n",
            "/tmp/ipython-input-4088842435.py:150: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  sp500_data = yf.download(\"^GSPC\", start=START, end=END, interval=\"1mo\")[\"Close\"]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-4088842435.py:154: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  set_daily = yf.download(\"^SET.BK\", start=START, end=END, interval=\"1d\")[\"Close\"]\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "             Close_BBL  Close_KBANK  Close_KKP  Close_KTB  Close_TCAP  \\\n",
            "Date                                                                    \n",
            "2015-02-01  120.324242   151.045563  18.905380  13.843618   16.486799   \n",
            "2015-03-01  121.310509   159.398285  18.784966  13.843618   16.369032   \n",
            "2015-04-01  121.639305   146.173111  17.821629  12.143525   16.015741   \n",
            "2015-05-01  122.538742   137.793167  17.965874  11.427542   16.611540   \n",
            "2015-06-01  119.845604   133.553375  17.591583  10.796185   16.126530   \n",
            "...                ...          ...        ...        ...         ...   \n",
            "2025-09-01  147.045898   165.540939  57.287346  24.412216   48.975368   \n",
            "2025-10-01  158.500000   186.500000  65.750000  26.823908   51.000000   \n",
            "2025-11-01  158.000000   186.500000  64.250000  27.070000   54.500000   \n",
            "2025-12-01  169.500000   194.500000  68.000000  28.250000   58.250000   \n",
            "2026-01-01  170.500000   191.500000  66.250000  28.750000   57.750000   \n",
            "\n",
            "            Close_TISCO  Close_TTB  Close_KTC  Close_AEONTS  Close_JMT  ...  \\\n",
            "Date                                                                    ...   \n",
            "2015-02-01    21.595558   1.766926   6.761017     75.498390   7.235691  ...   \n",
            "2015-03-01    21.021212   1.743523   7.632539     72.367119   6.783460  ...   \n",
            "2015-04-01    20.791471   1.521194   8.362266     70.279617   6.671340  ...   \n",
            "2015-05-01    21.600693   1.518632   7.376149     67.142464   6.445744  ...   \n",
            "2015-06-01    22.080709   1.399055   7.750873     66.788155   5.545500  ...   \n",
            "...                 ...        ...        ...           ...        ...  ...   \n",
            "2025-09-01   100.009758   1.834346  30.000000    113.939011  11.800000  ...   \n",
            "2025-10-01   107.500000   1.786073  28.500000    103.180824   9.750000  ...   \n",
            "2025-11-01   106.000000   1.930000  27.250000     96.000000   8.600000  ...   \n",
            "2025-12-01   110.500000   2.020000  26.250000    107.500000   8.750000  ...   \n",
            "2026-01-01   109.500000   2.040000  25.250000     98.000000   8.300000  ...   \n",
            "\n",
            "            THB_per_USD  THB_per_CNY  SP500_Index    SET_Index  IPI_Surprise  \\\n",
            "Date                                                                           \n",
            "2015-02-01    32.341000     0.193350  2104.500000  1582.699951     -0.000066   \n",
            "2015-03-01    32.540001     0.190400  2067.889893  1582.140015      0.000380   \n",
            "2015-04-01    32.838001     0.188270  2085.510010  1525.579956     -0.000670   \n",
            "2015-05-01    33.734001     0.183510  2107.389893  1519.880005     -0.000330   \n",
            "2015-06-01    33.729000     0.183590  2063.110107  1476.869995     -0.000280   \n",
            "...                 ...          ...          ...          ...           ...   \n",
            "2025-09-01    32.209999     0.220962  6688.459961  1244.479980     -0.000291   \n",
            "2025-10-01    32.299999     0.220050  6840.200195  1275.030029     -0.000291   \n",
            "2025-11-01    32.084999     0.220339  6849.089844  1308.859985     -0.000291   \n",
            "2025-12-01    31.450001     0.222381  6845.500000  1276.569946     -0.000291   \n",
            "2026-01-01    31.379999     0.222168  6977.270020  1280.050049     -0.000291   \n",
            "\n",
            "            Inflation_Surprise  5Y_1Y_Bond_Spread  10Y_5Y_Bond_Spread  \\\n",
            "Date                                                                    \n",
            "2015-02-01             -0.0066             0.0035              0.0056   \n",
            "2015-03-01             -0.0019             0.0045              0.0058   \n",
            "2015-04-01             -0.0012             0.0048              0.0051   \n",
            "2015-05-01             -0.0024             0.0042              0.0078   \n",
            "2015-06-01             -0.0015             0.0056              0.0082   \n",
            "...                        ...                ...                 ...   \n",
            "2025-09-01              0.0013            -0.0010              0.0027   \n",
            "2025-10-01              0.0013            -0.0010              0.0027   \n",
            "2025-11-01              0.0013            -0.0010              0.0027   \n",
            "2025-12-01              0.0013            -0.0010              0.0027   \n",
            "2026-01-01              0.0013            -0.0010              0.0027   \n",
            "\n",
            "            3M_1M_THOR_Spread  6M_1M_THOR_Spread  \n",
            "Date                                              \n",
            "2015-02-01           0.000015           0.000068  \n",
            "2015-03-01           0.000032           0.000077  \n",
            "2015-04-01           0.001167           0.001528  \n",
            "2015-05-01           0.001280           0.002220  \n",
            "2015-06-01           0.001854           0.003469  \n",
            "...                       ...                ...  \n",
            "2025-09-01           0.000052           0.000139  \n",
            "2025-10-01           0.000052           0.000139  \n",
            "2025-11-01           0.000052           0.000139  \n",
            "2025-12-01           0.000052           0.000139  \n",
            "2026-01-01           0.000052           0.000139  \n",
            "\n",
            "[132 rows x 35 columns]\n",
            "\n",
            "=== HEAD ===\n",
            "             Close_BBL  Close_KBANK  Close_KKP  Close_KTB  Close_TCAP  \\\n",
            "Date                                                                    \n",
            "2015-02-01  120.324242   151.045563  18.905380  13.843618   16.486799   \n",
            "2015-03-01  121.310509   159.398285  18.784966  13.843618   16.369032   \n",
            "2015-04-01  121.639305   146.173111  17.821629  12.143525   16.015741   \n",
            "2015-05-01  122.538742   137.793167  17.965874  11.427542   16.611540   \n",
            "2015-06-01  119.845604   133.553375  17.591583  10.796185   16.126530   \n",
            "2015-07-01  111.766098   125.780434  15.221087  11.048728   15.156514   \n",
            "2015-08-01  110.756165   127.547043  16.094425  11.490677   14.307744   \n",
            "2015-09-01  107.726334   120.834000  15.345847  10.796185   15.399016   \n",
            "2015-10-01  114.194626   122.236328  17.232651  10.796185   16.247778   \n",
            "2015-11-01  114.194626   121.173431  18.775869  10.733049   17.481976   \n",
            "\n",
            "            Close_TISCO  Close_TTB  Close_KTC  Close_AEONTS  Close_JMT  ...  \\\n",
            "Date                                                                    ...   \n",
            "2015-02-01    21.595558   1.766926   6.761017     75.498390   7.235691  ...   \n",
            "2015-03-01    21.021212   1.743523   7.632539     72.367119   6.783460  ...   \n",
            "2015-04-01    20.791471   1.521194   8.362266     70.279617   6.671340  ...   \n",
            "2015-05-01    21.600693   1.518632   7.376149     67.142464   6.445744  ...   \n",
            "2015-06-01    22.080709   1.399055   7.750873     66.788155   5.545500  ...   \n",
            "2015-07-01    20.400661   1.399055   6.251977     62.359226   5.401460  ...   \n",
            "2015-08-01    18.960609   1.411012   6.942258     60.233356   4.969345  ...   \n",
            "2015-09-01    17.040550   1.446885   7.395871     67.851097   5.401460  ...   \n",
            "2015-10-01    18.120584   1.590377   7.869208     69.799820   5.617519  ...   \n",
            "2015-11-01    20.160650   1.554505   7.770596     70.834801   4.789297  ...   \n",
            "\n",
            "            THB_per_USD  THB_per_CNY  SP500_Index    SET_Index  IPI_Surprise  \\\n",
            "Date                                                                           \n",
            "2015-02-01    32.341000      0.19335  2104.500000  1582.699951     -0.000066   \n",
            "2015-03-01    32.540001      0.19040  2067.889893  1582.140015      0.000380   \n",
            "2015-04-01    32.838001      0.18827  2085.510010  1525.579956     -0.000670   \n",
            "2015-05-01    33.734001      0.18351  2107.389893  1519.880005     -0.000330   \n",
            "2015-06-01    33.729000      0.18359  2063.110107  1476.869995     -0.000280   \n",
            "2015-07-01    35.090000      0.17655  2103.840088  1491.619995     -0.000285   \n",
            "2015-08-01    35.723000      0.17805  1972.180054  1442.040039      0.000045   \n",
            "2015-09-01    36.396999      0.17444  1920.030029  1362.390015     -0.000200   \n",
            "2015-10-01    35.606998      0.17707  2079.360107  1345.150024     -0.000200   \n",
            "2015-11-01    35.890999      0.17655  2080.409912  1413.339966     -0.000042   \n",
            "\n",
            "            Inflation_Surprise  5Y_1Y_Bond_Spread  10Y_5Y_Bond_Spread  \\\n",
            "Date                                                                    \n",
            "2015-02-01             -0.0066            0.00350             0.00560   \n",
            "2015-03-01             -0.0019            0.00450             0.00580   \n",
            "2015-04-01             -0.0012            0.00480             0.00510   \n",
            "2015-05-01             -0.0024            0.00420             0.00780   \n",
            "2015-06-01             -0.0015            0.00560             0.00820   \n",
            "2015-07-01             -0.0007            0.00630             0.00630   \n",
            "2015-08-01             -0.0007            0.00530             0.00620   \n",
            "2015-09-01              0.0001            0.00575             0.00535   \n",
            "2015-10-01              0.0001            0.00575             0.00535   \n",
            "2015-11-01              0.0017            0.00530             0.00640   \n",
            "\n",
            "            3M_1M_THOR_Spread  6M_1M_THOR_Spread  \n",
            "Date                                              \n",
            "2015-02-01           0.000015           0.000068  \n",
            "2015-03-01           0.000032           0.000077  \n",
            "2015-04-01           0.001167           0.001528  \n",
            "2015-05-01           0.001280           0.002220  \n",
            "2015-06-01           0.001854           0.003469  \n",
            "2015-07-01           0.000772           0.002587  \n",
            "2015-08-01           0.000024           0.001743  \n",
            "2015-09-01           0.000020           0.000980  \n",
            "2015-10-01           0.000020           0.000980  \n",
            "2015-11-01           0.000020           0.000049  \n",
            "\n",
            "[10 rows x 35 columns]\n",
            "\n",
            "=== TAIL ===\n",
            "             Close_BBL  Close_KBANK  Close_KKP  Close_KTB  Close_TCAP  \\\n",
            "Date                                                                    \n",
            "2025-04-01  131.839539   147.193665  46.073654  19.992119   44.601631   \n",
            "2025-05-01  139.644257   149.878723  41.927025  21.852873   46.051464   \n",
            "2025-06-01  137.177048   151.704681  44.123444  20.966944   44.589512   \n",
            "2025-07-01  146.059021   160.105255  53.874481  21.656000   48.000732   \n",
            "2025-08-01  153.460663   166.529236  58.018673  24.215345   49.462685   \n",
            "2025-09-01  147.045898   165.540939  57.287346  24.412216   48.975368   \n",
            "2025-10-01  158.500000   186.500000  65.750000  26.823908   51.000000   \n",
            "2025-11-01  158.000000   186.500000  64.250000  27.070000   54.500000   \n",
            "2025-12-01  169.500000   194.500000  68.000000  28.250000   58.250000   \n",
            "2026-01-01  170.500000   191.500000  66.250000  28.750000   57.750000   \n",
            "\n",
            "            Close_TISCO  Close_TTB  Close_KTC  Close_AEONTS  Close_JMT  ...  \\\n",
            "Date                                                                    ...   \n",
            "2025-04-01    90.793785   1.703317   45.15099    100.401062  13.528524  ...   \n",
            "2025-05-01    95.597565   1.853654   38.50000    100.735779   9.068032  ...   \n",
            "2025-06-01    94.862198   1.824691   24.00000     91.689117   8.724917  ...   \n",
            "2025-07-01    97.313416   1.863309   28.50000     96.579208  10.881639  ...   \n",
            "2025-08-01    99.029266   1.834346   27.25000    107.092888  11.469835  ...   \n",
            "2025-09-01   100.009758   1.834346   30.00000    113.939011  11.800000  ...   \n",
            "2025-10-01   107.500000   1.786073   28.50000    103.180824   9.750000  ...   \n",
            "2025-11-01   106.000000   1.930000   27.25000     96.000000   8.600000  ...   \n",
            "2025-12-01   110.500000   2.020000   26.25000    107.500000   8.750000  ...   \n",
            "2026-01-01   109.500000   2.040000   25.25000     98.000000   8.300000  ...   \n",
            "\n",
            "            THB_per_USD  THB_per_CNY  SP500_Index    SET_Index  IPI_Surprise  \\\n",
            "Date                                                                           \n",
            "2025-04-01    33.430000     0.217374  5569.060059  1168.020020     -0.000291   \n",
            "2025-05-01    32.529999     0.219625  5911.689941  1198.979980     -0.000291   \n",
            "2025-06-01    32.636002     0.219666  6204.950195  1132.020020     -0.000291   \n",
            "2025-07-01    32.709999     0.219328  6339.390137  1110.010010     -0.000291   \n",
            "2025-08-01    32.279999     0.220721  6460.259766  1218.329956     -0.000291   \n",
            "2025-09-01    32.209999     0.220962  6688.459961  1244.479980     -0.000291   \n",
            "2025-10-01    32.299999     0.220050  6840.200195  1275.030029     -0.000291   \n",
            "2025-11-01    32.084999     0.220339  6849.089844  1308.859985     -0.000291   \n",
            "2025-12-01    31.450001     0.222381  6845.500000  1276.569946     -0.000291   \n",
            "2026-01-01    31.379999     0.222168  6977.270020  1280.050049     -0.000291   \n",
            "\n",
            "            Inflation_Surprise  5Y_1Y_Bond_Spread  10Y_5Y_Bond_Spread  \\\n",
            "Date                                                                    \n",
            "2025-04-01              0.0013             -0.001              0.0027   \n",
            "2025-05-01              0.0013             -0.001              0.0027   \n",
            "2025-06-01              0.0013             -0.001              0.0027   \n",
            "2025-07-01              0.0013             -0.001              0.0027   \n",
            "2025-08-01              0.0013             -0.001              0.0027   \n",
            "2025-09-01              0.0013             -0.001              0.0027   \n",
            "2025-10-01              0.0013             -0.001              0.0027   \n",
            "2025-11-01              0.0013             -0.001              0.0027   \n",
            "2025-12-01              0.0013             -0.001              0.0027   \n",
            "2026-01-01              0.0013             -0.001              0.0027   \n",
            "\n",
            "            3M_1M_THOR_Spread  6M_1M_THOR_Spread  \n",
            "Date                                              \n",
            "2025-04-01           0.000052           0.000139  \n",
            "2025-05-01           0.000052           0.000139  \n",
            "2025-06-01           0.000052           0.000139  \n",
            "2025-07-01           0.000052           0.000139  \n",
            "2025-08-01           0.000052           0.000139  \n",
            "2025-09-01           0.000052           0.000139  \n",
            "2025-10-01           0.000052           0.000139  \n",
            "2025-11-01           0.000052           0.000139  \n",
            "2025-12-01           0.000052           0.000139  \n",
            "2026-01-01           0.000052           0.000139  \n",
            "\n",
            "[10 rows x 35 columns]\n",
            "\n",
            "=== COLUMNS ===\n",
            "['Close_BBL', 'Close_KBANK', 'Close_KKP', 'Close_KTB', 'Close_TCAP', 'Close_TISCO', 'Close_TTB', 'Close_KTC', 'Close_AEONTS', 'Close_JMT', 'Close_SAWAD', 'Inflation', 'Inflation_Forecast', 'IPI', 'IPI_Forecast', 'BroadMoney_M1M2_Growth', 'THOR_1M', 'THOR_3M', 'THOR_6M', 'Bond_Yield_1Y', 'Bond_Yield_5Y', 'Bond_Yield_10Y', 'Yield_Spread_10Y_5Y', 'Yield_Spread_5Y_1Y', 'Yield_Spread_10Y_1Y', 'THB_per_USD', 'THB_per_CNY', 'SP500_Index', 'SET_Index', 'IPI_Surprise', 'Inflation_Surprise', '5Y_1Y_Bond_Spread', '10Y_5Y_Bond_Spread', '3M_1M_THOR_Spread', '6M_1M_THOR_Spread']\n",
            "\n",
            "=== NA COUNTS ===\n",
            "Close_BBL                 0\n",
            "Close_KBANK               0\n",
            "Close_KKP                 0\n",
            "Close_KTB                 0\n",
            "Close_TCAP                0\n",
            "Close_TISCO               0\n",
            "Close_TTB                 0\n",
            "Close_KTC                 0\n",
            "Close_AEONTS              0\n",
            "Close_JMT                 0\n",
            "Close_SAWAD               0\n",
            "Inflation                 0\n",
            "Inflation_Forecast        0\n",
            "IPI                       0\n",
            "IPI_Forecast              0\n",
            "BroadMoney_M1M2_Growth    0\n",
            "THOR_1M                   0\n",
            "THOR_3M                   0\n",
            "THOR_6M                   0\n",
            "Bond_Yield_1Y             0\n",
            "Bond_Yield_5Y             0\n",
            "Bond_Yield_10Y            0\n",
            "Yield_Spread_10Y_5Y       0\n",
            "Yield_Spread_5Y_1Y        0\n",
            "Yield_Spread_10Y_1Y       0\n",
            "THB_per_USD               0\n",
            "THB_per_CNY               0\n",
            "SP500_Index               0\n",
            "SET_Index                 0\n",
            "IPI_Surprise              0\n",
            "Inflation_Surprise        0\n",
            "5Y_1Y_Bond_Spread         0\n",
            "10Y_5Y_Bond_Spread        0\n",
            "3M_1M_THOR_Spread         0\n",
            "6M_1M_THOR_Spread         0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# ================== Setup ==================\n",
        "# pip install yfinance fredapi pandas pandas-datareader\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from fredapi import Fred\n",
        "from pandas_datareader import wb\n",
        "from datetime import date\n",
        "import io, requests\n",
        "from pathlib import Path\n",
        "\n",
        "# ----- Parameters -----\n",
        "START = \"2013-01-01\"\n",
        "END   = date.today().isoformat()         # à¸§à¸±à¸™à¸™à¸µà¹‰\n",
        "FRED_API_KEY = \"c948956426006ca126a2dd3bd1f07cee\"\n",
        "\n",
        "# FRED client (à¸à¸±à¸™à¸­à¸´à¸™à¹€à¸—à¸­à¸£à¹Œà¹€à¸™à¹‡à¸•à¸¥à¹ˆà¸¡)\n",
        "try:\n",
        "    fred = Fred(api_key=FRED_API_KEY)\n",
        "except Exception:\n",
        "    fred = None\n",
        "\n",
        "# ================== Helper Functions ==================\n",
        "def get_fred_series(series_id: str, rename_to: str = None) -> pd.Series:\n",
        "    \"\"\"à¸”à¸¶à¸‡à¸‹à¸µà¸£à¸µà¸ªà¹Œà¸ˆà¸²à¸ FRED\"\"\"\n",
        "    if fred is None:\n",
        "        return pd.Series(dtype=\"float64\", name=rename_to or series_id)\n",
        "    s = fred.get_series(series_id)\n",
        "    s.name = rename_to or series_id\n",
        "    s.index = pd.to_datetime(s.index)\n",
        "    return s.sort_index()\n",
        "\n",
        "def expand_period_to_target_index(target_index: pd.DatetimeIndex,\n",
        "                                  lowfreq_series: pd.Series,\n",
        "                                  freq: str) -> pd.Series:\n",
        "    \"\"\"à¸‚à¸¢à¸²à¸¢à¸„à¹ˆà¸²à¸„à¸§à¸²à¸¡à¸–à¸µà¹ˆà¸•à¹ˆà¸³à¹„à¸›à¸—à¸µà¹ˆ target_index\"\"\"\n",
        "    if lowfreq_series is None or lowfreq_series.empty:\n",
        "        return pd.Series(index=target_index, dtype=\"float64\", name=getattr(lowfreq_series, \"name\", None))\n",
        "    s = lowfreq_series.dropna().copy()\n",
        "    s.index = pd.PeriodIndex(s.index, freq=freq)\n",
        "    df = pd.DataFrame(index=target_index)\n",
        "    df[\"period\"] = df.index.to_period(freq)\n",
        "    out = df.join(s.rename(s.name), on=\"period\")[s.name]\n",
        "    out.name = s.name\n",
        "    return out\n",
        "\n",
        "# ================== 2) Macro: à¹ƒà¸Šà¹‰ Macro_data.xlsx ==================\n",
        "macro_candidates = [Path(\"/mnt/data/Macro_data.xlsx\"), Path(\"Macro_data.xlsx\")]\n",
        "macro_path = next((str(p) for p in macro_candidates if p.exists()), \"Macro_data.xlsx\")\n",
        "\n",
        "macro = pd.read_excel(macro_path, sheet_name=0)\n",
        "\n",
        "def _pct_to_float(col: pd.Series) -> pd.Series:\n",
        "    \"\"\"à¹à¸›à¸¥à¸‡à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ % à¹ƒà¸«à¹‰à¹€à¸›à¹‡à¸™à¸•à¸±à¸§à¹€à¸¥à¸‚\"\"\"\n",
        "    return (\n",
        "        col.astype(str)\n",
        "           .str.strip()\n",
        "           .str.replace(\",\", \"\", regex=False)\n",
        "           .str.replace(\"%\", \"\", regex=False)\n",
        "           .str.replace(\"(\", \"-\", regex=False)\n",
        "           .str.replace(\")\", \"\", regex=False)\n",
        "           .replace({\"\": None})\n",
        "           .pipe(pd.to_numeric, errors=\"coerce\")\n",
        "    )\n",
        "\n",
        "macro[\"Date\"] = pd.to_datetime(macro[\"Date\"], dayfirst=True, errors=\"coerce\")\n",
        "\n",
        "for col in [\"CPI_Actual\", \"CPI_Forecast\", \"IPI_Actual\", \"IPI_Forecast\"]:\n",
        "    if col in macro.columns:\n",
        "        macro[col] = _pct_to_float(macro[col])\n",
        "\n",
        "macro = (macro.rename(columns={\n",
        "            \"M1M2_Actual\": \"BroadMoney_M1M2_Level\",\n",
        "            \"CPI_Actual\": \"Inflation\",\n",
        "            \"CPI_Forecast\": \"Inflation_Forecast\",\n",
        "            \"THOR_1M\": \"THOR_1M\",\n",
        "            \"THOR_3M\": \"THOR_3M\",\n",
        "            \"THOR_6M\": \"THOR_6M\",\n",
        "            \"IPI_Actual\": \"IPI\",\n",
        "            \"IPI_Forecast\": \"IPI_Forecast\",\n",
        "            \"Bond_1Y\": \"Bond_Yield_1Y\",\n",
        "            \"Bond_5Y\": \"Bond_Yield_5Y\",\n",
        "            \"Bond_10Y\": \"Bond_Yield_10Y\",\n",
        "            \"Bond_spread_10Y_5Y\": \"Yield_Spread_10Y_5Y\",\n",
        "            \"Bond_spread_5Y_1Y\": \"Yield_Spread_5Y_1Y\",\n",
        "            \"Bond_spread_10Y_1Y\": \"Yield_Spread_10Y_1Y\"\n",
        "        })\n",
        "        .sort_values(\"Date\")\n",
        "        .set_index(\"Date\"))\n",
        "\n",
        "# ================== 1) Stock Prices ==================\n",
        "SECTORS = {\n",
        "    \"Banking\": [\"BBL\",\"KBANK\",\"KKP\",\"KTB\",\"TCAP\",\"TISCO\",\"TTB\"],\n",
        "    \"Finance_Securities\": [\"KTC\",\"AEONTS\",\"JMT\",\"SAWAD\"],\n",
        "    # \"Energy_Utilities\": [\"BANPU\",\"BCP\",\"EGCO\",\"GPSC\",\"GULF\",\"OR\",\"PTT\",\"PTTEP\",\"RATCH\",\"TOP\",\"BGRIM\",\"BCPG\",\"EA\",\"GUNKUL\",\"IRPC\",\"SPRC\",\"WHAUP\",\"CKP\"],\n",
        "    # \"Food_Beverage\": [\"CBG\",\"CPF\",\"OSP\",\"TU\",\"ITC\",\"BTG\",\"ICHI\",\"M\",\"TFG\",\"COCOCO\",\"SAPPE\",\"SNNP\"],\n",
        "    # \"Commerce\": [\"BJC\",\"COM7\",\"CPALL\",\"CRC\",\"HMPRO\",\"GLOBAL\",\"DOHOME\",\"MEGA\",\"MOSHI\"],\n",
        "    # \"Property_Development\": [\"AWC\",\"CPN\",\"LH\",\"WHA\",\"AMATA\",\"AP\",\"MBK\",\"QH\",\"SIRI\",\"SPALI\",\"ROJNA\"],\n",
        "    # \"Health_Care_Services\": [\"BDMS\",\"BH\",\"BCH\",\"CHG\"],       =>\n",
        "    # \"Electronic_Components\": [\"CCET\",\"DELTA\",\"HANA\",\"KCE\"],\n",
        "    # \"Construction_Materials\": [\"SCC\",\"TASCO\",\"TOA\"],\n",
        "    # \"ICT\": [\"ADVANC\",\"TRUE\",\"JAS\",\"JMART\",\"JTS\",\"SKY\"],\n",
        "    # \"Transportation_Logistics\": [\"AOT\",\"BEM\",\"BTS\",\"AAV\",\"BA\",\"RCL\"],     =>\n",
        "}\n",
        "\n",
        "df_stocks = pd.DataFrame()\n",
        "for sector, tickers in SECTORS.items():\n",
        "    for ticker in tickers:\n",
        "        try:\n",
        "            ticker_yf = ticker + \".BK\"\n",
        "            data = yf.download(ticker_yf, start=START, end=END, interval=\"1mo\")['Close']\n",
        "            if isinstance(data, pd.Series):\n",
        "                df_stocks[f\"Close_{ticker}\"] = data\n",
        "            else:\n",
        "                df_stocks[f\"Close_{ticker}\"] = data[ticker_yf]\n",
        "        except Exception:\n",
        "            df_stocks[f\"Close_{ticker}\"] = pd.Series(dtype=\"float64\")\n",
        "\n",
        "df_stocks = df_stocks.dropna(how=\"all\")\n",
        "\n",
        "if not df_stocks.empty:\n",
        "    quarterly_index = df_stocks.index\n",
        "else:\n",
        "    quarterly_index = pd.date_range(start=pd.to_datetime(START), end=pd.to_datetime(END), freq=\"QS\")\n",
        "\n",
        "# ================== 2) Align Macro ==================\n",
        "if not macro.index.is_unique:\n",
        "    macro = macro[~macro.index.duplicated(keep=\"last\")]\n",
        "\n",
        "macro_q = macro.reindex(quarterly_index, method=\"ffill\")\n",
        "\n",
        "# FX THB/USD\n",
        "fx_thb_usd = yf.download(\"THB=X\", start=START, end=END, interval=\"1mo\")[\"Close\"]\n",
        "fx_thb_usd.name = \"THB_per_USD\"\n",
        "\n",
        "# FX THB/CNY\n",
        "fx_thb_cny = yf.download(\"THBCNY=X\", start=START, end=END, interval=\"1mo\")[\"Close\"]\n",
        "fx_thb_cny.name = \"THB_per_CNY\"\n",
        "\n",
        "# Brent Oil (USD per barrel)\n",
        "brent_data = yf.download(\"BZ=F\", start=START, end=END, interval=\"1mo\")[\"Close\"]\n",
        "brent_data.name = \"Brent_Oil_USD_per_bbl\"\n",
        "\n",
        "# CRB Index\n",
        "crb_data = yf.download(\"^CRB\", start=START, end=END, interval=\"1mo\")[\"Close\"]\n",
        "crb_data.name = \"CRB_Index\"\n",
        "\n",
        "# S&P 500 Index\n",
        "sp500_data = yf.download(\"^GSPC\", start=START, end=END, interval=\"1mo\")[\"Close\"]\n",
        "sp500_data.name = \"SP500_Index\"\n",
        "\n",
        "# SET Index (Thailand)\n",
        "set_daily = yf.download(\"^SET.BK\", start=START, end=END, interval=\"1d\")[\"Close\"]\n",
        "\n",
        "# --- à¹€à¸¥à¸·à¸­à¸à¸£à¸²à¸„à¸²à¸›à¸´à¸”à¸‚à¸­à¸‡ \"à¸§à¸±à¸™à¹à¸£à¸à¸‚à¸­à¸‡à¹à¸•à¹ˆà¸¥à¸°à¹€à¸”à¸·à¸­à¸™\" ---\n",
        "set_monthly = set_daily.resample(\"MS\").first()\n",
        "set_monthly.name = \"SET_Index\"\n",
        "\n",
        "# ================== 4) Combine à¸«à¸¸à¹‰à¸™ + Macro ==================\n",
        "df = df_stocks.copy()\n",
        "if df.empty:\n",
        "    df = pd.DataFrame(index=quarterly_index)\n",
        "\n",
        "# Macro Variables\n",
        "if \"Inflation\" in macro_q.columns:\n",
        "    df[\"Inflation\"] = macro_q[\"Inflation\"] / 100.0\n",
        "if \"Inflation_Forecast\" in macro_q.columns:\n",
        "    df[\"Inflation_Forecast\"] = macro_q[\"Inflation_Forecast\"] / 100.0\n",
        "if \"IPI\" in macro_q.columns:\n",
        "    df[\"IPI\"] = macro_q[\"IPI\"] / 100.0\n",
        "if \"IPI_Forecast\" in macro_q.columns:\n",
        "    df[\"IPI_Forecast\"] = macro_q[\"IPI_Forecast\"] / 100.0\n",
        "\n",
        "# âœ… BroadMoney: à¹ƒà¸Šà¹‰à¸ªà¸¹à¸•à¸£ ln(S_t / S_{t-1}) à¹à¸¥à¸°à¹ƒà¸«à¹‰à¹à¸–à¸§à¹à¸£à¸à¹€à¸›à¹‡à¸™ 0\n",
        "if \"BroadMoney_M1M2_Level\" in macro_q.columns:\n",
        "    money_series = macro_q[\"BroadMoney_M1M2_Level\"]\n",
        "    money_growth = np.log(money_series / money_series.shift(1))\n",
        "    money_growth.iloc[0] = 0.0  # à¹à¸–à¸§à¹à¸£à¸à¹ƒà¸«à¹‰à¹€à¸›à¹‡à¸™ 0%\n",
        "    df[\"BroadMoney_M1M2_Growth\"] = money_growth\n",
        "\n",
        "# Interest Rates\n",
        "for col in [\"THOR_1M\", \"THOR_3M\", \"THOR_6M\",\n",
        "            \"Bond_Yield_1Y\", \"Bond_Yield_5Y\", \"Bond_Yield_10Y\",\n",
        "            \"Yield_Spread_10Y_5Y\", \"Yield_Spread_5Y_1Y\", \"Yield_Spread_10Y_1Y\"]:\n",
        "    if col in macro_q.columns:\n",
        "        df[col] = macro_q[col]\n",
        "\n",
        "# Combine Global Indicators\n",
        "df[\"THB_per_USD\"] = fx_thb_usd\n",
        "df[\"THB_per_CNY\"] = fx_thb_cny\n",
        "# df[\"Brent_Oil_USD_per_bbl\"] = brent_data\n",
        "df[\"CRB_Index\"] = crb_data\n",
        "df[\"SP500_Index\"] = sp500_data\n",
        "df[\"SET_Index\"] = set_monthly\n",
        "\n",
        "df['IPI_Surprise'] = df['IPI'] - df['IPI_Forecast']\n",
        "df['Inflation_Surprise'] = df['Inflation'] - df['Inflation_Forecast']\n",
        "df['5Y_1Y_Bond_Spread'] = df[\"Bond_Yield_5Y\"] - df[\"Bond_Yield_1Y\"]\n",
        "df['10Y_5Y_Bond_Spread'] = df[\"Bond_Yield_10Y\"] - df[\"Bond_Yield_5Y\"]\n",
        "df['3M_1M_THOR_Spread'] = df[\"THOR_3M\"] - df[\"THOR_1M\"]\n",
        "df['6M_1M_THOR_Spread'] = df[\"THOR_6M\"] - df[\"THOR_1M\"]\n",
        "\n",
        "\n",
        "\n",
        "# ================== 5) à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œ ==================\n",
        "df = df.iloc[25:]\n",
        "df.drop([\"CRB_Index\"], axis=1, inplace=True)\n",
        "\n",
        "print(df)\n",
        "print(\"\\n=== HEAD ===\")\n",
        "print(df.head(10))\n",
        "print(\"\\n=== TAIL ===\")\n",
        "print(df.tail(10))\n",
        "print(\"\\n=== COLUMNS ===\")\n",
        "print(df.columns.tolist())\n",
        "print(\"\\n=== NA COUNTS ===\")\n",
        "print(df.isna().sum())\n",
        "\n",
        "# (Optional) Save to CSV\n",
        "# df.to_csv(\"th_stock_macro_2013_today_quarterly.csv\", encoding=\"utf-8-sig\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSokRAAP4TTp",
        "outputId": "c00c7456-0a8d-49bb-97e9-946ff4f9df70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "ðŸ“Š BLOCK 1.5: Chow-Lin Temporal Disaggregation\n",
            "============================================================\n",
            "\n",
            "ðŸ“¥ Loading GDP Quarterly data...\n",
            "âœ… GDP Quarterly loaded: 51 quarters\n",
            "   Period: 2013-01 to 2025-07\n",
            "\n",
            "ðŸ“¥ Preparing IPI as high-frequency indicator...\n",
            "âœ… IPI Monthly loaded: 132 months\n",
            "   Period: 2015-02 to 2026-01\n",
            "\n",
            "ðŸ”„ Applying Chow-Lin disaggregation (GDP Quarterly â†’ Monthly)...\n",
            "âš ï¸ Warning: Not enough high-freq data. Need 129, have 128\n",
            "\n",
            "âœ… Chow-Lin disaggregation completed!\n",
            "   - Estimated AR(1) rho: 0.8322\n",
            "   - Monthly GDP observations: 129\n",
            "\n",
            "ðŸ” Validation: Aggregating monthly back to quarterly...\n",
            "âœ… Mean Aggregation Error: 1.868700%\n",
            "   (Should be ~0% if Chow-Lin is working correctly)\n",
            "\n",
            "ðŸ“Œ Adding GDP_Monthly and GDP_Growth to main dataframe...\n",
            "âœ… Added 'GDP_Monthly' and 'GDP_Growth' to df\n",
            "   df shape: (132, 37)\n",
            "\n",
            "ðŸ“Š GDP columns preview:\n",
            "             GDP_Monthly  GDP_Growth\n",
            "Date                                \n",
            "2025-04-01  1.566892e+06   -0.014493\n",
            "2025-05-01  1.536566e+06   -0.019544\n",
            "2025-06-01  1.521829e+06   -0.009637\n",
            "2025-07-01  1.522122e+06    0.000192\n",
            "2025-08-01  1.537391e+06    0.009982\n",
            "2025-09-01  1.543481e+06    0.003953\n",
            "2025-10-01  1.538713e+06   -0.003094\n",
            "2025-11-01  1.538713e+06   -0.003094\n",
            "2025-12-01  1.538713e+06   -0.003094\n",
            "2026-01-01  1.538713e+06   -0.003094\n",
            "\n",
            "============================================================\n",
            "âœ… BLOCK 1.5 COMPLETED: Chow-Lin Temporal Disaggregation\n",
            "============================================================\n",
            "\n",
            "Summary:\n",
            "- Input:  GDP Quarterly (Total_CUR) - 51 quarters\n",
            "- Output: GDP Monthly - 129 months\n",
            "- Indicator used: IPI (Industrial Production Index)\n",
            "- Method: Chow-Lin (1971) with AR(1) residual structure\n",
            "- Estimated rho: 0.8322\n",
            "\n",
            "New columns added to df:\n",
            "- 'GDP_Monthly': Monthly GDP level (Current Price, Mil THB)\n",
            "- 'GDP_Growth': Monthly GDP growth rate (Log %)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# ðŸ“Š BLOCK 1.5: Chow-Lin Temporal Disaggregation (GDP Quarterly â†’ Monthly)\n",
        "#    Reference: Chow & Lin (1971) - Best Linear Unbiased Interpolation\n",
        "#    Insert this block AFTER Block 1 (Data Collection) and BEFORE Block 2\n",
        "# ============================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import linalg\n",
        "\n",
        "# ================== 1) Chow-Lin Function ==================\n",
        "def chow_lin_disaggregate(y_low: pd.Series, X_high: pd.DataFrame,\n",
        "                          agg_method: str = 'sum', rho: float = None) -> tuple:\n",
        "    \"\"\"\n",
        "    Chow-Lin temporal disaggregation: à¹à¸›à¸¥à¸‡ Low-frequency â†’ High-frequency\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    y_low : pd.Series\n",
        "        Low-frequency series (e.g., Quarterly GDP) with DatetimeIndex\n",
        "    X_high : pd.DataFrame\n",
        "        High-frequency indicator(s) (e.g., Monthly IPI) with DatetimeIndex\n",
        "    agg_method : str\n",
        "        'sum' for flow variables (GDP), 'mean' for stock/average variables\n",
        "    rho : float or None\n",
        "        AR(1) autocorrelation parameter. If None, estimate from data.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    tuple: (pd.Series of monthly data, beta coefficients, estimated rho)\n",
        "    \"\"\"\n",
        "\n",
        "    # 1) Align data\n",
        "    y_low = y_low.dropna().copy()\n",
        "    X_high = X_high.dropna().copy()\n",
        "\n",
        "    # Determine frequency ratio (3 for Qâ†’M)\n",
        "    n_high_per_low = 3  # Monthly to Quarterly\n",
        "\n",
        "    # 2) Create date mapping\n",
        "    quarters = y_low.index\n",
        "    months = X_high.index\n",
        "\n",
        "    # Filter to overlapping period\n",
        "    min_date = max(quarters.min(), months.min().to_period('Q').to_timestamp())\n",
        "    max_date = min(quarters.max(), months.max().to_period('Q').to_timestamp())\n",
        "\n",
        "    y_low = y_low[(y_low.index >= min_date) & (y_low.index <= max_date)]\n",
        "\n",
        "    # Get monthly data for the period\n",
        "    month_start = y_low.index.min()\n",
        "    month_end = (y_low.index.max() + pd.offsets.QuarterEnd()).to_period('M').to_timestamp()\n",
        "\n",
        "    X_high = X_high[(X_high.index >= month_start) & (X_high.index <= month_end)]\n",
        "\n",
        "    n_low = len(y_low)\n",
        "    n_high = n_low * n_high_per_low\n",
        "\n",
        "    # Trim X_high to exact size\n",
        "    X_high = X_high.iloc[:n_high]\n",
        "\n",
        "    if len(X_high) < n_high:\n",
        "        print(f\"âš ï¸ Warning: Not enough high-freq data. Need {n_high}, have {len(X_high)}\")\n",
        "        # Pad with last value\n",
        "        pad_size = n_high - len(X_high)\n",
        "        last_idx = X_high.index[-1]\n",
        "        new_idx = pd.date_range(start=last_idx + pd.offsets.MonthBegin(), periods=pad_size, freq='MS')\n",
        "        pad_df = pd.DataFrame(index=new_idx, columns=X_high.columns)\n",
        "        for col in X_high.columns:\n",
        "            pad_df[col] = X_high[col].iloc[-1]\n",
        "        X_high = pd.concat([X_high, pad_df])\n",
        "\n",
        "    # 3) Build aggregation matrix C (n_low x n_high)\n",
        "    C = np.zeros((n_low, n_high))\n",
        "    for i in range(n_low):\n",
        "        start_col = i * n_high_per_low\n",
        "        end_col = start_col + n_high_per_low\n",
        "        if agg_method == 'sum':\n",
        "            C[i, start_col:end_col] = 1.0\n",
        "        elif agg_method == 'mean':\n",
        "            C[i, start_col:end_col] = 1.0 / n_high_per_low\n",
        "        else:  # 'last'\n",
        "            C[i, end_col - 1] = 1.0\n",
        "\n",
        "    # 4) Prepare X matrix (add constant)\n",
        "    X = X_high.values\n",
        "    if X.ndim == 1:\n",
        "        X = X.reshape(-1, 1)\n",
        "    X = np.column_stack([np.ones(n_high), X])  # Add intercept\n",
        "\n",
        "    # 5) Aggregate X to match y_low\n",
        "    X_low = C @ X\n",
        "    y = y_low.values.flatten()\n",
        "\n",
        "    # 6) OLS on aggregated data\n",
        "    beta_ols = np.linalg.lstsq(X_low, y, rcond=None)[0]\n",
        "    u_low = y - X_low @ beta_ols\n",
        "\n",
        "    # 7) Estimate rho (AR1 coefficient) if not provided\n",
        "    if rho is None:\n",
        "        if len(u_low) > 1:\n",
        "            rho = np.corrcoef(u_low[:-1], u_low[1:])[0, 1]\n",
        "            rho = np.clip(rho, -0.99, 0.99)\n",
        "        else:\n",
        "            rho = 0.0\n",
        "\n",
        "    # 8) Build covariance matrix V (AR1 structure)\n",
        "    V = np.zeros((n_high, n_high))\n",
        "    for i in range(n_high):\n",
        "        for j in range(n_high):\n",
        "            V[i, j] = rho ** abs(i - j)\n",
        "\n",
        "    # 9) GLS estimation\n",
        "    V_low = C @ V @ C.T\n",
        "    try:\n",
        "        V_low_inv = np.linalg.inv(V_low)\n",
        "    except np.linalg.LinAlgError:\n",
        "        V_low_inv = np.linalg.pinv(V_low)\n",
        "\n",
        "    XVX = X_low.T @ V_low_inv @ X_low\n",
        "    XVy = X_low.T @ V_low_inv @ y\n",
        "    try:\n",
        "        beta_gls = np.linalg.solve(XVX, XVy)\n",
        "    except np.linalg.LinAlgError:\n",
        "        beta_gls = np.linalg.lstsq(XVX, XVy, rcond=None)[0]\n",
        "\n",
        "    # 10) Preliminary high-frequency estimate\n",
        "    p_high = X @ beta_gls\n",
        "\n",
        "    # 11) Distribute residuals\n",
        "    u_low_gls = y - X_low @ beta_gls\n",
        "    VCt = V @ C.T\n",
        "    try:\n",
        "        dist_matrix = VCt @ np.linalg.inv(V_low)\n",
        "    except np.linalg.LinAlgError:\n",
        "        dist_matrix = VCt @ np.linalg.pinv(V_low)\n",
        "\n",
        "    # Final disaggregated series\n",
        "    y_high = p_high + dist_matrix @ u_low_gls\n",
        "\n",
        "    # 12) Create output Series\n",
        "    result = pd.Series(y_high, index=X_high.index, name=y_low.name or 'GDP_Monthly')\n",
        "\n",
        "    return result, beta_gls, rho\n",
        "\n",
        "\n",
        "# ================== 2) Load GDP Quarterly Data ==================\n",
        "print(\"=\"*60)\n",
        "print(\"ðŸ“Š BLOCK 1.5: Chow-Lin Temporal Disaggregation\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nðŸ“¥ Loading GDP Quarterly data...\")\n",
        "\n",
        "gdp_df = pd.read_excel(\"thai_gdp_quarterly_full.xlsx\", sheet_name=0)\n",
        "\n",
        "# Create proper datetime index\n",
        "quarter_map = {'Q1': '01', 'Q2': '04', 'Q3': '07', 'Q4': '10'}\n",
        "gdp_df['Date'] = gdp_df.apply(\n",
        "    lambda row: pd.Timestamp(f\"{row['Year']}-{quarter_map[row['Quarter']]}-01\"),\n",
        "    axis=1\n",
        ")\n",
        "gdp_df = gdp_df.set_index('Date').sort_index()\n",
        "\n",
        "# Use Total_CUR (Current Price GDP)\n",
        "gdp_quarterly = gdp_df['Total_CUR'].copy()\n",
        "gdp_quarterly.name = 'GDP_CUR'\n",
        "\n",
        "print(f\"âœ… GDP Quarterly loaded: {len(gdp_quarterly)} quarters\")\n",
        "print(f\"   Period: {gdp_quarterly.index.min().strftime('%Y-%m')} to {gdp_quarterly.index.max().strftime('%Y-%m')}\")\n",
        "\n",
        "\n",
        "# ================== 3) Prepare IPI as High-Frequency Indicator ==================\n",
        "print(\"\\nðŸ“¥ Preparing IPI as high-frequency indicator...\")\n",
        "\n",
        "# IPI should already be in 'df' from Block 1\n",
        "# If running standalone, load from Macro_data.xlsx\n",
        "if 'df' not in globals() or 'IPI' not in df.columns:\n",
        "    macro_temp = pd.read_excel(\"Macro_data.xlsx\", sheet_name=0)\n",
        "    macro_temp['Date'] = pd.to_datetime(macro_temp['Date'], dayfirst=True, errors='coerce')\n",
        "    macro_temp = macro_temp.set_index('Date').sort_index()\n",
        "    ipi_monthly = macro_temp['IPI_Actual'].dropna().copy()\n",
        "else:\n",
        "    ipi_monthly = df['IPI'].dropna().copy()\n",
        "\n",
        "ipi_monthly.name = 'IPI'\n",
        "\n",
        "# Convert to level if it's in growth rate form\n",
        "if ipi_monthly.abs().mean() < 1:  # It's in decimal/percentage\n",
        "    ipi_level = (1 + ipi_monthly).cumprod() * 100\n",
        "else:\n",
        "    ipi_level = ipi_monthly\n",
        "\n",
        "ipi_level.name = 'IPI_Level'\n",
        "\n",
        "print(f\"âœ… IPI Monthly loaded: {len(ipi_level)} months\")\n",
        "print(f\"   Period: {ipi_level.index.min().strftime('%Y-%m')} to {ipi_level.index.max().strftime('%Y-%m')}\")\n",
        "\n",
        "\n",
        "# ================== 4) Apply Chow-Lin Disaggregation ==================\n",
        "print(\"\\nðŸ”„ Applying Chow-Lin disaggregation (GDP Quarterly â†’ Monthly)...\")\n",
        "\n",
        "X_indicator = pd.DataFrame({'IPI': ipi_level})\n",
        "\n",
        "gdp_monthly, beta_chowlin, rho_chowlin = chow_lin_disaggregate(\n",
        "    y_low=gdp_quarterly,\n",
        "    X_high=X_indicator,\n",
        "    agg_method='sum',  # GDP is a flow variable\n",
        "    rho=None  # Auto-estimate\n",
        ")\n",
        "\n",
        "# Calculate GDP Growth Rate (Monthly, Log %)\n",
        "gdp_growth_monthly = np.log(gdp_monthly / gdp_monthly.shift(1))\n",
        "gdp_growth_monthly.name = 'GDP_Growth_Monthly'\n",
        "\n",
        "print(f\"\\nâœ… Chow-Lin disaggregation completed!\")\n",
        "print(f\"   - Estimated AR(1) rho: {rho_chowlin:.4f}\")\n",
        "print(f\"   - Monthly GDP observations: {len(gdp_monthly)}\")\n",
        "\n",
        "\n",
        "# ================== 5) Validation ==================\n",
        "print(\"\\nðŸ” Validation: Aggregating monthly back to quarterly...\")\n",
        "\n",
        "gdp_monthly_to_q = gdp_monthly.resample('QS').sum()\n",
        "validation = pd.DataFrame({\n",
        "    'Original_Q': gdp_quarterly,\n",
        "    'ChowLin_Agg_Q': gdp_monthly_to_q\n",
        "}).dropna()\n",
        "validation['Error_%'] = abs(validation['ChowLin_Agg_Q'] - validation['Original_Q']) / validation['Original_Q'] * 100\n",
        "\n",
        "print(f\"âœ… Mean Aggregation Error: {validation['Error_%'].mean():.6f}%\")\n",
        "print(\"   (Should be ~0% if Chow-Lin is working correctly)\")\n",
        "\n",
        "\n",
        "# ================== 6) Add to Main DataFrame ==================\n",
        "print(\"\\nðŸ“Œ Adding GDP_Monthly and GDP_Growth to main dataframe...\")\n",
        "\n",
        "# Reindex to match the main df index\n",
        "if 'df' in globals():\n",
        "    # Add GDP columns to df\n",
        "    df['GDP_Monthly'] = gdp_monthly.reindex(df.index)\n",
        "    df['GDP_Growth'] = gdp_growth_monthly.reindex(df.index)\n",
        "\n",
        "    # Forward fill any gaps (for dates where we have stock data but no GDP yet)\n",
        "    df['GDP_Monthly'] = df['GDP_Monthly'].ffill()\n",
        "    df['GDP_Growth'] = df['GDP_Growth'].ffill()\n",
        "\n",
        "    print(f\"âœ… Added 'GDP_Monthly' and 'GDP_Growth' to df\")\n",
        "    print(f\"   df shape: {df.shape}\")\n",
        "    print(f\"\\nðŸ“Š GDP columns preview:\")\n",
        "    print(df[['GDP_Monthly', 'GDP_Growth']].dropna().tail(10))\n",
        "else:\n",
        "    print(\"âš ï¸ Main dataframe 'df' not found. Creating standalone GDP dataframe...\")\n",
        "    gdp_output = pd.DataFrame({\n",
        "        'GDP_Monthly': gdp_monthly,\n",
        "        'GDP_Growth': gdp_growth_monthly\n",
        "    })\n",
        "    print(gdp_output.tail(10))\n",
        "\n",
        "\n",
        "# ================== 7) Summary ==================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"âœ… BLOCK 1.5 COMPLETED: Chow-Lin Temporal Disaggregation\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\"\"\n",
        "Summary:\n",
        "- Input:  GDP Quarterly (Total_CUR) - {len(gdp_quarterly)} quarters\n",
        "- Output: GDP Monthly - {len(gdp_monthly)} months\n",
        "- Indicator used: IPI (Industrial Production Index)\n",
        "- Method: Chow-Lin (1971) with AR(1) residual structure\n",
        "- Estimated rho: {rho_chowlin:.4f}\n",
        "\n",
        "New columns added to df:\n",
        "- 'GDP_Monthly': Monthly GDP level (Current Price, Mil THB)\n",
        "- 'GDP_Growth': Monthly GDP growth rate (Log %)\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kbl9fHdopGI_"
      },
      "source": [
        "**2 Data preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 832
        },
        "id": "ZXefL-WtoerI",
        "outputId": "5b35d5db-6125-4155-e690-ce927affa16f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Combined data shape: (118, 25)\n",
            "âœ… Stocks: 11 | Macros: 14\n",
            "âœ… Differenced data ready: (117, 47)\n",
            "\n",
            "=== Combined_dfs (Levels) ===\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-75848cbf-75c2-49b9-b251-b4031db143d8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Close_BBL</th>\n",
              "      <th>Close_KBANK</th>\n",
              "      <th>Close_KKP</th>\n",
              "      <th>Close_KTB</th>\n",
              "      <th>Close_TCAP</th>\n",
              "      <th>Close_TISCO</th>\n",
              "      <th>Close_TTB</th>\n",
              "      <th>Close_KTC</th>\n",
              "      <th>Close_AEONTS</th>\n",
              "      <th>Close_JMT</th>\n",
              "      <th>...</th>\n",
              "      <th>Logclose_KBANK</th>\n",
              "      <th>Logclose_KKP</th>\n",
              "      <th>Logclose_KTB</th>\n",
              "      <th>Logclose_TCAP</th>\n",
              "      <th>Logclose_TISCO</th>\n",
              "      <th>Logclose_TTB</th>\n",
              "      <th>Logclose_KTC</th>\n",
              "      <th>Logclose_AEONTS</th>\n",
              "      <th>Logclose_JMT</th>\n",
              "      <th>Logclose_SAWAD</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2016-04-01</th>\n",
              "      <td>111.808441</td>\n",
              "      <td>117.630341</td>\n",
              "      <td>21.347910</td>\n",
              "      <td>11.048728</td>\n",
              "      <td>17.233999</td>\n",
              "      <td>20.880671</td>\n",
              "      <td>1.363181</td>\n",
              "      <td>7.560795</td>\n",
              "      <td>68.491669</td>\n",
              "      <td>3.997082</td>\n",
              "      <td>...</td>\n",
              "      <td>4.767547</td>\n",
              "      <td>3.060954</td>\n",
              "      <td>2.402315</td>\n",
              "      <td>2.846884</td>\n",
              "      <td>3.038824</td>\n",
              "      <td>0.309821</td>\n",
              "      <td>2.022976</td>\n",
              "      <td>4.226712</td>\n",
              "      <td>1.385564</td>\n",
              "      <td>3.230630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-05-01</th>\n",
              "      <td>114.526146</td>\n",
              "      <td>125.922653</td>\n",
              "      <td>22.376720</td>\n",
              "      <td>10.796185</td>\n",
              "      <td>17.386007</td>\n",
              "      <td>21.757637</td>\n",
              "      <td>1.397547</td>\n",
              "      <td>7.273935</td>\n",
              "      <td>66.148521</td>\n",
              "      <td>3.582022</td>\n",
              "      <td>...</td>\n",
              "      <td>4.835668</td>\n",
              "      <td>3.108021</td>\n",
              "      <td>2.379193</td>\n",
              "      <td>2.855666</td>\n",
              "      <td>3.079965</td>\n",
              "      <td>0.334718</td>\n",
              "      <td>1.984297</td>\n",
              "      <td>4.191903</td>\n",
              "      <td>1.275927</td>\n",
              "      <td>3.236598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-06-01</th>\n",
              "      <td>111.023811</td>\n",
              "      <td>123.027908</td>\n",
              "      <td>23.455124</td>\n",
              "      <td>10.761127</td>\n",
              "      <td>17.897360</td>\n",
              "      <td>25.046576</td>\n",
              "      <td>1.323992</td>\n",
              "      <td>8.134515</td>\n",
              "      <td>70.771049</td>\n",
              "      <td>4.203393</td>\n",
              "      <td>...</td>\n",
              "      <td>4.812411</td>\n",
              "      <td>3.155089</td>\n",
              "      <td>2.375940</td>\n",
              "      <td>2.884653</td>\n",
              "      <td>3.220737</td>\n",
              "      <td>0.280651</td>\n",
              "      <td>2.096116</td>\n",
              "      <td>4.259450</td>\n",
              "      <td>1.435892</td>\n",
              "      <td>3.124680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-07-01</th>\n",
              "      <td>119.429390</td>\n",
              "      <td>142.929504</td>\n",
              "      <td>28.307909</td>\n",
              "      <td>11.487339</td>\n",
              "      <td>20.837645</td>\n",
              "      <td>27.323536</td>\n",
              "      <td>1.385288</td>\n",
              "      <td>10.040080</td>\n",
              "      <td>73.528366</td>\n",
              "      <td>5.117174</td>\n",
              "      <td>...</td>\n",
              "      <td>4.962352</td>\n",
              "      <td>3.343141</td>\n",
              "      <td>2.441245</td>\n",
              "      <td>3.036761</td>\n",
              "      <td>3.307748</td>\n",
              "      <td>0.325908</td>\n",
              "      <td>2.306585</td>\n",
              "      <td>4.297671</td>\n",
              "      <td>1.632602</td>\n",
              "      <td>3.137752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-08-01</th>\n",
              "      <td>118.728935</td>\n",
              "      <td>142.929504</td>\n",
              "      <td>27.903509</td>\n",
              "      <td>12.543647</td>\n",
              "      <td>20.454126</td>\n",
              "      <td>27.323536</td>\n",
              "      <td>1.385288</td>\n",
              "      <td>11.392418</td>\n",
              "      <td>72.609253</td>\n",
              "      <td>5.336482</td>\n",
              "      <td>...</td>\n",
              "      <td>4.962352</td>\n",
              "      <td>3.328752</td>\n",
              "      <td>2.529214</td>\n",
              "      <td>3.018185</td>\n",
              "      <td>3.307748</td>\n",
              "      <td>0.325908</td>\n",
              "      <td>2.432948</td>\n",
              "      <td>4.285092</td>\n",
              "      <td>1.674567</td>\n",
              "      <td>3.163394</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 36 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75848cbf-75c2-49b9-b251-b4031db143d8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-75848cbf-75c2-49b9-b251-b4031db143d8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-75848cbf-75c2-49b9-b251-b4031db143d8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "             Close_BBL  Close_KBANK  Close_KKP  Close_KTB  Close_TCAP  \\\n",
              "Date                                                                    \n",
              "2016-04-01  111.808441   117.630341  21.347910  11.048728   17.233999   \n",
              "2016-05-01  114.526146   125.922653  22.376720  10.796185   17.386007   \n",
              "2016-06-01  111.023811   123.027908  23.455124  10.761127   17.897360   \n",
              "2016-07-01  119.429390   142.929504  28.307909  11.487339   20.837645   \n",
              "2016-08-01  118.728935   142.929504  27.903509  12.543647   20.454126   \n",
              "\n",
              "            Close_TISCO  Close_TTB  Close_KTC  Close_AEONTS  Close_JMT  ...  \\\n",
              "Date                                                                    ...   \n",
              "2016-04-01    20.880671   1.363181   7.560795     68.491669   3.997082  ...   \n",
              "2016-05-01    21.757637   1.397547   7.273935     66.148521   3.582022  ...   \n",
              "2016-06-01    25.046576   1.323992   8.134515     70.771049   4.203393  ...   \n",
              "2016-07-01    27.323536   1.385288  10.040080     73.528366   5.117174  ...   \n",
              "2016-08-01    27.323536   1.385288  11.392418     72.609253   5.336482  ...   \n",
              "\n",
              "            Logclose_KBANK  Logclose_KKP  Logclose_KTB  Logclose_TCAP  \\\n",
              "Date                                                                    \n",
              "2016-04-01        4.767547      3.060954      2.402315       2.846884   \n",
              "2016-05-01        4.835668      3.108021      2.379193       2.855666   \n",
              "2016-06-01        4.812411      3.155089      2.375940       2.884653   \n",
              "2016-07-01        4.962352      3.343141      2.441245       3.036761   \n",
              "2016-08-01        4.962352      3.328752      2.529214       3.018185   \n",
              "\n",
              "            Logclose_TISCO  Logclose_TTB  Logclose_KTC  Logclose_AEONTS  \\\n",
              "Date                                                                      \n",
              "2016-04-01        3.038824      0.309821      2.022976         4.226712   \n",
              "2016-05-01        3.079965      0.334718      1.984297         4.191903   \n",
              "2016-06-01        3.220737      0.280651      2.096116         4.259450   \n",
              "2016-07-01        3.307748      0.325908      2.306585         4.297671   \n",
              "2016-08-01        3.307748      0.325908      2.432948         4.285092   \n",
              "\n",
              "            Logclose_JMT  Logclose_SAWAD  \n",
              "Date                                      \n",
              "2016-04-01      1.385564        3.230630  \n",
              "2016-05-01      1.275927        3.236598  \n",
              "2016-06-01      1.435892        3.124680  \n",
              "2016-07-01      1.632602        3.137752  \n",
              "2016-08-01      1.674567        3.163394  \n",
              "\n",
              "[5 rows x 36 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Combined_dfs_diff (Differenced) ===\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-c992f9c0-6d26-4464-9011-e0a6997659b5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Close_BBL</th>\n",
              "      <th>Close_KBANK</th>\n",
              "      <th>Close_KKP</th>\n",
              "      <th>Close_KTB</th>\n",
              "      <th>Close_TCAP</th>\n",
              "      <th>Close_TISCO</th>\n",
              "      <th>Close_TTB</th>\n",
              "      <th>Close_KTC</th>\n",
              "      <th>Close_AEONTS</th>\n",
              "      <th>Close_JMT</th>\n",
              "      <th>...</th>\n",
              "      <th>D_Logclose_KBANK</th>\n",
              "      <th>D_Logclose_KKP</th>\n",
              "      <th>D_Logclose_KTB</th>\n",
              "      <th>D_Logclose_TCAP</th>\n",
              "      <th>D_Logclose_TISCO</th>\n",
              "      <th>D_Logclose_TTB</th>\n",
              "      <th>D_Logclose_KTC</th>\n",
              "      <th>D_Logclose_AEONTS</th>\n",
              "      <th>D_Logclose_JMT</th>\n",
              "      <th>D_Logclose_SAWAD</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2016-05-01</th>\n",
              "      <td>114.526146</td>\n",
              "      <td>125.922653</td>\n",
              "      <td>22.376720</td>\n",
              "      <td>10.796185</td>\n",
              "      <td>17.386007</td>\n",
              "      <td>21.757637</td>\n",
              "      <td>1.397547</td>\n",
              "      <td>7.273935</td>\n",
              "      <td>66.148521</td>\n",
              "      <td>3.582022</td>\n",
              "      <td>...</td>\n",
              "      <td>0.068121</td>\n",
              "      <td>0.047067</td>\n",
              "      <td>-0.023122</td>\n",
              "      <td>0.008782</td>\n",
              "      <td>0.041141</td>\n",
              "      <td>0.024898</td>\n",
              "      <td>-0.038679</td>\n",
              "      <td>-0.034810</td>\n",
              "      <td>-0.109637</td>\n",
              "      <td>0.005968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-06-01</th>\n",
              "      <td>111.023811</td>\n",
              "      <td>123.027908</td>\n",
              "      <td>23.455124</td>\n",
              "      <td>10.761127</td>\n",
              "      <td>17.897360</td>\n",
              "      <td>25.046576</td>\n",
              "      <td>1.323992</td>\n",
              "      <td>8.134515</td>\n",
              "      <td>70.771049</td>\n",
              "      <td>4.203393</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.023257</td>\n",
              "      <td>0.047068</td>\n",
              "      <td>-0.003253</td>\n",
              "      <td>0.028988</td>\n",
              "      <td>0.140772</td>\n",
              "      <td>-0.054067</td>\n",
              "      <td>0.111819</td>\n",
              "      <td>0.067547</td>\n",
              "      <td>0.159965</td>\n",
              "      <td>-0.111918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-07-01</th>\n",
              "      <td>119.429390</td>\n",
              "      <td>142.929504</td>\n",
              "      <td>28.307909</td>\n",
              "      <td>11.487339</td>\n",
              "      <td>20.837645</td>\n",
              "      <td>27.323536</td>\n",
              "      <td>1.385288</td>\n",
              "      <td>10.040080</td>\n",
              "      <td>73.528366</td>\n",
              "      <td>5.117174</td>\n",
              "      <td>...</td>\n",
              "      <td>0.149940</td>\n",
              "      <td>0.188052</td>\n",
              "      <td>0.065305</td>\n",
              "      <td>0.152108</td>\n",
              "      <td>0.087011</td>\n",
              "      <td>0.045257</td>\n",
              "      <td>0.210469</td>\n",
              "      <td>0.038221</td>\n",
              "      <td>0.196710</td>\n",
              "      <td>0.013072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-08-01</th>\n",
              "      <td>118.728935</td>\n",
              "      <td>142.929504</td>\n",
              "      <td>27.903509</td>\n",
              "      <td>12.543647</td>\n",
              "      <td>20.454126</td>\n",
              "      <td>27.323536</td>\n",
              "      <td>1.385288</td>\n",
              "      <td>11.392418</td>\n",
              "      <td>72.609253</td>\n",
              "      <td>5.336482</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.014389</td>\n",
              "      <td>0.087969</td>\n",
              "      <td>-0.018577</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.126363</td>\n",
              "      <td>-0.012579</td>\n",
              "      <td>0.041964</td>\n",
              "      <td>0.025642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-09-01</th>\n",
              "      <td>113.825684</td>\n",
              "      <td>135.692520</td>\n",
              "      <td>28.577501</td>\n",
              "      <td>11.619377</td>\n",
              "      <td>20.709803</td>\n",
              "      <td>26.564548</td>\n",
              "      <td>1.299473</td>\n",
              "      <td>12.089076</td>\n",
              "      <td>73.344536</td>\n",
              "      <td>5.117174</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.051960</td>\n",
              "      <td>0.023867</td>\n",
              "      <td>-0.076540</td>\n",
              "      <td>0.012423</td>\n",
              "      <td>-0.028171</td>\n",
              "      <td>-0.063949</td>\n",
              "      <td>0.059354</td>\n",
              "      <td>0.010076</td>\n",
              "      <td>-0.041964</td>\n",
              "      <td>-0.092782</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 47 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c992f9c0-6d26-4464-9011-e0a6997659b5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c992f9c0-6d26-4464-9011-e0a6997659b5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c992f9c0-6d26-4464-9011-e0a6997659b5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "             Close_BBL  Close_KBANK  Close_KKP  Close_KTB  Close_TCAP  \\\n",
              "Date                                                                    \n",
              "2016-05-01  114.526146   125.922653  22.376720  10.796185   17.386007   \n",
              "2016-06-01  111.023811   123.027908  23.455124  10.761127   17.897360   \n",
              "2016-07-01  119.429390   142.929504  28.307909  11.487339   20.837645   \n",
              "2016-08-01  118.728935   142.929504  27.903509  12.543647   20.454126   \n",
              "2016-09-01  113.825684   135.692520  28.577501  11.619377   20.709803   \n",
              "\n",
              "            Close_TISCO  Close_TTB  Close_KTC  Close_AEONTS  Close_JMT  ...  \\\n",
              "Date                                                                    ...   \n",
              "2016-05-01    21.757637   1.397547   7.273935     66.148521   3.582022  ...   \n",
              "2016-06-01    25.046576   1.323992   8.134515     70.771049   4.203393  ...   \n",
              "2016-07-01    27.323536   1.385288  10.040080     73.528366   5.117174  ...   \n",
              "2016-08-01    27.323536   1.385288  11.392418     72.609253   5.336482  ...   \n",
              "2016-09-01    26.564548   1.299473  12.089076     73.344536   5.117174  ...   \n",
              "\n",
              "            D_Logclose_KBANK  D_Logclose_KKP  D_Logclose_KTB  D_Logclose_TCAP  \\\n",
              "Date                                                                            \n",
              "2016-05-01          0.068121        0.047067       -0.023122         0.008782   \n",
              "2016-06-01         -0.023257        0.047068       -0.003253         0.028988   \n",
              "2016-07-01          0.149940        0.188052        0.065305         0.152108   \n",
              "2016-08-01          0.000000       -0.014389        0.087969        -0.018577   \n",
              "2016-09-01         -0.051960        0.023867       -0.076540         0.012423   \n",
              "\n",
              "            D_Logclose_TISCO  D_Logclose_TTB  D_Logclose_KTC  \\\n",
              "Date                                                           \n",
              "2016-05-01          0.041141        0.024898       -0.038679   \n",
              "2016-06-01          0.140772       -0.054067        0.111819   \n",
              "2016-07-01          0.087011        0.045257        0.210469   \n",
              "2016-08-01          0.000000        0.000000        0.126363   \n",
              "2016-09-01         -0.028171       -0.063949        0.059354   \n",
              "\n",
              "            D_Logclose_AEONTS  D_Logclose_JMT  D_Logclose_SAWAD  \n",
              "Date                                                             \n",
              "2016-05-01          -0.034810       -0.109637          0.005968  \n",
              "2016-06-01           0.067547        0.159965         -0.111918  \n",
              "2016-07-01           0.038221        0.196710          0.013072  \n",
              "2016-08-01          -0.012579        0.041964          0.025642  \n",
              "2016-09-01           0.010076       -0.041964         -0.092782  \n",
              "\n",
              "[5 rows x 47 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# =====================================================\n",
        "# âš™ï¸ BLOCK 2: Prepare Combined Data (No PCA, No LASSO)\n",
        "# =====================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ======== 1) Filter & split ========\n",
        "df_filtered = df.iloc[14:].copy()  # à¸•à¸±à¸”à¸Šà¹ˆà¸§à¸‡à¹à¸£à¸à¸—à¸µà¹ˆ NA à¹€à¸¢à¸­à¸°\n",
        "\n",
        "# à¹€à¸¥à¸·à¸­à¸à¸«à¸¸à¹‰à¸™ (à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡ 8 à¸•à¸±à¸§à¹à¸£à¸)\n",
        "stock_columns = [c for c in df_filtered.columns if c.startswith(\"Close_\")]\n",
        "selected_stock_data = df_filtered[stock_columns]\n",
        "\n",
        "# à¹€à¸¥à¸·à¸­à¸à¸•à¸±à¸§à¹à¸›à¸£ macro à¸—à¸µà¹ˆà¸¡à¸µà¸­à¸¢à¸¹à¹ˆà¸ˆà¸£à¸´à¸‡\n",
        "macro_columns = [\n",
        "    \"BroadMoney_M1M2_Growth\",\n",
        "    \"Inflation_Surprise\",\n",
        "    \"IPI_Surprise\",\n",
        "    \"THOR_1M\",\n",
        "    \"THOR_6M\",\n",
        "    \"3M_1M_THOR_Spread\",\n",
        "    \"6M_1M_THOR_Spread\",\n",
        "    \"5Y_1Y_Bond_Spread\",\n",
        "    \"10Y_5Y_Bond_Spread\",\n",
        "    \"THB_per_USD\",\n",
        "    # \"Brent_Oil_USD_per_bbl\",\n",
        "    \"SP500_Index\",\n",
        "    \"SET_Index\",\n",
        "    \"THB_per_CNY\",\n",
        "    \"GDP_Growth\"\n",
        "]\n",
        "macro_columns = [c for c in macro_columns if c in df_filtered.columns]\n",
        "selected_macro_data = df_filtered[macro_columns]\n",
        "\n",
        "# ======== 2) Combine + clean ========\n",
        "combined_df = pd.concat([selected_stock_data, selected_macro_data], axis=1)\n",
        "combined_df = combined_df.ffill().replace([np.inf, -np.inf], np.nan).dropna(how=\"any\")\n",
        "\n",
        "print(\"âœ… Combined data shape:\", combined_df.shape)\n",
        "print(\"âœ… Stocks:\", len(stock_columns), \"| Macros:\", len(macro_columns))\n",
        "\n",
        "# ======== 3) Log-transform à¸«à¸¸à¹‰à¸™à¹à¸¥à¸°à¸ªà¸£à¹‰à¸²à¸‡ Î”log ========\n",
        "combined_dfs = combined_df.copy()\n",
        "for c in stock_columns:\n",
        "    combined_dfs[f\"Logclose_{c.replace('Close_','')}\"] = np.log(combined_df[c])\n",
        "\n",
        "combined_dfs_diff = combined_dfs.copy()\n",
        "for c in stock_columns:\n",
        "    stock_name = c.replace(\"Close_\",\"\")\n",
        "    combined_dfs_diff[f\"D_Logclose_{stock_name}\"] = combined_dfs[f\"Logclose_{stock_name}\"].diff()\n",
        "\n",
        "# ======== 4) Drop à¹à¸–à¸§à¹à¸£à¸à¸‚à¸­à¸‡ differenced ========\n",
        "combined_dfs_diff = combined_dfs_diff.dropna()\n",
        "\n",
        "print(\"âœ… Differenced data ready:\", combined_dfs_diff.shape)\n",
        "\n",
        "# ======== 5) à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œ ========\n",
        "print(\"\\n=== Combined_dfs (Levels) ===\")\n",
        "display(combined_dfs.head())\n",
        "\n",
        "print(\"\\n=== Combined_dfs_diff (Differenced) ===\")\n",
        "display(combined_dfs_diff.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "id": "mSL8-kKqouv3",
        "outputId": "25d5e478-e0d2-46ab-de77-48960f31b5cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ“Š Combined data for sector: Banking\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-d14dfa51-0855-4808-b570-03604d15db6d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Logclose_BBL</th>\n",
              "      <th>Logclose_KBANK</th>\n",
              "      <th>Logclose_KKP</th>\n",
              "      <th>Logclose_KTB</th>\n",
              "      <th>Logclose_TCAP</th>\n",
              "      <th>Logclose_TISCO</th>\n",
              "      <th>Logclose_TTB</th>\n",
              "      <th>BroadMoney_M1M2_Growth</th>\n",
              "      <th>Inflation_Surprise</th>\n",
              "      <th>IPI_Surprise</th>\n",
              "      <th>...</th>\n",
              "      <th>THOR_6M</th>\n",
              "      <th>3M_1M_THOR_Spread</th>\n",
              "      <th>6M_1M_THOR_Spread</th>\n",
              "      <th>5Y_1Y_Bond_Spread</th>\n",
              "      <th>10Y_5Y_Bond_Spread</th>\n",
              "      <th>THB_per_USD</th>\n",
              "      <th>SP500_Index</th>\n",
              "      <th>SET_Index</th>\n",
              "      <th>THB_per_CNY</th>\n",
              "      <th>GDP_Growth</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2015-02-01</th>\n",
              "      <td>4.790190</td>\n",
              "      <td>5.017582</td>\n",
              "      <td>2.939447</td>\n",
              "      <td>2.627824</td>\n",
              "      <td>2.802560</td>\n",
              "      <td>3.072488</td>\n",
              "      <td>0.569241</td>\n",
              "      <td>0.009765</td>\n",
              "      <td>-0.0066</td>\n",
              "      <td>-0.000066</td>\n",
              "      <td>...</td>\n",
              "      <td>0.020023</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000068</td>\n",
              "      <td>0.0035</td>\n",
              "      <td>0.0056</td>\n",
              "      <td>32.341000</td>\n",
              "      <td>2104.500000</td>\n",
              "      <td>1582.699951</td>\n",
              "      <td>0.19335</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-03-01</th>\n",
              "      <td>4.798353</td>\n",
              "      <td>5.071406</td>\n",
              "      <td>2.933057</td>\n",
              "      <td>2.627824</td>\n",
              "      <td>2.795391</td>\n",
              "      <td>3.045532</td>\n",
              "      <td>0.555908</td>\n",
              "      <td>0.004617</td>\n",
              "      <td>-0.0019</td>\n",
              "      <td>0.000380</td>\n",
              "      <td>...</td>\n",
              "      <td>0.020019</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000077</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0058</td>\n",
              "      <td>32.540001</td>\n",
              "      <td>2067.889893</td>\n",
              "      <td>1582.140015</td>\n",
              "      <td>0.19040</td>\n",
              "      <td>-0.020455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-04-01</th>\n",
              "      <td>4.801060</td>\n",
              "      <td>4.984792</td>\n",
              "      <td>2.880413</td>\n",
              "      <td>2.496796</td>\n",
              "      <td>2.773572</td>\n",
              "      <td>3.034543</td>\n",
              "      <td>0.419496</td>\n",
              "      <td>-0.001550</td>\n",
              "      <td>-0.0012</td>\n",
              "      <td>-0.000670</td>\n",
              "      <td>...</td>\n",
              "      <td>0.019729</td>\n",
              "      <td>0.001167</td>\n",
              "      <td>0.001528</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0051</td>\n",
              "      <td>32.838001</td>\n",
              "      <td>2085.510010</td>\n",
              "      <td>1525.579956</td>\n",
              "      <td>0.18827</td>\n",
              "      <td>-0.015059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-05-01</th>\n",
              "      <td>4.808427</td>\n",
              "      <td>4.925754</td>\n",
              "      <td>2.888474</td>\n",
              "      <td>2.436026</td>\n",
              "      <td>2.810098</td>\n",
              "      <td>3.072725</td>\n",
              "      <td>0.417810</td>\n",
              "      <td>0.001422</td>\n",
              "      <td>-0.0024</td>\n",
              "      <td>-0.000330</td>\n",
              "      <td>...</td>\n",
              "      <td>0.019148</td>\n",
              "      <td>0.001280</td>\n",
              "      <td>0.002220</td>\n",
              "      <td>0.0042</td>\n",
              "      <td>0.0078</td>\n",
              "      <td>33.734001</td>\n",
              "      <td>2107.389893</td>\n",
              "      <td>1519.880005</td>\n",
              "      <td>0.18351</td>\n",
              "      <td>-0.011596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-06-01</th>\n",
              "      <td>4.786204</td>\n",
              "      <td>4.894501</td>\n",
              "      <td>2.867421</td>\n",
              "      <td>2.379193</td>\n",
              "      <td>2.780466</td>\n",
              "      <td>3.094704</td>\n",
              "      <td>0.335797</td>\n",
              "      <td>-0.005075</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.000280</td>\n",
              "      <td>...</td>\n",
              "      <td>0.018408</td>\n",
              "      <td>0.001854</td>\n",
              "      <td>0.003469</td>\n",
              "      <td>0.0056</td>\n",
              "      <td>0.0082</td>\n",
              "      <td>33.729000</td>\n",
              "      <td>2063.110107</td>\n",
              "      <td>1476.869995</td>\n",
              "      <td>0.18359</td>\n",
              "      <td>-0.002867</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d14dfa51-0855-4808-b570-03604d15db6d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d14dfa51-0855-4808-b570-03604d15db6d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d14dfa51-0855-4808-b570-03604d15db6d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "            Logclose_BBL  Logclose_KBANK  Logclose_KKP  Logclose_KTB  \\\n",
              "Date                                                                   \n",
              "2015-02-01      4.790190        5.017582      2.939447      2.627824   \n",
              "2015-03-01      4.798353        5.071406      2.933057      2.627824   \n",
              "2015-04-01      4.801060        4.984792      2.880413      2.496796   \n",
              "2015-05-01      4.808427        4.925754      2.888474      2.436026   \n",
              "2015-06-01      4.786204        4.894501      2.867421      2.379193   \n",
              "\n",
              "            Logclose_TCAP  Logclose_TISCO  Logclose_TTB  \\\n",
              "Date                                                      \n",
              "2015-02-01       2.802560        3.072488      0.569241   \n",
              "2015-03-01       2.795391        3.045532      0.555908   \n",
              "2015-04-01       2.773572        3.034543      0.419496   \n",
              "2015-05-01       2.810098        3.072725      0.417810   \n",
              "2015-06-01       2.780466        3.094704      0.335797   \n",
              "\n",
              "            BroadMoney_M1M2_Growth  Inflation_Surprise  IPI_Surprise  ...  \\\n",
              "Date                                                                  ...   \n",
              "2015-02-01                0.009765             -0.0066     -0.000066  ...   \n",
              "2015-03-01                0.004617             -0.0019      0.000380  ...   \n",
              "2015-04-01               -0.001550             -0.0012     -0.000670  ...   \n",
              "2015-05-01                0.001422             -0.0024     -0.000330  ...   \n",
              "2015-06-01               -0.005075             -0.0015     -0.000280  ...   \n",
              "\n",
              "             THOR_6M  3M_1M_THOR_Spread  6M_1M_THOR_Spread  5Y_1Y_Bond_Spread  \\\n",
              "Date                                                                            \n",
              "2015-02-01  0.020023           0.000015           0.000068             0.0035   \n",
              "2015-03-01  0.020019           0.000032           0.000077             0.0045   \n",
              "2015-04-01  0.019729           0.001167           0.001528             0.0048   \n",
              "2015-05-01  0.019148           0.001280           0.002220             0.0042   \n",
              "2015-06-01  0.018408           0.001854           0.003469             0.0056   \n",
              "\n",
              "            10Y_5Y_Bond_Spread  THB_per_USD  SP500_Index    SET_Index  \\\n",
              "Date                                                                    \n",
              "2015-02-01              0.0056    32.341000  2104.500000  1582.699951   \n",
              "2015-03-01              0.0058    32.540001  2067.889893  1582.140015   \n",
              "2015-04-01              0.0051    32.838001  2085.510010  1525.579956   \n",
              "2015-05-01              0.0078    33.734001  2107.389893  1519.880005   \n",
              "2015-06-01              0.0082    33.729000  2063.110107  1476.869995   \n",
              "\n",
              "            THB_per_CNY  GDP_Growth  \n",
              "Date                                 \n",
              "2015-02-01      0.19335         NaN  \n",
              "2015-03-01      0.19040   -0.020455  \n",
              "2015-04-01      0.18827   -0.015059  \n",
              "2015-05-01      0.18351   -0.011596  \n",
              "2015-06-01      0.18359   -0.002867  \n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ“Š Combined data for sector: Finance_Securities\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"    display(combined_df[cols_to_show_present]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2015-02-01 00:00:00\",\n        \"max\": \"2015-06-01 00:00:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2015-03-01 00:00:00\",\n          \"2015-06-01 00:00:00\",\n          \"2015-04-01 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_KTC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07740740011302624,\n        \"min\": 1.9111733702322047,\n        \"max\": 2.1237293935939574,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2.0324205910192723,\n          2.047805493644061,\n          2.1237293935939574\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_AEONTS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.051637434281402196,\n        \"min\": 4.201525738501825,\n        \"max\": 4.32411133414361,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4.281752036498539,\n          4.201525738501825,\n          4.2524818180788335\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_JMT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09908742266611925,\n        \"min\": 1.7129867522923479,\n        \"max\": 1.979025873221527,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.9144873169369114,\n          1.7129867522923479,\n          1.8978208090830728\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_SAWAD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.037914055567284714,\n        \"min\": 3.1060198061570525,\n        \"max\": 3.2000023952507157,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3.1060198061570525,\n          3.151212227193906,\n          3.1939603767065883\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BroadMoney_M1M2_Growth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005700984043555338,\n        \"min\": -0.005074892972240728,\n        \"max\": 0.009765467965924778,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.004616556335225512,\n          -0.005074892972240728,\n          -0.0015500193021271292\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Inflation_Surprise\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.002215174936658503,\n        \"min\": -0.0066,\n        \"max\": -0.0011999999999999988,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.0018999999999999998,\n          -0.0014999999999999979,\n          -0.0011999999999999988\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IPI_Surprise\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00038675728823126264,\n        \"min\": -0.00067,\n        \"max\": 0.00037999999999999997,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.00037999999999999997,\n          -0.0002799999999999999,\n          -0.00067\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"THOR_1M\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.002129944855624201,\n        \"min\": 0.0149395,\n        \"max\": 0.0199545,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.0199419,\n          0.0149395,\n          0.018201099999999998\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"THOR_6M\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0006903075669583813,\n        \"min\": 0.018408,\n        \"max\": 0.020023,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.020019300000000004,\n          0.018408,\n          0.0197291\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"3M_1M_THOR_Spread\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0008153057475573194,\n        \"min\": 1.5000000000001124e-05,\n        \"max\": 0.001854200000000002,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3.170000000000256e-05,\n          0.001854200000000002,\n          0.0011670000000000014\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"6M_1M_THOR_Spread\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0014545681087525597,\n        \"min\": 6.849999999999912e-05,\n        \"max\": 0.003468500000000001,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7.740000000000524e-05,\n          0.003468500000000001,\n          0.0015280000000000016\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"5Y_1Y_Bond_Spread\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0007726577508832749,\n        \"min\": 0.0034999999999999996,\n        \"max\": 0.005600000000000001,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.0045000000000000005,\n          0.005600000000000001,\n          0.0048000000000000004\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"10Y_5Y_Bond_Spread\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0013999999999999998,\n        \"min\": 0.0051,\n        \"max\": 0.008199999999999999,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.0058,\n          0.008199999999999999,\n          0.0051\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"THB_per_USD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6587294761773956,\n        \"min\": 32.340999603271484,\n        \"max\": 33.73400115966797,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          32.540000915527344,\n          33.729000091552734,\n          32.8380012512207\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SP500_Index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20.318887183489874,\n        \"min\": 2063.110107421875,\n        \"max\": 2107.389892578125,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2067.889892578125,\n          2063.110107421875,\n          2085.510009765625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SET_Index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 45.17824108770902,\n        \"min\": 1476.8699951171875,\n        \"max\": 1582.699951171875,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1582.1400146484375,\n          1476.8699951171875,\n          1525.5799560546875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"THB_per_CNY\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.004298510346507137,\n        \"min\": 0.18351000547409058,\n        \"max\": 0.19335000216960907,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.19040000438690186,\n          0.18358999490737915,\n          0.18827000260353088\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GDP_Growth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007381267122894923,\n        \"min\": -0.020455447676879235,\n        \"max\": -0.002867079683681288,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -0.015059346674021852,\n          -0.002867079683681288,\n          -0.020455447676879235\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-229d557f-c0ca-443d-bf6b-d360a98e4959\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Logclose_KTC</th>\n",
              "      <th>Logclose_AEONTS</th>\n",
              "      <th>Logclose_JMT</th>\n",
              "      <th>Logclose_SAWAD</th>\n",
              "      <th>BroadMoney_M1M2_Growth</th>\n",
              "      <th>Inflation_Surprise</th>\n",
              "      <th>IPI_Surprise</th>\n",
              "      <th>THOR_1M</th>\n",
              "      <th>THOR_6M</th>\n",
              "      <th>3M_1M_THOR_Spread</th>\n",
              "      <th>6M_1M_THOR_Spread</th>\n",
              "      <th>5Y_1Y_Bond_Spread</th>\n",
              "      <th>10Y_5Y_Bond_Spread</th>\n",
              "      <th>THB_per_USD</th>\n",
              "      <th>SP500_Index</th>\n",
              "      <th>SET_Index</th>\n",
              "      <th>THB_per_CNY</th>\n",
              "      <th>GDP_Growth</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2015-02-01</th>\n",
              "      <td>1.911173</td>\n",
              "      <td>4.324111</td>\n",
              "      <td>1.979026</td>\n",
              "      <td>3.156030</td>\n",
              "      <td>0.009765</td>\n",
              "      <td>-0.0066</td>\n",
              "      <td>-0.000066</td>\n",
              "      <td>0.019955</td>\n",
              "      <td>0.020023</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000068</td>\n",
              "      <td>0.0035</td>\n",
              "      <td>0.0056</td>\n",
              "      <td>32.341000</td>\n",
              "      <td>2104.500000</td>\n",
              "      <td>1582.699951</td>\n",
              "      <td>0.19335</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-03-01</th>\n",
              "      <td>2.032421</td>\n",
              "      <td>4.281752</td>\n",
              "      <td>1.914487</td>\n",
              "      <td>3.106020</td>\n",
              "      <td>0.004617</td>\n",
              "      <td>-0.0019</td>\n",
              "      <td>0.000380</td>\n",
              "      <td>0.019942</td>\n",
              "      <td>0.020019</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000077</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0058</td>\n",
              "      <td>32.540001</td>\n",
              "      <td>2067.889893</td>\n",
              "      <td>1582.140015</td>\n",
              "      <td>0.19040</td>\n",
              "      <td>-0.020455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-04-01</th>\n",
              "      <td>2.123729</td>\n",
              "      <td>4.252482</td>\n",
              "      <td>1.897821</td>\n",
              "      <td>3.193960</td>\n",
              "      <td>-0.001550</td>\n",
              "      <td>-0.0012</td>\n",
              "      <td>-0.000670</td>\n",
              "      <td>0.018201</td>\n",
              "      <td>0.019729</td>\n",
              "      <td>0.001167</td>\n",
              "      <td>0.001528</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0051</td>\n",
              "      <td>32.838001</td>\n",
              "      <td>2085.510010</td>\n",
              "      <td>1525.579956</td>\n",
              "      <td>0.18827</td>\n",
              "      <td>-0.015059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-05-01</th>\n",
              "      <td>1.998252</td>\n",
              "      <td>4.206817</td>\n",
              "      <td>1.863420</td>\n",
              "      <td>3.200002</td>\n",
              "      <td>0.001422</td>\n",
              "      <td>-0.0024</td>\n",
              "      <td>-0.000330</td>\n",
              "      <td>0.016928</td>\n",
              "      <td>0.019148</td>\n",
              "      <td>0.001280</td>\n",
              "      <td>0.002220</td>\n",
              "      <td>0.0042</td>\n",
              "      <td>0.0078</td>\n",
              "      <td>33.734001</td>\n",
              "      <td>2107.389893</td>\n",
              "      <td>1519.880005</td>\n",
              "      <td>0.18351</td>\n",
              "      <td>-0.011596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-06-01</th>\n",
              "      <td>2.047805</td>\n",
              "      <td>4.201526</td>\n",
              "      <td>1.712987</td>\n",
              "      <td>3.151212</td>\n",
              "      <td>-0.005075</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.000280</td>\n",
              "      <td>0.014939</td>\n",
              "      <td>0.018408</td>\n",
              "      <td>0.001854</td>\n",
              "      <td>0.003469</td>\n",
              "      <td>0.0056</td>\n",
              "      <td>0.0082</td>\n",
              "      <td>33.729000</td>\n",
              "      <td>2063.110107</td>\n",
              "      <td>1476.869995</td>\n",
              "      <td>0.18359</td>\n",
              "      <td>-0.002867</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-229d557f-c0ca-443d-bf6b-d360a98e4959')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-229d557f-c0ca-443d-bf6b-d360a98e4959 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-229d557f-c0ca-443d-bf6b-d360a98e4959');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "            Logclose_KTC  Logclose_AEONTS  Logclose_JMT  Logclose_SAWAD  \\\n",
              "Date                                                                      \n",
              "2015-02-01      1.911173         4.324111      1.979026        3.156030   \n",
              "2015-03-01      2.032421         4.281752      1.914487        3.106020   \n",
              "2015-04-01      2.123729         4.252482      1.897821        3.193960   \n",
              "2015-05-01      1.998252         4.206817      1.863420        3.200002   \n",
              "2015-06-01      2.047805         4.201526      1.712987        3.151212   \n",
              "\n",
              "            BroadMoney_M1M2_Growth  Inflation_Surprise  IPI_Surprise  \\\n",
              "Date                                                                   \n",
              "2015-02-01                0.009765             -0.0066     -0.000066   \n",
              "2015-03-01                0.004617             -0.0019      0.000380   \n",
              "2015-04-01               -0.001550             -0.0012     -0.000670   \n",
              "2015-05-01                0.001422             -0.0024     -0.000330   \n",
              "2015-06-01               -0.005075             -0.0015     -0.000280   \n",
              "\n",
              "             THOR_1M   THOR_6M  3M_1M_THOR_Spread  6M_1M_THOR_Spread  \\\n",
              "Date                                                                   \n",
              "2015-02-01  0.019955  0.020023           0.000015           0.000068   \n",
              "2015-03-01  0.019942  0.020019           0.000032           0.000077   \n",
              "2015-04-01  0.018201  0.019729           0.001167           0.001528   \n",
              "2015-05-01  0.016928  0.019148           0.001280           0.002220   \n",
              "2015-06-01  0.014939  0.018408           0.001854           0.003469   \n",
              "\n",
              "            5Y_1Y_Bond_Spread  10Y_5Y_Bond_Spread  THB_per_USD  SP500_Index  \\\n",
              "Date                                                                          \n",
              "2015-02-01             0.0035              0.0056    32.341000  2104.500000   \n",
              "2015-03-01             0.0045              0.0058    32.540001  2067.889893   \n",
              "2015-04-01             0.0048              0.0051    32.838001  2085.510010   \n",
              "2015-05-01             0.0042              0.0078    33.734001  2107.389893   \n",
              "2015-06-01             0.0056              0.0082    33.729000  2063.110107   \n",
              "\n",
              "              SET_Index  THB_per_CNY  GDP_Growth  \n",
              "Date                                              \n",
              "2015-02-01  1582.699951      0.19335         NaN  \n",
              "2015-03-01  1582.140015      0.19040   -0.020455  \n",
              "2015-04-01  1525.579956      0.18827   -0.015059  \n",
              "2015-05-01  1519.880005      0.18351   -0.011596  \n",
              "2015-06-01  1476.869995      0.18359   -0.002867  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ======== Filter sector log-prices + macro variables ========\n",
        "\n",
        "# Macro columns à¸—à¸µà¹ˆà¸¡à¸µà¸­à¸¢à¸¹à¹ˆà¸ˆà¸£à¸´à¸‡à¹ƒà¸™ Excel + yfinance\n",
        "macro_columns = [\n",
        "    \"BroadMoney_M1M2_Growth\",\n",
        "    \"Inflation_Surprise\",\n",
        "    \"IPI_Surprise\",\n",
        "    \"THOR_1M\",\n",
        "    \"THOR_6M\",\n",
        "    \"3M_1M_THOR_Spread\",\n",
        "    \"6M_1M_THOR_Spread\",\n",
        "    \"5Y_1Y_Bond_Spread\",\n",
        "    \"10Y_5Y_Bond_Spread\",\n",
        "    \"THB_per_USD\",\n",
        "    # \"Brent_Oil_USD_per_bbl\",\n",
        "    \"SP500_Index\",\n",
        "    \"SET_Index\",\n",
        "    \"THB_per_CNY\",\n",
        "    \"GDP_Growth\"\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "# ======== à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸² df à¸–à¸¹à¸à¸ªà¸£à¹‰à¸²à¸‡à¹à¸¥à¹‰à¸§à¸ˆà¸²à¸ Block à¸à¹ˆà¸­à¸™à¸«à¸™à¹‰à¸² ========\n",
        "if 'df' not in globals():\n",
        "    raise RuntimeError(\"âŒ Variable 'df' not found. Please run the data-preparation block first.\")\n",
        "\n",
        "df_filtered_macro = df\n",
        "\n",
        "# à¹€à¸à¹‡à¸šà¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¹à¸¢à¸ sector\n",
        "combined_dfs = {}\n",
        "\n",
        "for sector, tickers_list in SECTORS.items():\n",
        "    sector_frames = []\n",
        "\n",
        "    for ticker in tickers_list:\n",
        "        colname = f\"Close_{ticker}\"\n",
        "        if colname not in df.columns:\n",
        "            print(f\"âš ï¸ {colname} not found in df. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        # âœ… à¹ƒà¸Šà¹‰ Logclose à¹à¸—à¸™ log-return\n",
        "        tmp = df[[colname]].copy()\n",
        "        tmp[f\"Logclose_{ticker}\"] = np.log(tmp[colname])\n",
        "        tmp = tmp[[f\"Logclose_{ticker}\"]]\n",
        "\n",
        "        # align index à¹ƒà¸«à¹‰à¸•à¸£à¸‡à¸à¸±à¸š macro\n",
        "        tmp = tmp.loc[df_filtered_macro.index]\n",
        "        sector_frames.append(tmp)\n",
        "\n",
        "    if len(sector_frames) == 0:\n",
        "        continue\n",
        "\n",
        "    # à¸£à¸§à¸¡ Logclose à¸‚à¸­à¸‡à¸«à¸¸à¹‰à¸™à¸—à¸¸à¸à¸•à¸±à¸§à¹ƒà¸™ sector\n",
        "    sector_data = pd.concat(sector_frames, axis=1)\n",
        "\n",
        "    # à¸£à¸§à¸¡à¸à¸±à¸š macro\n",
        "    combined_df = pd.concat([sector_data, df_filtered_macro], axis=1).ffill()\n",
        "\n",
        "    # à¸•à¸±à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸›à¸µ 2025 (à¸›à¹‰à¸­à¸‡à¸à¸±à¸™ incomplete data)\n",
        "    combined_df = combined_df[combined_df.index.year != 2025]\n",
        "\n",
        "    combined_dfs[sector] = combined_df\n",
        "\n",
        "# ======== à¹à¸ªà¸”à¸‡à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œ ========\n",
        "for sector, combined_df in combined_dfs.items():\n",
        "    print(f\"\\nðŸ“Š Combined data for sector: {sector}\")\n",
        "    cols_to_show = [c for c in combined_df.columns if c.startswith(\"Logclose_\")] + macro_columns\n",
        "    cols_to_show_present = [col for col in cols_to_show if col in combined_df.columns]\n",
        "    display(combined_df[cols_to_show_present].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JiapIQVQrUOF",
        "outputId": "bc37abb3-1d5b-4df9-9ce8-ab844492c4c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Displaying head of combined dataframes for each sector:\n",
            "\n",
            "--- Combined dataframe for Banking ---\n",
            "Columns in the combined dataframe for Banking:\n",
            "Index(['Logclose_BBL', 'Logclose_KBANK', 'Logclose_KKP', 'Logclose_KTB',\n",
            "       'Logclose_TCAP', 'Logclose_TISCO', 'Logclose_TTB', 'Close_BBL',\n",
            "       'Close_KBANK', 'Close_KKP', 'Close_KTB', 'Close_TCAP', 'Close_TISCO',\n",
            "       'Close_TTB', 'Close_KTC', 'Close_AEONTS', 'Close_JMT', 'Close_SAWAD',\n",
            "       'Inflation', 'Inflation_Forecast', 'IPI', 'IPI_Forecast',\n",
            "       'BroadMoney_M1M2_Growth', 'THOR_1M', 'THOR_3M', 'THOR_6M',\n",
            "       'Bond_Yield_1Y', 'Bond_Yield_5Y', 'Bond_Yield_10Y',\n",
            "       'Yield_Spread_10Y_5Y', 'Yield_Spread_5Y_1Y', 'Yield_Spread_10Y_1Y',\n",
            "       'THB_per_USD', 'THB_per_CNY', 'SP500_Index', 'SET_Index',\n",
            "       'IPI_Surprise', 'Inflation_Surprise', '5Y_1Y_Bond_Spread',\n",
            "       '10Y_5Y_Bond_Spread', '3M_1M_THOR_Spread', '6M_1M_THOR_Spread',\n",
            "       'GDP_Monthly', 'GDP_Growth'],\n",
            "      dtype='object')\n",
            "\n",
            "Head of the combined dataframe for Banking:\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-e9479205-1f5b-4464-b0f9-45c601dcbeb3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Logclose_BBL</th>\n",
              "      <th>Logclose_KBANK</th>\n",
              "      <th>Logclose_KKP</th>\n",
              "      <th>Logclose_KTB</th>\n",
              "      <th>Logclose_TCAP</th>\n",
              "      <th>Logclose_TISCO</th>\n",
              "      <th>Logclose_TTB</th>\n",
              "      <th>Close_BBL</th>\n",
              "      <th>Close_KBANK</th>\n",
              "      <th>Close_KKP</th>\n",
              "      <th>...</th>\n",
              "      <th>SP500_Index</th>\n",
              "      <th>SET_Index</th>\n",
              "      <th>IPI_Surprise</th>\n",
              "      <th>Inflation_Surprise</th>\n",
              "      <th>5Y_1Y_Bond_Spread</th>\n",
              "      <th>10Y_5Y_Bond_Spread</th>\n",
              "      <th>3M_1M_THOR_Spread</th>\n",
              "      <th>6M_1M_THOR_Spread</th>\n",
              "      <th>GDP_Monthly</th>\n",
              "      <th>GDP_Growth</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2015-02-01</th>\n",
              "      <td>4.790190</td>\n",
              "      <td>5.017582</td>\n",
              "      <td>2.939447</td>\n",
              "      <td>2.627824</td>\n",
              "      <td>2.802560</td>\n",
              "      <td>3.072488</td>\n",
              "      <td>0.569241</td>\n",
              "      <td>120.324242</td>\n",
              "      <td>151.045563</td>\n",
              "      <td>18.905380</td>\n",
              "      <td>...</td>\n",
              "      <td>2104.500000</td>\n",
              "      <td>1582.699951</td>\n",
              "      <td>-0.000066</td>\n",
              "      <td>-0.0066</td>\n",
              "      <td>0.0035</td>\n",
              "      <td>0.0056</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000068</td>\n",
              "      <td>1.165382e+06</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-03-01</th>\n",
              "      <td>4.798353</td>\n",
              "      <td>5.071406</td>\n",
              "      <td>2.933057</td>\n",
              "      <td>2.627824</td>\n",
              "      <td>2.795391</td>\n",
              "      <td>3.045532</td>\n",
              "      <td>0.555908</td>\n",
              "      <td>121.310509</td>\n",
              "      <td>159.398285</td>\n",
              "      <td>18.784966</td>\n",
              "      <td>...</td>\n",
              "      <td>2067.889893</td>\n",
              "      <td>1582.140015</td>\n",
              "      <td>0.000380</td>\n",
              "      <td>-0.0019</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0058</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000077</td>\n",
              "      <td>1.141786e+06</td>\n",
              "      <td>-0.020455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-04-01</th>\n",
              "      <td>4.801060</td>\n",
              "      <td>4.984792</td>\n",
              "      <td>2.880413</td>\n",
              "      <td>2.496796</td>\n",
              "      <td>2.773572</td>\n",
              "      <td>3.034543</td>\n",
              "      <td>0.419496</td>\n",
              "      <td>121.639305</td>\n",
              "      <td>146.173111</td>\n",
              "      <td>17.821629</td>\n",
              "      <td>...</td>\n",
              "      <td>2085.510010</td>\n",
              "      <td>1525.579956</td>\n",
              "      <td>-0.000670</td>\n",
              "      <td>-0.0012</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0051</td>\n",
              "      <td>0.001167</td>\n",
              "      <td>0.001528</td>\n",
              "      <td>1.124720e+06</td>\n",
              "      <td>-0.015059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-05-01</th>\n",
              "      <td>4.808427</td>\n",
              "      <td>4.925754</td>\n",
              "      <td>2.888474</td>\n",
              "      <td>2.436026</td>\n",
              "      <td>2.810098</td>\n",
              "      <td>3.072725</td>\n",
              "      <td>0.417810</td>\n",
              "      <td>122.538742</td>\n",
              "      <td>137.793167</td>\n",
              "      <td>17.965874</td>\n",
              "      <td>...</td>\n",
              "      <td>2107.389893</td>\n",
              "      <td>1519.880005</td>\n",
              "      <td>-0.000330</td>\n",
              "      <td>-0.0024</td>\n",
              "      <td>0.0042</td>\n",
              "      <td>0.0078</td>\n",
              "      <td>0.001280</td>\n",
              "      <td>0.002220</td>\n",
              "      <td>1.111753e+06</td>\n",
              "      <td>-0.011596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-06-01</th>\n",
              "      <td>4.786204</td>\n",
              "      <td>4.894501</td>\n",
              "      <td>2.867421</td>\n",
              "      <td>2.379193</td>\n",
              "      <td>2.780466</td>\n",
              "      <td>3.094704</td>\n",
              "      <td>0.335797</td>\n",
              "      <td>119.845604</td>\n",
              "      <td>133.553375</td>\n",
              "      <td>17.591583</td>\n",
              "      <td>...</td>\n",
              "      <td>2063.110107</td>\n",
              "      <td>1476.869995</td>\n",
              "      <td>-0.000280</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>0.0056</td>\n",
              "      <td>0.0082</td>\n",
              "      <td>0.001854</td>\n",
              "      <td>0.003469</td>\n",
              "      <td>1.108570e+06</td>\n",
              "      <td>-0.002867</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 44 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9479205-1f5b-4464-b0f9-45c601dcbeb3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e9479205-1f5b-4464-b0f9-45c601dcbeb3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e9479205-1f5b-4464-b0f9-45c601dcbeb3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "            Logclose_BBL  Logclose_KBANK  Logclose_KKP  Logclose_KTB  \\\n",
              "Date                                                                   \n",
              "2015-02-01      4.790190        5.017582      2.939447      2.627824   \n",
              "2015-03-01      4.798353        5.071406      2.933057      2.627824   \n",
              "2015-04-01      4.801060        4.984792      2.880413      2.496796   \n",
              "2015-05-01      4.808427        4.925754      2.888474      2.436026   \n",
              "2015-06-01      4.786204        4.894501      2.867421      2.379193   \n",
              "\n",
              "            Logclose_TCAP  Logclose_TISCO  Logclose_TTB   Close_BBL  \\\n",
              "Date                                                                  \n",
              "2015-02-01       2.802560        3.072488      0.569241  120.324242   \n",
              "2015-03-01       2.795391        3.045532      0.555908  121.310509   \n",
              "2015-04-01       2.773572        3.034543      0.419496  121.639305   \n",
              "2015-05-01       2.810098        3.072725      0.417810  122.538742   \n",
              "2015-06-01       2.780466        3.094704      0.335797  119.845604   \n",
              "\n",
              "            Close_KBANK  Close_KKP  ...  SP500_Index    SET_Index  \\\n",
              "Date                                ...                             \n",
              "2015-02-01   151.045563  18.905380  ...  2104.500000  1582.699951   \n",
              "2015-03-01   159.398285  18.784966  ...  2067.889893  1582.140015   \n",
              "2015-04-01   146.173111  17.821629  ...  2085.510010  1525.579956   \n",
              "2015-05-01   137.793167  17.965874  ...  2107.389893  1519.880005   \n",
              "2015-06-01   133.553375  17.591583  ...  2063.110107  1476.869995   \n",
              "\n",
              "            IPI_Surprise  Inflation_Surprise  5Y_1Y_Bond_Spread  \\\n",
              "Date                                                              \n",
              "2015-02-01     -0.000066             -0.0066             0.0035   \n",
              "2015-03-01      0.000380             -0.0019             0.0045   \n",
              "2015-04-01     -0.000670             -0.0012             0.0048   \n",
              "2015-05-01     -0.000330             -0.0024             0.0042   \n",
              "2015-06-01     -0.000280             -0.0015             0.0056   \n",
              "\n",
              "            10Y_5Y_Bond_Spread  3M_1M_THOR_Spread  6M_1M_THOR_Spread  \\\n",
              "Date                                                                   \n",
              "2015-02-01              0.0056           0.000015           0.000068   \n",
              "2015-03-01              0.0058           0.000032           0.000077   \n",
              "2015-04-01              0.0051           0.001167           0.001528   \n",
              "2015-05-01              0.0078           0.001280           0.002220   \n",
              "2015-06-01              0.0082           0.001854           0.003469   \n",
              "\n",
              "             GDP_Monthly  GDP_Growth  \n",
              "Date                                  \n",
              "2015-02-01  1.165382e+06         NaN  \n",
              "2015-03-01  1.141786e+06   -0.020455  \n",
              "2015-04-01  1.124720e+06   -0.015059  \n",
              "2015-05-01  1.111753e+06   -0.011596  \n",
              "2015-06-01  1.108570e+06   -0.002867  \n",
              "\n",
              "[5 rows x 44 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Combined dataframe for Finance_Securities ---\n",
            "Columns in the combined dataframe for Finance_Securities:\n",
            "Index(['Logclose_KTC', 'Logclose_AEONTS', 'Logclose_JMT', 'Logclose_SAWAD',\n",
            "       'Close_BBL', 'Close_KBANK', 'Close_KKP', 'Close_KTB', 'Close_TCAP',\n",
            "       'Close_TISCO', 'Close_TTB', 'Close_KTC', 'Close_AEONTS', 'Close_JMT',\n",
            "       'Close_SAWAD', 'Inflation', 'Inflation_Forecast', 'IPI', 'IPI_Forecast',\n",
            "       'BroadMoney_M1M2_Growth', 'THOR_1M', 'THOR_3M', 'THOR_6M',\n",
            "       'Bond_Yield_1Y', 'Bond_Yield_5Y', 'Bond_Yield_10Y',\n",
            "       'Yield_Spread_10Y_5Y', 'Yield_Spread_5Y_1Y', 'Yield_Spread_10Y_1Y',\n",
            "       'THB_per_USD', 'THB_per_CNY', 'SP500_Index', 'SET_Index',\n",
            "       'IPI_Surprise', 'Inflation_Surprise', '5Y_1Y_Bond_Spread',\n",
            "       '10Y_5Y_Bond_Spread', '3M_1M_THOR_Spread', '6M_1M_THOR_Spread',\n",
            "       'GDP_Monthly', 'GDP_Growth'],\n",
            "      dtype='object')\n",
            "\n",
            "Head of the combined dataframe for Finance_Securities:\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-fdcb0bad-d911-47aa-b86a-2709a5c493bd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Logclose_KTC</th>\n",
              "      <th>Logclose_AEONTS</th>\n",
              "      <th>Logclose_JMT</th>\n",
              "      <th>Logclose_SAWAD</th>\n",
              "      <th>Close_BBL</th>\n",
              "      <th>Close_KBANK</th>\n",
              "      <th>Close_KKP</th>\n",
              "      <th>Close_KTB</th>\n",
              "      <th>Close_TCAP</th>\n",
              "      <th>Close_TISCO</th>\n",
              "      <th>...</th>\n",
              "      <th>SP500_Index</th>\n",
              "      <th>SET_Index</th>\n",
              "      <th>IPI_Surprise</th>\n",
              "      <th>Inflation_Surprise</th>\n",
              "      <th>5Y_1Y_Bond_Spread</th>\n",
              "      <th>10Y_5Y_Bond_Spread</th>\n",
              "      <th>3M_1M_THOR_Spread</th>\n",
              "      <th>6M_1M_THOR_Spread</th>\n",
              "      <th>GDP_Monthly</th>\n",
              "      <th>GDP_Growth</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2015-02-01</th>\n",
              "      <td>1.911173</td>\n",
              "      <td>4.324111</td>\n",
              "      <td>1.979026</td>\n",
              "      <td>3.156030</td>\n",
              "      <td>120.324242</td>\n",
              "      <td>151.045563</td>\n",
              "      <td>18.905380</td>\n",
              "      <td>13.843618</td>\n",
              "      <td>16.486799</td>\n",
              "      <td>21.595558</td>\n",
              "      <td>...</td>\n",
              "      <td>2104.500000</td>\n",
              "      <td>1582.699951</td>\n",
              "      <td>-0.000066</td>\n",
              "      <td>-0.0066</td>\n",
              "      <td>0.0035</td>\n",
              "      <td>0.0056</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000068</td>\n",
              "      <td>1.165382e+06</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-03-01</th>\n",
              "      <td>2.032421</td>\n",
              "      <td>4.281752</td>\n",
              "      <td>1.914487</td>\n",
              "      <td>3.106020</td>\n",
              "      <td>121.310509</td>\n",
              "      <td>159.398285</td>\n",
              "      <td>18.784966</td>\n",
              "      <td>13.843618</td>\n",
              "      <td>16.369032</td>\n",
              "      <td>21.021212</td>\n",
              "      <td>...</td>\n",
              "      <td>2067.889893</td>\n",
              "      <td>1582.140015</td>\n",
              "      <td>0.000380</td>\n",
              "      <td>-0.0019</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0058</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000077</td>\n",
              "      <td>1.141786e+06</td>\n",
              "      <td>-0.020455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-04-01</th>\n",
              "      <td>2.123729</td>\n",
              "      <td>4.252482</td>\n",
              "      <td>1.897821</td>\n",
              "      <td>3.193960</td>\n",
              "      <td>121.639305</td>\n",
              "      <td>146.173111</td>\n",
              "      <td>17.821629</td>\n",
              "      <td>12.143525</td>\n",
              "      <td>16.015741</td>\n",
              "      <td>20.791471</td>\n",
              "      <td>...</td>\n",
              "      <td>2085.510010</td>\n",
              "      <td>1525.579956</td>\n",
              "      <td>-0.000670</td>\n",
              "      <td>-0.0012</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0051</td>\n",
              "      <td>0.001167</td>\n",
              "      <td>0.001528</td>\n",
              "      <td>1.124720e+06</td>\n",
              "      <td>-0.015059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-05-01</th>\n",
              "      <td>1.998252</td>\n",
              "      <td>4.206817</td>\n",
              "      <td>1.863420</td>\n",
              "      <td>3.200002</td>\n",
              "      <td>122.538742</td>\n",
              "      <td>137.793167</td>\n",
              "      <td>17.965874</td>\n",
              "      <td>11.427542</td>\n",
              "      <td>16.611540</td>\n",
              "      <td>21.600693</td>\n",
              "      <td>...</td>\n",
              "      <td>2107.389893</td>\n",
              "      <td>1519.880005</td>\n",
              "      <td>-0.000330</td>\n",
              "      <td>-0.0024</td>\n",
              "      <td>0.0042</td>\n",
              "      <td>0.0078</td>\n",
              "      <td>0.001280</td>\n",
              "      <td>0.002220</td>\n",
              "      <td>1.111753e+06</td>\n",
              "      <td>-0.011596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-06-01</th>\n",
              "      <td>2.047805</td>\n",
              "      <td>4.201526</td>\n",
              "      <td>1.712987</td>\n",
              "      <td>3.151212</td>\n",
              "      <td>119.845604</td>\n",
              "      <td>133.553375</td>\n",
              "      <td>17.591583</td>\n",
              "      <td>10.796185</td>\n",
              "      <td>16.126530</td>\n",
              "      <td>22.080709</td>\n",
              "      <td>...</td>\n",
              "      <td>2063.110107</td>\n",
              "      <td>1476.869995</td>\n",
              "      <td>-0.000280</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>0.0056</td>\n",
              "      <td>0.0082</td>\n",
              "      <td>0.001854</td>\n",
              "      <td>0.003469</td>\n",
              "      <td>1.108570e+06</td>\n",
              "      <td>-0.002867</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 41 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fdcb0bad-d911-47aa-b86a-2709a5c493bd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fdcb0bad-d911-47aa-b86a-2709a5c493bd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fdcb0bad-d911-47aa-b86a-2709a5c493bd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "            Logclose_KTC  Logclose_AEONTS  Logclose_JMT  Logclose_SAWAD  \\\n",
              "Date                                                                      \n",
              "2015-02-01      1.911173         4.324111      1.979026        3.156030   \n",
              "2015-03-01      2.032421         4.281752      1.914487        3.106020   \n",
              "2015-04-01      2.123729         4.252482      1.897821        3.193960   \n",
              "2015-05-01      1.998252         4.206817      1.863420        3.200002   \n",
              "2015-06-01      2.047805         4.201526      1.712987        3.151212   \n",
              "\n",
              "             Close_BBL  Close_KBANK  Close_KKP  Close_KTB  Close_TCAP  \\\n",
              "Date                                                                    \n",
              "2015-02-01  120.324242   151.045563  18.905380  13.843618   16.486799   \n",
              "2015-03-01  121.310509   159.398285  18.784966  13.843618   16.369032   \n",
              "2015-04-01  121.639305   146.173111  17.821629  12.143525   16.015741   \n",
              "2015-05-01  122.538742   137.793167  17.965874  11.427542   16.611540   \n",
              "2015-06-01  119.845604   133.553375  17.591583  10.796185   16.126530   \n",
              "\n",
              "            Close_TISCO  ...  SP500_Index    SET_Index  IPI_Surprise  \\\n",
              "Date                     ...                                           \n",
              "2015-02-01    21.595558  ...  2104.500000  1582.699951     -0.000066   \n",
              "2015-03-01    21.021212  ...  2067.889893  1582.140015      0.000380   \n",
              "2015-04-01    20.791471  ...  2085.510010  1525.579956     -0.000670   \n",
              "2015-05-01    21.600693  ...  2107.389893  1519.880005     -0.000330   \n",
              "2015-06-01    22.080709  ...  2063.110107  1476.869995     -0.000280   \n",
              "\n",
              "            Inflation_Surprise  5Y_1Y_Bond_Spread  10Y_5Y_Bond_Spread  \\\n",
              "Date                                                                    \n",
              "2015-02-01             -0.0066             0.0035              0.0056   \n",
              "2015-03-01             -0.0019             0.0045              0.0058   \n",
              "2015-04-01             -0.0012             0.0048              0.0051   \n",
              "2015-05-01             -0.0024             0.0042              0.0078   \n",
              "2015-06-01             -0.0015             0.0056              0.0082   \n",
              "\n",
              "            3M_1M_THOR_Spread  6M_1M_THOR_Spread   GDP_Monthly  GDP_Growth  \n",
              "Date                                                                        \n",
              "2015-02-01           0.000015           0.000068  1.165382e+06         NaN  \n",
              "2015-03-01           0.000032           0.000077  1.141786e+06   -0.020455  \n",
              "2015-04-01           0.001167           0.001528  1.124720e+06   -0.015059  \n",
              "2015-05-01           0.001280           0.002220  1.111753e+06   -0.011596  \n",
              "2015-06-01           0.001854           0.003469  1.108570e+06   -0.002867  \n",
              "\n",
              "[5 rows x 41 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Select the dataframe for the first stock (e.g., 'BBL') from the combined_dfs dictionary\n",
        "# This cell is intended to display example dataframes from combined_dfs,\n",
        "# which are structured by sector, not individual tickers.\n",
        "# Iterate through the combined_dfs dictionary using sector names as keys.\n",
        "\n",
        "if 'combined_dfs' in globals() and combined_dfs:\n",
        "    print(\"Displaying head of combined dataframes for each sector:\")\n",
        "    for sector, combined_df_example in combined_dfs.items():\n",
        "        print(f\"\\n--- Combined dataframe for {sector} ---\")\n",
        "        # Display the columns of the example combined dataframe\n",
        "        print(f\"Columns in the combined dataframe for {sector}:\")\n",
        "        print(combined_df_example.columns)\n",
        "\n",
        "        # Display the head of the example combined dataframe\n",
        "        print(f\"\\nHead of the combined dataframe for {sector}:\")\n",
        "        display(combined_df_example.head())\n",
        "else:\n",
        "    print(\"The 'combined_dfs' dictionary is not available or is empty. Please run the data processing cell first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKCrzkPXBDzD"
      },
      "source": [
        "** 3 Econometric **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        },
        "id": "eb8545b7",
        "outputId": "51ad8907-4aef-4f43-d612-0ee2657d3ab5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== âœ… Logclose columns collected ===\n",
            "Total: 11 stocks\n",
            "\n",
            "ðŸ“… First available data per stock:\n",
            "Logclose_BBL             : 2015-02-01 00:00:00\n",
            "Logclose_KBANK           : 2015-02-01 00:00:00\n",
            "Logclose_KKP             : 2015-02-01 00:00:00\n",
            "Logclose_KTB             : 2015-02-01 00:00:00\n",
            "Logclose_TCAP            : 2015-02-01 00:00:00\n",
            "Logclose_TISCO           : 2015-02-01 00:00:00\n",
            "Logclose_TTB             : 2015-02-01 00:00:00\n",
            "Logclose_KTC             : 2015-02-01 00:00:00\n",
            "Logclose_AEONTS          : 2015-02-01 00:00:00\n",
            "Logclose_JMT             : 2015-02-01 00:00:00\n",
            "Logclose_SAWAD           : 2015-02-01 00:00:00\n",
            "\n",
            "âœ… Dynamic Panel Ready: shape=(132, 11)\n",
            "ðŸ• Date range: 2015-02-01 â†’ 2026-01-01\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"    print(df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2015-02-01 00:00:00\",\n        \"max\": \"2015-11-01 00:00:00\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"2015-10-01 00:00:00\",\n          \"2015-03-01 00:00:00\",\n          \"2015-07-01 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_BBL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.046045772991002834,\n        \"min\": 4.679594063264345,\n        \"max\": 4.808427241743183,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          4.679594063264345,\n          4.798353446393913,\n          4.716408277011181\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_KBANK\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09917345092034925,\n        \"min\": 4.794417699822085,\n        \"max\": 5.071406006650233,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          4.805956286722616,\n          5.071406006650233,\n          4.834537796833894\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_KKP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08159483420324642,\n        \"min\": 2.722681736355765,\n        \"max\": 2.93944655081549,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          2.846805884141314,\n          2.933056843258302,\n          2.722681736355765\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_KTB\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0992786912779285,\n        \"min\": 2.373327709436082,\n        \"max\": 2.6278243605957488,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          2.6278243605957488,\n          2.4967961161005086,\n          2.441536000472151\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_TCAP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05564399180655622,\n        \"min\": 2.6608009309784273,\n        \"max\": 2.8611703818859495,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          2.787956157200616,\n          2.795391251340349,\n          2.7184304176129563\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_TISCO\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08430384302311811,\n        \"min\": 2.8355958114862707,\n        \"max\": 3.094704352115409,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          2.897048556602056,\n          3.045532005278821,\n          3.015567325251252\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-deec8f0b-732f-4e18-8806-936dc80fe252\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Logclose_BBL</th>\n",
              "      <th>Logclose_KBANK</th>\n",
              "      <th>Logclose_KKP</th>\n",
              "      <th>Logclose_KTB</th>\n",
              "      <th>Logclose_TCAP</th>\n",
              "      <th>Logclose_TISCO</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2015-02-01</th>\n",
              "      <td>4.790190</td>\n",
              "      <td>5.017582</td>\n",
              "      <td>2.939447</td>\n",
              "      <td>2.627824</td>\n",
              "      <td>2.802560</td>\n",
              "      <td>3.072488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-03-01</th>\n",
              "      <td>4.798353</td>\n",
              "      <td>5.071406</td>\n",
              "      <td>2.933057</td>\n",
              "      <td>2.627824</td>\n",
              "      <td>2.795391</td>\n",
              "      <td>3.045532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-04-01</th>\n",
              "      <td>4.801060</td>\n",
              "      <td>4.984792</td>\n",
              "      <td>2.880413</td>\n",
              "      <td>2.496796</td>\n",
              "      <td>2.773572</td>\n",
              "      <td>3.034543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-05-01</th>\n",
              "      <td>4.808427</td>\n",
              "      <td>4.925754</td>\n",
              "      <td>2.888474</td>\n",
              "      <td>2.436026</td>\n",
              "      <td>2.810098</td>\n",
              "      <td>3.072725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-06-01</th>\n",
              "      <td>4.786204</td>\n",
              "      <td>4.894501</td>\n",
              "      <td>2.867421</td>\n",
              "      <td>2.379193</td>\n",
              "      <td>2.780466</td>\n",
              "      <td>3.094704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-07-01</th>\n",
              "      <td>4.716408</td>\n",
              "      <td>4.834538</td>\n",
              "      <td>2.722682</td>\n",
              "      <td>2.402315</td>\n",
              "      <td>2.718430</td>\n",
              "      <td>3.015567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-08-01</th>\n",
              "      <td>4.707331</td>\n",
              "      <td>4.848485</td>\n",
              "      <td>2.778473</td>\n",
              "      <td>2.441536</td>\n",
              "      <td>2.660801</td>\n",
              "      <td>2.942364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-09-01</th>\n",
              "      <td>4.679594</td>\n",
              "      <td>4.794418</td>\n",
              "      <td>2.730845</td>\n",
              "      <td>2.379193</td>\n",
              "      <td>2.734304</td>\n",
              "      <td>2.835596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-10-01</th>\n",
              "      <td>4.737904</td>\n",
              "      <td>4.805956</td>\n",
              "      <td>2.846806</td>\n",
              "      <td>2.379193</td>\n",
              "      <td>2.787956</td>\n",
              "      <td>2.897049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-11-01</th>\n",
              "      <td>4.737904</td>\n",
              "      <td>4.797223</td>\n",
              "      <td>2.932573</td>\n",
              "      <td>2.373328</td>\n",
              "      <td>2.861170</td>\n",
              "      <td>3.003733</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-deec8f0b-732f-4e18-8806-936dc80fe252')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-deec8f0b-732f-4e18-8806-936dc80fe252 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-deec8f0b-732f-4e18-8806-936dc80fe252');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "            Logclose_BBL  Logclose_KBANK  Logclose_KKP  Logclose_KTB  \\\n",
              "Date                                                                   \n",
              "2015-02-01      4.790190        5.017582      2.939447      2.627824   \n",
              "2015-03-01      4.798353        5.071406      2.933057      2.627824   \n",
              "2015-04-01      4.801060        4.984792      2.880413      2.496796   \n",
              "2015-05-01      4.808427        4.925754      2.888474      2.436026   \n",
              "2015-06-01      4.786204        4.894501      2.867421      2.379193   \n",
              "2015-07-01      4.716408        4.834538      2.722682      2.402315   \n",
              "2015-08-01      4.707331        4.848485      2.778473      2.441536   \n",
              "2015-09-01      4.679594        4.794418      2.730845      2.379193   \n",
              "2015-10-01      4.737904        4.805956      2.846806      2.379193   \n",
              "2015-11-01      4.737904        4.797223      2.932573      2.373328   \n",
              "\n",
              "            Logclose_TCAP  Logclose_TISCO  \n",
              "Date                                       \n",
              "2015-02-01       2.802560        3.072488  \n",
              "2015-03-01       2.795391        3.045532  \n",
              "2015-04-01       2.773572        3.034543  \n",
              "2015-05-01       2.810098        3.072725  \n",
              "2015-06-01       2.780466        3.094704  \n",
              "2015-07-01       2.718430        3.015567  \n",
              "2015-08-01       2.660801        2.942364  \n",
              "2015-09-01       2.734304        2.835596  \n",
              "2015-10-01       2.787956        2.897049  \n",
              "2015-11-01       2.861170        3.003733  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ============================================================\n",
        "# ðŸ§  MULTI-STOCK PIPELINE (Logclose + Dynamic Alignment)\n",
        "# ============================================================\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# --- Safety check ---\n",
        "if 'combined_dfs' not in globals() or not isinstance(combined_dfs, dict) or not combined_dfs:\n",
        "    raise RuntimeError(\"âŒ combined_dfs not found or empty. Run previous macro/stock preparation cells first.\")\n",
        "\n",
        "if 'SECTORS' not in globals():\n",
        "    raise RuntimeError(\"âŒ SECTORS not defined. Make sure the sector mapping dict is loaded.\")\n",
        "\n",
        "# ============================================================\n",
        "# 1ï¸âƒ£ Helper functions\n",
        "# ============================================================\n",
        "def _norm(s: str) -> str:\n",
        "    return re.sub(r'[^a-z0-9]+', '', str(s).lower())\n",
        "\n",
        "PRICE_TOKENS = (\"logclose\",\"close\",\"adjclose\",\"price\",\"px\",\"pxlast\",\"last\")\n",
        "\n",
        "def _find_price_like_col(df_one: pd.DataFrame, ticker: str) -> str | None:\n",
        "    \"\"\"à¸„à¹‰à¸™à¸«à¸²à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸£à¸²à¸„à¸²à¸«à¸£à¸·à¸­ logclose à¸—à¸µà¹ˆà¸•à¸£à¸‡à¸à¸±à¸šà¸Šà¸·à¹ˆà¸­à¸«à¸¸à¹‰à¸™\"\"\"\n",
        "    if df_one is None or df_one.empty:\n",
        "        return None\n",
        "    exacts = [\n",
        "        f\"Logclose_{ticker}\",\n",
        "        f\"Close_{ticker}\",\n",
        "        f\"close_{ticker}\",\n",
        "        f\"AdjClose_{ticker}\",\n",
        "        f\"Adj_Close_{ticker}\"\n",
        "    ]\n",
        "    for c in exacts:\n",
        "        if c in df_one.columns:\n",
        "            return c\n",
        "    generics = [\"Logclose\", \"Close\", \"Adj Close\", \"Price\", \"PX\", \"PX_LAST\", \"Last\"]\n",
        "    for c in generics:\n",
        "        if c in df_one.columns:\n",
        "            return c\n",
        "    numeric_cols = [c for c in df_one.columns if pd.api.types.is_numeric_dtype(df_one[c])]\n",
        "    want = {_norm(t)+_norm(ticker) for t in PRICE_TOKENS}\n",
        "    best, best_nn = None, -1\n",
        "    for c in numeric_cols:\n",
        "        nc = _norm(c)\n",
        "        if any(tok in nc for tok in want) or any(t in nc for t in PRICE_TOKENS):\n",
        "            nn = df_one[c].notna().sum()\n",
        "            if nn > best_nn:\n",
        "                best, best_nn = c, nn\n",
        "    return best\n",
        "\n",
        "def _align(s: pd.Series, idx: pd.Index) -> pd.Series:\n",
        "    if s is None:\n",
        "        return None\n",
        "    s = s.copy()\n",
        "    s.index = pd.to_datetime(s.index)\n",
        "    return s.reindex(idx)\n",
        "\n",
        "# ============================================================\n",
        "# 2ï¸âƒ£ Build base index (union of all sectors)\n",
        "# ============================================================\n",
        "union_idx = None\n",
        "for d in combined_dfs.values():\n",
        "    idx = pd.to_datetime(d.index)\n",
        "    union_idx = idx if union_idx is None else union_idx.union(idx)\n",
        "if 'df' in globals() and isinstance(df, pd.DataFrame) and not df.empty:\n",
        "    union_idx = (pd.to_datetime(df.index) if union_idx is None else union_idx.union(pd.to_datetime(df.index)))\n",
        "if union_idx is None:\n",
        "    raise RuntimeError(\"âŒ No index found to build panel.\")\n",
        "union_idx = union_idx.sort_values()\n",
        "\n",
        "# Base DataFrame\n",
        "df_master = (df.reindex(union_idx).copy()\n",
        "             if 'df' in globals() and isinstance(df, pd.DataFrame)\n",
        "             else pd.DataFrame(index=union_idx))\n",
        "\n",
        "# ============================================================\n",
        "# 3ï¸âƒ£ Collect Logclose per ticker\n",
        "# ============================================================\n",
        "TARGET_TICKERS = [ticker for tickers in SECTORS.values() for ticker in tickers]\n",
        "source_used, missing = {}, []\n",
        "\n",
        "for ticker in TARGET_TICKERS:\n",
        "    dsec = None\n",
        "    for sec, d in combined_dfs.items():\n",
        "        if f\"Logclose_{ticker}\" in d.columns or f\"Close_{ticker}\" in d.columns:\n",
        "            dsec = d\n",
        "            break\n",
        "\n",
        "    price, src, col_used = None, None, None\n",
        "    if dsec is not None:\n",
        "        pcol = _find_price_like_col(dsec, ticker)\n",
        "        if pcol is not None:\n",
        "            price = _align(pd.to_numeric(dsec[pcol], errors='coerce'), union_idx)\n",
        "            src, col_used = 'combined', pcol\n",
        "\n",
        "    if price is None and 'df' in globals() and isinstance(df, pd.DataFrame):\n",
        "        pcol_g = _find_price_like_col(df, ticker)\n",
        "        if pcol_g is not None:\n",
        "            price = _align(pd.to_numeric(df[pcol_g], errors='coerce'), union_idx)\n",
        "            src, col_used = 'global', pcol_g\n",
        "\n",
        "    if price is None:\n",
        "        missing.append(ticker)\n",
        "        source_used[ticker] = None\n",
        "        continue\n",
        "\n",
        "    logc = f\"Logclose_{ticker}\"\n",
        "    df_master[logc] = price.astype(float)\n",
        "    source_used[ticker] = (src, col_used)\n",
        "\n",
        "print(\"=== âœ… Logclose columns collected ===\")\n",
        "print(f\"Total: {len([c for c in df_master.columns if 'Logclose_' in c])} stocks\")\n",
        "\n",
        "# ============================================================\n",
        "# 4ï¸âƒ£ Dynamic Start Date per Ticker\n",
        "# ============================================================\n",
        "logclose_cols = [f\"Logclose_{t}\" for t in TARGET_TICKERS if f\"Logclose_{t}\" in df_master.columns]\n",
        "\n",
        "first_valid_dates = {}\n",
        "for c in logclose_cols:\n",
        "    valid = df_master[c].first_valid_index()\n",
        "    first_valid_dates[c] = valid\n",
        "\n",
        "print(\"\\nðŸ“… First available data per stock:\")\n",
        "for k, v in first_valid_dates.items():\n",
        "    print(f\"{k:25s}: {v}\")\n",
        "\n",
        "# --- à¸ªà¸£à¹‰à¸²à¸‡ Dynamic Panel ---\n",
        "df_dynamic = pd.DataFrame(index=df_master.index)\n",
        "for c in logclose_cols:\n",
        "    start_date = first_valid_dates[c]\n",
        "    if start_date is not None:\n",
        "        tmp = df_master.loc[start_date:, c]\n",
        "        df_dynamic[c] = tmp\n",
        "\n",
        "# --- à¹€à¸•à¸´à¸¡à¸„à¹ˆà¸²à¸«à¸¥à¸±à¸‡à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¸”à¹‰à¸§à¸¢ ffill 1 step (à¹€à¸žà¸·à¹ˆà¸­à¸„à¸§à¸²à¸¡à¸•à¹ˆà¸­à¹€à¸™à¸·à¹ˆà¸­à¸‡à¹€à¸¥à¹‡à¸à¸™à¹‰à¸­à¸¢) ---\n",
        "df_dynamic = df_dynamic.sort_index().ffill(limit=1)\n",
        "\n",
        "# ============================================================\n",
        "# 5ï¸âƒ£ Final Panel\n",
        "# ============================================================\n",
        "df = df_dynamic.copy()\n",
        "\n",
        "print(f\"\\nâœ… Dynamic Panel Ready: shape={df.shape}\")\n",
        "print(f\"ðŸ• Date range: {df.index.min().date()} â†’ {df.index.max().date()}\")\n",
        "if missing:\n",
        "    print(f\"\\nâš ï¸ Missing Logclose for: {missing}\")\n",
        "\n",
        "# --- Preview ---\n",
        "try:\n",
        "    from IPython.display import display\n",
        "    display(df.iloc[:10, :6])\n",
        "except Exception:\n",
        "    print(df.iloc[:10, :6])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zejkXEGI1i7n",
        "outputId": "2ac8ded6-2bef-4f86-a08d-6fe7bd7cb839"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting arch\n",
            "  Downloading arch-8.0.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from arch) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from arch) (2.2.2)\n",
            "Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.12/dist-packages (from arch) (1.16.3)\n",
            "Requirement already satisfied: statsmodels>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from arch) (0.14.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from arch) (25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4.0->arch) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4.0->arch) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4.0->arch) (2025.3)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.13.0->arch) (1.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->arch) (1.17.0)\n",
            "Downloading arch-8.0.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (981 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m981.3/981.3 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: arch\n",
            "Successfully installed arch-8.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install arch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03ddfc94",
        "outputId": "9cbff338-c687-4239-cf55-76d608d41f40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Integration Order Detected ===\n",
            "BroadMoney_M1M2_Growth    â†’ I(0)\n",
            "Inflation_Surprise        â†’ I(0)\n",
            "IPI_Surprise              â†’ I(0)\n",
            "THOR_1M                   â†’ I(1)\n",
            "THOR_6M                   â†’ I(1)\n",
            "3M_1M_THOR_Spread         â†’ I(1)\n",
            "6M_1M_THOR_Spread         â†’ I(1)\n",
            "5Y_1Y_Bond_Spread         â†’ I(0)\n",
            "10Y_5Y_Bond_Spread        â†’ I(1)\n",
            "THB_per_USD               â†’ I(1)\n",
            "SET_Index                 â†’ I(1)\n",
            "SP500_Index               â†’ I(1)\n",
            "THB_per_CNY               â†’ I(1)\n",
            "\n",
            "âœ… Built 'combined_dfs_selective_diff' successfully.\n",
            "Diffed Macros (I(1)): ['THOR_1M', 'THOR_6M', '3M_1M_THOR_Spread', '6M_1M_THOR_Spread', '10Y_5Y_Bond_Spread', 'THB_per_USD', 'SET_Index', 'SP500_Index', 'THB_per_CNY']\n",
            "Kept in Levels (I(0)): ['BroadMoney_M1M2_Growth', 'Inflation_Surprise', 'IPI_Surprise', '5Y_1Y_Bond_Spread']\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# âš™ï¸ Build Selectively-Differenced Panel (Diff only I(1))\n",
        "# ============================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "# --- Check availability ---\n",
        "if 'combined_dfs' not in globals() or not isinstance(combined_dfs, dict) or not combined_dfs:\n",
        "    raise RuntimeError(\"âŒ combined_dfs not found or empty. Please run previous block first.\")\n",
        "\n",
        "# --- Helper function: classify I(0) vs I(1) ---\n",
        "def classify_order(series, signif=0.05):\n",
        "    series = series.dropna()\n",
        "    if len(series) < 10:\n",
        "        return None\n",
        "    try:\n",
        "        adf_result = adfuller(series, autolag='AIC')\n",
        "        pval = adf_result[1]\n",
        "        return \"I(0)\" if pval < signif else \"I(1)\"\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "# --- Detect integration order for all macros ---\n",
        "macro_candidates = [\n",
        "    \"BroadMoney_M1M2_Growth\", \"Inflation_Surprise\", \"IPI_Surprise\",\n",
        "    \"THOR_1M\", \"THOR_6M\", \"3M_1M_THOR_Spread\", \"6M_1M_THOR_Spread\",\n",
        "    \"5Y_1Y_Bond_Spread\", \"10Y_5Y_Bond_Spread\",\n",
        "    \"THB_per_USD\", \"SET_Index\",\n",
        "    \"SP500_Index\", \"THB_per_CNY\"\n",
        "]\n",
        "\n",
        "macro_orders = {}\n",
        "for sector, df_sec in combined_dfs.items():\n",
        "    for m in macro_candidates:\n",
        "        if m in df_sec.columns and m not in macro_orders:\n",
        "            order = classify_order(df_sec[m])\n",
        "            if order:\n",
        "                macro_orders[m] = order\n",
        "\n",
        "print(\"=== Integration Order Detected ===\")\n",
        "for k, v in macro_orders.items():\n",
        "    print(f\"{k:25s} â†’ {v}\")\n",
        "\n",
        "# --- Build differenced dataset selectively ---\n",
        "combined_dfs_selective_diff = {}\n",
        "\n",
        "for sector, df_sec in combined_dfs.items():\n",
        "    df_sec = df_sec.copy()\n",
        "    out = pd.DataFrame(index=df_sec.index)\n",
        "\n",
        "    # 1ï¸âƒ£ à¸«à¸¸à¹‰à¸™: à¹ƒà¸Šà¹‰ Î”log à¹€à¸ªà¸¡à¸­\n",
        "    for col in df_sec.columns:\n",
        "        if col.startswith(\"Logclose_\"):\n",
        "            out[col] = df_sec[col].diff()\n",
        "\n",
        "    # 2ï¸âƒ£ Macro: diff à¹€à¸‰à¸žà¸²à¸° I(1)\n",
        "    for m in macro_candidates:\n",
        "        if m not in df_sec.columns:\n",
        "            continue\n",
        "        if macro_orders.get(m, \"I(1)\") == \"I(1)\":\n",
        "            out[m] = df_sec[m].diff()\n",
        "        else:  # I(0)\n",
        "            out[m] = df_sec[m]\n",
        "\n",
        "    # 3ï¸âƒ£ Drop NA\n",
        "    combined_dfs_selective_diff[sector] = out.dropna(how='all')\n",
        "\n",
        "print(\"\\nâœ… Built 'combined_dfs_selective_diff' successfully.\")\n",
        "print(\"Diffed Macros (I(1)):\", [k for k, v in macro_orders.items() if v == \"I(1)\"])\n",
        "print(\"Kept in Levels (I(0)):\", [k for k, v in macro_orders.items() if v == \"I(0)\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 979
        },
        "id": "ge8JSCNOi2m_",
        "outputId": "55448f5a-61bf-408f-d428-aceccdbe6f10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Checking macro variable presence in combined_dfs_selective_diff ===\n",
            "\n",
            "ðŸ“‚ Sector: Banking\n",
            "  â€¢ Stocks found: 7 (Logclose_BBL, Logclose_KBANK, Logclose_KKP, Logclose_KTB, Logclose_TCAP...)\n",
            "  â€¢ Macros present (11): ['BroadMoney_M1M2_Growth', 'Inflation_Surprise', 'IPI_Surprise', 'THOR_6M', '3M_1M_THOR_Spread', '5Y_1Y_Bond_Spread', '10Y_5Y_Bond_Spread', 'THB_per_USD', 'SET_Index', 'SP500_Index', 'THB_per_CNY']\n",
            "  â€¢ Macros missing (0): []\n",
            "--------------------------------------------------------------------------------\n",
            "ðŸ“‚ Sector: Finance_Securities\n",
            "  â€¢ Stocks found: 4 (Logclose_KTC, Logclose_AEONTS, Logclose_JMT, Logclose_SAWAD)\n",
            "  â€¢ Macros present (11): ['BroadMoney_M1M2_Growth', 'Inflation_Surprise', 'IPI_Surprise', 'THOR_6M', '3M_1M_THOR_Spread', '5Y_1Y_Bond_Spread', '10Y_5Y_Bond_Spread', 'THB_per_USD', 'SET_Index', 'SP500_Index', 'THB_per_CNY']\n",
            "  â€¢ Macros missing (0): []\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "=== Summary of Macro Coverage per Sector ===\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_summary\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"Sector\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Finance_Securities\",\n          \"Banking\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"N_stocks\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 4,\n        \"max\": 7,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Macros_present\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 11,\n        \"max\": 11,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Macros_missing\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Missing_list\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_summary"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-733c5594-0344-44a3-a609-591c6ceed599\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sector</th>\n",
              "      <th>N_stocks</th>\n",
              "      <th>Macros_present</th>\n",
              "      <th>Macros_missing</th>\n",
              "      <th>Missing_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Banking</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Finance_Securities</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-733c5594-0344-44a3-a609-591c6ceed599')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-733c5594-0344-44a3-a609-591c6ceed599 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-733c5594-0344-44a3-a609-591c6ceed599');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_36be1e1d-1bce-48be-8079-4af28dfd86aa\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_summary')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_36be1e1d-1bce-48be-8079-4af28dfd86aa button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_summary');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "               Sector  N_stocks  Macros_present  Macros_missing Missing_list\n",
              "0             Banking         7              11               0             \n",
              "1  Finance_Securities         4              11               0             "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Removed first NaN row and cleaned selective-diff dataframes successfully.\n",
            "\n",
            "=== Example after cleaning: 'Banking' ===\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"display(combined_dfs_selective_diff[sector_to_inspect]\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2015-03-01 00:00:00\",\n        \"max\": \"2015-12-01 00:00:00\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"2015-11-01 00:00:00\",\n          \"2015-04-01 00:00:00\",\n          \"2015-08-01 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_BBL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.041386724197883876,\n        \"min\": -0.08728284647822715,\n        \"max\": 0.05831017378275849,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.0,\n          0.002706703761200302,\n          -0.009077207776929441\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_KBANK\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.053093982854199764,\n        \"min\": -0.12438366339666906,\n        \"max\": 0.053824475322254095,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          -0.008733450018356237,\n          -0.08661439579898023,\n          0.013947463217661493\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_KKP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07489405547444718,\n        \"min\": -0.1447388269817762,\n        \"max\": 0.11596099200057042,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.0857666170710436,\n          -0.05264403534899387,\n          0.05579121489093186\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_KTB\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05069759123443731,\n        \"min\": -0.1310282444952402,\n        \"max\": 0.039220693234364834,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          -0.00586516725688524,\n          -0.1310282444952402,\n          0.039220693234364834\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_TCAP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0515230264599097,\n        \"min\": -0.06203530528910495,\n        \"max\": 0.07350270499285294,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.07321422468533356,\n          -0.02181917848164394,\n          -0.05762948663452905\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_TISCO\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06707738968416622,\n        \"min\": -0.10676782807482121,\n        \"max\": 0.10668414070871535,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.10668414070871535,\n          -0.01098912759114068,\n          -0.07320368569016011\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logclose_TTB\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06397347687555906,\n        \"min\": -0.13641196593804145,\n        \"max\": 0.0945580108487395,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          -0.022814372173894648,\n          -0.13641196593804145,\n          0.0085105438050182\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BroadMoney_M1M2_Growth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0065984557901388186,\n        \"min\": -0.005074892972240728,\n        \"max\": 0.015938220710077576,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.015938220710077576,\n          -0.0015500193021271292,\n          -0.0025739528159563017\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Inflation_Surprise\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0013093255261138583,\n        \"min\": -0.0026000000000000007,\n        \"max\": 0.0016999999999999984,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          -0.0011999999999999988,\n          9.99999999999994e-05,\n          -0.0018999999999999998\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IPI_Surprise\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0002984172321506324,\n        \"min\": -0.00067,\n        \"max\": 0.00037999999999999997,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          -4.199999999999999e-05,\n          -0.00067,\n          4.500000000000001e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"THOR_1M\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0008223859745345314,\n        \"min\": -0.0019887000000000012,\n        \"max\": 7.500000000000562e-06,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1.3999999999968898e-06,\n          -0.0017408000000000007,\n          -9.099999999999733e-06\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"THOR_6M\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0003917997254834278,\n        \"min\": -0.0009302000000000026,\n        \"max\": 0.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.0,\n          -0.00029020000000000434,\n          -0.000853099999999999\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"3M_1M_THOR_Spread\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0006111912274857651,\n        \"min\": -0.001082600000000003,\n        \"max\": 0.0011352999999999988,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          -8.999999999946551e-07,\n          0.0011352999999999988,\n          -0.0007472999999999994\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"6M_1M_THOR_Spread\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0008870153251839056,\n        \"min\": -0.0009315999999999994,\n        \"max\": 0.0014505999999999963,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          -0.0009315999999999994,\n          0.0014505999999999963,\n          -0.0008439999999999993\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"5Y_1Y_Bond_Spread\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0007253543195493414,\n        \"min\": 0.004150000000000001,\n        \"max\": 0.006299999999999998,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.005299999999999999,\n          0.0048000000000000004,\n          0.005300000000000003\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"10Y_5Y_Bond_Spread\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0012537610085924134,\n        \"min\": -0.001899999999999999,\n        \"max\": 0.002700000000000001,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.0010499999999999989,\n          -0.0006999999999999992,\n          -0.00010000000000000286\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"THB_per_USD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5791193199982163,\n        \"min\": -0.7900009155273438,\n        \"max\": 1.3610000610351562,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.2840003967285156,\n          0.2980003356933594,\n          0.6329994201660156\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SET_Index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 43.62481382091014,\n        \"min\": -79.6500244140625,\n        \"max\": 68.18994140625,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          68.18994140625,\n          -56.56005859375,\n          -49.5799560546875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SP500_Index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 76.12387614545916,\n        \"min\": -131.6600341796875,\n        \"max\": 159.330078125,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1.0498046875,\n          17.6201171875,\n          -131.6600341796875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"THB_per_CNY\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0033448528827884744,\n        \"min\": -0.00703999400138855,\n        \"max\": 0.00330999493598938,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          -0.0005200058221817017,\n          -0.0021300017833709717,\n          0.0014999955892562866\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-e1f4c6de-03c0-4e09-b912-b1c58e2f4cea\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Logclose_BBL</th>\n",
              "      <th>Logclose_KBANK</th>\n",
              "      <th>Logclose_KKP</th>\n",
              "      <th>Logclose_KTB</th>\n",
              "      <th>Logclose_TCAP</th>\n",
              "      <th>Logclose_TISCO</th>\n",
              "      <th>Logclose_TTB</th>\n",
              "      <th>BroadMoney_M1M2_Growth</th>\n",
              "      <th>Inflation_Surprise</th>\n",
              "      <th>IPI_Surprise</th>\n",
              "      <th>THOR_1M</th>\n",
              "      <th>THOR_6M</th>\n",
              "      <th>3M_1M_THOR_Spread</th>\n",
              "      <th>6M_1M_THOR_Spread</th>\n",
              "      <th>5Y_1Y_Bond_Spread</th>\n",
              "      <th>10Y_5Y_Bond_Spread</th>\n",
              "      <th>THB_per_USD</th>\n",
              "      <th>SET_Index</th>\n",
              "      <th>SP500_Index</th>\n",
              "      <th>THB_per_CNY</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2015-03-01</th>\n",
              "      <td>0.008163</td>\n",
              "      <td>0.053824</td>\n",
              "      <td>-0.006390</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.007169</td>\n",
              "      <td>-0.026956</td>\n",
              "      <td>-0.013334</td>\n",
              "      <td>0.004617</td>\n",
              "      <td>-0.0019</td>\n",
              "      <td>0.000380</td>\n",
              "      <td>-1.260000e-05</td>\n",
              "      <td>-0.000004</td>\n",
              "      <td>1.670000e-05</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.00450</td>\n",
              "      <td>0.00020</td>\n",
              "      <td>0.199001</td>\n",
              "      <td>-0.559937</td>\n",
              "      <td>-36.610107</td>\n",
              "      <td>-0.00295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-04-01</th>\n",
              "      <td>0.002707</td>\n",
              "      <td>-0.086614</td>\n",
              "      <td>-0.052644</td>\n",
              "      <td>-0.131028</td>\n",
              "      <td>-0.021819</td>\n",
              "      <td>-0.010989</td>\n",
              "      <td>-0.136412</td>\n",
              "      <td>-0.001550</td>\n",
              "      <td>-0.0012</td>\n",
              "      <td>-0.000670</td>\n",
              "      <td>-1.740800e-03</td>\n",
              "      <td>-0.000290</td>\n",
              "      <td>1.135300e-03</td>\n",
              "      <td>0.001451</td>\n",
              "      <td>0.00480</td>\n",
              "      <td>-0.00070</td>\n",
              "      <td>0.298000</td>\n",
              "      <td>-56.560059</td>\n",
              "      <td>17.620117</td>\n",
              "      <td>-0.00213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-05-01</th>\n",
              "      <td>0.007367</td>\n",
              "      <td>-0.059038</td>\n",
              "      <td>0.008061</td>\n",
              "      <td>-0.060770</td>\n",
              "      <td>0.036526</td>\n",
              "      <td>0.038183</td>\n",
              "      <td>-0.001686</td>\n",
              "      <td>0.001422</td>\n",
              "      <td>-0.0024</td>\n",
              "      <td>-0.000330</td>\n",
              "      <td>-1.272900e-03</td>\n",
              "      <td>-0.000581</td>\n",
              "      <td>1.132000e-04</td>\n",
              "      <td>0.000692</td>\n",
              "      <td>0.00420</td>\n",
              "      <td>0.00270</td>\n",
              "      <td>0.896000</td>\n",
              "      <td>-5.699951</td>\n",
              "      <td>21.879883</td>\n",
              "      <td>-0.00476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-06-01</th>\n",
              "      <td>-0.022223</td>\n",
              "      <td>-0.031253</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>-0.056834</td>\n",
              "      <td>-0.029632</td>\n",
              "      <td>0.021979</td>\n",
              "      <td>-0.082013</td>\n",
              "      <td>-0.005075</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.000280</td>\n",
              "      <td>-1.988700e-03</td>\n",
              "      <td>-0.000740</td>\n",
              "      <td>5.740000e-04</td>\n",
              "      <td>0.001249</td>\n",
              "      <td>0.00560</td>\n",
              "      <td>0.00040</td>\n",
              "      <td>-0.005001</td>\n",
              "      <td>-43.010010</td>\n",
              "      <td>-44.279785</td>\n",
              "      <td>0.00008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-07-01</th>\n",
              "      <td>-0.069796</td>\n",
              "      <td>-0.059963</td>\n",
              "      <td>-0.144739</td>\n",
              "      <td>0.023122</td>\n",
              "      <td>-0.062035</td>\n",
              "      <td>-0.079137</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.001889</td>\n",
              "      <td>-0.0007</td>\n",
              "      <td>-0.000285</td>\n",
              "      <td>-4.200000e-06</td>\n",
              "      <td>-0.000885</td>\n",
              "      <td>-1.082600e-03</td>\n",
              "      <td>-0.000881</td>\n",
              "      <td>0.00630</td>\n",
              "      <td>-0.00190</td>\n",
              "      <td>1.361000</td>\n",
              "      <td>14.750000</td>\n",
              "      <td>40.729980</td>\n",
              "      <td>-0.00704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-08-01</th>\n",
              "      <td>-0.009077</td>\n",
              "      <td>0.013947</td>\n",
              "      <td>0.055791</td>\n",
              "      <td>0.039221</td>\n",
              "      <td>-0.057629</td>\n",
              "      <td>-0.073204</td>\n",
              "      <td>0.008511</td>\n",
              "      <td>-0.002574</td>\n",
              "      <td>-0.0007</td>\n",
              "      <td>0.000045</td>\n",
              "      <td>-9.100000e-06</td>\n",
              "      <td>-0.000853</td>\n",
              "      <td>-7.473000e-04</td>\n",
              "      <td>-0.000844</td>\n",
              "      <td>0.00530</td>\n",
              "      <td>-0.00010</td>\n",
              "      <td>0.632999</td>\n",
              "      <td>-49.579956</td>\n",
              "      <td>-131.660034</td>\n",
              "      <td>0.00150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-09-01</th>\n",
              "      <td>-0.027737</td>\n",
              "      <td>-0.054068</td>\n",
              "      <td>-0.047628</td>\n",
              "      <td>-0.062343</td>\n",
              "      <td>0.073503</td>\n",
              "      <td>-0.106768</td>\n",
              "      <td>0.025106</td>\n",
              "      <td>0.003077</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>-0.000200</td>\n",
              "      <td>4.000000e-07</td>\n",
              "      <td>-0.000763</td>\n",
              "      <td>-3.900000e-06</td>\n",
              "      <td>-0.000763</td>\n",
              "      <td>0.00575</td>\n",
              "      <td>-0.00085</td>\n",
              "      <td>0.674000</td>\n",
              "      <td>-79.650024</td>\n",
              "      <td>-52.150024</td>\n",
              "      <td>-0.00361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-10-01</th>\n",
              "      <td>0.058310</td>\n",
              "      <td>0.011539</td>\n",
              "      <td>0.115961</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.053653</td>\n",
              "      <td>0.061453</td>\n",
              "      <td>0.094558</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>-0.000200</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00575</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>-0.790001</td>\n",
              "      <td>-17.239990</td>\n",
              "      <td>159.330078</td>\n",
              "      <td>0.00263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-11-01</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.008733</td>\n",
              "      <td>0.085767</td>\n",
              "      <td>-0.005865</td>\n",
              "      <td>0.073214</td>\n",
              "      <td>0.106684</td>\n",
              "      <td>-0.022814</td>\n",
              "      <td>0.015938</td>\n",
              "      <td>0.0017</td>\n",
              "      <td>-0.000042</td>\n",
              "      <td>1.400000e-06</td>\n",
              "      <td>-0.000930</td>\n",
              "      <td>-9.000000e-07</td>\n",
              "      <td>-0.000932</td>\n",
              "      <td>0.00530</td>\n",
              "      <td>0.00105</td>\n",
              "      <td>0.284000</td>\n",
              "      <td>68.189941</td>\n",
              "      <td>1.049805</td>\n",
              "      <td>-0.00052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-12-01</th>\n",
              "      <td>-0.087283</td>\n",
              "      <td>-0.124384</td>\n",
              "      <td>-0.006873</td>\n",
              "      <td>-0.011834</td>\n",
              "      <td>0.034847</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.071744</td>\n",
              "      <td>0.011460</td>\n",
              "      <td>-0.0026</td>\n",
              "      <td>0.000210</td>\n",
              "      <td>7.500000e-06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-4.600000e-06</td>\n",
              "      <td>-0.000008</td>\n",
              "      <td>0.00415</td>\n",
              "      <td>-0.00085</td>\n",
              "      <td>0.105000</td>\n",
              "      <td>-56.329956</td>\n",
              "      <td>-36.469971</td>\n",
              "      <td>0.00331</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1f4c6de-03c0-4e09-b912-b1c58e2f4cea')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e1f4c6de-03c0-4e09-b912-b1c58e2f4cea button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e1f4c6de-03c0-4e09-b912-b1c58e2f4cea');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "            Logclose_BBL  Logclose_KBANK  Logclose_KKP  Logclose_KTB  \\\n",
              "Date                                                                   \n",
              "2015-03-01      0.008163        0.053824     -0.006390      0.000000   \n",
              "2015-04-01      0.002707       -0.086614     -0.052644     -0.131028   \n",
              "2015-05-01      0.007367       -0.059038      0.008061     -0.060770   \n",
              "2015-06-01     -0.022223       -0.031253     -0.021053     -0.056834   \n",
              "2015-07-01     -0.069796       -0.059963     -0.144739      0.023122   \n",
              "2015-08-01     -0.009077        0.013947      0.055791      0.039221   \n",
              "2015-09-01     -0.027737       -0.054068     -0.047628     -0.062343   \n",
              "2015-10-01      0.058310        0.011539      0.115961      0.000000   \n",
              "2015-11-01      0.000000       -0.008733      0.085767     -0.005865   \n",
              "2015-12-01     -0.087283       -0.124384     -0.006873     -0.011834   \n",
              "\n",
              "            Logclose_TCAP  Logclose_TISCO  Logclose_TTB  \\\n",
              "Date                                                      \n",
              "2015-03-01      -0.007169       -0.026956     -0.013334   \n",
              "2015-04-01      -0.021819       -0.010989     -0.136412   \n",
              "2015-05-01       0.036526        0.038183     -0.001686   \n",
              "2015-06-01      -0.029632        0.021979     -0.082013   \n",
              "2015-07-01      -0.062035       -0.079137      0.000000   \n",
              "2015-08-01      -0.057629       -0.073204      0.008511   \n",
              "2015-09-01       0.073503       -0.106768      0.025106   \n",
              "2015-10-01       0.053653        0.061453      0.094558   \n",
              "2015-11-01       0.073214        0.106684     -0.022814   \n",
              "2015-12-01       0.034847        0.000000     -0.071744   \n",
              "\n",
              "            BroadMoney_M1M2_Growth  Inflation_Surprise  IPI_Surprise  \\\n",
              "Date                                                                   \n",
              "2015-03-01                0.004617             -0.0019      0.000380   \n",
              "2015-04-01               -0.001550             -0.0012     -0.000670   \n",
              "2015-05-01                0.001422             -0.0024     -0.000330   \n",
              "2015-06-01               -0.005075             -0.0015     -0.000280   \n",
              "2015-07-01               -0.001889             -0.0007     -0.000285   \n",
              "2015-08-01               -0.002574             -0.0007      0.000045   \n",
              "2015-09-01                0.003077              0.0001     -0.000200   \n",
              "2015-10-01                0.000000              0.0001     -0.000200   \n",
              "2015-11-01                0.015938              0.0017     -0.000042   \n",
              "2015-12-01                0.011460             -0.0026      0.000210   \n",
              "\n",
              "                 THOR_1M   THOR_6M  3M_1M_THOR_Spread  6M_1M_THOR_Spread  \\\n",
              "Date                                                                       \n",
              "2015-03-01 -1.260000e-05 -0.000004       1.670000e-05           0.000009   \n",
              "2015-04-01 -1.740800e-03 -0.000290       1.135300e-03           0.001451   \n",
              "2015-05-01 -1.272900e-03 -0.000581       1.132000e-04           0.000692   \n",
              "2015-06-01 -1.988700e-03 -0.000740       5.740000e-04           0.001249   \n",
              "2015-07-01 -4.200000e-06 -0.000885      -1.082600e-03          -0.000881   \n",
              "2015-08-01 -9.100000e-06 -0.000853      -7.473000e-04          -0.000844   \n",
              "2015-09-01  4.000000e-07 -0.000763      -3.900000e-06          -0.000763   \n",
              "2015-10-01  0.000000e+00  0.000000       0.000000e+00           0.000000   \n",
              "2015-11-01  1.400000e-06 -0.000930      -9.000000e-07          -0.000932   \n",
              "2015-12-01  7.500000e-06  0.000000      -4.600000e-06          -0.000008   \n",
              "\n",
              "            5Y_1Y_Bond_Spread  10Y_5Y_Bond_Spread  THB_per_USD  SET_Index  \\\n",
              "Date                                                                        \n",
              "2015-03-01            0.00450             0.00020     0.199001  -0.559937   \n",
              "2015-04-01            0.00480            -0.00070     0.298000 -56.560059   \n",
              "2015-05-01            0.00420             0.00270     0.896000  -5.699951   \n",
              "2015-06-01            0.00560             0.00040    -0.005001 -43.010010   \n",
              "2015-07-01            0.00630            -0.00190     1.361000  14.750000   \n",
              "2015-08-01            0.00530            -0.00010     0.632999 -49.579956   \n",
              "2015-09-01            0.00575            -0.00085     0.674000 -79.650024   \n",
              "2015-10-01            0.00575             0.00000    -0.790001 -17.239990   \n",
              "2015-11-01            0.00530             0.00105     0.284000  68.189941   \n",
              "2015-12-01            0.00415            -0.00085     0.105000 -56.329956   \n",
              "\n",
              "            SP500_Index  THB_per_CNY  \n",
              "Date                                  \n",
              "2015-03-01   -36.610107     -0.00295  \n",
              "2015-04-01    17.620117     -0.00213  \n",
              "2015-05-01    21.879883     -0.00476  \n",
              "2015-06-01   -44.279785      0.00008  \n",
              "2015-07-01    40.729980     -0.00704  \n",
              "2015-08-01  -131.660034      0.00150  \n",
              "2015-09-01   -52.150024     -0.00361  \n",
              "2015-10-01   159.330078      0.00263  \n",
              "2015-11-01     1.049805     -0.00052  \n",
              "2015-12-01   -36.469971      0.00331  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ============================================================\n",
        "# ðŸ” CHECK DATA CONSISTENCY BEFORE ARDL (Selective Diff Version)\n",
        "# ============================================================\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "print(\"=== Checking macro variable presence in combined_dfs_selective_diff ===\\n\")\n",
        "\n",
        "# List à¸‚à¸­à¸‡à¸•à¸±à¸§à¹à¸›à¸£à¸—à¸µà¹ˆ ARDL à¸•à¹‰à¸­à¸‡à¹ƒà¸Šà¹‰ (à¸›à¸£à¸±à¸šà¹ƒà¸«à¹‰à¸•à¸£à¸‡à¸à¸±à¸š macro_vars à¸ˆà¸£à¸´à¸‡)\n",
        "macro_vars = [\n",
        "    \"BroadMoney_M1M2_Growth\", \"Inflation_Surprise\", \"IPI_Surprise\",\n",
        "    \"THOR_6M\", \"3M_1M_THOR_Spread\",\n",
        "    \"5Y_1Y_Bond_Spread\", \"10Y_5Y_Bond_Spread\",\n",
        "    \"THB_per_USD\", \"SET_Index\",\n",
        "    \"SP500_Index\", \"THB_per_CNY\"\n",
        "]\n",
        "\n",
        "summary_records = []\n",
        "\n",
        "for sector, df_sec in combined_dfs_selective_diff.items():\n",
        "    present = [m for m in macro_vars if m in df_sec.columns]\n",
        "    missing = [m for m in macro_vars if m not in df_sec.columns]\n",
        "    logclose_cols = [c for c in df_sec.columns if c.startswith(\"Logclose_\")]\n",
        "\n",
        "    print(f\"ðŸ“‚ Sector: {sector}\")\n",
        "    print(f\"  â€¢ Stocks found: {len(logclose_cols)} ({', '.join(logclose_cols[:5])}{'...' if len(logclose_cols)>5 else ''})\")\n",
        "    print(f\"  â€¢ Macros present ({len(present)}): {present}\")\n",
        "    print(f\"  â€¢ Macros missing ({len(missing)}): {missing}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    summary_records.append({\n",
        "        \"Sector\": sector,\n",
        "        \"N_stocks\": len(logclose_cols),\n",
        "        \"Macros_present\": len(present),\n",
        "        \"Macros_missing\": len(missing),\n",
        "        \"Missing_list\": \", \".join(missing)\n",
        "    })\n",
        "\n",
        "# à¸£à¸§à¸¡à¹€à¸›à¹‡à¸™à¸•à¸²à¸£à¸²à¸‡à¸ à¸²à¸žà¸£à¸§à¸¡\n",
        "df_summary = pd.DataFrame(summary_records)\n",
        "print(\"\\n=== Summary of Macro Coverage per Sector ===\")\n",
        "display(df_summary)\n",
        "\n",
        "# # à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡ dataframe à¸ˆà¸£à¸´à¸‡\n",
        "# sector_to_inspect = list(combined_dfs_selective_diff.keys())[0]\n",
        "# print(f\"\\n\\n=== Example: head() of combined_dfs_selective_diff['{sector_to_inspect}'] ===\")\n",
        "# display(combined_dfs_selective_diff[sector_to_inspect].head(10))\n",
        "\n",
        "# ============================================================\n",
        "# ðŸ§¹ CLEAN: Drop first NaN row from all selective-diff dataframes\n",
        "# ============================================================\n",
        "\n",
        "for sector in combined_dfs_selective_diff:\n",
        "    df_tmp = combined_dfs_selective_diff[sector].copy()\n",
        "\n",
        "    # à¸¥à¸šà¹à¸–à¸§à¹à¸£à¸à¸—à¸µà¹ˆà¹€à¸›à¹‡à¸™ NaN à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”\n",
        "    df_tmp = df_tmp.dropna(how=\"all\")\n",
        "\n",
        "    # à¸¥à¸š NaN à¹€à¸‰à¸žà¸²à¸°à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸«à¸¥à¸±à¸ (à¸–à¹‰à¸²à¸šà¸²à¸‡ macro à¹€à¸£à¸´à¹ˆà¸¡à¸Šà¹‰à¸²)\n",
        "    df_tmp = df_tmp.dropna(thresh=int(0.8 * len(df_tmp.columns)))  # à¸­à¸¢à¹ˆà¸²à¸‡à¸™à¹‰à¸­à¸¢ 80% à¸•à¹‰à¸­à¸‡à¹„à¸¡à¹ˆ NA\n",
        "\n",
        "    combined_dfs_selective_diff[sector] = df_tmp\n",
        "\n",
        "print(\"âœ… Removed first NaN row and cleaned selective-diff dataframes successfully.\\n\")\n",
        "\n",
        "# à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸«à¸¥à¸±à¸‡ clean\n",
        "sector_to_inspect = list(combined_dfs_selective_diff.keys())[0]\n",
        "print(f\"=== Example after cleaning: '{sector_to_inspect}' ===\")\n",
        "display(combined_dfs_selective_diff[sector_to_inspect].head(10))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TX-tHo1AHRqs"
      },
      "source": [
        "# ARDL + ECM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqmP28-XHTYE",
        "outputId": "3ddae3ab-5c8b-45b8-ad49-b6de10cb309f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== ðŸ“‚ Sector: Banking =====\n",
            "â³ ARDL(p=3,q=3) fit: BBL (119 obs, 11 Xs)...\n",
            "âœ… BBL: Î±=-1.4067, p=0.000, RÂ²=0.785\n",
            "â³ ARDL(p=3,q=3) fit: KBANK (119 obs, 11 Xs)...\n",
            "âœ… KBANK: Î±=-1.2785, p=0.000, RÂ²=0.749\n",
            "â³ ARDL(p=3,q=3) fit: KKP (119 obs, 11 Xs)...\n",
            "âœ… KKP: Î±=-1.2168, p=0.000, RÂ²=0.780\n",
            "â³ ARDL(p=3,q=3) fit: KTB (119 obs, 11 Xs)...\n",
            "âœ… KTB: Î±=-1.1768, p=0.000, RÂ²=0.712\n",
            "â³ ARDL(p=3,q=3) fit: TCAP (119 obs, 11 Xs)...\n",
            "âœ… TCAP: Î±=-1.3892, p=0.000, RÂ²=0.811\n",
            "â³ ARDL(p=3,q=3) fit: TISCO (119 obs, 11 Xs)...\n",
            "âœ… TISCO: Î±=-1.1359, p=0.000, RÂ²=0.768\n",
            "â³ ARDL(p=3,q=3) fit: TTB (119 obs, 11 Xs)...\n",
            "âœ… TTB: Î±=-1.4532, p=0.000, RÂ²=0.766\n",
            "\n",
            "===== ðŸ“‚ Sector: Finance_Securities =====\n",
            "â³ ARDL(p=3,q=3) fit: KTC (119 obs, 11 Xs)...\n",
            "âœ… KTC: Î±=-0.8296, p=0.000, RÂ²=0.702\n",
            "â³ ARDL(p=3,q=3) fit: AEONTS (119 obs, 11 Xs)...\n",
            "âœ… AEONTS: Î±=-1.1432, p=0.000, RÂ²=0.725\n",
            "â³ ARDL(p=3,q=3) fit: JMT (119 obs, 11 Xs)...\n",
            "âœ… JMT: Î±=-0.9830, p=0.000, RÂ²=0.550\n",
            "â³ ARDL(p=3,q=3) fit: SAWAD (119 obs, 11 Xs)...\n",
            "âœ… SAWAD: Î±=-1.3086, p=0.000, RÂ²=0.646\n",
            "\n",
            "âœ… Exported â†’ Stock_ARDL_ECM_FixedLag3_GROUPED.xlsx\n",
            "\n",
            "========================================================================================\n",
            "ðŸ“‚ Sector: Banking\n",
            "========================================================================================\n",
            "\n",
            "--- BBL ---\n",
            "Î± (ECT speed): -1.4067***   p=0.000\n",
            "\n",
            "Long-run Relationship (Î²):\n",
            "              Variable  Î² (Long-run)\n",
            "                 const     -0.007671\n",
            "BroadMoney_M1M2_Growth     -1.551600\n",
            "    Inflation_Surprise      1.031999\n",
            "          IPI_Surprise     43.670218\n",
            "               THOR_6M      4.388908\n",
            "     3M_1M_THOR_Spread     -4.262637\n",
            "     5Y_1Y_Bond_Spread      3.137091\n",
            "    10Y_5Y_Bond_Spread     -7.292723\n",
            "           THB_per_USD     -0.005875\n",
            "             SET_Index      0.000078\n",
            "           SP500_Index      0.000171\n",
            "           THB_per_CNY      2.431789\n",
            "\n",
            "Short-run Dynamics (Î³):\n",
            "                   Variable     Coef     pval Signif\n",
            "       D.10Y_5Y_Bond_Spread   1.6856   0.6826       \n",
            "    D.L1.10Y_5Y_Bond_Spread   2.4216   0.4898       \n",
            "    D.L2.10Y_5Y_Bond_Spread  -1.1393   0.5993       \n",
            "        D.3M_1M_THOR_Spread -12.1887   0.1383       \n",
            "     D.L1.3M_1M_THOR_Spread   4.5789   0.6563       \n",
            "     D.L2.3M_1M_THOR_Spread  27.3022   0.0128     **\n",
            "        D.5Y_1Y_Bond_Spread  12.3206   0.0000    ***\n",
            "     D.L1.5Y_1Y_Bond_Spread   0.1793   0.9482       \n",
            "     D.L2.5Y_1Y_Bond_Spread  -1.7374   0.4243       \n",
            "   D.BroadMoney_M1M2_Growth  -2.0459   0.0040    ***\n",
            "D.L1.BroadMoney_M1M2_Growth   0.8670   0.1244       \n",
            "D.L2.BroadMoney_M1M2_Growth   0.2340   0.6506       \n",
            "             D.IPI_Surprise  50.0952   0.0024    ***\n",
            "          D.L1.IPI_Surprise -17.5825   0.1841       \n",
            "          D.L2.IPI_Surprise -20.8617   0.2547       \n",
            "       D.Inflation_Surprise  -0.2023   0.8356       \n",
            "    D.L1.Inflation_Surprise  -2.6057   0.0025    ***\n",
            "    D.L2.Inflation_Surprise  -1.9813   0.0375     **\n",
            "          D.L1.Logclose_BBL   0.2959   0.0335     **\n",
            "          D.L2.Logclose_BBL   0.0723   0.5333       \n",
            "                D.SET_Index   0.0001   0.5083       \n",
            "             D.L1.SET_Index   0.0000   0.7229       \n",
            "             D.L2.SET_Index  -0.0001   0.3120       \n",
            "              D.SP500_Index   0.0001   0.0000    ***\n",
            "           D.L1.SP500_Index  -0.0001   0.0009    ***\n",
            "           D.L2.SP500_Index  -0.0001   0.0001    ***\n",
            "              D.THB_per_CNY  -0.7116   0.6119       \n",
            "           D.L1.THB_per_CNY  -1.8705   0.2568       \n",
            "           D.L2.THB_per_CNY  -4.2105   0.0489     **\n",
            "              D.THB_per_USD  -0.0206   0.0140     **\n",
            "           D.L1.THB_per_USD  -0.0090   0.1889       \n",
            "           D.L2.THB_per_USD  -0.0197   0.0085    ***\n",
            "                  D.THOR_6M  14.3659   0.4649       \n",
            "               D.L1.THOR_6M  43.9836   0.0011    ***\n",
            "               D.L2.THOR_6M  43.1513   0.0013    ***\n",
            "                      const   0.0000   1.0000       \n",
            "----------------------------------------------------------------------------------------\n",
            "\n",
            "--- KBANK ---\n",
            "Î± (ECT speed): -1.2785***   p=0.000\n",
            "\n",
            "Long-run Relationship (Î²):\n",
            "              Variable  Î² (Long-run)\n",
            "                 const      0.006435\n",
            "BroadMoney_M1M2_Growth     -2.836262\n",
            "    Inflation_Surprise      6.845581\n",
            "          IPI_Surprise     50.498108\n",
            "               THOR_6M     10.994843\n",
            "     3M_1M_THOR_Spread     -2.019797\n",
            "     5Y_1Y_Bond_Spread      0.698867\n",
            "    10Y_5Y_Bond_Spread      8.126561\n",
            "           THB_per_USD     -0.030424\n",
            "             SET_Index      0.000064\n",
            "           SP500_Index      0.000193\n",
            "           THB_per_CNY     -3.499476\n",
            "\n",
            "Short-run Dynamics (Î³):\n",
            "                   Variable     Coef     pval Signif\n",
            "       D.10Y_5Y_Bond_Spread  10.4291   0.0139     **\n",
            "    D.L1.10Y_5Y_Bond_Spread  -3.5621   0.3732       \n",
            "    D.L2.10Y_5Y_Bond_Spread  -6.0934   0.0934      *\n",
            "        D.3M_1M_THOR_Spread -14.8199   0.0902      *\n",
            "     D.L1.3M_1M_THOR_Spread -18.4918   0.1633       \n",
            "     D.L2.3M_1M_THOR_Spread  21.4524   0.1803       \n",
            "        D.5Y_1Y_Bond_Spread  16.2066   0.0001    ***\n",
            "     D.L1.5Y_1Y_Bond_Spread  -3.4029   0.2737       \n",
            "     D.L2.5Y_1Y_Bond_Spread   2.2952   0.6102       \n",
            "   D.BroadMoney_M1M2_Growth  -3.1938   0.0000    ***\n",
            "D.L1.BroadMoney_M1M2_Growth   1.7410   0.0643      *\n",
            "D.L2.BroadMoney_M1M2_Growth   2.3440   0.0000    ***\n",
            "             D.IPI_Surprise  68.3154   0.0016    ***\n",
            "          D.L1.IPI_Surprise -14.0883   0.4185       \n",
            "          D.L2.IPI_Surprise -21.1874   0.2991       \n",
            "       D.Inflation_Surprise   0.1311   0.9258       \n",
            "    D.L1.Inflation_Surprise  -5.9264   0.0000    ***\n",
            "    D.L2.Inflation_Surprise  -3.4795   0.0032    ***\n",
            "        D.L1.Logclose_KBANK   0.3549   0.0217     **\n",
            "        D.L2.Logclose_KBANK   0.2574   0.0516      *\n",
            "                D.SET_Index   0.0000   0.9094       \n",
            "             D.L1.SET_Index   0.0000   0.8898       \n",
            "             D.L2.SET_Index   0.0001   0.1721       \n",
            "              D.SP500_Index   0.0002   0.0000    ***\n",
            "           D.L1.SP500_Index  -0.0001   0.0110     **\n",
            "           D.L2.SP500_Index  -0.0001   0.0627      *\n",
            "              D.THB_per_CNY  -1.9223   0.3002       \n",
            "           D.L1.THB_per_CNY   4.7106   0.0291     **\n",
            "           D.L2.THB_per_CNY  -1.7934   0.4804       \n",
            "              D.THB_per_USD  -0.0378   0.0000    ***\n",
            "           D.L1.THB_per_USD   0.0088   0.2750       \n",
            "           D.L2.THB_per_USD  -0.0142   0.1774       \n",
            "                  D.THOR_6M -23.1867   0.4071       \n",
            "               D.L1.THOR_6M  58.4483   0.0311     **\n",
            "               D.L2.THOR_6M  48.7413   0.2427       \n",
            "                      const  -0.0000   1.0000       \n",
            "----------------------------------------------------------------------------------------\n",
            "\n",
            "--- KKP ---\n",
            "Î± (ECT speed): -1.2168***   p=0.000\n",
            "\n",
            "Long-run Relationship (Î²):\n",
            "              Variable  Î² (Long-run)\n",
            "                 const     -0.012937\n",
            "BroadMoney_M1M2_Growth     -2.071675\n",
            "    Inflation_Surprise      3.822940\n",
            "          IPI_Surprise     18.199522\n",
            "               THOR_6M    -24.137466\n",
            "     3M_1M_THOR_Spread     10.751509\n",
            "     5Y_1Y_Bond_Spread      4.088882\n",
            "    10Y_5Y_Bond_Spread    -21.625896\n",
            "           THB_per_USD      0.005848\n",
            "             SET_Index      0.000159\n",
            "           SP500_Index      0.000484\n",
            "           THB_per_CNY      5.114228\n",
            "\n",
            "Short-run Dynamics (Î³):\n",
            "                   Variable     Coef     pval Signif\n",
            "       D.10Y_5Y_Bond_Spread   1.6089   0.7191       \n",
            "    D.L1.10Y_5Y_Bond_Spread   9.6823   0.0265     **\n",
            "    D.L2.10Y_5Y_Bond_Spread   2.0573   0.6546       \n",
            "        D.3M_1M_THOR_Spread -11.2806   0.3394       \n",
            "     D.L1.3M_1M_THOR_Spread -14.3498   0.3431       \n",
            "     D.L2.3M_1M_THOR_Spread  15.5122   0.2006       \n",
            "        D.5Y_1Y_Bond_Spread  13.2936   0.0006    ***\n",
            "     D.L1.5Y_1Y_Bond_Spread   0.2920   0.9149       \n",
            "     D.L2.5Y_1Y_Bond_Spread  -7.6903   0.0503      *\n",
            "   D.BroadMoney_M1M2_Growth  -3.5850   0.0099    ***\n",
            "D.L1.BroadMoney_M1M2_Growth   2.1298   0.0485     **\n",
            "D.L2.BroadMoney_M1M2_Growth   2.3561   0.0014    ***\n",
            "             D.IPI_Surprise  68.9508   0.0024    ***\n",
            "          D.L1.IPI_Surprise  -0.0143   0.9994       \n",
            "          D.L2.IPI_Surprise -13.6058   0.4469       \n",
            "       D.Inflation_Surprise  -0.3361   0.8182       \n",
            "    D.L1.Inflation_Surprise  -4.7466   0.0009    ***\n",
            "    D.L2.Inflation_Surprise  -3.2884   0.0102     **\n",
            "          D.L1.Logclose_KKP   0.1111   0.2820       \n",
            "          D.L2.Logclose_KKP   0.0970   0.4044       \n",
            "                D.SET_Index   0.0000   0.9181       \n",
            "             D.L1.SET_Index  -0.0000   0.7983       \n",
            "             D.L2.SET_Index  -0.0001   0.2192       \n",
            "              D.SP500_Index   0.0002   0.0000    ***\n",
            "           D.L1.SP500_Index  -0.0003   0.0000    ***\n",
            "           D.L2.SP500_Index  -0.0002   0.0000    ***\n",
            "              D.THB_per_CNY   4.0504   0.1471       \n",
            "           D.L1.THB_per_CNY  -2.2781   0.5923       \n",
            "           D.L2.THB_per_CNY  -4.3946   0.2192       \n",
            "              D.THB_per_USD  -0.0011   0.9189       \n",
            "           D.L1.THB_per_USD  -0.0226   0.0959      *\n",
            "           D.L2.THB_per_USD  -0.0270   0.0363     **\n",
            "                  D.THOR_6M -26.9423   0.3180       \n",
            "               D.L1.THOR_6M 109.5526   0.0001    ***\n",
            "               D.L2.THOR_6M  92.5689   0.0084    ***\n",
            "                      const   0.0000   1.0000       \n",
            "----------------------------------------------------------------------------------------\n",
            "\n",
            "--- KTB ---\n",
            "Î± (ECT speed): -1.1768***   p=0.000\n",
            "\n",
            "Long-run Relationship (Î²):\n",
            "              Variable  Î² (Long-run)\n",
            "                 const     -0.023257\n",
            "BroadMoney_M1M2_Growth     -0.471071\n",
            "    Inflation_Surprise      8.249468\n",
            "          IPI_Surprise    -56.617243\n",
            "               THOR_6M     10.428713\n",
            "     3M_1M_THOR_Spread      8.094182\n",
            "     5Y_1Y_Bond_Spread      3.500092\n",
            "    10Y_5Y_Bond_Spread     -4.244436\n",
            "           THB_per_USD      0.001905\n",
            "             SET_Index      0.000012\n",
            "           SP500_Index      0.000411\n",
            "           THB_per_CNY      1.480241\n",
            "\n",
            "Short-run Dynamics (Î³):\n",
            "                   Variable     Coef     pval Signif\n",
            "       D.10Y_5Y_Bond_Spread  -2.3934   0.6245       \n",
            "    D.L1.10Y_5Y_Bond_Spread   0.4659   0.9193       \n",
            "    D.L2.10Y_5Y_Bond_Spread  -0.4515   0.8869       \n",
            "        D.3M_1M_THOR_Spread  -8.8338   0.3758       \n",
            "     D.L1.3M_1M_THOR_Spread -18.6082   0.2169       \n",
            "     D.L2.3M_1M_THOR_Spread  -3.2679   0.7851       \n",
            "        D.5Y_1Y_Bond_Spread  11.2645   0.0003    ***\n",
            "     D.L1.5Y_1Y_Bond_Spread  -0.6667   0.7741       \n",
            "     D.L2.5Y_1Y_Bond_Spread  -4.0016   0.1085       \n",
            "   D.BroadMoney_M1M2_Growth  -1.8112   0.0010    ***\n",
            "D.L1.BroadMoney_M1M2_Growth  -0.3286   0.6369       \n",
            "D.L2.BroadMoney_M1M2_Growth   0.0259   0.9631       \n",
            "             D.IPI_Surprise   4.1367   0.7849       \n",
            "          D.L1.IPI_Surprise  44.4690   0.0179     **\n",
            "          D.L2.IPI_Surprise  10.0591   0.5477       \n",
            "       D.Inflation_Surprise   0.4916   0.6524       \n",
            "    D.L1.Inflation_Surprise  -5.8948   0.0000    ***\n",
            "    D.L2.Inflation_Surprise  -1.7274   0.0979      *\n",
            "          D.L1.Logclose_KTB   0.2220   0.0621      *\n",
            "          D.L2.Logclose_KTB   0.1329   0.0944      *\n",
            "                D.SET_Index  -0.0001   0.2083       \n",
            "             D.L1.SET_Index   0.0000   0.9005       \n",
            "             D.L2.SET_Index   0.0000   0.6775       \n",
            "              D.SP500_Index   0.0002   0.0000    ***\n",
            "           D.L1.SP500_Index  -0.0002   0.0000    ***\n",
            "           D.L2.SP500_Index  -0.0002   0.0000    ***\n",
            "              D.THB_per_CNY   2.0636   0.3335       \n",
            "           D.L1.THB_per_CNY   2.6348   0.2149       \n",
            "           D.L2.THB_per_CNY   1.6729   0.4355       \n",
            "              D.THB_per_USD  -0.0103   0.3561       \n",
            "           D.L1.THB_per_USD  -0.0180   0.0332     **\n",
            "           D.L2.THB_per_USD  -0.0117   0.1836       \n",
            "                  D.THOR_6M   3.4182   0.8855       \n",
            "               D.L1.THOR_6M  54.2823   0.0091    ***\n",
            "               D.L2.THOR_6M  30.9069   0.1079       \n",
            "                      const   0.0000   1.0000       \n",
            "----------------------------------------------------------------------------------------\n",
            "\n",
            "--- TCAP ---\n",
            "Î± (ECT speed): -1.3892***   p=0.000\n",
            "\n",
            "Long-run Relationship (Î²):\n",
            "              Variable  Î² (Long-run)\n",
            "                 const      0.002477\n",
            "BroadMoney_M1M2_Growth     -1.130755\n",
            "    Inflation_Surprise      0.874593\n",
            "          IPI_Surprise     15.182632\n",
            "               THOR_6M     11.662630\n",
            "     3M_1M_THOR_Spread    -48.920363\n",
            "     5Y_1Y_Bond_Spread      1.003935\n",
            "    10Y_5Y_Bond_Spread    -13.247090\n",
            "           THB_per_USD      0.004586\n",
            "             SET_Index      0.000242\n",
            "           SP500_Index      0.000205\n",
            "           THB_per_CNY      2.235223\n",
            "\n",
            "Short-run Dynamics (Î³):\n",
            "                   Variable     Coef     pval Signif\n",
            "       D.10Y_5Y_Bond_Spread  -0.4219   0.9211       \n",
            "    D.L1.10Y_5Y_Bond_Spread  11.1665   0.0217     **\n",
            "    D.L2.10Y_5Y_Bond_Spread   2.5412   0.4810       \n",
            "        D.3M_1M_THOR_Spread -40.9124   0.0003    ***\n",
            "     D.L1.3M_1M_THOR_Spread  23.0982   0.1569       \n",
            "     D.L2.3M_1M_THOR_Spread  23.9669   0.0557      *\n",
            "        D.5Y_1Y_Bond_Spread   0.0852   0.9774       \n",
            "     D.L1.5Y_1Y_Bond_Spread   2.1881   0.4309       \n",
            "     D.L2.5Y_1Y_Bond_Spread   0.8007   0.8294       \n",
            "   D.BroadMoney_M1M2_Growth  -2.4321   0.0218     **\n",
            "D.L1.BroadMoney_M1M2_Growth   2.1719   0.0162     **\n",
            "D.L2.BroadMoney_M1M2_Growth   0.4591   0.5581       \n",
            "             D.IPI_Surprise  39.7845   0.0129     **\n",
            "          D.L1.IPI_Surprise  19.6245   0.3320       \n",
            "          D.L2.IPI_Surprise -17.0609   0.3385       \n",
            "       D.Inflation_Surprise  -1.2581   0.4099       \n",
            "    D.L1.Inflation_Surprise  -3.1029   0.0396     **\n",
            "    D.L2.Inflation_Surprise  -1.9638   0.1287       \n",
            "         D.L1.Logclose_TCAP   0.2049   0.2368       \n",
            "         D.L2.Logclose_TCAP   0.1280   0.2093       \n",
            "                D.SET_Index   0.0001   0.3657       \n",
            "             D.L1.SET_Index  -0.0002   0.1155       \n",
            "             D.L2.SET_Index  -0.0001   0.4656       \n",
            "              D.SP500_Index   0.0002   0.0000    ***\n",
            "           D.L1.SP500_Index  -0.0001   0.0541      *\n",
            "           D.L2.SP500_Index  -0.0001   0.0372     **\n",
            "              D.THB_per_CNY   2.8348   0.2631       \n",
            "           D.L1.THB_per_CNY   3.1452   0.3811       \n",
            "           D.L2.THB_per_CNY   0.3492   0.8761       \n",
            "              D.THB_per_USD   0.0027   0.7935       \n",
            "           D.L1.THB_per_USD  -0.0003   0.9802       \n",
            "           D.L2.THB_per_USD  -0.0163   0.1206       \n",
            "                  D.THOR_6M -37.9724   0.0829      *\n",
            "               D.L1.THOR_6M  38.6399   0.1316       \n",
            "               D.L2.THOR_6M  21.3669   0.3390       \n",
            "                      const  -0.0000   1.0000       \n",
            "----------------------------------------------------------------------------------------\n",
            "\n",
            "--- TISCO ---\n",
            "Î± (ECT speed): -1.1359***   p=0.000\n",
            "\n",
            "Long-run Relationship (Î²):\n",
            "              Variable  Î² (Long-run)\n",
            "                 const      0.014572\n",
            "BroadMoney_M1M2_Growth     -0.431137\n",
            "    Inflation_Surprise      6.370746\n",
            "          IPI_Surprise     23.936560\n",
            "               THOR_6M      8.273848\n",
            "     3M_1M_THOR_Spread    -24.263201\n",
            "     5Y_1Y_Bond_Spread     -0.937301\n",
            "    10Y_5Y_Bond_Spread      0.793386\n",
            "           THB_per_USD     -0.006897\n",
            "             SET_Index      0.000344\n",
            "           SP500_Index      0.000162\n",
            "           THB_per_CNY      0.448990\n",
            "\n",
            "Short-run Dynamics (Î³):\n",
            "                   Variable     Coef     pval Signif\n",
            "       D.10Y_5Y_Bond_Spread   5.8936   0.0659      *\n",
            "    D.L1.10Y_5Y_Bond_Spread   5.4114   0.1898       \n",
            "    D.L2.10Y_5Y_Bond_Spread   3.9064   0.2206       \n",
            "        D.3M_1M_THOR_Spread -19.1994   0.0605      *\n",
            "     D.L1.3M_1M_THOR_Spread  10.3464   0.3616       \n",
            "     D.L2.3M_1M_THOR_Spread  22.9538   0.0208     **\n",
            "        D.5Y_1Y_Bond_Spread  -4.1180   0.1276       \n",
            "     D.L1.5Y_1Y_Bond_Spread   2.0159   0.3838       \n",
            "     D.L2.5Y_1Y_Bond_Spread  -1.3423   0.6690       \n",
            "   D.BroadMoney_M1M2_Growth  -1.7737   0.0510      *\n",
            "D.L1.BroadMoney_M1M2_Growth  -0.2930   0.6417       \n",
            "D.L2.BroadMoney_M1M2_Growth   0.0308   0.9640       \n",
            "             D.IPI_Surprise  49.0688   0.0045    ***\n",
            "          D.L1.IPI_Surprise   8.2385   0.6034       \n",
            "          D.L2.IPI_Surprise   1.6772   0.9076       \n",
            "       D.Inflation_Surprise   0.5757   0.6361       \n",
            "    D.L1.Inflation_Surprise  -4.7268   0.0001    ***\n",
            "    D.L2.Inflation_Surprise  -3.5364   0.0003    ***\n",
            "        D.L1.Logclose_TISCO   0.1572   0.1868       \n",
            "        D.L2.Logclose_TISCO   0.0568   0.4036       \n",
            "                D.SET_Index   0.0002   0.0097    ***\n",
            "             D.L1.SET_Index  -0.0002   0.0748      *\n",
            "             D.L2.SET_Index  -0.0002   0.0023    ***\n",
            "              D.SP500_Index   0.0001   0.0001    ***\n",
            "           D.L1.SP500_Index  -0.0001   0.0607      *\n",
            "           D.L2.SP500_Index  -0.0001   0.0143     **\n",
            "              D.THB_per_CNY   0.9129   0.5866       \n",
            "           D.L1.THB_per_CNY   4.8930   0.0374     **\n",
            "           D.L2.THB_per_CNY   2.3563   0.2847       \n",
            "              D.THB_per_USD  -0.0119   0.0953      *\n",
            "           D.L1.THB_per_USD   0.0113   0.1440       \n",
            "           D.L2.THB_per_USD  -0.0090   0.3361       \n",
            "                  D.THOR_6M -45.5825   0.0044    ***\n",
            "               D.L1.THOR_6M  39.7725   0.0679      *\n",
            "               D.L2.THOR_6M  41.6671   0.0726      *\n",
            "                      const  -0.0000   1.0000       \n",
            "----------------------------------------------------------------------------------------\n",
            "\n",
            "--- TTB ---\n",
            "Î± (ECT speed): -1.4532***   p=0.000\n",
            "\n",
            "Long-run Relationship (Î²):\n",
            "              Variable  Î² (Long-run)\n",
            "                 const     -0.019134\n",
            "BroadMoney_M1M2_Growth     -1.017297\n",
            "    Inflation_Surprise      0.407603\n",
            "          IPI_Surprise     16.762281\n",
            "               THOR_6M     14.569231\n",
            "     3M_1M_THOR_Spread     32.162416\n",
            "     5Y_1Y_Bond_Spread      3.844463\n",
            "    10Y_5Y_Bond_Spread    -12.594743\n",
            "           THB_per_USD     -0.008942\n",
            "             SET_Index     -0.000002\n",
            "           SP500_Index      0.000306\n",
            "           THB_per_CNY     -2.873908\n",
            "\n",
            "Short-run Dynamics (Î³):\n",
            "                   Variable     Coef     pval Signif\n",
            "       D.10Y_5Y_Bond_Spread   3.2763   0.5116       \n",
            "    D.L1.10Y_5Y_Bond_Spread  11.7159   0.0433     **\n",
            "    D.L2.10Y_5Y_Bond_Spread  -0.5895   0.8748       \n",
            "        D.3M_1M_THOR_Spread  -4.3668   0.6040       \n",
            "     D.L1.3M_1M_THOR_Spread -62.7320   0.0000    ***\n",
            "     D.L2.3M_1M_THOR_Spread -22.3455   0.1320       \n",
            "        D.5Y_1Y_Bond_Spread  11.7398   0.0060    ***\n",
            "     D.L1.5Y_1Y_Bond_Spread  -3.2562   0.3053       \n",
            "     D.L2.5Y_1Y_Bond_Spread   0.4799   0.8693       \n",
            "   D.BroadMoney_M1M2_Growth  -1.5478   0.1339       \n",
            "D.L1.BroadMoney_M1M2_Growth   2.6950   0.0019    ***\n",
            "D.L2.BroadMoney_M1M2_Growth   4.2373   0.0000    ***\n",
            "             D.IPI_Surprise  29.6680   0.0788      *\n",
            "          D.L1.IPI_Surprise   0.7303   0.9646       \n",
            "          D.L2.IPI_Surprise  12.2424   0.4564       \n",
            "       D.Inflation_Surprise  -0.8910   0.5380       \n",
            "    D.L1.Inflation_Surprise  -1.4003   0.3205       \n",
            "    D.L2.Inflation_Surprise  -0.8812   0.5792       \n",
            "          D.L1.Logclose_TTB   0.3098   0.0030    ***\n",
            "          D.L2.Logclose_TTB   0.1555   0.0578      *\n",
            "                D.SET_Index   0.0000   0.7954       \n",
            "             D.L1.SET_Index   0.0000   0.7180       \n",
            "             D.L2.SET_Index   0.0001   0.1325       \n",
            "              D.SP500_Index   0.0002   0.0000    ***\n",
            "           D.L1.SP500_Index  -0.0001   0.0038    ***\n",
            "           D.L2.SP500_Index  -0.0001   0.0141     **\n",
            "              D.THB_per_CNY  -4.0371   0.1450       \n",
            "           D.L1.THB_per_CNY   2.0851   0.2570       \n",
            "           D.L2.THB_per_CNY  -0.9090   0.7527       \n",
            "              D.THB_per_USD  -0.0330   0.0126     **\n",
            "           D.L1.THB_per_USD  -0.0096   0.2348       \n",
            "           D.L2.THB_per_USD  -0.0280   0.0197     **\n",
            "                  D.THOR_6M   7.5574   0.8197       \n",
            "               D.L1.THOR_6M  66.3556   0.0005    ***\n",
            "               D.L2.THOR_6M  53.1137   0.0494     **\n",
            "                      const  -0.0000   1.0000       \n",
            "----------------------------------------------------------------------------------------\n",
            "\n",
            "========================================================================================\n",
            "ðŸ“‚ Sector: Finance_Securities\n",
            "========================================================================================\n",
            "\n",
            "--- AEONTS ---\n",
            "Î± (ECT speed): -1.1432***   p=0.000\n",
            "\n",
            "Long-run Relationship (Î²):\n",
            "              Variable  Î² (Long-run)\n",
            "                 const     -0.009852\n",
            "BroadMoney_M1M2_Growth     -2.264955\n",
            "    Inflation_Surprise     -0.900546\n",
            "          IPI_Surprise    103.517444\n",
            "               THOR_6M    -17.678133\n",
            "     3M_1M_THOR_Spread     15.302393\n",
            "     5Y_1Y_Bond_Spread      5.907266\n",
            "    10Y_5Y_Bond_Spread    -20.060477\n",
            "           THB_per_USD     -0.065468\n",
            "             SET_Index      0.000121\n",
            "           SP500_Index      0.000237\n",
            "           THB_per_CNY     -4.081848\n",
            "\n",
            "Short-run Dynamics (Î³):\n",
            "                   Variable     Coef     pval Signif\n",
            "       D.10Y_5Y_Bond_Spread -15.0218   0.0004    ***\n",
            "    D.L1.10Y_5Y_Bond_Spread   7.5950   0.1441       \n",
            "    D.L2.10Y_5Y_Bond_Spread  10.9669   0.0102     **\n",
            "        D.3M_1M_THOR_Spread  13.6241   0.3158       \n",
            "     D.L1.3M_1M_THOR_Spread   4.2776   0.7892       \n",
            "     D.L2.3M_1M_THOR_Spread  -9.7221   0.5095       \n",
            "        D.5Y_1Y_Bond_Spread   0.9402   0.8335       \n",
            "     D.L1.5Y_1Y_Bond_Spread   1.0464   0.8185       \n",
            "     D.L2.5Y_1Y_Bond_Spread  -7.2135   0.0635      *\n",
            "   D.BroadMoney_M1M2_Growth  -2.2595   0.0783      *\n",
            "D.L1.BroadMoney_M1M2_Growth   4.6784   0.0000    ***\n",
            "D.L2.BroadMoney_M1M2_Growth   2.8254   0.0047    ***\n",
            "             D.IPI_Surprise  80.1402   0.0001    ***\n",
            "          D.L1.IPI_Surprise -57.3233   0.0129     **\n",
            "          D.L2.IPI_Surprise -85.1289   0.0000    ***\n",
            "       D.Inflation_Surprise  -1.2430   0.4848       \n",
            "    D.L1.Inflation_Surprise  -1.9899   0.2402       \n",
            "    D.L2.Inflation_Surprise  -2.5693   0.2243       \n",
            "       D.L1.Logclose_AEONTS   0.1319   0.2439       \n",
            "       D.L2.Logclose_AEONTS  -0.0192   0.8357       \n",
            "                D.SET_Index   0.0003   0.0615      *\n",
            "             D.L1.SET_Index   0.0001   0.3217       \n",
            "             D.L2.SET_Index  -0.0001   0.3258       \n",
            "              D.SP500_Index   0.0000   0.8659       \n",
            "           D.L1.SP500_Index  -0.0003   0.0000    ***\n",
            "           D.L2.SP500_Index  -0.0002   0.0018    ***\n",
            "              D.THB_per_CNY  10.8604   0.0004    ***\n",
            "           D.L1.THB_per_CNY   7.3986   0.0674      *\n",
            "           D.L2.THB_per_CNY   1.7369   0.6728       \n",
            "              D.THB_per_USD   0.0122   0.3364       \n",
            "           D.L1.THB_per_USD   0.0326   0.0271     **\n",
            "           D.L2.THB_per_USD   0.0128   0.4531       \n",
            "                  D.THOR_6M -67.5714   0.0613      *\n",
            "               D.L1.THOR_6M 102.5397   0.0008    ***\n",
            "               D.L2.THOR_6M  81.4256   0.0279     **\n",
            "                      const   0.0000   1.0000       \n",
            "----------------------------------------------------------------------------------------\n",
            "\n",
            "--- JMT ---\n",
            "Î± (ECT speed): -0.9830***   p=0.000\n",
            "\n",
            "Long-run Relationship (Î²):\n",
            "              Variable  Î² (Long-run)\n",
            "                 const      0.055270\n",
            "BroadMoney_M1M2_Growth     -2.674860\n",
            "    Inflation_Surprise     -9.232892\n",
            "          IPI_Surprise    337.267342\n",
            "               THOR_6M    -56.858754\n",
            "     3M_1M_THOR_Spread     89.163778\n",
            "     5Y_1Y_Bond_Spread     -2.366561\n",
            "    10Y_5Y_Bond_Spread    -23.812667\n",
            "           THB_per_USD      0.012213\n",
            "             SET_Index      0.000058\n",
            "           SP500_Index     -0.000314\n",
            "           THB_per_CNY     11.888524\n",
            "\n",
            "Short-run Dynamics (Î³):\n",
            "                   Variable      Coef     pval Signif\n",
            "       D.10Y_5Y_Bond_Spread   -2.3835   0.8182       \n",
            "    D.L1.10Y_5Y_Bond_Spread   23.4604   0.0276     **\n",
            "    D.L2.10Y_5Y_Bond_Spread   21.6321   0.0093    ***\n",
            "        D.3M_1M_THOR_Spread   -1.8754   0.9258       \n",
            "     D.L1.3M_1M_THOR_Spread  -25.8293   0.2030       \n",
            "     D.L2.3M_1M_THOR_Spread  -54.4460   0.0175     **\n",
            "        D.5Y_1Y_Bond_Spread    8.9421   0.2302       \n",
            "     D.L1.5Y_1Y_Bond_Spread    9.2595   0.2938       \n",
            "     D.L2.5Y_1Y_Bond_Spread    9.0380   0.1899       \n",
            "   D.BroadMoney_M1M2_Growth   -3.1021   0.1084       \n",
            "D.L1.BroadMoney_M1M2_Growth    2.6071   0.1454       \n",
            "D.L2.BroadMoney_M1M2_Growth    1.9532   0.3153       \n",
            "             D.IPI_Surprise   86.5954   0.0401     **\n",
            "          D.L1.IPI_Surprise -149.2309   0.0230     **\n",
            "          D.L2.IPI_Surprise  -66.5700   0.1949       \n",
            "       D.Inflation_Surprise   -3.2065   0.3042       \n",
            "    D.L1.Inflation_Surprise    2.4589   0.4577       \n",
            "    D.L2.Inflation_Surprise   -0.1125   0.9726       \n",
            "          D.L1.Logclose_JMT    0.0849   0.6008       \n",
            "          D.L2.Logclose_JMT   -0.0406   0.7111       \n",
            "                D.SET_Index    0.0000   0.9418       \n",
            "             D.L1.SET_Index    0.0002   0.5491       \n",
            "             D.L2.SET_Index    0.0002   0.4291       \n",
            "              D.SP500_Index   -0.0001   0.5778       \n",
            "           D.L1.SP500_Index    0.0003   0.0237     **\n",
            "           D.L2.SP500_Index    0.0000   0.7665       \n",
            "              D.THB_per_CNY    0.2983   0.9577       \n",
            "           D.L1.THB_per_CNY  -15.4295   0.0855      *\n",
            "           D.L2.THB_per_CNY   -5.9871   0.3155       \n",
            "              D.THB_per_USD    0.0139   0.5771       \n",
            "           D.L1.THB_per_USD   -0.0204   0.4867       \n",
            "           D.L2.THB_per_USD   -0.0174   0.4372       \n",
            "                  D.THOR_6M  -29.7116   0.5689       \n",
            "               D.L1.THOR_6M  114.0686   0.0471     **\n",
            "               D.L2.THOR_6M   42.3735   0.3869       \n",
            "                      const    0.0000   1.0000       \n",
            "----------------------------------------------------------------------------------------\n",
            "\n",
            "--- KTC ---\n",
            "Î± (ECT speed): -0.8296***   p=0.000\n",
            "\n",
            "Long-run Relationship (Î²):\n",
            "              Variable  Î² (Long-run)\n",
            "                 const      0.103740\n",
            "BroadMoney_M1M2_Growth     -6.814398\n",
            "    Inflation_Surprise      0.589863\n",
            "          IPI_Surprise    342.539865\n",
            "               THOR_6M     -2.783160\n",
            "     3M_1M_THOR_Spread   -184.414084\n",
            "     5Y_1Y_Bond_Spread     -5.391041\n",
            "    10Y_5Y_Bond_Spread    -24.301720\n",
            "           THB_per_USD     -0.139811\n",
            "             SET_Index      0.000259\n",
            "           SP500_Index     -0.000622\n",
            "           THB_per_CNY    -17.589363\n",
            "\n",
            "Short-run Dynamics (Î³):\n",
            "                   Variable      Coef     pval Signif\n",
            "       D.10Y_5Y_Bond_Spread   -7.0955   0.2367       \n",
            "    D.L1.10Y_5Y_Bond_Spread    9.9790   0.2045       \n",
            "    D.L2.10Y_5Y_Bond_Spread   14.6522   0.0090    ***\n",
            "        D.3M_1M_THOR_Spread  -26.9928   0.1030       \n",
            "     D.L1.3M_1M_THOR_Spread   97.2126   0.0002    ***\n",
            "     D.L2.3M_1M_THOR_Spread   46.0802   0.0047    ***\n",
            "        D.5Y_1Y_Bond_Spread   -3.2437   0.5868       \n",
            "     D.L1.5Y_1Y_Bond_Spread    9.2459   0.1398       \n",
            "     D.L2.5Y_1Y_Bond_Spread    4.7325   0.2894       \n",
            "   D.BroadMoney_M1M2_Growth   -2.5586   0.0538      *\n",
            "D.L1.BroadMoney_M1M2_Growth    4.7130   0.0000    ***\n",
            "D.L2.BroadMoney_M1M2_Growth    2.0011   0.1574       \n",
            "             D.IPI_Surprise   82.9132   0.0055    ***\n",
            "          D.L1.IPI_Surprise -161.2099   0.0000    ***\n",
            "          D.L2.IPI_Surprise -119.9776   0.0000    ***\n",
            "       D.Inflation_Surprise   -4.6616   0.0693      *\n",
            "    D.L1.Inflation_Surprise   -5.5030   0.0070    ***\n",
            "    D.L2.Inflation_Surprise   -3.5210   0.1494       \n",
            "          D.L1.Logclose_KTC   -0.3157   0.0014    ***\n",
            "          D.L2.Logclose_KTC   -0.0826   0.2027       \n",
            "                D.SET_Index    0.0003   0.0175     **\n",
            "             D.L1.SET_Index    0.0004   0.0428     **\n",
            "             D.L2.SET_Index    0.0002   0.1358       \n",
            "              D.SP500_Index   -0.0002   0.1457       \n",
            "           D.L1.SP500_Index    0.0003   0.0008    ***\n",
            "           D.L2.SP500_Index   -0.0000   0.8857       \n",
            "              D.THB_per_CNY   -1.1018   0.7575       \n",
            "           D.L1.THB_per_CNY    2.8537   0.4854       \n",
            "           D.L2.THB_per_CNY   -0.9181   0.8088       \n",
            "              D.THB_per_USD   -0.0301   0.0543      *\n",
            "           D.L1.THB_per_USD    0.0466   0.0338     **\n",
            "           D.L2.THB_per_USD    0.0197   0.2690       \n",
            "                  D.THOR_6M -136.8189   0.0140     **\n",
            "               D.L1.THOR_6M  -55.3390   0.0813      *\n",
            "               D.L2.THOR_6M   53.9992   0.3351       \n",
            "                      const    0.0000   1.0000       \n",
            "----------------------------------------------------------------------------------------\n",
            "\n",
            "--- SAWAD ---\n",
            "Î± (ECT speed): -1.3086***   p=0.000\n",
            "\n",
            "Long-run Relationship (Î²):\n",
            "              Variable  Î² (Long-run)\n",
            "                 const      0.012312\n",
            "BroadMoney_M1M2_Growth     -5.520974\n",
            "    Inflation_Surprise     -4.880879\n",
            "          IPI_Surprise    131.768262\n",
            "               THOR_6M    -21.438865\n",
            "     3M_1M_THOR_Spread      4.648092\n",
            "     5Y_1Y_Bond_Spread      4.248585\n",
            "    10Y_5Y_Bond_Spread      4.856046\n",
            "           THB_per_USD     -0.041112\n",
            "             SET_Index     -0.000163\n",
            "           SP500_Index      0.000055\n",
            "           THB_per_CNY      1.726104\n",
            "\n",
            "Short-run Dynamics (Î³):\n",
            "                   Variable     Coef     pval Signif\n",
            "       D.10Y_5Y_Bond_Spread  -4.0115   0.6457       \n",
            "    D.L1.10Y_5Y_Bond_Spread   1.4794   0.8873       \n",
            "    D.L2.10Y_5Y_Bond_Spread   3.2195   0.5873       \n",
            "        D.3M_1M_THOR_Spread  10.5785   0.5430       \n",
            "     D.L1.3M_1M_THOR_Spread  31.9415   0.1108       \n",
            "     D.L2.3M_1M_THOR_Spread  -1.4924   0.9368       \n",
            "        D.5Y_1Y_Bond_Spread   0.9544   0.8837       \n",
            "     D.L1.5Y_1Y_Bond_Spread   2.1976   0.6858       \n",
            "     D.L2.5Y_1Y_Bond_Spread  -7.1251   0.1346       \n",
            "   D.BroadMoney_M1M2_Growth  -3.7185   0.0490     **\n",
            "D.L1.BroadMoney_M1M2_Growth   7.2389   0.0000    ***\n",
            "D.L2.BroadMoney_M1M2_Growth   4.9631   0.0075    ***\n",
            "             D.IPI_Surprise  48.2642   0.0877      *\n",
            "          D.L1.IPI_Surprise -91.6986   0.0317     **\n",
            "          D.L2.IPI_Surprise -61.0876   0.0901      *\n",
            "       D.Inflation_Surprise  -6.6406   0.1129       \n",
            "    D.L1.Inflation_Surprise  -2.0012   0.4224       \n",
            "    D.L2.Inflation_Surprise  -1.2299   0.6490       \n",
            "        D.L1.Logclose_SAWAD   0.1740   0.2534       \n",
            "        D.L2.Logclose_SAWAD   0.1433   0.2278       \n",
            "                D.SET_Index   0.0000   0.8274       \n",
            "             D.L1.SET_Index   0.0005   0.0319     **\n",
            "             D.L2.SET_Index   0.0002   0.4094       \n",
            "              D.SP500_Index  -0.0000   0.8911       \n",
            "           D.L1.SP500_Index  -0.0001   0.5971       \n",
            "           D.L2.SP500_Index  -0.0002   0.1055       \n",
            "              D.THB_per_CNY   3.2678   0.4457       \n",
            "           D.L1.THB_per_CNY  -7.8302   0.0979      *\n",
            "           D.L2.THB_per_CNY  -3.7444   0.4527       \n",
            "              D.THB_per_USD  -0.0061   0.7540       \n",
            "           D.L1.THB_per_USD   0.0010   0.9658       \n",
            "           D.L2.THB_per_USD   0.0069   0.6618       \n",
            "                  D.THOR_6M -74.4394   0.1424       \n",
            "               D.L1.THOR_6M  60.8469   0.1232       \n",
            "               D.L2.THOR_6M  17.4774   0.6078       \n",
            "                      const   0.0000   1.0000       \n",
            "----------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# âœ… ARDL+ECM (HAC Robust, Fixed lag=3, Final v4 â€“ Grouped Lags)\n",
        "# ============================================================\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tsa.ardl import ARDL\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ---------- CONFIG ----------\n",
        "LAG_Y = 3\n",
        "LAG_X = 3\n",
        "MIN_OBS = 40\n",
        "\n",
        "macro_vars = [\n",
        "    \"BroadMoney_M1M2_Growth\", \"Inflation_Surprise\", \"IPI_Surprise\",\n",
        "    \"THOR_6M\", \"3M_1M_THOR_Spread\",\n",
        "    \"5Y_1Y_Bond_Spread\", \"10Y_5Y_Bond_Spread\",\n",
        "    \"THB_per_USD\", \"SET_Index\",\n",
        "    \"SP500_Index\", \"THB_per_CNY\"\n",
        "]\n",
        "\n",
        "alpha_list, beta_list, gamma_list, diag_list = [], [], [], []\n",
        "\n",
        "# ============================================================\n",
        "# ðŸ§© HELPER FUNCTIONS\n",
        "# ============================================================\n",
        "\n",
        "def get_param_names(res):\n",
        "    if hasattr(res.model, \"_xnames\"):\n",
        "        return res.model._xnames\n",
        "    elif hasattr(res.model, \"data\") and hasattr(res.model.data, \"param_names\"):\n",
        "        return res.model.data.param_names\n",
        "    elif hasattr(res, \"params\"):\n",
        "        return list(res.params.index)\n",
        "    else:\n",
        "        raise AttributeError(\"Cannot extract param names from model object.\")\n",
        "\n",
        "def _nw_lags(T: int) -> int:\n",
        "    return max(1, int(np.floor(4 * (T / 100.0) ** (2.0 / 9.0))))\n",
        "\n",
        "def _is_endog_lag(name: str, endog: str) -> bool:\n",
        "    return bool(\n",
        "        re.search(rf\"(?:^L\\d+\\.){re.escape(endog)}$\", name)\n",
        "        or re.search(rf\"^{re.escape(endog)}\\.L\\d+$\", name)\n",
        "    )\n",
        "\n",
        "def _is_exog_term(name: str, var: str) -> bool:\n",
        "    return bool(\n",
        "        name == var\n",
        "        or re.search(rf\"^L\\d+\\.{re.escape(var)}$\", name)\n",
        "        or re.search(rf\"^{re.escape(var)}\\.L\\d+$\", name)\n",
        "    )\n",
        "\n",
        "def compute_long_run_from_ardl(res, endog_name: str, exog_list: list) -> pd.Series:\n",
        "    params = res.params\n",
        "    names = get_param_names(res)\n",
        "\n",
        "    phi_sum = np.sum([params[n] for n in names if _is_endog_lag(n, endog_name)])\n",
        "    denom = 1 - phi_sum if abs(1 - phi_sum) > 1e-8 else np.nan\n",
        "\n",
        "    const = params.get(\"const\", 0.0)\n",
        "    lr = {\"const\": (const / denom) if denom else np.nan}\n",
        "\n",
        "    for v in exog_list:\n",
        "        theta_sum = np.sum([params[n] for n in names if _is_exog_term(n, v) and n in params])\n",
        "        lr[v] = (theta_sum / denom) if denom else np.nan\n",
        "\n",
        "    return pd.Series(lr)\n",
        "\n",
        "def build_ecm_design(df_model: pd.DataFrame, y_col: str, x_cols: list, p: int, q: int):\n",
        "    \"\"\"à¸ªà¸£à¹‰à¸²à¸‡ ECM design matrix à¸žà¸£à¹‰à¸­à¸¡à¸•à¸±à¹‰à¸‡à¸Šà¸·à¹ˆà¸­à¸Šà¸±à¸”à¹€à¸ˆà¸™\"\"\"\n",
        "    dy = df_model[y_col].diff()\n",
        "    dy.name = f\"D.{y_col}\"\n",
        "\n",
        "    # lag Î”y\n",
        "    Dy_lags = []\n",
        "    for l in range(1, p):\n",
        "        s = df_model[y_col].diff().shift(l)\n",
        "        s.name = f\"D.L{l}.{y_col}\"\n",
        "        Dy_lags.append(s)\n",
        "\n",
        "    # lag Î”x\n",
        "    Dx_cols = []\n",
        "    for v in x_cols:\n",
        "        s0 = df_model[v].diff()\n",
        "        s0.name = f\"D.{v}\"\n",
        "        Dx_cols.append(s0)\n",
        "        for l in range(1, q):\n",
        "            s = df_model[v].diff().shift(l)\n",
        "            s.name = f\"D.L{l}.{v}\"\n",
        "            Dx_cols.append(s)\n",
        "\n",
        "    X = pd.concat(\n",
        "        [pd.Series(1.0, index=df_model.index, name=\"const\")] + Dy_lags + Dx_cols,\n",
        "        axis=1\n",
        "    )\n",
        "    return dy, X\n",
        "\n",
        "def star(p):\n",
        "    if p < 0.01: return \"***\"\n",
        "    elif p < 0.05: return \"**\"\n",
        "    elif p < 0.1: return \"*\"\n",
        "    return \"\"\n",
        "\n",
        "def sort_by_base_and_lag(varname: str) -> tuple:\n",
        "    \"\"\"à¸ˆà¸±à¸”à¹€à¸£à¸µà¸¢à¸‡à¸•à¸±à¸§à¹à¸›à¸£ Î” à¹ƒà¸«à¹‰à¹€à¸£à¸µà¸¢à¸‡ lag à¸•à¹ˆà¸­à¸à¸±à¸™ (à¹€à¸«à¸¡à¸·à¸­à¸™ EViews)\"\"\"\n",
        "    name = varname.replace(\"D.\", \"\")\n",
        "    lag_match = re.search(r\"L(\\d+)\\.\", name)\n",
        "    if lag_match:\n",
        "        lag = int(lag_match.group(1))\n",
        "        base = re.sub(r\"L\\d+\\.\", \"\", name)\n",
        "    else:\n",
        "        lag = 0\n",
        "        base = name\n",
        "    return (base, lag)\n",
        "\n",
        "def eviews_summary_by_sector(df_alpha, df_beta, df_gamma):\n",
        "    sectors = sorted(df_alpha[\"Sector\"].unique())\n",
        "    for sector in sectors:\n",
        "        print(\"\\n\" + \"=\"*88)\n",
        "        print(f\"ðŸ“‚ Sector: {sector}\")\n",
        "        print(\"=\"*88)\n",
        "\n",
        "        df_a = df_alpha[df_alpha[\"Sector\"] == sector]\n",
        "        df_b = df_beta[df_beta[\"Sector\"] == sector]\n",
        "        df_g = df_gamma[df_gamma[\"Sector\"] == sector]\n",
        "\n",
        "        for stock in sorted(df_a[\"Stock\"].unique()):\n",
        "            print(f\"\\n--- {stock} ---\")\n",
        "            a_row = df_a[df_a[\"Stock\"] == stock].iloc[0]\n",
        "            alpha_val = a_row[\"Alpha\"]; pval = a_row[\"pval\"]\n",
        "            print(f\"Î± (ECT speed): {alpha_val:.4f}{star(pval)}   p={pval:.3f}\")\n",
        "\n",
        "            btab = df_b[df_b[\"Stock\"] == stock][[\"Variable\", \"coef\"]]\n",
        "            if not btab.empty:\n",
        "                btab = btab.rename(columns={\"coef\": \"Î² (Long-run)\"})\n",
        "                print(\"\\nLong-run Relationship (Î²):\")\n",
        "                print(btab.to_string(index=False, float_format=lambda x: f\"{x:.6f}\"))\n",
        "\n",
        "            gtab = df_g[df_g[\"Stock\"] == stock][[\"Variable\", \"Coef\", \"pval\"]]\n",
        "            if not gtab.empty:\n",
        "                gtab = gtab[~gtab[\"Variable\"].str.contains(\"ECT\", na=False)]\n",
        "                gtab[\"sort_key\"] = gtab[\"Variable\"].apply(sort_by_base_and_lag)\n",
        "                gtab = gtab.sort_values(\"sort_key\").drop(columns=[\"sort_key\"])\n",
        "                gtab[\"Signif\"] = gtab[\"pval\"].apply(star)\n",
        "                print(\"\\nShort-run Dynamics (Î³):\")\n",
        "                print(gtab.to_string(index=False, float_format=lambda x: f\"{x:8.4f}\"))\n",
        "\n",
        "            print(\"-\"*88)\n",
        "\n",
        "# ============================================================\n",
        "# ðŸš€ MAIN LOOP\n",
        "# ============================================================\n",
        "\n",
        "for sector, df_sec in combined_dfs_selective_diff.items():\n",
        "    print(f\"\\n===== ðŸ“‚ Sector: {sector} =====\")\n",
        "    if df_sec.empty:\n",
        "        continue\n",
        "\n",
        "    x_list = [v for v in macro_vars if v in df_sec.columns]\n",
        "    if not x_list:\n",
        "        print(\"âš ï¸ No macro variables in this sector.\")\n",
        "        continue\n",
        "\n",
        "    for col in df_sec.columns:\n",
        "        if not col.startswith(\"Logclose_\"):\n",
        "            continue\n",
        "\n",
        "        stock = col.replace(\"Logclose_\", \"\")\n",
        "        y = df_sec[col]\n",
        "        X = df_sec[x_list]\n",
        "        df_model = pd.concat([y, X], axis=1).dropna()\n",
        "\n",
        "        if len(df_model) < MIN_OBS:\n",
        "            print(f\"âš ï¸ Skip {stock}: insufficient data ({len(df_model)})\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            print(f\"â³ ARDL(p=3,q=3) fit: {stock} ({len(df_model)} obs, {len(x_list)} Xs)...\", flush=True)\n",
        "            res = ARDL(df_model[col], LAG_Y, df_model[x_list], LAG_X, trend='c').fit()\n",
        "\n",
        "            lr_ser = compute_long_run_from_ardl(res, col, x_list)\n",
        "\n",
        "            ect = df_model[col].shift(1) - (\n",
        "                lr_ser.get(\"const\", 0.0) + sum(lr_ser[v] * df_model[v].shift(1) for v in x_list)\n",
        "            )\n",
        "            ect.name = \"ECT_lag1\"\n",
        "\n",
        "            dy, X_ecm = build_ecm_design(df_model, col, x_list, LAG_Y, LAG_X)\n",
        "            X_ecm = pd.concat([X_ecm, ect], axis=1)\n",
        "            ecm_df = pd.concat([dy.rename(\"D.y\"), X_ecm], axis=1).dropna()\n",
        "\n",
        "            hac_bw = _nw_lags(len(ecm_df))\n",
        "            ecm = sm.OLS(ecm_df[\"D.y\"], ecm_df.drop(columns=[\"D.y\"])) \\\n",
        "                     .fit(cov_type=\"HAC\", cov_kwds={\"maxlags\": hac_bw})\n",
        "\n",
        "            beta_df = lr_ser.rename_axis(\"Variable\").reset_index(name=\"coef\")\n",
        "            beta_df[\"Stock\"], beta_df[\"Sector\"] = stock, sector\n",
        "            beta_list.append(beta_df)\n",
        "\n",
        "            alpha_list.append({\n",
        "                \"Stock\": stock, \"Sector\": sector,\n",
        "                \"Alpha\": ecm.params.get(\"ECT_lag1\", np.nan),\n",
        "                \"pval\": ecm.pvalues.get(\"ECT_lag1\", np.nan),\n",
        "                \"R2\": ecm.rsquared\n",
        "            })\n",
        "\n",
        "            g = pd.DataFrame({\n",
        "                \"Variable\": ecm.params.index,\n",
        "                \"Coef\": ecm.params.values,\n",
        "                \"pval\": ecm.pvalues.values\n",
        "            })\n",
        "            g[\"Stock\"], g[\"Sector\"] = stock, sector\n",
        "            gamma_list.append(g)\n",
        "\n",
        "            diag_list.append({\n",
        "                \"Stock\": stock, \"Sector\": sector,\n",
        "                \"R2\": ecm.rsquared, \"AdjR2\": ecm.rsquared_adj\n",
        "            })\n",
        "\n",
        "            print(f\"âœ… {stock}: Î±={ecm.params.get('ECT_lag1', np.nan):.4f}, \"\n",
        "                  f\"p={ecm.pvalues.get('ECT_lag1', np.nan):.3f}, RÂ²={ecm.rsquared:.3f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ {stock} failed: {e}\")\n",
        "\n",
        "# ============================================================\n",
        "# ðŸ’¾ EXPORT RESULTS + PRINT\n",
        "# ============================================================\n",
        "\n",
        "if beta_list:\n",
        "    df_alpha = pd.DataFrame(alpha_list)\n",
        "    df_beta  = pd.concat(beta_list, ignore_index=True)\n",
        "    df_gamma = pd.concat(gamma_list, ignore_index=True)\n",
        "    df_diag  = pd.DataFrame(diag_list)\n",
        "\n",
        "    with pd.ExcelWriter(\"Stock_ARDL_ECM_FixedLag3_GROUPED.xlsx\") as w:\n",
        "        df_alpha.to_excel(w, \"Alpha_Speed(ECT)\", index=False)\n",
        "        df_beta.to_excel(w, \"Beta_LongRun\", index=False)\n",
        "        df_gamma.to_excel(w, \"ShortRun(ECM)\", index=False)\n",
        "        df_diag.to_excel(w, \"Diagnostics\", index=False)\n",
        "\n",
        "    print(\"\\nâœ… Exported â†’ Stock_ARDL_ECM_FixedLag3_GROUPED.xlsx\")\n",
        "    eviews_summary_by_sector(df_alpha, df_beta, df_gamma)\n",
        "else:\n",
        "    print(\"\\nâš ï¸ No valid results to export/print.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpH9jpf15N6x"
      },
      "source": [
        "# Forecast Return from ARDL + ECM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 620
        },
        "id": "YDAjcIDp5NbX",
        "outputId": "712fbdf1-5058-48f7-e3d6-4d9486e657e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… BBL      | Sector=Banking              | Î”Å¶=+0.02543\n",
            "âœ… KBANK    | Sector=Banking              | Î”Å¶=+0.05695\n",
            "âœ… KKP      | Sector=Banking              | Î”Å¶=-0.03251\n",
            "âœ… KTB      | Sector=Banking              | Î”Å¶=+0.00309\n",
            "âœ… TCAP     | Sector=Banking              | Î”Å¶=+0.00953\n",
            "âœ… TISCO    | Sector=Banking              | Î”Å¶=+0.02024\n",
            "âœ… TTB      | Sector=Banking              | Î”Å¶=-0.06937\n",
            "âœ… KTC      | Sector=Finance_Securities   | Î”Å¶=+0.25061\n",
            "âœ… AEONTS   | Sector=Finance_Securities   | Î”Å¶=-0.08836\n",
            "âœ… JMT      | Sector=Finance_Securities   | Î”Å¶=+0.05498\n",
            "âœ… SAWAD    | Sector=Finance_Securities   | Î”Å¶=-0.09972\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_forecast_summary\",\n  \"rows\": 11,\n  \"fields\": [\n    {\n      \"column\": \"Stock\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"TISCO\",\n          \"BBL\",\n          \"JMT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sector\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Finance_Securities\",\n          \"Banking\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pred_dLogclose\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09606722705609329,\n        \"min\": -0.09972045275035238,\n        \"max\": 0.2506063604882989,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.020244871714549334,\n          0.025432231393694302\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Expected_Return_%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.60672270560933,\n        \"min\": -9.972045275035239,\n        \"max\": 25.06063604882989,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          2.0244871714549335,\n          2.5432231393694305\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Signal\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"SELL\",\n          \"BUY\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_forecast_summary"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-b1c16f10-4a40-4905-828a-e5affcea037e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Stock</th>\n",
              "      <th>Sector</th>\n",
              "      <th>Pred_dLogclose</th>\n",
              "      <th>Expected_Return_%</th>\n",
              "      <th>Signal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BBL</td>\n",
              "      <td>Banking</td>\n",
              "      <td>0.025432</td>\n",
              "      <td>2.543223</td>\n",
              "      <td>BUY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KBANK</td>\n",
              "      <td>Banking</td>\n",
              "      <td>0.056954</td>\n",
              "      <td>5.695436</td>\n",
              "      <td>BUY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>KKP</td>\n",
              "      <td>Banking</td>\n",
              "      <td>-0.032508</td>\n",
              "      <td>-3.250787</td>\n",
              "      <td>SELL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>KTB</td>\n",
              "      <td>Banking</td>\n",
              "      <td>0.003092</td>\n",
              "      <td>0.309182</td>\n",
              "      <td>BUY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TCAP</td>\n",
              "      <td>Banking</td>\n",
              "      <td>0.009530</td>\n",
              "      <td>0.953031</td>\n",
              "      <td>BUY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>TISCO</td>\n",
              "      <td>Banking</td>\n",
              "      <td>0.020245</td>\n",
              "      <td>2.024487</td>\n",
              "      <td>BUY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>TTB</td>\n",
              "      <td>Banking</td>\n",
              "      <td>-0.069369</td>\n",
              "      <td>-6.936894</td>\n",
              "      <td>SELL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>KTC</td>\n",
              "      <td>Finance_Securities</td>\n",
              "      <td>0.250606</td>\n",
              "      <td>25.060636</td>\n",
              "      <td>BUY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>AEONTS</td>\n",
              "      <td>Finance_Securities</td>\n",
              "      <td>-0.088355</td>\n",
              "      <td>-8.835528</td>\n",
              "      <td>SELL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>JMT</td>\n",
              "      <td>Finance_Securities</td>\n",
              "      <td>0.054977</td>\n",
              "      <td>5.497665</td>\n",
              "      <td>BUY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>SAWAD</td>\n",
              "      <td>Finance_Securities</td>\n",
              "      <td>-0.099720</td>\n",
              "      <td>-9.972045</td>\n",
              "      <td>SELL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b1c16f10-4a40-4905-828a-e5affcea037e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b1c16f10-4a40-4905-828a-e5affcea037e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b1c16f10-4a40-4905-828a-e5affcea037e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_e2221b12-6e6d-41d8-9157-66c38eb16863\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_forecast_summary')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e2221b12-6e6d-41d8-9157-66c38eb16863 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_forecast_summary');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     Stock              Sector  Pred_dLogclose  Expected_Return_% Signal\n",
              "0      BBL             Banking        0.025432           2.543223    BUY\n",
              "1    KBANK             Banking        0.056954           5.695436    BUY\n",
              "2      KKP             Banking       -0.032508          -3.250787   SELL\n",
              "3      KTB             Banking        0.003092           0.309182    BUY\n",
              "4     TCAP             Banking        0.009530           0.953031    BUY\n",
              "5    TISCO             Banking        0.020245           2.024487    BUY\n",
              "6      TTB             Banking       -0.069369          -6.936894   SELL\n",
              "7      KTC  Finance_Securities        0.250606          25.060636    BUY\n",
              "8   AEONTS  Finance_Securities       -0.088355          -8.835528   SELL\n",
              "9      JMT  Finance_Securities        0.054977           5.497665    BUY\n",
              "10   SAWAD  Finance_Securities       -0.099720          -9.972045   SELL"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "âœ… Exported â†’ Forecast_ARDL_ECM_NextMonth_Clean.xlsx\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# ============================================================\n",
        "# âœ… Forecast next-month Î”Logclose (ECM Full, Simplified)\n",
        "#   - à¹ƒà¸Šà¹‰à¹€à¸‰à¸žà¸²à¸° lagged Î” + ECT\n",
        "#   - à¹„à¸¡à¹ˆà¸„à¸³à¸™à¸§à¸“/à¹„à¸¡à¹ˆà¸„à¸·à¸™à¸„à¹ˆà¸² Logclose_next à¹à¸¥à¸° Close_next\n",
        "# ============================================================\n",
        "\n",
        "def forecast_next_month_full(\n",
        "    stock_name, sector_name,\n",
        "    df_macro_levels,      # df à¸£à¸°à¸”à¸±à¸š (levels) à¸ªà¸³à¸«à¸£à¸±à¸š X à¹€à¸žà¸·à¹ˆà¸­à¸„à¸³à¸™à¸§à¸“ Î”X lag à¹à¸¥à¸° ECT\n",
        "    df_gamma, df_alpha, df_beta,\n",
        "    combined_dfs_selective_diff  # à¹ƒà¸Šà¹‰à¸”à¸¶à¸‡ Logclose(series) à¸‚à¸­à¸‡à¸«à¸¸à¹‰à¸™ (à¸£à¸°à¸”à¸±à¸š log)\n",
        "):\n",
        "    # --- à¸”à¸¶à¸‡à¸žà¸²à¸£à¸²à¸¡à¸´à¹€à¸•à¸­à¸£à¹Œ ---\n",
        "    gtab = df_gamma[df_gamma[\"Stock\"] == stock_name].copy()\n",
        "    atab = df_alpha[df_alpha[\"Stock\"] == stock_name]\n",
        "    btab = df_beta[df_beta[\"Stock\"] == stock_name]\n",
        "    if gtab.empty or atab.empty or btab.empty:\n",
        "        return None\n",
        "\n",
        "    # --- à¸à¸£à¸­à¸‡à¹€à¸‰à¸žà¸²à¸°à¸•à¸±à¸§à¹à¸›à¸£à¸—à¸µà¹ˆà¹€à¸›à¹‡à¸™ lagged Î” à¹à¸¥à¸°à¹€à¸žà¸´à¹ˆà¸¡ ECT ---\n",
        "    gtab = gtab[gtab[\"Variable\"].str.contains(r\"D\\.L\\d+\\.\", regex=True, na=False)]\n",
        "    gtab = pd.concat(\n",
        "        [gtab, pd.DataFrame([{\"Variable\": \"ECT_lag1\", \"Coef\": float(atab[\"Alpha\"].iloc[0])}])],\n",
        "        ignore_index=True\n",
        "    )\n",
        "\n",
        "    # --- à¹€à¸•à¸£à¸µà¸¢à¸¡ series Logclose à¸‚à¸­à¸‡à¸«à¸¸à¹‰à¸™ (à¸£à¸°à¸”à¸±à¸š log) ---\n",
        "    df_stock = combined_dfs_selective_diff[sector_name][[f\"Logclose_{stock_name}\"]].copy()\n",
        "    df_stock.columns = [\"Logclose\"]\n",
        "\n",
        "    # --- à¹€à¸•à¸£à¸µà¸¢à¸¡ macro (levels) à¹ƒà¸«à¹‰ index à¸ªà¸­à¸”à¸„à¸¥à¹‰à¸­à¸‡à¸à¸±à¸šà¸«à¸¸à¹‰à¸™ ---\n",
        "    df_macro_aligned = df_macro_levels.reindex(df_stock.index).ffill().copy()\n",
        "\n",
        "    # --- Long-run coefficients à¸ªà¸³à¸«à¸£à¸±à¸š ECT ---\n",
        "    lr_params = btab.drop_duplicates(subset=\"Variable\").set_index(\"Variable\")[\"coef\"]\n",
        "\n",
        "    # à¹ƒà¸Šà¹‰ 3 à¹à¸–à¸§à¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢à¹€à¸žà¸·à¹ˆà¸­à¸„à¸³à¸™à¸§à¸“ Î” à¹à¸¥à¸° lag\n",
        "    last_row = df_macro_aligned.tail(3).copy()\n",
        "    deltas = {}\n",
        "\n",
        "    # ---------- à¸„à¸³à¸™à¸§à¸“ Î” lag à¹à¸¥à¸° ECT ----------\n",
        "    for var in gtab[\"Variable\"]:\n",
        "        if var == \"ECT_lag1\":\n",
        "            const = float(lr_params.get(\"const\", 0.0))\n",
        "            X_lag = {\n",
        "                k: float(last_row[k].iloc[-2])\n",
        "                for k in lr_params.index\n",
        "                if k != \"const\" and k in last_row.columns\n",
        "            }\n",
        "            Y_lag = float(df_stock[\"Logclose\"].iloc[-2])\n",
        "            ect_val = Y_lag - (const + sum(float(lr_params[k]) * X_lag[k] for k in X_lag))\n",
        "            deltas[var] = float(ect_val)\n",
        "            continue\n",
        "\n",
        "        # à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸Šà¸·à¹ˆà¸­: \"D.L1.THOR_6M\" -> lag=1, base=\"THOR_6M\"\n",
        "        parts = var.split(\".\")\n",
        "        lag = int(parts[1].replace(\"L\", \"\"))\n",
        "        base = parts[2]\n",
        "\n",
        "        if base.startswith(\"Logclose_\"):  # Î”Y lag\n",
        "            stock_base = base.replace(\"Logclose_\", \"\")\n",
        "            if stock_base != stock_name:\n",
        "                continue\n",
        "            # Î”Y_t-lag = logY_{t-lag} - logY_{t-lag-1}\n",
        "            if len(df_stock) > lag + 1:\n",
        "                dy = float(df_stock[\"Logclose\"].iloc[-lag]) - float(df_stock[\"Logclose\"].iloc[-(lag+1)])\n",
        "            else:\n",
        "                dy = 0.0\n",
        "            deltas[var] = dy\n",
        "        else:  # Î”X lag à¸ˆà¸²à¸ levels\n",
        "            if base in df_macro_aligned.columns and len(last_row) > lag + 1:\n",
        "                dx = float(last_row[base].iloc[-lag]) - float(last_row[base].iloc[-(lag+1)])\n",
        "            else:\n",
        "                dx = 0.0\n",
        "            deltas[var] = dx\n",
        "\n",
        "    # ---------- à¸£à¸§à¸¡ contribution à¹€à¸›à¹‡à¸™ Î”Å¶ ----------\n",
        "    df_pred = pd.DataFrame(list(deltas.items()), columns=[\"Variable\", \"Value\"])\n",
        "    merged = pd.merge(gtab[[\"Variable\", \"Coef\"]], df_pred, on=\"Variable\", how=\"left\")\n",
        "    merged[\"Contribution\"] = merged[\"Coef\"].astype(float) * merged[\"Value\"].astype(float)\n",
        "\n",
        "    pred_dy = float(merged[\"Contribution\"].sum())\n",
        "\n",
        "    return {\n",
        "        \"Stock\": stock_name,\n",
        "        \"Sector\": sector_name,\n",
        "        \"Pred_dLogclose\": pred_dy,  # <-- à¸„à¸·à¸™à¸„à¹ˆà¸²à¹€à¸‰à¸žà¸²à¸° Î”Å¶\n",
        "        \"Details\": merged           # à¸•à¸²à¸£à¸²à¸‡à¸­à¸‡à¸„à¹Œà¸›à¸£à¸°à¸à¸­à¸š (à¸–à¹‰à¸²à¸•à¹‰à¸­à¸‡à¸à¸²à¸£ inspect)\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# ðŸš€ Run for ALL stocks (Clean Output)\n",
        "# ============================================================\n",
        "\n",
        "forecast_results = []\n",
        "\n",
        "for sector_name, df_sec in combined_dfs_selective_diff.items():\n",
        "    for col in df_sec.columns:\n",
        "        if not col.startswith(\"Logclose_\"):\n",
        "            continue\n",
        "        stock_name = col.replace(\"Logclose_\", \"\")\n",
        "        try:\n",
        "            res = forecast_next_month_full(\n",
        "                stock_name, sector_name,\n",
        "                df,            # levels macro (à¸•à¸±à¸§à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸šà¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸ªà¸£à¹‰à¸²à¸‡à¸Šà¸¸à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥)\n",
        "                df_gamma, df_alpha, df_beta,\n",
        "                combined_dfs_selective_diff\n",
        "            )\n",
        "            if res:\n",
        "                forecast_results.append({\n",
        "                    \"Stock\": stock_name,\n",
        "                    \"Sector\": sector_name,\n",
        "                    \"Pred_dLogclose\": res[\"Pred_dLogclose\"],\n",
        "                })\n",
        "                print(f\"âœ… {stock_name:<8} | Sector={sector_name:<20} | Î”Å¶={res['Pred_dLogclose']:+.5f}\")\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ {stock_name} failed: {e}\")\n",
        "\n",
        "# à¸•à¸²à¸£à¸²à¸‡à¸ªà¸£à¸¸à¸› CLEAN (à¹„à¸¡à¹ˆà¸¡à¸µ Logclose_next / Close_next)\n",
        "df_forecast_summary = pd.DataFrame(forecast_results)\n",
        "df_forecast_summary[\"Expected_Return_%\"] = df_forecast_summary[\"Pred_dLogclose\"] * 100.0\n",
        "df_forecast_summary[\"Signal\"] = np.where(df_forecast_summary[\"Pred_dLogclose\"] > 0, \"BUY\", \"SELL\")\n",
        "\n",
        "# à¹à¸ªà¸”à¸‡à¸œà¸¥à¹à¸¥à¸°à¸šà¸±à¸™à¸—à¸¶à¸\n",
        "display(df_forecast_summary)\n",
        "df_forecast_summary.to_excel(\"Forecast_ARDL_ECM_NextMonth_Clean.xlsx\", index=False)\n",
        "print(\"\\nâœ… Exported â†’ Forecast_ARDL_ECM_NextMonth_Clean.xlsx\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzlO7rCf_-Q9"
      },
      "source": [
        "# Technical Indicators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1C8fkZTfC9iA",
        "outputId": "04e299c1-c802-482a-e300-600302c84b12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ta\n",
            "  Downloading ta-0.11.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from ta) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from ta) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->ta) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->ta) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->ta) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->ta) (1.17.0)\n",
            "Building wheels for collected packages: ta\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta: filename=ta-0.11.0-py3-none-any.whl size=29412 sha256=a2fd65c50b94cec50297d7758f8db15f05c05328f3d9699246df5d549e4e6abc\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/a1/5f/c6b85a7d9452057be4ce68a8e45d77ba34234a6d46581777c6\n",
            "Successfully built ta\n",
            "Installing collected packages: ta\n",
            "Successfully installed ta-0.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install ta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6yzCB4C_-X8",
        "outputId": "a47864b5-2c4b-4586-dce2-a2674ecce044"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“¥ Downloading Banking â†’ BBL.BK ...\n",
            "ðŸ“¥ Downloading Banking â†’ KBANK.BK ...\n",
            "ðŸ“¥ Downloading Banking â†’ KKP.BK ...\n",
            "ðŸ“¥ Downloading Banking â†’ KTB.BK ...\n",
            "ðŸ“¥ Downloading Banking â†’ TCAP.BK ...\n",
            "ðŸ“¥ Downloading Banking â†’ TISCO.BK ...\n",
            "ðŸ“¥ Downloading Banking â†’ TTB.BK ...\n",
            "ðŸ“¥ Downloading Finance_Securities â†’ KTC.BK ...\n",
            "ðŸ“¥ Downloading Finance_Securities â†’ AEONTS.BK ...\n",
            "ðŸ“¥ Downloading Finance_Securities â†’ JMT.BK ...\n",
            "ðŸ“¥ Downloading Finance_Securities â†’ SAWAD.BK ...\n",
            "\n",
            "âœ… Exported â†’ Historical_Technical_Indicators_bySector.xlsx\n",
            "âœ… Total sectors: 2, total stocks: 11, total rows: 26730\n",
            "\n",
            "ðŸ“ˆ Example â€” Banking / BBL\n",
            "Price       Date       Close     RSI_14      MACD     ADX_14    ATR_14  \\\n",
            "4850  2024-12-17  138.902374  41.742812  0.190827  14.296933  1.789800   \n",
            "4851  2024-12-18  139.844070  45.915842  0.075202  14.055360  1.796486   \n",
            "4852  2024-12-19  140.314926  47.924460  0.021317  13.139435  1.836329   \n",
            "4853  2024-12-20  140.785782  49.927153  0.016417  12.288933  1.839692   \n",
            "4854  2024-12-23  141.727493  53.757488  0.087513  11.671526  1.842816   \n",
            "4855  2024-12-24  141.727493  53.757488  0.142218  11.098220  1.812084   \n",
            "4856  2024-12-25  141.727493  53.757488  0.183457  10.565863  1.749914   \n",
            "4857  2024-12-26  141.727493  53.757488  0.213677  10.071533  1.692185   \n",
            "4858  2024-12-27  141.727493  53.757488  0.234918  10.031404  1.672213   \n",
            "4859  2024-12-30  142.198349  56.184943  0.286444   9.994141  1.620034   \n",
            "\n",
            "Price  TechScore      EMA_12      EMA_26    BB7_High     BB7_Low   BB14_High  \\\n",
            "4850    0.284825  141.116319  140.925492  144.912028  138.812023  144.593859   \n",
            "4851    0.307623  140.920588  140.845386  144.523146  138.259194  144.469173   \n",
            "4852    0.315722  140.827410  140.806093  143.128154  138.577944  144.297729   \n",
            "4853    0.324857  140.821005  140.804589  142.646652  138.655856  144.055026   \n",
            "4854    0.357197  140.960465  140.872952  142.388893  138.779085  144.101567   \n",
            "4855    0.351915  141.078469  140.936251  142.582118  138.720390  144.140940   \n",
            "4856    0.339930  141.178319  140.994862  142.758763  138.678275  144.140940   \n",
            "4857    0.330820  141.262808  141.049131  142.608042  139.636173  144.002592   \n",
            "4858    0.330228  141.334298  141.099380  142.484096  140.298239  143.736778   \n",
            "4859    0.346200  141.467229  141.180785  142.444667  140.875789  143.140056   \n",
            "\n",
            "Price    BB14_Low Pattern_Type  Pattern_Confidence Wave_Direction  \\\n",
            "4850   137.448569     Triangle                 0.7           Down   \n",
            "4851   137.775048     Triangle                 0.7             Up   \n",
            "4852   138.215550    DoubleTop                 0.0             Up   \n",
            "4853   138.794577    DoubleTop                 0.0             Up   \n",
            "4854   138.882566     Triangle                 0.7             Up   \n",
            "4855   138.977723     Triangle                 0.7             Up   \n",
            "4856   138.977723     Triangle                 0.7             Up   \n",
            "4857   138.981541     Triangle                 0.7             Up   \n",
            "4858   139.045559     Triangle                 0.7             Up   \n",
            "4859   139.373221     Triangle                 0.7             Up   \n",
            "\n",
            "Price  Wave_Strength  Wave_Valid  \n",
            "4850        1.006515         0.5  \n",
            "4851        0.181121         0.5  \n",
            "4852        0.268509         0.0  \n",
            "4853        0.355283         0.0  \n",
            "4854        0.290953         0.0  \n",
            "4855        0.502737         0.5  \n",
            "4856        0.499506         0.5  \n",
            "4857        0.278470         0.5  \n",
            "4858        0.278892         0.5  \n",
            "4859        0.347879         0.5  \n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# FIXED BLOCK â€” Daily Indicators + Pattern + Wave (SECTOR version)\n",
        "# ============================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ta\n",
        "import yfinance as yf\n",
        "from scipy.signal import argrelextrema\n",
        "from scipy.stats import skew, kurtosis\n",
        "from pathlib import Path\n",
        "\n",
        "# ---------- SECTORS ----------\n",
        "SECTORS = {\n",
        "    \"Banking\": [\"BBL\",\"KBANK\",\"KKP\",\"KTB\",\"TCAP\",\"TISCO\",\"TTB\"],\n",
        "    \"Finance_Securities\": [\"KTC\",\"AEONTS\",\"JMT\",\"SAWAD\"],\n",
        "    # \"Energy_Utilities\": [\"BANPU\",\"BCP\",\"EGCO\",\"GPSC\",\"GULF\",\"OR\",\"PTT\",\"PTTEP\",\"RATCH\",\"TOP\",\"BGRIM\",\"BCPG\",\"EA\",\"GUNKUL\",\"IRPC\",\"SPRC\",\"WHAUP\",\"CKP\"],\n",
        "    # \"Food_Beverage\": [\"CBG\",\"CPF\",\"OSP\",\"TU\",\"ITC\",\"BTG\",\"ICHI\",\"M\",\"TFG\",\"COCOCO\",\"SAPPE\",\"SNNP\"],\n",
        "    # \"Commerce\": [\"BJC\",\"COM7\",\"CPALL\",\"CRC\",\"HMPRO\",\"GLOBAL\",\"DOHOME\",\"MEGA\",\"MOSHI\"],\n",
        "    # \"Property_Development\": [\"AWC\",\"CPN\",\"LH\",\"WHA\",\"AMATA\",\"AP\",\"MBK\",\"QH\",\"SIRI\",\"SPALI\",\"ROJNA\"],\n",
        "    # \"Health_Care_Services\": [\"BDMS\",\"BH\",\"BCH\",\"CHG\",\"PR9\"],\n",
        "    # \"Electronic_Components\": [\"CCET\",\"DELTA\",\"HANA\",\"KCE\"],\n",
        "    # \"Construction_Materials\": [\"SCC\",\"TASCO\",\"TOA\"],\n",
        "    # \"ICT\": [\"ADVANC\",\"TRUE\",\"JAS\",\"JMART\",\"JTS\",\"SKY\"],\n",
        "    # \"Transportation_Logistics\": [\"AOT\",\"BEM\",\"BTS\",\"AAV\",\"BA\",\"PRM\",\"RCL\"],\n",
        "}\n",
        "\n",
        "START_DATE = \"2015-01-01\"\n",
        "END_DATE = \"2025-01-01\"\n",
        "\n",
        "ROLLING_WINDOW = 250\n",
        "VOL_LOOKBACK = 20\n",
        "VOL_MULTIPLIER = 0.5\n",
        "MIN_THRESHOLD = 0.002\n",
        "FIB_EXT, FIB_RET = 1.618, 0.618\n",
        "\n",
        "# ---------- Utility ----------\n",
        "def safe_skew(x):\n",
        "    x = x[~np.isnan(x)]\n",
        "    return skew(x, bias=False) if len(x) > 2 else np.nan\n",
        "\n",
        "def safe_kurtosis(x):\n",
        "    x = x[~np.isnan(x)]\n",
        "    return kurtosis(x, bias=False) if len(x) > 2 else np.nan\n",
        "\n",
        "def detect_zigzag(price_series, threshold):\n",
        "    zz_idx, last_p, direction = [], price_series.iloc[0], 0\n",
        "    for i, p in enumerate(price_series):\n",
        "        change = (p - last_p) / (abs(last_p) + 1e-9)\n",
        "        if direction == 0:\n",
        "            direction = np.sign(change)\n",
        "        elif direction > 0 and change <= -threshold:\n",
        "            zz_idx.append(i); direction = -1; last_p = p\n",
        "        elif direction < 0 and change >= threshold:\n",
        "            zz_idx.append(i); direction = 1; last_p = p\n",
        "    peaks = argrelextrema(price_series.values, np.greater, order=5)[0]\n",
        "    troughs = argrelextrema(price_series.values, np.less, order=5)[0]\n",
        "    zz_idx = sorted(list(set(zz_idx + list(peaks) + list(troughs))))\n",
        "    return [0] + zz_idx + [len(price_series) - 1]\n",
        "\n",
        "def detect_dominant_pattern(prices):\n",
        "    y = (prices - prices.min()) / (prices.max() - prices.min() + 1e-9)\n",
        "    peaks = argrelextrema(y.values, np.greater, order=5)[0]\n",
        "    troughs = argrelextrema(y.values, np.less, order=5)[0]\n",
        "    score_doubletop = score_headshoulder = score_triangle = 0\n",
        "    if len(peaks) >= 2:\n",
        "        diff = abs(y.iloc[peaks[-1]] - y.iloc[peaks[-2]])\n",
        "        if diff < 0.05: score_doubletop = 1 - diff\n",
        "    if len(peaks) >= 3:\n",
        "        l, m, r = y.iloc[peaks[-3]], y.iloc[peaks[-2]], y.iloc[peaks[-1]]\n",
        "        if m > l and m > r: score_headshoulder = min(abs(m - (l + r) / 2), 1)\n",
        "    highslope = (y.iloc[-1] - y.iloc[0]) / len(y)\n",
        "    std_band = y.rolling(10).std().iloc[-1]\n",
        "    if std_band < 0.05 and abs(highslope) < 0.02:\n",
        "        score_triangle = 0.7\n",
        "    scores = {\"DoubleTop\": score_doubletop, \"HeadShoulder\": score_headshoulder, \"Triangle\": score_triangle}\n",
        "    return max(scores, key=scores.get), float(scores[max(scores, key=scores.get)])\n",
        "\n",
        "def validate_wave_relaxed(deltas):\n",
        "    if len(deltas) < 3: return 0.0\n",
        "    if len(deltas) >= 5: d1, d3, d5 = deltas[0], deltas[2], deltas[4]\n",
        "    elif len(deltas) >= 3: d1, d3, d5 = deltas[0], deltas[2], deltas[-1]\n",
        "    else: return 0.0\n",
        "    ratio_13 = abs(d3 / (d1 + 1e-9))\n",
        "    ratio_35 = abs(d5 / (d3 + 1e-9))\n",
        "    cond1 = 1.0 <= ratio_13 / FIB_EXT <= 2.0\n",
        "    cond2 = 0.5 <= ratio_35 / FIB_RET <= 2.0\n",
        "    score = 0\n",
        "    if cond1: score += 0.5\n",
        "    if cond2: score += 0.5\n",
        "    return score\n",
        "\n",
        "# ---------- Download by SECTOR ----------\n",
        "all_data = []\n",
        "\n",
        "for sector, stocks in SECTORS.items():\n",
        "    for s in stocks:\n",
        "        ticker = s + \".BK\"\n",
        "        print(f\"ðŸ“¥ Downloading {sector} â†’ {ticker} ...\")\n",
        "        df = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n",
        "        if df.empty:\n",
        "            print(f\"âš ï¸ No data for {ticker}, skipped\")\n",
        "            continue\n",
        "\n",
        "        # Flatten MultiIndex (à¸šà¸²à¸‡ version à¸‚à¸­à¸‡ yfinance)\n",
        "        if isinstance(df.columns, pd.MultiIndex):\n",
        "            df.columns = df.columns.get_level_values(0)\n",
        "\n",
        "        df = df.reset_index()\n",
        "        df[\"Stock\"] = s\n",
        "        df[\"Sector\"] = sector\n",
        "        df.rename(columns={\"Date\":\"Date\",\"Close\":\"Close\",\"High\":\"High\",\"Low\":\"Low\",\"Volume\":\"Volume\"}, inplace=True)\n",
        "        all_data.append(df)\n",
        "\n",
        "df_all = pd.concat(all_data, ignore_index=True)\n",
        "\n",
        "# ---------- Compute indicators ----------\n",
        "results = []\n",
        "\n",
        "for stock, sub in df_all.groupby(\"Stock\"):\n",
        "    sub = sub.copy().sort_values(\"Date\")\n",
        "\n",
        "    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸à¸£à¸“à¸µ Close à¹€à¸›à¹‡à¸™ DataFrame (à¸ˆà¸²à¸ MultiColumn yfinance)\n",
        "    if isinstance(sub[\"Close\"], pd.DataFrame):\n",
        "        sub[\"Close\"] = sub[\"Close\"].iloc[:, 0]\n",
        "\n",
        "    # --- Basic Return ---\n",
        "    sub[\"Return\"] = sub[\"Close\"].pct_change()\n",
        "\n",
        "    # --- Momentum Indicators ---\n",
        "    sub[\"RSI_14\"] = ta.momentum.rsi(sub[\"Close\"], window=14)\n",
        "    sub[\"MACD\"] = ta.trend.macd(sub[\"Close\"])\n",
        "    sub[\"EMA_12\"] = ta.trend.ema_indicator(sub[\"Close\"], window=12)\n",
        "    sub[\"EMA_26\"] = ta.trend.ema_indicator(sub[\"Close\"], window=26)\n",
        "    sub[\"ADX_14\"] = ta.trend.adx(sub[\"High\"], sub[\"Low\"], sub[\"Close\"], window=14)\n",
        "    sub[\"ATR_14\"] = ta.volatility.average_true_range(sub[\"High\"], sub[\"Low\"], sub[\"Close\"], window=14)\n",
        "\n",
        "    # --- Bollinger Bands ---\n",
        "    bb7 = ta.volatility.BollingerBands(sub[\"Close\"], window=7, window_dev=2)\n",
        "    bb14 = ta.volatility.BollingerBands(sub[\"Close\"], window=14, window_dev=2)\n",
        "\n",
        "    sub[\"BB7_High\"] = bb7.bollinger_hband()\n",
        "    sub[\"BB7_Low\"] = bb7.bollinger_lband()\n",
        "    sub[\"BB14_High\"] = bb14.bollinger_hband()\n",
        "    sub[\"BB14_Low\"] = bb14.bollinger_lband()\n",
        "\n",
        "    # --- Normalize selected features ---\n",
        "    feats = [\n",
        "        \"RSI_14\", \"MACD\", \"ADX_14\", \"ATR_14\",\n",
        "        \"EMA_12\", \"EMA_26\", \"BB7_High\", \"BB7_Low\", \"BB14_High\", \"BB14_Low\"\n",
        "    ]\n",
        "    zdf = sub[feats].apply(lambda x: (x - x.mean()) / (x.std() + 1e-9))\n",
        "\n",
        "    # --- Technical Composite Score ---\n",
        "    sub[\"TechScore\"] = zdf.mean(axis=1)\n",
        "\n",
        "    # Pattern + Wave\n",
        "    pattern_types, pattern_conf, wave_dir, wave_strength, wave_valid = [], [], [], [], []\n",
        "    for i in range(len(sub)):\n",
        "        window = sub[\"Close\"].iloc[max(0, i - ROLLING_WINDOW):i+1]\n",
        "        if len(window) < 60:\n",
        "            pattern_types.append(None)\n",
        "            pattern_conf.append(np.nan)\n",
        "            wave_dir.append(None)\n",
        "            wave_strength.append(np.nan)\n",
        "            wave_valid.append(np.nan)\n",
        "            continue\n",
        "\n",
        "        log_prices = np.log(window)\n",
        "        log_prices = (log_prices - log_prices.mean()) / (log_prices.std() + 1e-9)\n",
        "        rolling_vol = log_prices.diff().std()\n",
        "        thr = max(MIN_THRESHOLD, VOL_MULTIPLIER * rolling_vol)\n",
        "        zz_idx = detect_zigzag(log_prices, thr)\n",
        "        pivots = log_prices.iloc[zz_idx].values\n",
        "\n",
        "        ptype, pconf = detect_dominant_pattern(log_prices)\n",
        "        if len(pivots) >= 3:\n",
        "            deltas = np.diff(pivots)\n",
        "            wdir = \"Up\" if deltas[-1] > 0 else \"Down\"\n",
        "            wstr = abs(deltas[-1] / (np.mean(np.abs(pivots)) + 1e-9))\n",
        "            wval = validate_wave_relaxed(deltas)\n",
        "        else:\n",
        "            wdir, wstr, wval = None, np.nan, np.nan\n",
        "\n",
        "        pattern_types.append(ptype)\n",
        "        pattern_conf.append(pconf)\n",
        "        wave_dir.append(wdir)\n",
        "        wave_strength.append(wstr)\n",
        "        wave_valid.append(wval)\n",
        "\n",
        "    sub[\"Pattern_Type\"] = pattern_types\n",
        "    sub[\"Pattern_Confidence\"] = pattern_conf\n",
        "    sub[\"Wave_Direction\"] = wave_dir\n",
        "    sub[\"Wave_Strength\"] = wave_strength\n",
        "    sub[\"Wave_Valid\"] = wave_valid\n",
        "\n",
        "    results.append(sub)\n",
        "\n",
        "# ---------- Combine ----------\n",
        "df_final = pd.concat(results).reset_index(drop=True)\n",
        "df_final = df_final.sort_values([\"Sector\", \"Stock\", \"Date\"])\n",
        "\n",
        "# ---------- Export ----------\n",
        "out_path = Path(\"Historical_Technical_Indicators_bySector.xlsx\")\n",
        "df_final.to_excel(out_path, index=False)\n",
        "print(f\"\\nâœ… Exported â†’ {out_path.name}\")\n",
        "print(f\"âœ… Total sectors: {df_final['Sector'].nunique()}, total stocks: {df_final['Stock'].nunique()}, total rows: {len(df_final)}\")\n",
        "\n",
        "# ---------- Example ----------\n",
        "sample_sector = df_final[\"Sector\"].iloc[0]\n",
        "sample_stock = df_final[df_final[\"Sector\"] == sample_sector][\"Stock\"].iloc[0]\n",
        "sample = df_final[df_final[\"Stock\"] == sample_stock].tail(10)[\n",
        "    [\"Date\",\"Close\",\"RSI_14\",\"MACD\",\"ADX_14\",\"ATR_14\",\"TechScore\",\"EMA_12\", \"EMA_26\", \"BB7_High\", \"BB7_Low\", \"BB14_High\", \"BB14_Low\" ,\n",
        "     \"Pattern_Type\",\"Pattern_Confidence\",\"Wave_Direction\",\"Wave_Strength\",\"Wave_Valid\"]\n",
        "]\n",
        "print(f\"\\nðŸ“ˆ Example â€” {sample_sector} / {sample_stock}\")\n",
        "print(sample)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDPx4_oMDZt_"
      },
      "source": [
        "ðŸ“Š à¸ªà¸£à¸¸à¸› DL Structure à¸‚à¸­à¸‡ Block 5.5\n",
        "Componentà¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”InputClose Price â†’ Kalman Filter â†’ MinMaxScaler â†’ Shape (60, 1)Model2 à¹‚à¸¡à¹€à¸”à¸¥: CNN-LSTM à¹à¸¥à¸° CNN-GRULayers7 layers: Conv1D â†’ BN â†’ MaxPool â†’ LSTM/GRU â†’ BN â†’ Dropout â†’ DenseOutputProbability [0,1] à¸§à¹ˆà¸²à¸£à¸²à¸„à¸²à¸ˆà¸°à¸‚à¸¶à¹‰à¸™Ensemble(LSTM + GRU) / 2OptimizerAdam (lr=0.001)LossBinary Crossentropy\n",
        "\n",
        "ðŸ”¬ Activation Functions\n",
        "LayerActivationà¹€à¸«à¸•à¸¸à¸œà¸¥Conv1DReLUà¹€à¸£à¹‡à¸§, à¹„à¸¡à¹ˆà¸¡à¸µ vanishing gradient, à¸”à¸µà¸ªà¸³à¸«à¸£à¸±à¸š feature extractionLSTM/GRUtanh + sigmoidBuilt-in à¸ªà¸³à¸«à¸£à¸±à¸š gates à¹à¸¥à¸° cell stateDense (Output)SigmoidBinary classification â†’ output à¹€à¸›à¹‡à¸™ probability [0,1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muOqS_uzDdnK"
      },
      "source": [
        "ðŸ§  Bidirectional + Attention à¸„à¸·à¸­à¸­à¸°à¹„à¸£ à¹à¸¥à¸°à¹€à¸žà¸´à¹ˆà¸¡à¹€à¸‚à¹‰à¸²à¹„à¸›à¸¢à¸±à¸‡à¹„à¸‡\n",
        "\n",
        "1. Bidirectional LSTM/GRU à¸„à¸·à¸­à¸­à¸°à¹„à¸£?\n",
        "à¸›à¸±à¸ˆà¸ˆà¸¸à¸šà¸±à¸™ (Unidirectional):\n",
        "Past â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> Future\n",
        " t-60   t-59   t-58   ...   t-2   t-1   t\n",
        "  â†’      â†’      â†’      â†’     â†’     â†’    [Output]\n",
        "à¸­à¹ˆà¸²à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸ à¸‹à¹‰à¸²à¸¢à¹„à¸›à¸‚à¸§à¸² à¸­à¸¢à¹ˆà¸²à¸‡à¹€à¸”à¸µà¸¢à¸§ (à¸­à¸”à¸µà¸• â†’ à¸›à¸±à¸ˆà¸ˆà¸¸à¸šà¸±à¸™)\n",
        "Bidirectional:\n",
        "Forward:   t-60 â†’ t-59 â†’ t-58 â†’ ... â†’ t-1 â†’ t\n",
        "                                            â†˜\n",
        "                                             [Concat] â†’ Output\n",
        "                                            â†—\n",
        "Backward:  t-60 â† t-59 â† t-58 â† ... â† t-1 â† t\n",
        "à¸­à¹ˆà¸²à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ à¸—à¸±à¹‰à¸‡à¸ªà¸­à¸‡à¸—à¸´à¸¨à¸—à¸²à¸‡ à¹à¸¥à¹‰à¸§à¸£à¸§à¸¡à¸à¸±à¸™\n",
        "à¸‚à¹‰à¸­à¸”à¸µ:\n",
        "\n",
        "à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆ Context à¹„à¸”à¹‰à¸”à¸µà¸‚à¸¶à¹‰à¸™ (à¸£à¸¹à¹‰à¸—à¸±à¹‰à¸‡à¸­à¸”à¸µà¸•à¹à¸¥à¸°à¸­à¸™à¸²à¸„à¸•à¸‚à¸­à¸‡à¹à¸•à¹ˆà¸¥à¸°à¸ˆà¸¸à¸”)\n",
        "à¸ˆà¸±à¸š Pattern à¸—à¸µà¹ˆà¸‹à¸±à¸šà¸‹à¹‰à¸­à¸™à¹„à¸”à¹‰à¸”à¸µà¸à¸§à¹ˆà¸²\n",
        "\n",
        "\n",
        "2. Attention Mechanism à¸„à¸·à¸­à¸­à¸°à¹„à¸£?\n",
        "à¸›à¸±à¸à¸«à¸²à¸‚à¸­à¸‡ LSTM à¸›à¸à¸•à¸´:\n",
        "\n",
        "Output à¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢à¸•à¹‰à¸­à¸‡ \"à¸ˆà¸³\" à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸±à¹‰à¸‡ 60 à¸§à¸±à¸™à¹„à¸§à¹‰à¹ƒà¸™ hidden state à¹€à¸”à¸µà¸¢à¸§\n",
        "à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸à¹ˆà¸²à¹† à¸­à¸²à¸ˆà¸–à¸¹à¸à¸¥à¸·à¸¡ (vanishing information)\n",
        "\n",
        "Attention à¹à¸à¹‰à¸›à¸±à¸à¸«à¸²à¸™à¸µà¹‰:\n",
        "Input: [t-60, t-59, t-58, ..., t-2, t-1, t]\n",
        "         â†“     â†“     â†“          â†“    â†“   â†“\n",
        "       [h1,   h2,   h3,   ..., h58, h59, h60]  â† Hidden states à¸—à¸¸à¸ timestep\n",
        "         â†“     â†“     â†“          â†“    â†“   â†“\n",
        "       [0.01, 0.02, 0.05, ..., 0.15, 0.30, 0.40]  â† Attention weights\n",
        "         â†“     â†“     â†“          â†“    â†“   â†“\n",
        "       â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Weighted Sum â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "                        â†“\n",
        "                   Context Vector\n",
        "                        â†“\n",
        "                     Output\n",
        "à¸‚à¹‰à¸­à¸”à¸µ:\n",
        "\n",
        "à¹‚à¸¡à¹€à¸”à¸¥ \"à¹€à¸¥à¸·à¸­à¸\" à¸§à¹ˆà¸²à¸ˆà¸°à¹ƒà¸«à¹‰à¸„à¸§à¸²à¸¡à¸ªà¸³à¸„à¸±à¸à¸à¸±à¸šà¸§à¸±à¸™à¹„à¸«à¸™à¸¡à¸²à¸à¸à¸§à¹ˆà¸²\n",
        "à¸§à¸±à¸™à¸—à¸µà¹ˆà¸ªà¸³à¸„à¸±à¸ (à¹€à¸Šà¹ˆà¸™ à¸§à¸±à¸™à¸—à¸µà¹ˆà¸¡à¸µ pattern breakout) à¸ˆà¸°à¹„à¸”à¹‰ weight à¸ªà¸¹à¸‡\n",
        "Interpretable: à¸”à¸¹à¹„à¸”à¹‰à¸§à¹ˆà¸²à¹‚à¸¡à¹€à¸”à¸¥à¸ªà¸™à¹ƒà¸ˆà¸§à¸±à¸™à¹„à¸«à¸™\n",
        "\n",
        "\n",
        "3. à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¹ƒà¸«à¸¡à¹ˆà¸—à¸µà¹ˆà¹€à¸ªà¸™à¸­\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚                  ðŸ—ï¸ UPGRADED MODEL: BiLSTM + Attention           â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚                                                                 â”‚\n",
        "â”‚  Input (60, 1)                                                  â”‚\n",
        "â”‚       â†“                                                         â”‚\n",
        "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\n",
        "â”‚  â”‚ Conv1D (64 filters, kernel=3, ReLU)                      â”‚   â”‚\n",
        "â”‚  â”‚ BatchNormalization                                       â”‚   â”‚\n",
        "â”‚  â”‚ MaxPooling1D (pool=2)                                    â”‚   â”‚\n",
        "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\n",
        "â”‚       â†“                                                         â”‚\n",
        "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\n",
        "â”‚  â”‚ ðŸ†• Bidirectional LSTM (50 units, return_sequences=True)  â”‚   â”‚\n",
        "â”‚  â”‚    Output: (timesteps, 100)  â† 50*2 à¹€à¸žà¸£à¸²à¸° bi-directional â”‚   â”‚\n",
        "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\n",
        "â”‚       â†“                                                         â”‚\n",
        "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\n",
        "â”‚  â”‚ ðŸ†• Attention Layer                                       â”‚   â”‚\n",
        "â”‚  â”‚    - Compute attention weights for each timestep         â”‚   â”‚\n",
        "â”‚  â”‚    - Weighted sum â†’ Context vector (100,)                â”‚   â”‚\n",
        "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\n",
        "â”‚       â†“                                                         â”‚\n",
        "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\n",
        "â”‚  â”‚ BatchNormalization                                       â”‚   â”‚\n",
        "â”‚  â”‚ Dropout (0.3)                                            â”‚   â”‚\n",
        "â”‚  â”‚ Dense (1, sigmoid)                                       â”‚   â”‚\n",
        "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\n",
        "â”‚       â†“                                                         â”‚\n",
        "â”‚  Output: P(price UP) âˆˆ [0, 1]                                   â”‚\n",
        "â”‚                                                                 â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "\n",
        "4. à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š à¹€à¸”à¸´à¸¡ vs à¹ƒà¸«à¸¡à¹ˆ\n",
        "Componentà¹€à¸”à¸´à¸¡ (Block 5.5)à¹ƒà¸«à¸¡à¹ˆ (Upgraded)LSTM/GRUUnidirectionalBidirectionalreturn_sequencesFalseTrue (à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸—à¸¸à¸ timestep)AttentionâŒ à¹„à¸¡à¹ˆà¸¡à¸µâœ… à¸¡à¸µOutput dimension50100 (50Ã—2)Interpretabilityà¸•à¹ˆà¸³à¸ªà¸¹à¸‡ (à¸”à¸¹ attention weights à¹„à¸”à¹‰)\n",
        "\n",
        "5. à¸‚à¹‰à¸­à¸„à¸§à¸£à¸£à¸°à¸§à¸±à¸‡\n",
        "à¸‚à¹‰à¸­à¸”à¸µà¸‚à¹‰à¸­à¹€à¸ªà¸µà¸¢à¸ˆà¸±à¸š pattern à¹„à¸”à¹‰à¸”à¸µà¸‚à¸¶à¹‰à¸™Parameters à¹€à¸žà¸´à¹ˆà¸¡à¸‚à¸¶à¹‰à¸™ ~2xInterpretable (attention weights)Train à¸™à¸²à¸™à¸‚à¸¶à¹‰à¸™à¸¥à¸” information lossà¸­à¸²à¸ˆ overfit à¸–à¹‰à¸²à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸™à¹‰à¸­à¸¢"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czUyyAvCABB1",
        "outputId": "ebf662a5-51a9-4884-e00d-4983a033719a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "ðŸ§  BLOCK 5.5: Deep Learning Signal (UPGRADED + ROLLING WINDOW)\n",
            "======================================================================\n",
            "\n",
            "ðŸ“¦ Model Architecture:\n",
            "   - Model 1: CNN + Bidirectional LSTM + Attention\n",
            "   - Model 2: CNN + Bidirectional GRU + Attention  \n",
            "   - Model 3: Stacked Bidirectional LSTM + Attention\n",
            "\n",
            "ðŸ”„ Rolling Window Configuration:\n",
            "   - Window 1: Train [2015-2018] â†’ Test [2019]\n",
            "   - Window 2: Train [2016-2019] â†’ Test [2020]\n",
            "   - Window 3: Train [2017-2020] â†’ Test [2021]\n",
            "   - Window 4: Train [2018-2021] â†’ Test [2022]\n",
            "   - Window 5: Train [2019-2022] â†’ Test [2023]\n",
            "   - Window 6: Train [2020-2023] â†’ Test [2024]\n",
            "   - Window 7: Train [2021-2024] â†’ Test [2025]\n",
            "\n",
            "âš™ï¸ Configuration:\n",
            "   - Lookback: 60 days\n",
            "   - Epochs: 20 (with EarlyStopping)\n",
            "   - Batch Size: 32\n",
            "   - Ensemble: Average of 3 models\n",
            "\n",
            "======================================================================\n",
            "\n",
            "==================================================\n",
            "ðŸ”¹ Processing: BBL\n",
            "==================================================\n",
            "   ðŸ“… Data range: 2015-01-05 to 2025-12-30\n",
            "   ðŸ“Š Total rows: 2672\n",
            "\n",
            "   ðŸ“Š Rolling Window Results for BBL:\n",
            "   Train Period    Test Year  Accuracy   F1 Score  \n",
            "   ---------------------------------------------\n",
            "   2015-2018       2019       30.74%     47.02%\n",
            "   2016-2019       2020       53.50%     51.08%\n",
            "   2017-2020       2021       63.07%     77.35%\n",
            "   2018-2021       2022       17.43%     0.00%\n",
            "   2019-2022       2023       51.44%     53.17%\n",
            "   2020-2023       2024       46.91%     63.87%\n",
            "   2021-2024       2025       67.22%     80.40%\n",
            "   ---------------------------------------------\n",
            "   AVERAGE                    47.19%     53.27%\n",
            "\n",
            "==================================================\n",
            "ðŸ”¹ Processing: KBANK\n",
            "==================================================\n",
            "   ðŸ“… Data range: 2015-01-05 to 2025-12-30\n",
            "   ðŸ“Š Total rows: 2672\n",
            "\n",
            "   ðŸ“Š Rolling Window Results for KBANK:\n",
            "   Train Period    Test Year  Accuracy   F1 Score  \n",
            "   ---------------------------------------------\n",
            "   2015-2018       2019       73.36%     0.00%\n",
            "   2016-2019       2020       41.15%     7.74%\n",
            "   2017-2020       2021       39.42%     13.10%\n",
            "   2018-2021       2022       46.47%     0.00%\n",
            "   2019-2022       2023       62.55%     0.00%\n",
            "   2020-2023       2024       70.78%     77.17%\n",
            "   2021-2024       2025       67.63%     78.33%\n",
            "   ---------------------------------------------\n",
            "   AVERAGE                    57.34%     25.19%\n",
            "\n",
            "==================================================\n",
            "ðŸ”¹ Processing: KKP\n",
            "==================================================\n",
            "   ðŸ“… Data range: 2015-01-05 to 2025-12-30\n",
            "   ðŸ“Š Total rows: 2672\n",
            "\n",
            "   ðŸ“Š Rolling Window Results for KKP:\n",
            "   Train Period    Test Year  Accuracy   F1 Score  \n",
            "   ---------------------------------------------\n",
            "   2015-2018       2019       50.82%     67.39%\n",
            "   2016-2019       2020       35.80%     52.73%\n",
            "   2017-2020       2021       70.95%     83.01%\n",
            "   2018-2021       2022       34.85%     37.94%\n",
            "   2019-2022       2023       38.68%     23.59%\n",
            "   2020-2023       2024       82.30%     82.87%\n",
            "   2021-2024       2025       74.69%     80.88%\n",
            "   ---------------------------------------------\n",
            "   AVERAGE                    55.44%     61.20%\n",
            "\n",
            "==================================================\n",
            "ðŸ”¹ Processing: KTB\n",
            "==================================================\n",
            "   ðŸ“… Data range: 2015-01-05 to 2025-12-30\n",
            "   ðŸ“Š Total rows: 2672\n",
            "\n",
            "   ðŸ“Š Rolling Window Results for KTB:\n",
            "   Train Period    Test Year  Accuracy   F1 Score  \n",
            "   ---------------------------------------------\n",
            "   2015-2018       2019       57.79%     0.00%\n",
            "   2016-2019       2020       22.63%     31.88%\n",
            "   2017-2020       2021       36.51%     53.50%\n",
            "   2018-2021       2022       46.47%     60.06%\n",
            "   2019-2022       2023       68.31%     71.59%\n",
            "   2020-2023       2024       47.33%     45.30%\n",
            "   2021-2024       2025       78.84%     88.17%\n",
            "   ---------------------------------------------\n",
            "   AVERAGE                    51.13%     50.07%\n",
            "\n",
            "==================================================\n",
            "ðŸ”¹ Processing: TCAP\n",
            "==================================================\n",
            "   ðŸ“… Data range: 2015-01-05 to 2025-12-30\n",
            "   ðŸ“Š Total rows: 2672\n",
            "\n",
            "   ðŸ“Š Rolling Window Results for TCAP:\n",
            "   Train Period    Test Year  Accuracy   F1 Score  \n",
            "   ---------------------------------------------\n",
            "   2015-2018       2019       74.18%     85.18%\n",
            "   2016-2019       2020       31.28%     47.65%\n",
            "   2017-2020       2021       75.10%     85.78%\n",
            "   2018-2021       2022       75.52%     83.66%\n",
            "   2019-2022       2023       75.72%     83.47%\n",
            "   2020-2023       2024       34.16%     20.79%\n",
            "   2021-2024       2025       65.98%     79.50%\n",
            "   ---------------------------------------------\n",
            "   AVERAGE                    61.70%     69.43%\n",
            "\n",
            "==================================================\n",
            "ðŸ”¹ Processing: TISCO\n",
            "==================================================\n",
            "   ðŸ“… Data range: 2015-01-05 to 2025-12-30\n",
            "   ðŸ“Š Total rows: 2672\n",
            "\n",
            "   ðŸ“Š Rolling Window Results for TISCO:\n",
            "   Train Period    Test Year  Accuracy   F1 Score  \n",
            "   ---------------------------------------------\n",
            "   2015-2018       2019       83.61%     91.07%\n",
            "   2016-2019       2020       60.08%     68.61%\n",
            "   2017-2020       2021       51.45%     57.45%\n",
            "   2018-2021       2022       67.22%     80.40%\n",
            "   2019-2022       2023       78.60%     88.02%\n",
            "   2020-2023       2024       76.95%     86.98%\n",
            "   2021-2024       2025       92.95%     96.34%\n",
            "   ---------------------------------------------\n",
            "   AVERAGE                    72.98%     81.27%\n",
            "\n",
            "==================================================\n",
            "ðŸ”¹ Processing: TTB\n",
            "==================================================\n",
            "   ðŸ“… Data range: 2015-01-05 to 2025-12-30\n",
            "   ðŸ“Š Total rows: 2672\n",
            "\n",
            "   ðŸ“Š Rolling Window Results for TTB:\n",
            "   Train Period    Test Year  Accuracy   F1 Score  \n",
            "   ---------------------------------------------\n",
            "   2015-2018       2019       72.13%     43.33%\n",
            "   2016-2019       2020       30.04%     46.20%\n",
            "   2017-2020       2021       36.10%     23.00%\n",
            "   2018-2021       2022       53.94%     29.30%\n",
            "   2019-2022       2023       26.75%     0.00%\n",
            "   2020-2023       2024       64.61%     72.61%\n",
            "   2021-2024       2025       77.18%     87.12%\n",
            "   ---------------------------------------------\n",
            "   AVERAGE                    51.54%     43.08%\n",
            "\n",
            "======================================================================\n",
            "ðŸ“Š OVERALL PERFORMANCE SUMMARY (All Stocks, All Windows)\n",
            "======================================================================\n",
            "\n",
            "ðŸ“… Performance by Test Year:\n",
            "--------------------------------------------------\n",
            "           Accuracy  Precision  Recall  F1_Score  Test_Samples\n",
            "Test_Year                                                     \n",
            "2019         0.6323     0.3914  0.6540    0.4771          1708\n",
            "2020         0.3921     0.2977  0.8739    0.4370          1701\n",
            "2021         0.5323     0.7864  0.5983    0.5617          1687\n",
            "2022         0.4884     0.6471  0.3692    0.4162          1687\n",
            "2023         0.5744     0.4773  0.5509    0.4569          1701\n",
            "2024         0.6044     0.7651  0.6526    0.6423          1701\n",
            "2025         0.7493     0.8269  0.8907    0.8439          1687\n",
            "\n",
            "ðŸ“ˆ Performance by Stock (Average across all windows):\n",
            "--------------------------------------------------\n",
            "       Accuracy  Precision  Recall  F1_Score\n",
            "Stock                                       \n",
            "BBL      0.4719     0.4660  0.7580    0.5327\n",
            "KBANK    0.5734     0.4061  0.2242    0.2519\n",
            "KKP      0.5544     0.6565  0.7988    0.6120\n",
            "KTB      0.5113     0.5861  0.5800    0.5007\n",
            "TCAP     0.6170     0.6996  0.8140    0.6943\n",
            "TISCO    0.7298     0.7830  0.9022    0.8127\n",
            "TTB      0.5154     0.5949  0.5125    0.4308\n",
            "\n",
            "==================================================\n",
            "ðŸŽ¯ OVERALL AVERAGE PERFORMANCE\n",
            "==================================================\n",
            "   â€¢ Accuracy:  56.76%\n",
            "   â€¢ Precision: 59.89%\n",
            "   â€¢ Recall:    65.57%\n",
            "   â€¢ F1 Score:  54.79%\n",
            "   â€¢ Total Test Samples: 11,872\n",
            "\n",
            "ðŸ’¾ Predictions saved to: DeepLearning_Signal_BiLSTM_Attention_RollingWindow.xlsx\n",
            "ðŸ’¾ Metrics saved to: DeepLearning_Metrics_BiLSTM_Attention_RollingWindow.xlsx\n",
            "\n",
            "======================================================================\n",
            "âœ… BLOCK 5.5 COMPLETED: BiLSTM/GRU + Attention + Rolling Window\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# ðŸ§  BLOCK 5.5: Deep Learning Signal (UPGRADED + ROLLING WINDOW)\n",
        "#    Config: Kalman -> CNN -> BN -> Bidirectional LSTM/GRU -> Attention -> Dropout\n",
        "#    Features:\n",
        "#    - Bidirectional LSTM/GRU (capture both past and future context)\n",
        "#    - Attention Mechanism (focus on important timesteps)\n",
        "#    - Rolling Window / Walk-Forward Validation\n",
        "#    - Improved Ensemble (3 models)\n",
        "# ============================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Dense, LSTM, GRU, Conv1D, MaxPooling1D, Input, Dropout,\n",
        "    BatchNormalization, Bidirectional, Layer\n",
        ")\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import warnings\n",
        "import os\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "# ============================================================\n",
        "# 1. TARGET STOCKS\n",
        "# ============================================================\n",
        "\n",
        "# [\n",
        "#     \"AAV\", \"AEONTS\", \"AOT\", \"BA\", \"BBL\", \"BCH\", \"BDMS\", \"BEM\", \"BH\", \"BTS\",\n",
        "#     \"CHG\", \"JMT\", \"KBANK\", \"KKP\", \"KTB\", \"KTC\", \"PR9\", \"PRM\", \"RCL\", \"SAWAD\",\n",
        "#     \"TCAP\", \"TISCO\", \"TTB\"\n",
        "# ]\n",
        "\n",
        "target_stocks = [\"BBL\",\"KBANK\",\"KKP\",\"KTB\",\"TCAP\",\"TISCO\",\"TTB\"]\n",
        "\n",
        "# ============================================================\n",
        "# 2. ROLLING WINDOW CONFIGURATION\n",
        "# ============================================================\n",
        "# Walk-Forward Validation Windows\n",
        "# Format: (train_start, train_end, test_year)\n",
        "ROLLING_WINDOWS = [\n",
        "    (\"2015-01-01\", \"2018-12-31\", 2019),\n",
        "    (\"2016-01-01\", \"2019-12-31\", 2020),\n",
        "    (\"2017-01-01\", \"2020-12-31\", 2021),\n",
        "    (\"2018-01-01\", \"2021-12-31\", 2022),\n",
        "    (\"2019-01-01\", \"2022-12-31\", 2023),\n",
        "    (\"2020-01-01\", \"2023-12-31\", 2024),\n",
        "    (\"2021-01-01\", \"2024-12-31\", 2025),\n",
        "]\n",
        "\n",
        "# ============================================================\n",
        "# 3. KALMAN FILTER (Noise Reduction)\n",
        "# ============================================================\n",
        "class KalmanFilter1D:\n",
        "    \"\"\"1D Kalman Filter for smoothing price data\"\"\"\n",
        "    def __init__(self, process_noise=1e-5, measurement_noise=1e-3, estimated_error=1.0):\n",
        "        self.Q = process_noise\n",
        "        self.R = measurement_noise\n",
        "        self.P = estimated_error\n",
        "        self.X = 0\n",
        "\n",
        "    def update(self, measurement):\n",
        "        self.P = self.P + self.Q\n",
        "        K = self.P / (self.P + self.R)\n",
        "        self.X = self.X + K * (measurement - self.X)\n",
        "        self.P = (1 - K) * self.P\n",
        "        return self.X\n",
        "\n",
        "    def smooth(self, data):\n",
        "        self.X = data[0]\n",
        "        result = []\n",
        "        for measurement in data:\n",
        "            result.append(self.update(measurement))\n",
        "        return np.array(result)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 4. ATTENTION LAYER (Custom Implementation)\n",
        "# ============================================================\n",
        "class AttentionLayer(Layer):\n",
        "    \"\"\"\n",
        "    Attention Mechanism for Time Series\n",
        "    \"\"\"\n",
        "    def __init__(self, return_attention=False, **kwargs):\n",
        "        self.return_attention = return_attention\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W = self.add_weight(\n",
        "            name='attention_weight',\n",
        "            shape=(input_shape[-1], input_shape[-1]),\n",
        "            initializer='glorot_uniform',\n",
        "            trainable=True\n",
        "        )\n",
        "        self.b = self.add_weight(\n",
        "            name='attention_bias',\n",
        "            shape=(input_shape[-1],),\n",
        "            initializer='zeros',\n",
        "            trainable=True\n",
        "        )\n",
        "        self.u = self.add_weight(\n",
        "            name='attention_context',\n",
        "            shape=(input_shape[-1], 1),\n",
        "            initializer='glorot_uniform',\n",
        "            trainable=True\n",
        "        )\n",
        "        super(AttentionLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        uit = tf.nn.tanh(tf.tensordot(x, self.W, axes=1) + self.b)\n",
        "        ait = tf.tensordot(uit, self.u, axes=1)\n",
        "        ait = tf.squeeze(ait, axis=-1)\n",
        "        ait = tf.nn.softmax(ait, axis=1)\n",
        "        ait_expanded = tf.expand_dims(ait, axis=-1)\n",
        "        weighted_input = x * ait_expanded\n",
        "        output = tf.reduce_sum(weighted_input, axis=1)\n",
        "\n",
        "        if self.return_attention:\n",
        "            return output, ait\n",
        "        return output\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], input_shape[-1])\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(AttentionLayer, self).get_config()\n",
        "        config.update({'return_attention': self.return_attention})\n",
        "        return config\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 5. MODEL ARCHITECTURES\n",
        "# ============================================================\n",
        "\n",
        "def build_cnn_bilstm_attention(input_shape):\n",
        "    \"\"\"Model 1: CNN + Bidirectional LSTM + Attention\"\"\"\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    x = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling1D(pool_size=2)(x)\n",
        "\n",
        "    x = Bidirectional(LSTM(50, return_sequences=True))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = AttentionLayer(return_attention=False)(x)\n",
        "\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Dense(32, activation='relu')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "def build_cnn_bigru_attention(input_shape):\n",
        "    \"\"\"Model 2: CNN + Bidirectional GRU + Attention\"\"\"\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    x = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling1D(pool_size=2)(x)\n",
        "\n",
        "    x = Bidirectional(GRU(50, return_sequences=True))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = AttentionLayer(return_attention=False)(x)\n",
        "\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Dense(32, activation='relu')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "def build_stacked_bilstm_attention(input_shape):\n",
        "    \"\"\"Model 3: Stacked Bidirectional LSTM + Attention\"\"\"\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    x = Bidirectional(LSTM(64, return_sequences=True))(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    x = Bidirectional(LSTM(32, return_sequences=True))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = AttentionLayer(return_attention=False)(x)\n",
        "\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Dense(32, activation='relu')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 6. DATA PREPARATION\n",
        "# ============================================================\n",
        "\n",
        "def create_dataset(data, look_back=60):\n",
        "    \"\"\"Create sequences for time series prediction\"\"\"\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - look_back - 1):\n",
        "        X.append(data[i:(i + look_back), 0])\n",
        "        y.append(1 if data[i + look_back, 0] > data[i + look_back - 1, 0] else 0)\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "\n",
        "def create_dataset_with_dates(df, scaled_data, look_back=60):\n",
        "    \"\"\"Create sequences with corresponding dates\"\"\"\n",
        "    X, y, dates = [], [], []\n",
        "    for i in range(len(scaled_data) - look_back - 1):\n",
        "        X.append(scaled_data[i:(i + look_back), 0])\n",
        "        y.append(1 if scaled_data[i + look_back, 0] > scaled_data[i + look_back - 1, 0] else 0)\n",
        "        dates.append(df.index[i + look_back])\n",
        "    return np.array(X), np.array(y), dates\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 7. ROLLING WINDOW TRAINING FUNCTION\n",
        "# ============================================================\n",
        "\n",
        "def train_with_rolling_window(df, scaled_data, look_back=60, epochs=20, batch_size=32):\n",
        "    \"\"\"\n",
        "    Train models using Rolling Window / Walk-Forward Validation\n",
        "\n",
        "    Returns:\n",
        "        all_predictions: List of predictions for each window\n",
        "        all_metrics: Performance metrics for each window\n",
        "    \"\"\"\n",
        "\n",
        "    # Create dataset with dates\n",
        "    X, y, dates = create_dataset_with_dates(df, scaled_data, look_back)\n",
        "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
        "\n",
        "    # Convert dates to DataFrame for easier filtering\n",
        "    dates_df = pd.DataFrame({'date': dates, 'idx': range(len(dates))})\n",
        "    dates_df['year'] = pd.to_datetime(dates_df['date']).dt.year\n",
        "\n",
        "    all_predictions = []\n",
        "    all_metrics = []\n",
        "\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor='loss',\n",
        "        patience=5,\n",
        "        restore_best_weights=True,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    for train_start, train_end, test_year in ROLLING_WINDOWS:\n",
        "        # Get indices for train and test\n",
        "        train_mask = (dates_df['date'] >= train_start) & (dates_df['date'] <= train_end)\n",
        "        test_mask = (dates_df['year'] == test_year)\n",
        "\n",
        "        train_idx = dates_df[train_mask]['idx'].values\n",
        "        test_idx = dates_df[test_mask]['idx'].values\n",
        "\n",
        "        if len(train_idx) < 100 or len(test_idx) < 10:\n",
        "            continue\n",
        "\n",
        "        X_train, y_train = X[train_idx], y[train_idx]\n",
        "        X_test, y_test = X[test_idx], y[test_idx]\n",
        "        test_dates = [dates[i] for i in test_idx]\n",
        "\n",
        "        input_shape = (look_back, 1)\n",
        "\n",
        "        # Train Model 1: CNN-BiLSTM-Attention\n",
        "        model1 = build_cnn_bilstm_attention(input_shape)\n",
        "        model1.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                   callbacks=[early_stop], verbose=0)\n",
        "        pred1 = model1.predict(X_test, verbose=0)\n",
        "\n",
        "        # Train Model 2: CNN-BiGRU-Attention\n",
        "        model2 = build_cnn_bigru_attention(input_shape)\n",
        "        model2.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                   callbacks=[early_stop], verbose=0)\n",
        "        pred2 = model2.predict(X_test, verbose=0)\n",
        "\n",
        "        # Train Model 3: Stacked BiLSTM-Attention\n",
        "        model3 = build_stacked_bilstm_attention(input_shape)\n",
        "        model3.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                   callbacks=[early_stop], verbose=0)\n",
        "        pred3 = model3.predict(X_test, verbose=0)\n",
        "\n",
        "        # Ensemble\n",
        "        ensemble_pred = (pred1 + pred2 + pred3) / 3.0\n",
        "        ensemble_binary = (ensemble_pred > 0.5).astype(int).flatten()\n",
        "\n",
        "        # Evaluate\n",
        "        accuracy = accuracy_score(y_test, ensemble_binary)\n",
        "        precision = precision_score(y_test, ensemble_binary, zero_division=0)\n",
        "        recall = recall_score(y_test, ensemble_binary, zero_division=0)\n",
        "        f1 = f1_score(y_test, ensemble_binary, zero_division=0)\n",
        "\n",
        "        all_metrics.append({\n",
        "            'Train_Period': f\"{train_start[:4]}-{train_end[:4]}\",\n",
        "            'Test_Year': test_year,\n",
        "            'Accuracy': accuracy,\n",
        "            'Precision': precision,\n",
        "            'Recall': recall,\n",
        "            'F1_Score': f1,\n",
        "            'Train_Samples': len(y_train),\n",
        "            'Test_Samples': len(y_test)\n",
        "        })\n",
        "\n",
        "        # Store predictions\n",
        "        for i, date in enumerate(test_dates):\n",
        "            all_predictions.append({\n",
        "                'Date': date,\n",
        "                'Test_Year': test_year,\n",
        "                'DL_Signal': ensemble_pred[i, 0],\n",
        "                'DL_Signal_Binary': ensemble_binary[i],\n",
        "                'Actual': y_test[i]\n",
        "            })\n",
        "\n",
        "        # Clean up memory\n",
        "        del model1, model2, model3\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "    return all_predictions, all_metrics\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 8. MAIN TRAINING LOOP\n",
        "# ============================================================\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"ðŸ§  BLOCK 5.5: Deep Learning Signal (UPGRADED + ROLLING WINDOW)\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\"\"\n",
        "ðŸ“¦ Model Architecture:\n",
        "   - Model 1: CNN + Bidirectional LSTM + Attention\n",
        "   - Model 2: CNN + Bidirectional GRU + Attention\n",
        "   - Model 3: Stacked Bidirectional LSTM + Attention\n",
        "\n",
        "ðŸ”„ Rolling Window Configuration:\n",
        "   - Window 1: Train [2015-2018] â†’ Test [2019]\n",
        "   - Window 2: Train [2016-2019] â†’ Test [2020]\n",
        "   - Window 3: Train [2017-2020] â†’ Test [2021]\n",
        "   - Window 4: Train [2018-2021] â†’ Test [2022]\n",
        "   - Window 5: Train [2019-2022] â†’ Test [2023]\n",
        "   - Window 6: Train [2020-2023] â†’ Test [2024]\n",
        "   - Window 7: Train [2021-2024] â†’ Test [2025]\n",
        "\n",
        "âš™ï¸ Configuration:\n",
        "   - Lookback: 60 days\n",
        "   - Epochs: 20 (with EarlyStopping)\n",
        "   - Batch Size: 32\n",
        "   - Ensemble: Average of 3 models\n",
        "\"\"\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Storage for results\n",
        "all_stock_predictions = []\n",
        "all_stock_metrics = []\n",
        "\n",
        "# Training parameters\n",
        "LOOK_BACK = 60\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "for stock in target_stocks:\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"ðŸ”¹ Processing: {stock}\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "    try:\n",
        "        # ===== 1. Download Data =====\n",
        "        df = yf.download(f\"{stock}.BK\", start=\"2015-01-01\", end=\"2025-12-31\", progress=False)\n",
        "\n",
        "        if len(df) < 500:\n",
        "            print(f\"âš ï¸ Skipped (insufficient data: {len(df)} rows)\")\n",
        "            continue\n",
        "\n",
        "        if isinstance(df.columns, pd.MultiIndex):\n",
        "            df.columns = df.columns.get_level_values(0)\n",
        "\n",
        "        data = df[['Close']].values\n",
        "\n",
        "        print(f\"   ðŸ“… Data range: {df.index.min().strftime('%Y-%m-%d')} to {df.index.max().strftime('%Y-%m-%d')}\")\n",
        "        print(f\"   ðŸ“Š Total rows: {len(df)}\")\n",
        "\n",
        "        # ===== 2. Preprocessing =====\n",
        "        kf = KalmanFilter1D(process_noise=1e-5, measurement_noise=0.01)\n",
        "        smoothed_data = kf.smooth(data.flatten()).reshape(-1, 1)\n",
        "\n",
        "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "        scaled_data = scaler.fit_transform(smoothed_data)\n",
        "\n",
        "        # ===== 3. Train with Rolling Window =====\n",
        "        predictions, metrics = train_with_rolling_window(\n",
        "            df, scaled_data,\n",
        "            look_back=LOOK_BACK,\n",
        "            epochs=EPOCHS,\n",
        "            batch_size=BATCH_SIZE\n",
        "        )\n",
        "\n",
        "        # Add stock name to results\n",
        "        for pred in predictions:\n",
        "            pred['Stock'] = stock\n",
        "        for metric in metrics:\n",
        "            metric['Stock'] = stock\n",
        "\n",
        "        all_stock_predictions.extend(predictions)\n",
        "        all_stock_metrics.extend(metrics)\n",
        "\n",
        "        # Print window results\n",
        "        print(f\"\\n   ðŸ“Š Rolling Window Results for {stock}:\")\n",
        "        print(f\"   {'Train Period':<15} {'Test Year':<10} {'Accuracy':<10} {'F1 Score':<10}\")\n",
        "        print(f\"   {'-'*45}\")\n",
        "        for m in metrics:\n",
        "            print(f\"   {m['Train_Period']:<15} {m['Test_Year']:<10} {m['Accuracy']:.2%}     {m['F1_Score']:.2%}\")\n",
        "\n",
        "        # Average performance\n",
        "        if metrics:\n",
        "            avg_acc = np.mean([m['Accuracy'] for m in metrics])\n",
        "            avg_f1 = np.mean([m['F1_Score'] for m in metrics])\n",
        "            print(f\"   {'-'*45}\")\n",
        "            print(f\"   {'AVERAGE':<15} {'':<10} {avg_acc:.2%}     {avg_f1:.2%}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error: {e}\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 9. SUMMARY & EXPORT\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"ðŸ“Š OVERALL PERFORMANCE SUMMARY (All Stocks, All Windows)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "if all_stock_metrics:\n",
        "    df_metrics = pd.DataFrame(all_stock_metrics)\n",
        "\n",
        "    # Summary by Test Year\n",
        "    print(\"\\nðŸ“… Performance by Test Year:\")\n",
        "    print(\"-\" * 50)\n",
        "    year_summary = df_metrics.groupby('Test_Year').agg({\n",
        "        'Accuracy': 'mean',\n",
        "        'Precision': 'mean',\n",
        "        'Recall': 'mean',\n",
        "        'F1_Score': 'mean',\n",
        "        'Test_Samples': 'sum'\n",
        "    }).round(4)\n",
        "    print(year_summary.to_string())\n",
        "\n",
        "    # Summary by Stock\n",
        "    print(\"\\nðŸ“ˆ Performance by Stock (Average across all windows):\")\n",
        "    print(\"-\" * 50)\n",
        "    stock_summary = df_metrics.groupby('Stock').agg({\n",
        "        'Accuracy': 'mean',\n",
        "        'Precision': 'mean',\n",
        "        'Recall': 'mean',\n",
        "        'F1_Score': 'mean'\n",
        "    }).round(4)\n",
        "    print(stock_summary.to_string())\n",
        "\n",
        "    # Overall Average\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"ðŸŽ¯ OVERALL AVERAGE PERFORMANCE\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"   â€¢ Accuracy:  {df_metrics['Accuracy'].mean():.2%}\")\n",
        "    print(f\"   â€¢ Precision: {df_metrics['Precision'].mean():.2%}\")\n",
        "    print(f\"   â€¢ Recall:    {df_metrics['Recall'].mean():.2%}\")\n",
        "    print(f\"   â€¢ F1 Score:  {df_metrics['F1_Score'].mean():.2%}\")\n",
        "    print(f\"   â€¢ Total Test Samples: {df_metrics['Test_Samples'].sum():,}\")\n",
        "\n",
        "# Export Results\n",
        "if all_stock_predictions:\n",
        "    df_predictions = pd.DataFrame(all_stock_predictions)\n",
        "\n",
        "    # Save predictions\n",
        "    outfile_signals = \"DeepLearning_Signal_BiLSTM_Attention_RollingWindow.xlsx\"\n",
        "    df_predictions.to_excel(outfile_signals, index=False)\n",
        "    print(f\"\\nðŸ’¾ Predictions saved to: {outfile_signals}\")\n",
        "\n",
        "    # Save metrics\n",
        "    outfile_metrics = \"DeepLearning_Metrics_BiLSTM_Attention_RollingWindow.xlsx\"\n",
        "    df_metrics.to_excel(outfile_metrics, index=False)\n",
        "    print(f\"ðŸ’¾ Metrics saved to: {outfile_metrics}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"âœ… BLOCK 5.5 COMPLETED: BiLSTM/GRU + Attention + Rolling Window\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-u-fC_JSABEf",
        "outputId": "54d85c92-e71a-48f5-9259-a74aef28cbee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â³ Integrating Data with Advanced Technicals...\n",
            "   ðŸ”¹ Step 1: Loading Full Price Data...\n",
            "   ðŸ”¹ Step 2 & 3: Merging Signals...\n",
            "âœ… Data Integration Complete!\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# ðŸ”— BLOCK 6: Data Integration (Standard)\n",
        "# ============================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"â³ Integrating Data with Advanced Technicals...\")\n",
        "\n",
        "# target_stocks = [\n",
        "#     \"AAV\", \"AEONTS\", \"AOT\", \"BA\", \"BBL\", \"BCH\", \"BDMS\", \"BEM\", \"BH\", \"BTS\",\n",
        "#     \"CHG\", \"JMT\", \"KBANK\", \"KKP\", \"KTB\", \"KTC\", \"PR9\", \"PRM\", \"RCL\", \"SAWAD\",\n",
        "#     \"TCAP\", \"TISCO\", \"TTB\"\n",
        "# ]\n",
        "\n",
        "target_stocks = [\"BBL\",\"KBANK\",\"KKP\",\"KTB\",\"TCAP\",\"TISCO\",\"TTB\"]\n",
        "\n",
        "def calculate_adx(df, window=14):\n",
        "    high = df['High']\n",
        "    low = df['Low']\n",
        "    close = df['Close']\n",
        "    plus_dm = high.diff()\n",
        "    minus_dm = low.diff()\n",
        "    plus_dm[plus_dm < 0] = 0\n",
        "    minus_dm[minus_dm > 0] = 0\n",
        "    tr1 = pd.DataFrame(high - low)\n",
        "    tr2 = pd.DataFrame(abs(high - close.shift(1)))\n",
        "    tr3 = pd.DataFrame(abs(low - close.shift(1)))\n",
        "    tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
        "    atr = tr.rolling(window).mean()\n",
        "    plus_di = 100 * (plus_dm.ewm(alpha=1/window).mean() / atr)\n",
        "    minus_di = 100 * (abs(minus_dm).ewm(alpha=1/window).mean() / atr)\n",
        "    dx = (abs(plus_di - minus_di) / abs(plus_di + minus_di)) * 100\n",
        "    return dx.rolling(window).mean()\n",
        "\n",
        "def add_technical_score(df):\n",
        "    df = df.copy()\n",
        "    df['EMA_200'] = df['Close'].ewm(span=200, adjust=False).mean()\n",
        "\n",
        "    delta = df['Close'].diff()\n",
        "    gain = (delta.where(delta > 0, 0)).rolling(14).mean()\n",
        "    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
        "    rs = gain / loss\n",
        "    df['RSI'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "    k = df['Close'].ewm(span=12, adjust=False).mean()\n",
        "    d = df['Close'].ewm(span=26, adjust=False).mean()\n",
        "    df['MACD'] = k - d\n",
        "    df['MACD_Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
        "\n",
        "    s_trend = np.where(df['Close'] > df['EMA_200'], 1, -1)\n",
        "    s_rsi = np.where(df['RSI'] < 30, 1, np.where(df['RSI'] > 70, -1, 0))\n",
        "    s_macd = np.where(df['MACD'] > df['MACD_Signal'], 1, -1)\n",
        "    df['Tech_Signal'] = (s_trend * 0.4) + (s_macd * 0.4) + (s_rsi * 0.2)\n",
        "    return df\n",
        "\n",
        "print(\"   ðŸ”¹ Step 1: Loading Full Price Data...\")\n",
        "df_price = pd.DataFrame()\n",
        "for stock in target_stocks:\n",
        "    try:\n",
        "        data = yf.download(f\"{stock}.BK\", start=\"2018-01-01\", end=\"2025-12-31\", progress=False)\n",
        "        if isinstance(data.columns, pd.MultiIndex): data.columns = data.columns.get_level_values(0)\n",
        "        data = data.reset_index()\n",
        "        data['Stock'] = stock\n",
        "        data['ADX'] = calculate_adx(data)\n",
        "        data = add_technical_score(data)\n",
        "        df_price = pd.concat([df_price, data], ignore_index=True)\n",
        "    except: pass\n",
        "\n",
        "req_cols = ['Date', 'Stock', 'Close', 'Tech_Signal', 'ADX', 'RSI', 'MACD']\n",
        "df_rl = df_price[req_cols].dropna().sort_values(['Stock', 'Date']).reset_index(drop=True)\n",
        "\n",
        "print(\"   ðŸ”¹ Step 2 & 3: Merging Signals...\")\n",
        "try:\n",
        "    df_macro = pd.read_excel(\"Forecast_ARDL_ECM_NextMonth_Clean.xlsx\")\n",
        "    sig_col = 'Pred_dLogclose' if 'Pred_dLogclose' in df_macro.columns else df_macro.select_dtypes(include=[np.number]).columns[0]\n",
        "    macro_map = df_macro.set_index('Stock')[sig_col].to_dict()\n",
        "    df_rl['Macro_Signal'] = df_rl['Stock'].map(macro_map).fillna(0)\n",
        "except: df_rl['Macro_Signal'] = 0\n",
        "\n",
        "try:\n",
        "    df_dl = pd.read_excel(\"DeepLearning_Signal_LSTM_GRU.xlsx\")\n",
        "    df_dl['Date'] = pd.to_datetime(df_dl['Date'])\n",
        "    df_rl = pd.merge(df_rl, df_dl[['Date', 'Stock', 'DL_Signal']], on=['Date', 'Stock'], how='left')\n",
        "    df_rl['DL_Signal'] = df_rl['DL_Signal'].fillna(0.5)\n",
        "except: df_rl['DL_Signal'] = 0.5\n",
        "\n",
        "df_rl.to_excel(\"Final_RL_Input_Ready.xlsx\", index=False)\n",
        "print(\"âœ… Data Integration Complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UieFy0V7HuYj",
        "outputId": "c5a8676f-5596-41ee-c980-ddaf16ce0d23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting stable_baselines3\n",
            "  Downloading stable_baselines3-2.7.1-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: gymnasium<1.3.0,>=0.29.1 in /usr/local/lib/python3.12/dist-packages (from stable_baselines3) (1.2.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.12/dist-packages (from stable_baselines3) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.12/dist-packages (from stable_baselines3) (2.9.0+cpu)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from stable_baselines3) (3.1.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from stable_baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from stable_baselines3) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable_baselines3) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable_baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.20.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2025.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable_baselines3) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable_baselines3) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable_baselines3) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable_baselines3) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable_baselines3) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable_baselines3) (3.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable_baselines3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->stable_baselines3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->stable_baselines3) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3.0,>=2.3->stable_baselines3) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3.0,>=2.3->stable_baselines3) (3.0.3)\n",
            "Downloading stable_baselines3-2.7.1-py3-none-any.whl (188 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m188.0/188.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: stable_baselines3\n",
            "Successfully installed stable_baselines3-2.7.1\n"
          ]
        }
      ],
      "source": [
        "!pip install stable_baselines3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mW6OMFtKhumH"
      },
      "source": [
        "ðŸ“‹ 1. Constraint à¸—à¸µà¹ˆà¸”à¸±à¸”à¸™à¸´à¸ªà¸±à¸¢ RLConstraintà¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”à¸ˆà¸¸à¸”à¸›à¸£à¸°à¸ªà¸‡à¸„à¹ŒCooldown 2 Daysà¸«à¸¥à¸±à¸‡ Sell à¸•à¹‰à¸­à¸‡à¸£à¸­ 2 à¸§à¸±à¸™à¸–à¸¶à¸‡à¸ˆà¸° Buy à¹„à¸”à¹‰à¸›à¹‰à¸­à¸‡à¸à¸±à¸™ OvertradingMomentum Rule (Buy)Buy à¹„à¸”à¹‰à¹€à¸¡à¸·à¹ˆà¸­ ADX > 25 à¹à¸¥à¸° RSI < 75 à¸«à¸£à¸·à¸­ RSI < 45à¸šà¸±à¸‡à¸„à¸±à¸šà¸‹à¸·à¹‰à¸­à¸•à¸²à¸¡ TrendðŸ†• Volatility-based SizingPosition Size 30-70% à¸•à¸²à¸¡ Volatilityà¸¥à¸”à¸„à¸§à¸²à¸¡à¹€à¸ªà¸µà¹ˆà¸¢à¸‡à¸Šà¹ˆà¸§à¸‡ Vol à¸ªà¸¹à¸‡ðŸ†• Max Consecutive Lossesà¸‚à¸²à¸”à¸—à¸¸à¸™ 5 à¸„à¸£à¸±à¹‰à¸‡à¸•à¸´à¸” â†’ à¸«à¸¢à¸¸à¸” 3 à¸§à¸±à¸™à¸«à¸¢à¸¸à¸”à¸žà¸±à¸à¹€à¸¡à¸·à¹ˆà¸­ Strategy à¹„à¸¡à¹ˆ workRandom Initial Position50% à¹‚à¸­à¸à¸²à¸ªà¹€à¸£à¸´à¹ˆà¸¡à¸¡à¸µà¸«à¸¸à¹‰à¸™à¸­à¸¢à¸¹à¹ˆà¹à¸¥à¹‰à¸§à¸à¸¶à¸à¹ƒà¸«à¹‰à¸£à¸±à¸šà¸¡à¸·à¸­à¸—à¸¸à¸à¸ªà¸–à¸²à¸™à¸à¸²à¸£à¸“à¹ŒðŸ›¡ï¸ 2. Risk ManagementRuleTriggerActionà¸ˆà¸¸à¸”à¸›à¸£à¸°à¸ªà¸‡à¸„à¹ŒHard Stop LossPnL â‰¤ -6%Force Sellà¸ˆà¸³à¸à¸±à¸”à¸‚à¸²à¸”à¸—à¸¸à¸™à¸ªà¸¹à¸‡à¸ªà¸¸à¸”Trailing StopPnL > +10% à¹à¸¥à¹‰à¸§à¸•à¸ > 4% à¸ˆà¸²à¸ PeakForce Sellà¸¥à¹‡à¸­à¸„à¸à¸³à¹„à¸£ðŸ†• Volatility Sizingà¸—à¸¸à¸à¸„à¸£à¸±à¹‰à¸‡à¸—à¸µà¹ˆ Buyà¸›à¸£à¸±à¸š Size 30-70%à¸¥à¸” Position à¸Šà¹ˆà¸§à¸‡ Vol à¸ªà¸¹à¸‡ðŸ†• Loss Pauseà¸‚à¸²à¸”à¸—à¸¸à¸™ 5 à¸„à¸£à¸±à¹‰à¸‡à¸•à¸´à¸”à¸«à¸¢à¸¸à¸” 3 à¸§à¸±à¸™à¸›à¹‰à¸­à¸‡à¸à¸±à¸™ Drawdown à¸•à¹ˆà¸­à¹€à¸™à¸·à¹ˆà¸­à¸‡ðŸŽ 3. Reward Shapingà¸ªà¸–à¸²à¸™à¸à¸²à¸£à¸“à¹ŒRewardà¸ˆà¸¸à¸”à¸›à¸£à¸°à¸ªà¸‡à¸„à¹ŒBuy à¸ªà¸³à¹€à¸£à¹‡à¸ˆ+0.1à¸à¸³à¸¥à¸±à¸‡à¹ƒà¸ˆ Take ActionSell à¸ˆà¸²à¸ Trailing Stop+2.0à¸£à¸²à¸‡à¸§à¸±à¸¥à¹ƒà¸«à¸à¹ˆà¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸³à¹„à¸£à¹€à¸¢à¸­à¸°Sell à¸ˆà¸²à¸ Stop Loss+0.1à¸£à¸²à¸‡à¸§à¸±à¸¥à¸ªà¸³à¸«à¸£à¸±à¸š DisciplineSell à¸¡à¸µà¸à¸³à¹„à¸£ (à¸›à¸à¸•à¸´)+PnL Ã— 10à¸•à¸²à¸¡à¸ªà¸±à¸”à¸ªà¹ˆà¸§à¸™à¸à¸³à¹„à¸£Sell à¸‚à¸²à¸”à¸—à¸¸à¸™ (à¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆ SL)-0.5à¸¥à¸‡à¹‚à¸—à¸© Sell à¸œà¸´à¸”à¸ˆà¸±à¸‡à¸«à¸§à¸°ðŸ†• Trigger Loss Pause-1.5à¸¥à¸‡à¹‚à¸—à¸©à¸«à¸™à¸±à¸à¹€à¸¡à¸·à¹ˆà¸­à¸‚à¸²à¸”à¸—à¸¸à¸™à¸•à¸´à¸” 5 à¸„à¸£à¸±à¹‰à¸‡ðŸ†• à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ Pause-0.3 à¸•à¹ˆà¸­à¸§à¸±à¸™à¸¥à¸‡à¹‚à¸—à¸© Opportunity Costà¸—à¸¸à¸ Step+(Î”NetWorth / NetWorth) Ã— 100à¸•à¸´à¸”à¸•à¸²à¸¡ Portfolio ValueðŸ“Š 4. State Vector (11 Features)#FeatureOriginal/New1Macro_SignalOriginal2DL_SignalOriginal3Tech_SignalOriginal4ADX / 100Original5Balance / 1MOriginal6Holdings Value / 1MOriginal7RSI / 100Original8MACD / 10Original9Volatility MultiplierðŸ†• New10Consecutive Losses / 5ðŸ†• New11Pause Counter / 3ðŸ†• New"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-w1olGHwiMR2"
      },
      "source": [
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "                    â”‚          RL Agent (PPO)             â”‚\n",
        "                    â”‚         à¹€à¸¥à¸·à¸­à¸ Action                â”‚\n",
        "                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                                    â”‚\n",
        "                                    â–¼\n",
        "                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "                    â”‚   ðŸ†• CHECK: Loss Pause Active?      â”‚\n",
        "                    â”‚      (à¸‚à¸²à¸”à¸—à¸¸à¸™ 5 à¸„à¸£à¸±à¹‰à¸‡ â†’ à¸«à¸¢à¸¸à¸” 3 à¸§à¸±à¸™)   â”‚\n",
        "                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                                    â”‚\n",
        "                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "                    â–¼                               â–¼\n",
        "              [Pause = YES]                   [Pause = NO]\n",
        "              Force HOLD                      Continue...\n",
        "              Reward -0.3                           â”‚\n",
        "                    â”‚                               â–¼\n",
        "                    â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "                    â”‚               â”‚    CHECK: Risk Management       â”‚\n",
        "                    â”‚               â”‚    â€¢ Stop Loss -6%?             â”‚\n",
        "                    â”‚               â”‚    â€¢ Trailing Stop?             â”‚\n",
        "                    â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                    â”‚                               â”‚\n",
        "                    â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "                    â”‚               â–¼                               â–¼\n",
        "                    â”‚         [Risk Trigger]                  [No Trigger]\n",
        "                    â”‚         Force SELL                      Continue...\n",
        "                    â”‚               â”‚                               â”‚\n",
        "                    â”‚               â”‚                               â–¼\n",
        "                    â”‚               â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "                    â”‚               â”‚               â”‚    CHECK: Cooldown Active?      â”‚\n",
        "                    â”‚               â”‚               â”‚    (à¸«à¸¥à¸±à¸‡ Sell à¸£à¸­ 2 à¸§à¸±à¸™)          â”‚\n",
        "                    â”‚               â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                    â”‚               â”‚                               â”‚\n",
        "                    â”‚               â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "                    â”‚               â”‚               â–¼                               â–¼\n",
        "                    â”‚               â”‚         [Cooldown = YES]               [Cooldown = NO]\n",
        "                    â”‚               â”‚         Block BUY                       Continue...\n",
        "                    â”‚               â”‚               â”‚                               â”‚\n",
        "                    â”‚               â”‚               â”‚                               â–¼\n",
        "                    â”‚               â”‚               â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "                    â”‚               â”‚               â”‚               â”‚      EXECUTE ACTION         â”‚\n",
        "                    â”‚               â”‚               â”‚               â”‚  BUY / HOLD / SELL          â”‚\n",
        "                    â”‚               â”‚               â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                    â”‚               â”‚               â”‚                               â”‚\n",
        "                    â”‚               â”‚               â”‚                               â–¼\n",
        "                    â”‚               â”‚               â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "                    â”‚               â”‚               â”‚               â”‚  ðŸ†• BUY: Volatility Sizing  â”‚\n",
        "                    â”‚               â”‚               â”‚               â”‚     High Vol â†’ 30-50%       â”‚\n",
        "                    â”‚               â”‚               â”‚               â”‚     Low Vol â†’ 50-70%        â”‚\n",
        "                    â”‚               â”‚               â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                    â”‚               â”‚               â”‚                               â”‚\n",
        "                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                                                    â”‚\n",
        "                                                    â–¼\n",
        "                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "                                    â”‚  ðŸ†• SELL: Track Consecutive     â”‚\n",
        "                                    â”‚     Losses (à¸–à¹‰à¸²à¸‚à¸²à¸”à¸—à¸¸à¸™)          â”‚\n",
        "                                    â”‚     à¸–à¹‰à¸²à¸„à¸£à¸š 5 â†’ Trigger Pause    â”‚\n",
        "                                    â”‚     Reward -1.5                 â”‚\n",
        "                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                                                    â”‚\n",
        "                                                    â–¼\n",
        "                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "                                    â”‚      Calculate Reward           â”‚\n",
        "                                    â”‚      Update State               â”‚\n",
        "                                    â”‚      Learn                      â”‚\n",
        "                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7YRj6DfABKt",
        "outputId": "f9cf2b5b-a0a2-4967-a654-90cf10ed6eec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "ðŸ¤– BLOCK 7: PPO Training (UPGRADED + ROLLING WINDOW + RISK MGMT V2)\n",
            "======================================================================\n",
            "\n",
            "ðŸ”„ Rolling Window Configuration:\n",
            "   - Window 1: Train [2015-2018] â†’ Test [2019]\n",
            "   - Window 2: Train [2016-2019] â†’ Test [2020]\n",
            "   - Window 3: Train [2017-2020] â†’ Test [2021]\n",
            "   - Window 4: Train [2018-2021] â†’ Test [2022]\n",
            "   - Window 5: Train [2019-2022] â†’ Test [2023]\n",
            "   - Window 6: Train [2020-2023] â†’ Test [2024]\n",
            "   - Window 7: Train [2021-2024] â†’ Test [2025]\n",
            "\n",
            "ðŸ›¡ï¸ Risk Management:\n",
            "   - Stop Loss: -6%\n",
            "   - Trailing Stop: Trigger +10%, Drop -4%\n",
            "   - Cooldown: 2 days after sell\n",
            "   \n",
            "ðŸ†• NEW Risk Management:\n",
            "   - Volatility-based Position Sizing (30-70% based on volatility)\n",
            "   - Max Consecutive Losses: 5 losses â†’ Pause 3 days\n",
            "   - Penalty: -0.3 per pause day, -1.5 when pause triggered\n",
            "\n",
            "âš™ï¸ PPO Configuration:\n",
            "   - Learning Rate: 0.0003\n",
            "   - Entropy Coef: 0.01\n",
            "   - Batch Size: 64\n",
            "   - Timesteps: 30,000 per window\n",
            "\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "ðŸ”¹ Processing: BBL\n",
            "============================================================\n",
            "   âœ… Window 2015-2018 â†’ 2019: Return=-20.81% | MDD=24.74% | WinRate=0.0% | Pauses=0\n",
            "   âœ… Window 2016-2019 â†’ 2020: Return=-4.40% | MDD=4.40% | WinRate=0.0% | Pauses=0\n",
            "   âœ… Window 2017-2020 â†’ 2021: Return=+0.00% | MDD=0.00% | WinRate=0.0% | Pauses=0\n",
            "   âœ… Window 2018-2021 â†’ 2022: Return=+0.00% | MDD=0.00% | WinRate=0.0% | Pauses=0\n",
            "   âœ… Window 2019-2022 â†’ 2023: Return=+6.82% | MDD=11.70% | WinRate=2.7% | Pauses=0\n",
            "   âœ… Window 2020-2023 â†’ 2024: Return=-1.97% | MDD=17.12% | WinRate=1.5% | Pauses=0\n",
            "   âœ… Window 2021-2024 â†’ 2025: Return=+16.46% | MDD=12.26% | WinRate=1.9% | Pauses=0\n",
            "\n",
            "   ðŸ“Š BBL Average: Return=-0.56% | MDD=10.03% | WinRate=0.9% | Total Pauses=0\n",
            "\n",
            "============================================================\n",
            "ðŸ”¹ Processing: KBANK\n",
            "============================================================\n",
            "   âœ… Window 2015-2018 â†’ 2019: Return=+0.61% | MDD=0.66% | WinRate=25.0% | Pauses=0\n",
            "   âœ… Window 2016-2019 â†’ 2020: Return=-5.90% | MDD=13.06% | WinRate=7.1% | Pauses=0\n",
            "   âœ… Window 2017-2020 â†’ 2021: Return=-1.10% | MDD=24.98% | WinRate=4.3% | Pauses=0\n",
            "   âœ… Window 2018-2021 â†’ 2022: Return=+10.28% | MDD=13.36% | WinRate=2.0% | Pauses=0\n",
            "   âœ… Window 2019-2022 â†’ 2023: Return=-12.70% | MDD=21.67% | WinRate=0.0% | Pauses=0\n",
            "   âœ… Window 2020-2023 â†’ 2024: Return=+32.05% | MDD=8.87% | WinRate=2.2% | Pauses=0\n",
            "   âœ… Window 2021-2024 â†’ 2025: Return=+10.32% | MDD=11.34% | WinRate=4.2% | Pauses=0\n",
            "\n",
            "   ðŸ“Š KBANK Average: Return=+4.79% | MDD=13.42% | WinRate=6.4% | Total Pauses=0\n",
            "\n",
            "============================================================\n",
            "ðŸ”¹ Processing: KKP\n",
            "============================================================\n",
            "   âœ… Window 2015-2018 â†’ 2019: Return=+11.55% | MDD=6.00% | WinRate=5.6% | Pauses=0\n",
            "   âœ… Window 2016-2019 â†’ 2020: Return=-2.13% | MDD=23.70% | WinRate=3.3% | Pauses=0\n",
            "   âœ… Window 2017-2020 â†’ 2021: Return=+12.40% | MDD=21.55% | WinRate=2.4% | Pauses=0\n",
            "   âœ… Window 2018-2021 â†’ 2022: Return=+21.54% | MDD=13.06% | WinRate=5.9% | Pauses=0\n",
            "   âœ… Window 2019-2022 â†’ 2023: Return=-25.28% | MDD=29.26% | WinRate=0.0% | Pauses=0\n",
            "   âœ… Window 2020-2023 â†’ 2024: Return=-0.09% | MDD=5.61% | WinRate=33.3% | Pauses=0\n",
            "   âœ… Window 2021-2024 â†’ 2025: Return=+21.96% | MDD=14.77% | WinRate=2.9% | Pauses=0\n",
            "\n",
            "   ðŸ“Š KKP Average: Return=+5.71% | MDD=16.28% | WinRate=7.6% | Total Pauses=0\n",
            "\n",
            "============================================================\n",
            "ðŸ”¹ Processing: KTB\n",
            "============================================================\n",
            "   âœ… Window 2015-2018 â†’ 2019: Return=-12.92% | MDD=19.22% | WinRate=0.0% | Pauses=0\n",
            "   âœ… Window 2016-2019 â†’ 2020: Return=-18.95% | MDD=31.13% | WinRate=1.4% | Pauses=0\n",
            "   âœ… Window 2017-2020 â†’ 2021: Return=+0.30% | MDD=21.10% | WinRate=2.3% | Pauses=0\n",
            "   âœ… Window 2018-2021 â†’ 2022: Return=+31.16% | MDD=8.97% | WinRate=2.1% | Pauses=0\n",
            "   âœ… Window 2019-2022 â†’ 2023: Return=-0.10% | MDD=14.84% | WinRate=1.0% | Pauses=0\n",
            "   âœ… Window 2020-2023 â†’ 2024: Return=+20.36% | MDD=13.68% | WinRate=2.9% | Pauses=0\n",
            "   âœ… Window 2021-2024 â†’ 2025: Return=+21.12% | MDD=14.60% | WinRate=10.0% | Pauses=0\n",
            "\n",
            "   ðŸ“Š KTB Average: Return=+5.86% | MDD=17.65% | WinRate=2.8% | Total Pauses=0\n",
            "\n",
            "============================================================\n",
            "ðŸ”¹ Processing: TCAP\n",
            "============================================================\n",
            "   âœ… Window 2015-2018 â†’ 2019: Return=+11.54% | MDD=13.98% | WinRate=1.8% | Pauses=0\n",
            "   âœ… Window 2016-2019 â†’ 2020: Return=+0.18% | MDD=33.08% | WinRate=1.6% | Pauses=1\n",
            "   âœ… Window 2017-2020 â†’ 2021: Return=+16.71% | MDD=11.40% | WinRate=2.0% | Pauses=0\n",
            "   âœ… Window 2018-2021 â†’ 2022: Return=+16.50% | MDD=14.48% | WinRate=0.0% | Pauses=0\n",
            "   âœ… Window 2019-2022 â†’ 2023: Return=+25.03% | MDD=7.45% | WinRate=2.3% | Pauses=0\n",
            "   âœ… Window 2020-2023 â†’ 2024: Return=+10.95% | MDD=12.35% | WinRate=2.1% | Pauses=0\n",
            "   âœ… Window 2021-2024 â†’ 2025: Return=+19.95% | MDD=11.28% | WinRate=0.0% | Pauses=0\n",
            "\n",
            "   ðŸ“Š TCAP Average: Return=+14.41% | MDD=14.86% | WinRate=1.4% | Total Pauses=1\n",
            "\n",
            "============================================================\n",
            "ðŸ”¹ Processing: TISCO\n",
            "============================================================\n",
            "   âœ… Window 2015-2018 â†’ 2019: Return=+12.52% | MDD=4.72% | WinRate=17.9% | Pauses=0\n",
            "   âœ… Window 2016-2019 â†’ 2020: Return=+15.58% | MDD=25.24% | WinRate=3.1% | Pauses=0\n",
            "   âœ… Window 2017-2020 â†’ 2021: Return=+14.63% | MDD=9.52% | WinRate=0.0% | Pauses=0\n",
            "   âœ… Window 2018-2021 â†’ 2022: Return=+9.82% | MDD=8.44% | WinRate=0.0% | Pauses=0\n",
            "   âœ… Window 2019-2022 â†’ 2023: Return=+9.47% | MDD=6.12% | WinRate=0.0% | Pauses=0\n",
            "   âœ… Window 2020-2023 â†’ 2024: Return=+6.89% | MDD=9.04% | WinRate=0.0% | Pauses=0\n",
            "   âœ… Window 2021-2024 â†’ 2025: Return=+21.29% | MDD=4.70% | WinRate=0.0% | Pauses=0\n",
            "\n",
            "   ðŸ“Š TISCO Average: Return=+12.89% | MDD=9.68% | WinRate=3.0% | Total Pauses=0\n",
            "\n",
            "============================================================\n",
            "ðŸ”¹ Processing: TTB\n",
            "============================================================\n",
            "   âœ… Window 2015-2018 â†’ 2019: Return=-9.38% | MDD=28.88% | WinRate=1.2% | Pauses=0\n",
            "   âœ… Window 2016-2019 â†’ 2020: Return=+0.00% | MDD=0.00% | WinRate=0.0% | Pauses=0\n",
            "   âœ… Window 2017-2020 â†’ 2021: Return=+0.00% | MDD=0.00% | WinRate=0.0% | Pauses=0\n",
            "   âœ… Window 2018-2021 â†’ 2022: Return=-0.59% | MDD=22.83% | WinRate=0.0% | Pauses=0\n",
            "   âœ… Window 2019-2022 â†’ 2023: Return=+18.61% | MDD=11.92% | WinRate=1.2% | Pauses=0\n",
            "   âœ… Window 2020-2023 â†’ 2024: Return=+16.48% | MDD=11.74% | WinRate=1.7% | Pauses=0\n",
            "   âœ… Window 2021-2024 â†’ 2025: Return=+16.79% | MDD=10.38% | WinRate=0.0% | Pauses=0\n",
            "\n",
            "   ðŸ“Š TTB Average: Return=+5.99% | MDD=12.25% | WinRate=0.6% | Total Pauses=0\n",
            "\n",
            "======================================================================\n",
            "ðŸ“Š OVERALL PERFORMANCE SUMMARY\n",
            "======================================================================\n",
            "\n",
            "ðŸ“… Performance by Test Year:\n",
            "----------------------------------------------------------------------\n",
            "          Total_Return         Max_Drawdown Win_Rate Pause_Triggered\n",
            "                  mean     std         mean     mean             sum\n",
            "Test_Year                                                           \n",
            "2019           -0.0098  0.1357       0.1403   0.0734               0\n",
            "2020           -0.0223  0.1021       0.1866   0.0237               1\n",
            "2021            0.0613  0.0801       0.1265   0.0158               0\n",
            "2022            0.1267  0.1144       0.1159   0.0142               0\n",
            "2023            0.0312  0.1752       0.1471   0.0102               0\n",
            "2024            0.1210  0.1198       0.1120   0.0625               0\n",
            "2025            0.1827  0.0413       0.1133   0.0271               0\n",
            "\n",
            "ðŸ“ˆ Performance by Stock:\n",
            "----------------------------------------------------------------------\n",
            "       Total_Return  Max_Drawdown  Win_Rate  Pause_Triggered\n",
            "Stock                                                       \n",
            "TCAP         0.1441        0.1486    0.0140                1\n",
            "TISCO        0.1289        0.0968    0.0300                0\n",
            "TTB          0.0599        0.1225    0.0059                0\n",
            "KTB          0.0586        0.1765    0.0281                0\n",
            "KKP          0.0571        0.1628    0.0763                0\n",
            "KBANK        0.0479        0.1342    0.0641                0\n",
            "BBL         -0.0056        0.1003    0.0086                0\n",
            "\n",
            "======================================================================\n",
            "ðŸŽ¯ OVERALL AVERAGE PERFORMANCE\n",
            "======================================================================\n",
            "   â€¢ Average Return:      +7.01%\n",
            "   â€¢ Std Dev Return:      13.03%\n",
            "   â€¢ Average Max DD:      13.45%\n",
            "   â€¢ Average Win Rate:    3.2%\n",
            "   â€¢ Total Pause Events:  1\n",
            "   â€¢ Win Rate (Return>0): 63.3%\n",
            "\n",
            "   ðŸ† Best:  KBANK (2020-2023 â†’ 2024): +32.05%\n",
            "   ðŸ’€ Worst: KKP (2019-2022 â†’ 2023): -25.28%\n",
            "\n",
            "ðŸ’¾ Results saved to: PPO_Backtest_Results_RollingWindow_V2.xlsx\n",
            "\n",
            "======================================================================\n",
            "âœ… BLOCK 7 COMPLETED: PPO + Rolling Window + Risk Management V2\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# ðŸ¤– BLOCK 7: Train PPO (UPGRADED + ROLLING WINDOW + RISK MANAGEMENT V2)\n",
        "#    Logic:\n",
        "#    - Cooldown 2 Days after Sell\n",
        "#    - Stop Loss -6%\n",
        "#    - Trailing Stop (Trigger 10%, Drop 4%)\n",
        "#    - ðŸ†• Volatility-based Position Sizing\n",
        "#    - ðŸ†• Max Consecutive Losses (5 losses â†’ pause 3 days)\n",
        "# ============================================================\n",
        "import os\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "os.makedirs(\"trained_models\", exist_ok=True)\n",
        "\n",
        "# ============================================================\n",
        "# 1. TARGET STOCKS\n",
        "# ============================================================\n",
        "[\"BBL\",\"KBANK\",\"KKP\",\"KTB\",\"TCAP\",\"TISCO\",\"TTB\"]\n",
        "# [\n",
        "#     \"AAV\", \"AEONTS\", \"AOT\", \"BA\", \"BBL\", \"BCH\", \"BDMS\", \"BEM\", \"BH\", \"BTS\",\n",
        "#     \"CHG\", \"JMT\", \"KBANK\", \"KKP\", \"KTB\", \"KTC\", \"PR9\", \"PRM\", \"RCL\", \"SAWAD\",\n",
        "#     \"TCAP\", \"TISCO\", \"TTB\"\n",
        "# ]\n",
        "\n",
        "target_stocks = [\"BBL\",\"KBANK\",\"KKP\",\"KTB\",\"TCAP\",\"TISCO\",\"TTB\"]\n",
        "\n",
        "# ============================================================\n",
        "# 2. ROLLING WINDOW CONFIGURATION\n",
        "# ============================================================\n",
        "ROLLING_WINDOWS = [\n",
        "    (2015, 2018, 2019),\n",
        "    (2016, 2019, 2020),\n",
        "    (2017, 2020, 2021),\n",
        "    (2018, 2021, 2022),\n",
        "    (2019, 2022, 2023),\n",
        "    (2020, 2023, 2024),\n",
        "    (2021, 2024, 2025),\n",
        "]\n",
        "\n",
        "# ============================================================\n",
        "# 3. LOAD DATA\n",
        "# ============================================================\n",
        "try:\n",
        "    df_rl_all = pd.read_excel(\"Final_RL_Input_Ready.xlsx\")\n",
        "    df_rl_all['Date'] = pd.to_datetime(df_rl_all['Date'])\n",
        "    df_rl_all['Year'] = df_rl_all['Date'].dt.year\n",
        "except:\n",
        "    raise RuntimeError(\"âŒ Missing Data: Final_RL_Input_Ready.xlsx\")\n",
        "\n",
        "# ============================================================\n",
        "# 4. TRADING ENVIRONMENT (UPGRADED)\n",
        "# ============================================================\n",
        "class StockTradingEnv(gym.Env):\n",
        "    \"\"\"\n",
        "    Stock Trading Environment with Enhanced Risk Management:\n",
        "\n",
        "    Original Features:\n",
        "    - Cooldown mechanism (2 days after sell)\n",
        "    - Stop Loss (-6%)\n",
        "    - Trailing Stop (Trigger +10%, Drop -4%)\n",
        "\n",
        "    ðŸ†• New Features:\n",
        "    - Volatility-based Position Sizing\n",
        "    - Max Consecutive Losses (5 losses â†’ pause 3 days)\n",
        "    - Penalty reward when forced to pause\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, df, volatility_lookback=20, base_position_pct=0.5,\n",
        "                 max_consecutive_losses=5, loss_pause_days=3):\n",
        "        super(StockTradingEnv, self).__init__()\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.initial_balance = 1_000_000\n",
        "\n",
        "        # Action & Observation Space\n",
        "        self.action_space = spaces.Discrete(3)  # 0=Hold, 1=Buy, 2=Sell\n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(11,), dtype=np.float32)\n",
        "\n",
        "        # ðŸ†• Volatility-based Sizing Parameters\n",
        "        self.volatility_lookback = volatility_lookback\n",
        "        self.base_position_pct = base_position_pct  # Base position size (50%)\n",
        "\n",
        "        # ðŸ†• Max Consecutive Losses Parameters\n",
        "        self.max_consecutive_losses = max_consecutive_losses  # 5 à¸„à¸£à¸±à¹‰à¸‡\n",
        "        self.loss_pause_days = loss_pause_days  # à¸«à¸¢à¸¸à¸” 3 à¸§à¸±à¸™\n",
        "\n",
        "        # Precompute volatility for entire dataset\n",
        "        self._precompute_volatility()\n",
        "\n",
        "        self.reset()\n",
        "\n",
        "    def _precompute_volatility(self):\n",
        "        \"\"\"Precompute rolling volatility for position sizing\"\"\"\n",
        "        prices = self.df['Close'].values\n",
        "        returns = np.diff(prices) / prices[:-1]\n",
        "        returns = np.insert(returns, 0, 0)  # Pad first value\n",
        "\n",
        "        # Rolling standard deviation\n",
        "        self.volatility = pd.Series(returns).rolling(\n",
        "            window=self.volatility_lookback,\n",
        "            min_periods=5\n",
        "        ).std().fillna(0.02).values  # Default 2% if not enough data\n",
        "\n",
        "        # Normalize volatility to [0.5, 1.5] range for position sizing\n",
        "        vol_mean = np.mean(self.volatility[self.volatility > 0])\n",
        "        vol_std = np.std(self.volatility[self.volatility > 0])\n",
        "\n",
        "        if vol_std > 0:\n",
        "            self.vol_multiplier = 1 - (self.volatility - vol_mean) / (2 * vol_std)\n",
        "            self.vol_multiplier = np.clip(self.vol_multiplier, 0.3, 1.0)  # 30% to 100%\n",
        "        else:\n",
        "            self.vol_multiplier = np.ones(len(self.df)) * 0.5\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.current_step = 0\n",
        "\n",
        "        # Random initial position (50% chance)\n",
        "        if np.random.rand() < 0.5:\n",
        "            self.balance = self.initial_balance\n",
        "            self.shares_held = 0\n",
        "            self.avg_cost = 0.0\n",
        "            self.highest_price = 0.0\n",
        "        else:\n",
        "            start_price = self.df.iloc[0]['Close']\n",
        "            invest_pct = np.random.uniform(0.2, 0.8)\n",
        "            cash_invested = self.initial_balance * invest_pct\n",
        "            self.shares_held = int(cash_invested // start_price)\n",
        "            self.balance = self.initial_balance - (self.shares_held * start_price)\n",
        "            self.avg_cost = start_price\n",
        "            self.highest_price = start_price\n",
        "\n",
        "        self.net_worth = self.initial_balance\n",
        "        self.prev_net_worth = self.initial_balance\n",
        "\n",
        "        # Original Cooldown\n",
        "        self.cooldown = 0\n",
        "\n",
        "        # ðŸ†• Consecutive Losses Tracking\n",
        "        self.consecutive_losses = 0\n",
        "        self.loss_pause_counter = 0  # Days remaining in pause\n",
        "\n",
        "        # ðŸ†• Statistics\n",
        "        self.total_trades = 0\n",
        "        self.winning_trades = 0\n",
        "        self.losing_trades = 0\n",
        "        self.pause_triggered_count = 0\n",
        "\n",
        "        return self._next_observation(), {}\n",
        "\n",
        "    def _get_current_volatility(self):\n",
        "        \"\"\"Get current volatility multiplier for position sizing\"\"\"\n",
        "        return self.vol_multiplier[min(self.current_step, len(self.vol_multiplier) - 1)]\n",
        "\n",
        "    def _next_observation(self):\n",
        "        \"\"\"\n",
        "        State vector (11 features):\n",
        "        - Original 8 features\n",
        "        - ðŸ†• 3 new features for risk management\n",
        "        \"\"\"\n",
        "        obs = self.df.iloc[self.current_step]\n",
        "        current_vol = self._get_current_volatility()\n",
        "\n",
        "        return np.array([\n",
        "            # Original features\n",
        "            obs.get('Macro_Signal', 0),\n",
        "            obs.get('DL_Signal', 0.5),\n",
        "            obs.get('Tech_Signal', 0),\n",
        "            obs.get('ADX', 25) / 100.0,\n",
        "            self.balance / 1_000_000.0,\n",
        "            (self.shares_held * obs['Close']) / 1_000_000.0,\n",
        "            obs.get('RSI', 50) / 100.0,\n",
        "            obs.get('MACD', 0) / 10.0,\n",
        "            # ðŸ†• New features\n",
        "            current_vol,  # Current volatility multiplier\n",
        "            self.consecutive_losses / self.max_consecutive_losses,  # Normalized loss streak\n",
        "            self.loss_pause_counter / self.loss_pause_days  # Normalized pause counter\n",
        "        ], dtype=np.float32)\n",
        "\n",
        "    def _calculate_position_size(self):\n",
        "        \"\"\"\n",
        "        ðŸ†• Volatility-based Position Sizing\n",
        "\n",
        "        Logic:\n",
        "        - High volatility â†’ Smaller position (30-50%)\n",
        "        - Low volatility â†’ Larger position (70-100%)\n",
        "\n",
        "        Formula: position_pct = base_pct Ã— volatility_multiplier\n",
        "        \"\"\"\n",
        "        vol_mult = self._get_current_volatility()\n",
        "        position_pct = self.base_position_pct * vol_mult\n",
        "\n",
        "        # Clamp to reasonable range\n",
        "        position_pct = np.clip(position_pct, 0.15, 0.70)  # 15% to 70%\n",
        "\n",
        "        return position_pct\n",
        "\n",
        "    def step(self, action):\n",
        "        current_price = self.df.iloc[self.current_step]['Close']\n",
        "        obs = self.df.iloc[self.current_step]\n",
        "\n",
        "        reward = 0.0\n",
        "        force_sell = False\n",
        "        reason = \"\"\n",
        "\n",
        "        # ============================================================\n",
        "        # ðŸ†• CHECK: Max Consecutive Losses Pause\n",
        "        # ============================================================\n",
        "        if self.loss_pause_counter > 0:\n",
        "            # Still in pause period - force HOLD\n",
        "            self.loss_pause_counter -= 1\n",
        "            action = 0  # Force Hold\n",
        "\n",
        "            # ðŸ†• Penalty for being in pause (missed opportunity cost)\n",
        "            reward -= 0.3\n",
        "\n",
        "            if self.loss_pause_counter == 0:\n",
        "                # Pause ended, reset consecutive losses\n",
        "                self.consecutive_losses = 0\n",
        "\n",
        "        # ============================================================\n",
        "        # CHECK: Risk Management (Stop Loss / Trailing Stop)\n",
        "        # ============================================================\n",
        "        if self.shares_held > 0:\n",
        "            if current_price > self.highest_price:\n",
        "                self.highest_price = current_price\n",
        "            pnl_pct = (current_price - self.avg_cost) / self.avg_cost\n",
        "\n",
        "            # 1. Hard Stop Loss (-6%)\n",
        "            if pnl_pct <= -0.06:\n",
        "                force_sell = True\n",
        "                reason = \"SL\"\n",
        "\n",
        "            # 2. Trailing Stop (Trigger > +10%, Drop -4%)\n",
        "            if pnl_pct > 0.10:\n",
        "                drop = (self.highest_price - current_price) / self.highest_price\n",
        "                if drop > 0.04:\n",
        "                    force_sell = True\n",
        "                    reason = \"TRAIL\"\n",
        "\n",
        "        if force_sell:\n",
        "            action = 2\n",
        "\n",
        "        # ============================================================\n",
        "        # CHECK: Original Cooldown (after sell)\n",
        "        # ============================================================\n",
        "        if self.cooldown > 0:\n",
        "            if action == 1:\n",
        "                action = 0  # Force Hold during cooldown\n",
        "            self.cooldown -= 1\n",
        "\n",
        "        # ============================================================\n",
        "        # EXECUTE ACTION\n",
        "        # ============================================================\n",
        "\n",
        "        # ----- BUY -----\n",
        "        if action == 1 and self.balance > current_price and self.loss_pause_counter == 0:\n",
        "            can_buy = False\n",
        "            rsi = obs.get('RSI', 50)\n",
        "            adx = obs.get('ADX', 0)\n",
        "\n",
        "            # Momentum Rule\n",
        "            if adx > 25 and rsi < 75:\n",
        "                can_buy = True\n",
        "            elif rsi < 45:\n",
        "                can_buy = True\n",
        "\n",
        "            if can_buy:\n",
        "                # ðŸ†• Volatility-based Position Sizing\n",
        "                position_pct = self._calculate_position_size()\n",
        "                budget = self.balance * position_pct\n",
        "\n",
        "                shares = int(budget // current_price)\n",
        "                if shares > 0:\n",
        "                    cost = shares * current_price\n",
        "                    self.avg_cost = ((self.shares_held * self.avg_cost) + cost) / (self.shares_held + shares)\n",
        "                    self.balance -= cost\n",
        "                    self.shares_held += shares\n",
        "                    self.highest_price = current_price\n",
        "                    self.total_trades += 1\n",
        "                    reward += 0.1  # Small reward for action\n",
        "\n",
        "        # ----- SELL -----\n",
        "        elif action == 2 and self.shares_held > 0:\n",
        "            revenue = self.shares_held * current_price\n",
        "            pnl_pct = (current_price - self.avg_cost) / self.avg_cost\n",
        "\n",
        "            self.balance += revenue\n",
        "            self.shares_held = 0\n",
        "            self.avg_cost = 0\n",
        "            self.highest_price = 0\n",
        "            self.cooldown = 2  # Original cooldown\n",
        "            self.total_trades += 1\n",
        "\n",
        "            # Track win/loss\n",
        "            is_loss = pnl_pct < 0\n",
        "\n",
        "            if reason == \"TRAIL\":\n",
        "                reward += 2.0  # Big reward for trailing stop profit\n",
        "                self.winning_trades += 1\n",
        "                self.consecutive_losses = 0  # Reset streak\n",
        "\n",
        "            elif reason == \"SL\":\n",
        "                reward += 0.1  # Small reward for discipline\n",
        "                self.losing_trades += 1\n",
        "\n",
        "                # ðŸ†• Track consecutive losses\n",
        "                self.consecutive_losses += 1\n",
        "\n",
        "            else:\n",
        "                if pnl_pct > 0:\n",
        "                    reward += pnl_pct * 10\n",
        "                    self.winning_trades += 1\n",
        "                    self.consecutive_losses = 0  # Reset streak\n",
        "                else:\n",
        "                    reward -= 0.5  # Penalty for bad sell\n",
        "                    self.losing_trades += 1\n",
        "\n",
        "                    # ðŸ†• Track consecutive losses\n",
        "                    self.consecutive_losses += 1\n",
        "\n",
        "            # ============================================================\n",
        "            # ðŸ†• CHECK: Trigger Loss Pause\n",
        "            # ============================================================\n",
        "            if self.consecutive_losses >= self.max_consecutive_losses:\n",
        "                self.loss_pause_counter = self.loss_pause_days\n",
        "                self.pause_triggered_count += 1\n",
        "\n",
        "                # ðŸ†• Heavy penalty for triggering pause\n",
        "                reward -= 1.5\n",
        "\n",
        "                # Note: consecutive_losses will reset when pause ends\n",
        "\n",
        "        # ============================================================\n",
        "        # STEP FORWARD\n",
        "        # ============================================================\n",
        "        self.current_step += 1\n",
        "        done = self.current_step >= len(self.df) - 1\n",
        "\n",
        "        # Calculate new net worth\n",
        "        if not done:\n",
        "            next_val = self.balance + (self.shares_held * self.df.iloc[self.current_step]['Close'])\n",
        "        else:\n",
        "            next_val = self.balance + (self.shares_held * current_price)\n",
        "\n",
        "        reward += ((next_val - self.prev_net_worth) / self.prev_net_worth) * 100\n",
        "        self.prev_net_worth = next_val\n",
        "\n",
        "        return self._next_observation(), reward, done, False, {}\n",
        "\n",
        "    def get_stats(self):\n",
        "        \"\"\"Return trading statistics\"\"\"\n",
        "        return {\n",
        "            'total_trades': self.total_trades,\n",
        "            'winning_trades': self.winning_trades,\n",
        "            'losing_trades': self.losing_trades,\n",
        "            'pause_triggered_count': self.pause_triggered_count,\n",
        "            'win_rate': self.winning_trades / max(1, self.total_trades)\n",
        "        }\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 5. BACKTESTING FUNCTION\n",
        "# ============================================================\n",
        "def backtest_model(model, test_df):\n",
        "    \"\"\"Backtest trained model on test data\"\"\"\n",
        "    env = StockTradingEnv(test_df)\n",
        "    obs, _ = env.reset()\n",
        "\n",
        "    total_reward = 0\n",
        "    actions = []\n",
        "    net_worths = [env.initial_balance]\n",
        "\n",
        "    done = False\n",
        "    while not done:\n",
        "        action, _ = model.predict(obs, deterministic=True)\n",
        "        obs, reward, done, _, _ = env.step(action)\n",
        "        total_reward += reward\n",
        "        actions.append(action)\n",
        "\n",
        "        current_price = test_df.iloc[min(env.current_step, len(test_df)-1)]['Close']\n",
        "        net_worths.append(env.balance + (env.shares_held * current_price))\n",
        "\n",
        "    # Calculate metrics\n",
        "    final_value = net_worths[-1]\n",
        "    initial_value = env.initial_balance\n",
        "    total_return = (final_value - initial_value) / initial_value\n",
        "\n",
        "    # Maximum Drawdown\n",
        "    peak = net_worths[0]\n",
        "    max_drawdown = 0\n",
        "    for nw in net_worths:\n",
        "        if nw > peak:\n",
        "            peak = nw\n",
        "        drawdown = (peak - nw) / peak\n",
        "        if drawdown > max_drawdown:\n",
        "            max_drawdown = drawdown\n",
        "\n",
        "    # Action counts\n",
        "    n_buys = sum(1 for a in actions if a == 1)\n",
        "    n_sells = sum(1 for a in actions if a == 2)\n",
        "    n_holds = sum(1 for a in actions if a == 0)\n",
        "\n",
        "    # Get env stats\n",
        "    stats = env.get_stats()\n",
        "\n",
        "    return {\n",
        "        'Total_Return': total_return,\n",
        "        'Final_Value': final_value,\n",
        "        'Max_Drawdown': max_drawdown,\n",
        "        'Total_Reward': total_reward,\n",
        "        'N_Buys': n_buys,\n",
        "        'N_Sells': n_sells,\n",
        "        'N_Holds': n_holds,\n",
        "        'N_Trades': stats['total_trades'],\n",
        "        'Win_Rate': stats['win_rate'],\n",
        "        'Pause_Triggered': stats['pause_triggered_count']\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 6. MAIN TRAINING LOOP\n",
        "# ============================================================\n",
        "print(\"=\" * 70)\n",
        "print(\"ðŸ¤– BLOCK 7: PPO Training (UPGRADED + ROLLING WINDOW + RISK MGMT V2)\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\"\"\n",
        "ðŸ”„ Rolling Window Configuration:\n",
        "   - Window 1: Train [2015-2018] â†’ Test [2019]\n",
        "   - Window 2: Train [2016-2019] â†’ Test [2020]\n",
        "   - Window 3: Train [2017-2020] â†’ Test [2021]\n",
        "   - Window 4: Train [2018-2021] â†’ Test [2022]\n",
        "   - Window 5: Train [2019-2022] â†’ Test [2023]\n",
        "   - Window 6: Train [2020-2023] â†’ Test [2024]\n",
        "   - Window 7: Train [2021-2024] â†’ Test [2025]\n",
        "\n",
        "ðŸ›¡ï¸ Risk Management:\n",
        "   - Stop Loss: -6%\n",
        "   - Trailing Stop: Trigger +10%, Drop -4%\n",
        "   - Cooldown: 2 days after sell\n",
        "\n",
        "ðŸ†• NEW Risk Management:\n",
        "   - Volatility-based Position Sizing (30-70% based on volatility)\n",
        "   - Max Consecutive Losses: 5 losses â†’ Pause 3 days\n",
        "   - Penalty: -0.3 per pause day, -1.5 when pause triggered\n",
        "\n",
        "âš™ï¸ PPO Configuration:\n",
        "   - Learning Rate: 0.0003\n",
        "   - Entropy Coef: 0.01\n",
        "   - Batch Size: 64\n",
        "   - Timesteps: 30,000 per window\n",
        "\"\"\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Storage\n",
        "all_backtest_metrics = []\n",
        "\n",
        "for stock in target_stocks:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"ðŸ”¹ Processing: {stock}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    stock_df = df_rl_all[df_rl_all['Stock'] == stock].copy()\n",
        "\n",
        "    if len(stock_df) < 200:\n",
        "        print(f\"âš ï¸ Skipped (insufficient data: {len(stock_df)} rows)\")\n",
        "        continue\n",
        "\n",
        "    stock_metrics = []\n",
        "\n",
        "    for train_start, train_end, test_year in ROLLING_WINDOWS:\n",
        "        train_df = stock_df[(stock_df['Year'] >= train_start) & (stock_df['Year'] <= train_end)].copy()\n",
        "        test_df = stock_df[stock_df['Year'] == test_year].copy()\n",
        "\n",
        "        if len(train_df) < 50:\n",
        "            print(f\"   âš ï¸ Window {train_start}-{train_end} â†’ {test_year}: Insufficient train data\")\n",
        "            continue\n",
        "\n",
        "        if len(test_df) < 10:\n",
        "            print(f\"   âš ï¸ Window {train_start}-{train_end} â†’ {test_year}: Insufficient test data\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # Create environment with new parameters\n",
        "            env = DummyVecEnv([lambda df=train_df: StockTradingEnv(\n",
        "                df,\n",
        "                volatility_lookback=20,\n",
        "                base_position_pct=0.5,\n",
        "                max_consecutive_losses=5,\n",
        "                loss_pause_days=3\n",
        "            )])\n",
        "\n",
        "            model = PPO(\n",
        "                \"MlpPolicy\",\n",
        "                env,\n",
        "                verbose=0,\n",
        "                learning_rate=0.0003,\n",
        "                ent_coef=0.01,\n",
        "                batch_size=64\n",
        "            )\n",
        "\n",
        "            model.learn(total_timesteps=30000)\n",
        "\n",
        "            # Save model\n",
        "            model_path = f\"trained_models/ppo_{stock}_train{train_start}_{train_end}_test{test_year}\"\n",
        "            model.save(model_path)\n",
        "\n",
        "            # Backtest\n",
        "            metrics = backtest_model(model, test_df)\n",
        "            metrics['Stock'] = stock\n",
        "            metrics['Train_Period'] = f\"{train_start}-{train_end}\"\n",
        "            metrics['Test_Year'] = test_year\n",
        "            metrics['Train_Samples'] = len(train_df)\n",
        "            metrics['Test_Samples'] = len(test_df)\n",
        "\n",
        "            stock_metrics.append(metrics)\n",
        "            all_backtest_metrics.append(metrics)\n",
        "\n",
        "            print(f\"   âœ… Window {train_start}-{train_end} â†’ {test_year}: \"\n",
        "                  f\"Return={metrics['Total_Return']:+.2%} | MDD={metrics['Max_Drawdown']:.2%} | \"\n",
        "                  f\"WinRate={metrics['Win_Rate']:.1%} | Pauses={metrics['Pause_Triggered']}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   âŒ Window {train_start}-{train_end} â†’ {test_year}: Error - {e}\")\n",
        "\n",
        "    # Summary for this stock\n",
        "    if stock_metrics:\n",
        "        avg_return = np.mean([m['Total_Return'] for m in stock_metrics])\n",
        "        avg_mdd = np.mean([m['Max_Drawdown'] for m in stock_metrics])\n",
        "        avg_winrate = np.mean([m['Win_Rate'] for m in stock_metrics])\n",
        "        total_pauses = sum([m['Pause_Triggered'] for m in stock_metrics])\n",
        "        print(f\"\\n   ðŸ“Š {stock} Average: Return={avg_return:+.2%} | MDD={avg_mdd:.2%} | \"\n",
        "              f\"WinRate={avg_winrate:.1%} | Total Pauses={total_pauses}\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 7. OVERALL SUMMARY\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"ðŸ“Š OVERALL PERFORMANCE SUMMARY\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "if all_backtest_metrics:\n",
        "    df_metrics = pd.DataFrame(all_backtest_metrics)\n",
        "\n",
        "    # Summary by Test Year\n",
        "    print(\"\\nðŸ“… Performance by Test Year:\")\n",
        "    print(\"-\" * 70)\n",
        "    year_summary = df_metrics.groupby('Test_Year').agg({\n",
        "        'Total_Return': ['mean', 'std'],\n",
        "        'Max_Drawdown': 'mean',\n",
        "        'Win_Rate': 'mean',\n",
        "        'Pause_Triggered': 'sum'\n",
        "    }).round(4)\n",
        "    print(year_summary.to_string())\n",
        "\n",
        "    # Summary by Stock\n",
        "    print(\"\\nðŸ“ˆ Performance by Stock:\")\n",
        "    print(\"-\" * 70)\n",
        "    stock_summary = df_metrics.groupby('Stock').agg({\n",
        "        'Total_Return': 'mean',\n",
        "        'Max_Drawdown': 'mean',\n",
        "        'Win_Rate': 'mean',\n",
        "        'Pause_Triggered': 'sum'\n",
        "    }).round(4).sort_values('Total_Return', ascending=False)\n",
        "    print(stock_summary.to_string())\n",
        "\n",
        "    # Overall Average\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"ðŸŽ¯ OVERALL AVERAGE PERFORMANCE\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"   â€¢ Average Return:      {df_metrics['Total_Return'].mean():+.2%}\")\n",
        "    print(f\"   â€¢ Std Dev Return:      {df_metrics['Total_Return'].std():.2%}\")\n",
        "    print(f\"   â€¢ Average Max DD:      {df_metrics['Max_Drawdown'].mean():.2%}\")\n",
        "    print(f\"   â€¢ Average Win Rate:    {df_metrics['Win_Rate'].mean():.1%}\")\n",
        "    print(f\"   â€¢ Total Pause Events:  {df_metrics['Pause_Triggered'].sum()}\")\n",
        "    print(f\"   â€¢ Win Rate (Return>0): {(df_metrics['Total_Return'] > 0).mean():.1%}\")\n",
        "\n",
        "    # Best and Worst\n",
        "    best = df_metrics.loc[df_metrics['Total_Return'].idxmax()]\n",
        "    worst = df_metrics.loc[df_metrics['Total_Return'].idxmin()]\n",
        "\n",
        "    print(f\"\\n   ðŸ† Best:  {best['Stock']} ({best['Train_Period']} â†’ {best['Test_Year']}): {best['Total_Return']:+.2%}\")\n",
        "    print(f\"   ðŸ’€ Worst: {worst['Stock']} ({worst['Train_Period']} â†’ {worst['Test_Year']}): {worst['Total_Return']:+.2%}\")\n",
        "\n",
        "    # Export\n",
        "    outfile = \"PPO_Backtest_Results_RollingWindow_V2.xlsx\"\n",
        "    df_metrics.to_excel(outfile, index=False)\n",
        "    print(f\"\\nðŸ’¾ Results saved to: {outfile}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"âœ… BLOCK 7 COMPLETED: PPO + Rolling Window + Risk Management V2\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyqSl5NnABSu",
        "outputId": "bb172f96-15ff-48f4-c80e-4aad99233512"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "ðŸ† BLOCK 8: Evaluation & Prediction (UPGRADED)\n",
            "================================================================================\n",
            "\n",
            "ðŸ“Š Performance Metrics:\n",
            "   - Total Return (%)\n",
            "   - Annualized Return (%)\n",
            "   - Sharpe Ratio\n",
            "   - Sortino Ratio\n",
            "   - Maximum Drawdown (%)\n",
            "   - Calmar Ratio\n",
            "   - Win Rate (%)\n",
            "   - Profit Factor\n",
            "\n",
            "ðŸ“ˆ Benchmark: Buy-and-Hold Strategy\n",
            "\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "ðŸ”¹ Evaluating: BBL\n",
            "============================================================\n",
            "   2019: AI=-20.9% vs BH=-18.5% | Sharpe=-1.31 | MDD=25.7% | âŒ LOSS\n",
            "   2020: AI=+0.0% vs BH=-24.3% | Sharpe=0.00 | MDD=0.0% | âœ… WIN\n",
            "   2021: AI=+0.0% vs BH=+3.8% | Sharpe=0.00 | MDD=0.0% | âŒ LOSS\n",
            "   2022: AI=+0.0% vs BH=+21.9% | Sharpe=0.00 | MDD=0.0% | âŒ LOSS\n",
            "   2023: AI=+0.5% vs BH=+6.9% | Sharpe=-0.00 | MDD=17.1% | âŒ LOSS\n",
            "   2024: AI=+9.1% vs BH=+2.8% | Sharpe=0.51 | MDD=10.8% | âœ… WIN\n",
            "   2025: AI=+17.6% vs BH=+18.4% | Sharpe=0.98 | MDD=12.5% | âŒ LOSS\n",
            "\n",
            "   ðŸ“Š BBL Summary:\n",
            "      Avg AI Return: +0.89%\n",
            "      Avg BH Return: +1.56%\n",
            "      Avg Sharpe:    0.03\n",
            "      Beat BH:       2/7 windows\n",
            "\n",
            "============================================================\n",
            "ðŸ”¹ Evaluating: KBANK\n",
            "============================================================\n",
            "   2019: AI=+0.0% vs BH=-16.6% | Sharpe=0.00 | MDD=0.0% | âœ… WIN\n",
            "   2020: AI=-6.9% vs BH=-22.9% | Sharpe=-0.01 | MDD=32.6% | âœ… WIN\n",
            "   2021: AI=-4.0% vs BH=+28.5% | Sharpe=-0.24 | MDD=21.2% | âŒ LOSS\n",
            "   2022: AI=-2.6% vs BH=+3.5% | Sharpe=-0.19 | MDD=18.9% | âŒ LOSS\n",
            "   2023: AI=-2.7% vs BH=-6.6% | Sharpe=-0.33 | MDD=12.9% | âœ… WIN\n",
            "   2024: AI=+29.3% vs BH=+22.1% | Sharpe=1.50 | MDD=8.8% | âœ… WIN\n",
            "   2025: AI=+11.0% vs BH=+36.0% | Sharpe=0.84 | MDD=8.6% | âŒ LOSS\n",
            "\n",
            "   ðŸ“Š KBANK Summary:\n",
            "      Avg AI Return: +3.44%\n",
            "      Avg BH Return: +6.28%\n",
            "      Avg Sharpe:    0.22\n",
            "      Beat BH:       4/7 windows\n",
            "\n",
            "============================================================\n",
            "ðŸ”¹ Evaluating: KKP\n",
            "============================================================\n",
            "   2019: AI=+10.0% vs BH=+5.6% | Sharpe=0.69 | MDD=6.3% | âœ… WIN\n",
            "   2020: AI=-23.6% vs BH=-17.9% | Sharpe=-1.19 | MDD=26.7% | âŒ LOSS\n",
            "   2021: AI=+11.4% vs BH=+22.2% | Sharpe=0.54 | MDD=22.5% | âŒ LOSS\n",
            "   2022: AI=+9.2% vs BH=+26.7% | Sharpe=0.48 | MDD=17.0% | âŒ LOSS\n",
            "   2023: AI=-29.1% vs BH=-30.3% | Sharpe=-1.76 | MDD=33.4% | âœ… WIN\n",
            "   2024: AI=+15.7% vs BH=+11.6% | Sharpe=1.50 | MDD=1.4% | âœ… WIN\n",
            "   2025: AI=+34.7% vs BH=+41.9% | Sharpe=1.25 | MDD=23.0% | âŒ LOSS\n",
            "\n",
            "   ðŸ“Š KKP Summary:\n",
            "      Avg AI Return: +4.04%\n",
            "      Avg BH Return: +8.53%\n",
            "      Avg Sharpe:    0.22\n",
            "      Beat BH:       3/7 windows\n",
            "\n",
            "============================================================\n",
            "ðŸ”¹ Evaluating: KTB\n",
            "============================================================\n",
            "   2019: AI=-11.8% vs BH=-11.8% | Sharpe=-1.17 | MDD=18.5% | âŒ LOSS\n",
            "   2020: AI=-17.2% vs BH=-29.1% | Sharpe=-0.43 | MDD=31.8% | âœ… WIN\n",
            "   2021: AI=-0.7% vs BH=+20.7% | Sharpe=-4.40 | MDD=0.7% | âŒ LOSS\n",
            "   2022: AI=+31.9% vs BH=+35.4% | Sharpe=1.38 | MDD=9.0% | âŒ LOSS\n",
            "   2023: AI=-0.2% vs BH=+7.6% | Sharpe=-0.05 | MDD=16.1% | âŒ LOSS\n",
            "   2024: AI=+22.9% vs BH=+20.2% | Sharpe=1.11 | MDD=12.8% | âœ… WIN\n",
            "   2025: AI=+21.7% vs BH=+46.7% | Sharpe=0.90 | MDD=18.8% | âŒ LOSS\n",
            "\n",
            "   ðŸ“Š KTB Summary:\n",
            "      Avg AI Return: +6.65%\n",
            "      Avg BH Return: +12.82%\n",
            "      Avg Sharpe:    -0.38\n",
            "      Beat BH:       2/7 windows\n",
            "\n",
            "============================================================\n",
            "ðŸ”¹ Evaluating: TCAP\n",
            "============================================================\n",
            "   2019: AI=+12.5% vs BH=+19.8% | Sharpe=0.58 | MDD=16.8% | âŒ LOSS\n",
            "   2020: AI=-6.3% vs BH=-29.5% | Sharpe=-0.09 | MDD=34.8% | âœ… WIN\n",
            "   2021: AI=-3.2% vs BH=+19.8% | Sharpe=-0.34 | MDD=12.9% | âŒ LOSS\n",
            "   2022: AI=+1.2% vs BH=+18.9% | Sharpe=-0.14 | MDD=3.5% | âŒ LOSS\n",
            "   2023: AI=-1.0% vs BH=+23.0% | Sharpe=-0.32 | MDD=7.6% | âŒ LOSS\n",
            "   2024: AI=+0.0% vs BH=+9.4% | Sharpe=0.00 | MDD=0.0% | âŒ LOSS\n",
            "   2025: AI=+19.8% vs BH=+26.6% | Sharpe=1.04 | MDD=11.8% | âŒ LOSS\n",
            "\n",
            "   ðŸ“Š TCAP Summary:\n",
            "      Avg AI Return: +3.29%\n",
            "      Avg BH Return: +12.58%\n",
            "      Avg Sharpe:    0.10\n",
            "      Beat BH:       1/7 windows\n",
            "\n",
            "============================================================\n",
            "ðŸ”¹ Evaluating: TISCO\n",
            "============================================================\n",
            "   2019: AI=+18.2% vs BH=+34.7% | Sharpe=1.50 | MDD=7.0% | âŒ LOSS\n",
            "   2020: AI=+7.7% vs BH=-3.5% | Sharpe=0.34 | MDD=26.9% | âœ… WIN\n",
            "   2021: AI=+13.7% vs BH=+15.7% | Sharpe=0.77 | MDD=9.5% | âŒ LOSS\n",
            "   2022: AI=+9.6% vs BH=+8.6% | Sharpe=0.81 | MDD=8.4% | âœ… WIN\n",
            "   2023: AI=+10.5% vs BH=+10.9% | Sharpe=0.86 | MDD=6.2% | âŒ LOSS\n",
            "   2024: AI=+7.2% vs BH=+6.7% | Sharpe=0.55 | MDD=9.0% | âœ… WIN\n",
            "   2025: AI=+21.2% vs BH=+21.4% | Sharpe=1.80 | MDD=4.7% | âŒ LOSS\n",
            "\n",
            "   ðŸ“Š TISCO Summary:\n",
            "      Avg AI Return: +12.58%\n",
            "      Avg BH Return: +13.49%\n",
            "      Avg Sharpe:    0.95\n",
            "      Beat BH:       3/7 windows\n",
            "\n",
            "============================================================\n",
            "ðŸ”¹ Evaluating: TTB\n",
            "============================================================\n",
            "   2019: AI=-6.7% vs BH=-12.0% | Sharpe=-1.33 | MDD=10.1% | âœ… WIN\n",
            "   2020: AI=+0.0% vs BH=-35.0% | Sharpe=0.00 | MDD=0.0% | âœ… WIN\n",
            "   2021: AI=+0.0% vs BH=+44.1% | Sharpe=0.00 | MDD=0.0% | âŒ LOSS\n",
            "   2022: AI=-2.2% vs BH=+0.3% | Sharpe=-0.11 | MDD=23.7% | âŒ LOSS\n",
            "   2023: AI=+18.5% vs BH=+26.7% | Sharpe=1.29 | MDD=8.8% | âŒ LOSS\n",
            "   2024: AI=+10.3% vs BH=+19.6% | Sharpe=0.50 | MDD=15.2% | âŒ LOSS\n",
            "   2025: AI=+17.5% vs BH=+17.3% | Sharpe=0.91 | MDD=10.4% | âœ… WIN\n",
            "\n",
            "   ðŸ“Š TTB Summary:\n",
            "      Avg AI Return: +5.35%\n",
            "      Avg BH Return: +8.72%\n",
            "      Avg Sharpe:    0.18\n",
            "      Beat BH:       3/7 windows\n",
            "\n",
            "================================================================================\n",
            "ðŸ“Š OVERALL PERFORMANCE SUMMARY\n",
            "================================================================================\n",
            "\n",
            "ðŸ“… Performance by Test Year:\n",
            "--------------------------------------------------------------------------------\n",
            "           AI_Return  BH_Return  Sharpe    MDD  Win_Rate\n",
            "Test_Year                                               \n",
            "2019            0.18       0.18   -0.15  12.05      0.43\n",
            "2020           -6.62     -23.17   -0.20  21.83      0.86\n",
            "2021            2.45      22.11   -0.52   9.56      0.00\n",
            "2022            6.74      16.47    0.32  11.50      0.14\n",
            "2023           -0.50       5.45   -0.04  14.59      0.29\n",
            "2024           13.48      13.19    0.81   8.28      0.71\n",
            "2025           20.51      29.76    1.10  12.83      0.14\n",
            "\n",
            "ðŸ“ˆ Performance by Stock:\n",
            "--------------------------------------------------------------------------------\n",
            "       AI_Return  BH_Return  Sharpe    MDD  Win_Rate\n",
            "Stock                                               \n",
            "TISCO      12.58      13.49    0.95  10.27      0.43\n",
            "KTB         6.65      12.82   -0.38  15.38      0.29\n",
            "TTB         5.35       8.72    0.18   9.73      0.43\n",
            "KKP         4.04       8.53    0.22  18.61      0.43\n",
            "KBANK       3.44       6.28    0.22  14.72      0.57\n",
            "TCAP        3.29      12.58    0.10  12.48      0.14\n",
            "BBL         0.89       1.56    0.03   9.45      0.29\n",
            "\n",
            "================================================================================\n",
            "ðŸŽ¯ OVERALL STATISTICS\n",
            "================================================================================\n",
            "\n",
            "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
            "â”‚                        AI STRATEGY vs BUY-AND-HOLD                      â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚                            â”‚     AI Strategy    â”‚    Buy-and-Hold      â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ Average Return             â”‚       +5.18%     â”‚       +9.14%      â”‚\n",
            "â”‚ Median Return              â”‚       +1.25%     â”‚      +11.60%      â”‚\n",
            "â”‚ Std Dev Return             â”‚       13.60%     â”‚       20.95%      â”‚\n",
            "â”‚ Average Sharpe Ratio       â”‚        0.19       â”‚        0.50        â”‚\n",
            "â”‚ Average Max Drawdown       â”‚       12.95%     â”‚       21.07%      â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ Win Rate vs Benchmark      â”‚        36.7%     â”‚        -             â”‚\n",
            "â”‚ Total Test Windows         â”‚          49         â”‚        -             â”‚\n",
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\n",
            "   ðŸ† Best Return:  KKP (2025): +34.73%\n",
            "   ðŸ’€ Worst Return: KKP (2023): -29.06%\n",
            "   ðŸ“ˆ Best Sharpe:  TISCO (2025): 1.80\n",
            "\n",
            "ðŸ’¾ Detailed results saved to: Block8_Performance_Detailed.xlsx\n",
            "\n",
            "================================================================================\n",
            "âœ… BLOCK 8 COMPLETED: Evaluation with Sharpe, MDD & Benchmark Comparison\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# ðŸ† BLOCK 8: Evaluation & Prediction (UPGRADED)\n",
        "#    Features:\n",
        "#    - Star Rating System\n",
        "#    - ðŸ†• Performance Metrics: Sharpe Ratio, Max Drawdown, Calmar Ratio\n",
        "#    - ðŸ†• Benchmark Comparison vs Buy-and-Hold\n",
        "#    - ðŸ†• Rolling Window Evaluation\n",
        "# ============================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "import os\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "from stable_baselines3 import PPO\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ============================================================\n",
        "# 1. CONFIGURATION\n",
        "# ============================================================\n",
        "\n",
        "# [\n",
        "#     \"AAV\", \"AEONTS\", \"AOT\", \"BA\", \"BBL\", \"BCH\", \"BDMS\", \"BEM\", \"BH\", \"BTS\",\n",
        "#     \"CHG\", \"JMT\", \"KBANK\", \"KKP\", \"KTB\", \"KTC\", \"PR9\", \"PRM\", \"RCL\", \"SAWAD\",\n",
        "#     \"TCAP\", \"TISCO\", \"TTB\"\n",
        "# ]\n",
        "\n",
        "stock_symbols = [\"BBL\",\"KBANK\",\"KKP\",\"KTB\",\"TCAP\",\"TISCO\",\"TTB\"]\n",
        "\n",
        "INITIAL_BALANCE = 1_000_000\n",
        "COMMISSION = 0.00157\n",
        "RISK_FREE_RATE = 0.02  # 2% annual risk-free rate (Thai government bond ~2%)\n",
        "TRADING_DAYS_PER_YEAR = 245  # Thai market\n",
        "\n",
        "# Rolling Window Configuration\n",
        "ROLLING_WINDOWS = [\n",
        "    (2015, 2018, 2019),\n",
        "    (2016, 2019, 2020),\n",
        "    (2017, 2020, 2021),\n",
        "    (2018, 2021, 2022),\n",
        "    (2019, 2022, 2023),\n",
        "    (2020, 2023, 2024),\n",
        "    (2021, 2024, 2025),\n",
        "]\n",
        "\n",
        "# ============================================================\n",
        "# 2. LOAD DATA\n",
        "# ============================================================\n",
        "try:\n",
        "    df_rl_all = pd.read_excel(\"Final_RL_Input_Ready.xlsx\")\n",
        "    df_rl_all['Date'] = pd.to_datetime(df_rl_all['Date'])\n",
        "    df_rl_all['Year'] = df_rl_all['Date'].dt.year\n",
        "except:\n",
        "    raise RuntimeError(\"âŒ Missing Data: Final_RL_Input_Ready.xlsx\")\n",
        "\n",
        "# ============================================================\n",
        "# 3. TRADING ENVIRONMENT\n",
        "# ============================================================\n",
        "class StockTradingEnv(gym.Env):\n",
        "    \"\"\"Trading environment matching Block 7 V2\"\"\"\n",
        "    def __init__(self, df):\n",
        "        super().__init__()\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.balance = INITIAL_BALANCE\n",
        "        self.shares_held = 0\n",
        "        self.current_step = 0\n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(11,), dtype=np.float32)\n",
        "        self.action_space = spaces.Discrete(3)\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        self.current_step = 0\n",
        "        self.balance = INITIAL_BALANCE\n",
        "        self.shares_held = 0\n",
        "        return self._next_observation(), {}\n",
        "\n",
        "    def _next_observation(self):\n",
        "        if self.current_step >= len(self.df):\n",
        "            self.current_step = len(self.df) - 1\n",
        "        obs = self.df.iloc[self.current_step]\n",
        "        return np.array([\n",
        "            obs.get('Macro_Signal', 0),\n",
        "            obs.get('DL_Signal', 0.5),\n",
        "            obs.get('Tech_Signal', 0),\n",
        "            obs.get('ADX', 25) / 100.0,\n",
        "            self.balance / 1_000_000.0,\n",
        "            (self.shares_held * obs['Close']) / 1_000_000.0,\n",
        "            obs.get('RSI', 50) / 100.0,\n",
        "            obs.get('MACD', 0) / 10.0,\n",
        "            0.5,  # Volatility placeholder\n",
        "            0.0,  # Consecutive losses placeholder\n",
        "            0.0   # Pause counter placeholder\n",
        "        ], dtype=np.float32)\n",
        "\n",
        "    def step(self, action):\n",
        "        self.current_step += 1\n",
        "        done = self.current_step >= len(self.df) - 1\n",
        "        return self._next_observation(), 0, done, False, {}\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 4. PERFORMANCE METRICS CALCULATOR\n",
        "# ============================================================\n",
        "class PerformanceMetrics:\n",
        "    \"\"\"\n",
        "    Calculate comprehensive trading performance metrics\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_returns(equity_curve):\n",
        "        \"\"\"Calculate daily returns from equity curve\"\"\"\n",
        "        equity = np.array(equity_curve)\n",
        "        returns = np.diff(equity) / equity[:-1]\n",
        "        return returns\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_sharpe_ratio(returns, risk_free_rate=RISK_FREE_RATE,\n",
        "                                trading_days=TRADING_DAYS_PER_YEAR):\n",
        "        \"\"\"\n",
        "        Calculate annualized Sharpe Ratio\n",
        "\n",
        "        Formula: Sharpe = (Mean Return - Risk Free Rate) / Std Dev Ã— âˆš(Trading Days)\n",
        "        \"\"\"\n",
        "        if len(returns) < 2:\n",
        "            return 0.0\n",
        "\n",
        "        # Daily risk-free rate\n",
        "        daily_rf = risk_free_rate / trading_days\n",
        "\n",
        "        # Excess returns\n",
        "        excess_returns = returns - daily_rf\n",
        "\n",
        "        # Sharpe Ratio\n",
        "        if np.std(excess_returns) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        sharpe = np.mean(excess_returns) / np.std(excess_returns)\n",
        "\n",
        "        # Annualize\n",
        "        sharpe_annualized = sharpe * np.sqrt(trading_days)\n",
        "\n",
        "        return sharpe_annualized\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_sortino_ratio(returns, risk_free_rate=RISK_FREE_RATE,\n",
        "                                 trading_days=TRADING_DAYS_PER_YEAR):\n",
        "        \"\"\"\n",
        "        Calculate annualized Sortino Ratio (downside risk only)\n",
        "\n",
        "        Formula: Sortino = (Mean Return - Risk Free Rate) / Downside Std Dev Ã— âˆš(Trading Days)\n",
        "        \"\"\"\n",
        "        if len(returns) < 2:\n",
        "            return 0.0\n",
        "\n",
        "        daily_rf = risk_free_rate / trading_days\n",
        "        excess_returns = returns - daily_rf\n",
        "\n",
        "        # Downside returns only\n",
        "        downside_returns = excess_returns[excess_returns < 0]\n",
        "\n",
        "        if len(downside_returns) == 0 or np.std(downside_returns) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        sortino = np.mean(excess_returns) / np.std(downside_returns)\n",
        "        sortino_annualized = sortino * np.sqrt(trading_days)\n",
        "\n",
        "        return sortino_annualized\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_max_drawdown(equity_curve):\n",
        "        \"\"\"\n",
        "        Calculate Maximum Drawdown (MDD)\n",
        "\n",
        "        Formula: MDD = (Peak - Trough) / Peak\n",
        "        \"\"\"\n",
        "        equity = np.array(equity_curve)\n",
        "        peak = equity[0]\n",
        "        max_dd = 0.0\n",
        "\n",
        "        for value in equity:\n",
        "            if value > peak:\n",
        "                peak = value\n",
        "            drawdown = (peak - value) / peak\n",
        "            if drawdown > max_dd:\n",
        "                max_dd = drawdown\n",
        "\n",
        "        return max_dd\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_calmar_ratio(total_return, max_drawdown, years=1):\n",
        "        \"\"\"\n",
        "        Calculate Calmar Ratio\n",
        "\n",
        "        Formula: Calmar = Annualized Return / Max Drawdown\n",
        "        \"\"\"\n",
        "        if max_drawdown == 0:\n",
        "            return 0.0\n",
        "\n",
        "        annualized_return = total_return / years if years > 0 else total_return\n",
        "        calmar = annualized_return / max_drawdown\n",
        "\n",
        "        return calmar\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_win_rate(trades):\n",
        "        \"\"\"Calculate win rate from list of trade PnLs\"\"\"\n",
        "        if len(trades) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        wins = sum(1 for t in trades if t > 0)\n",
        "        return wins / len(trades)\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_profit_factor(trades):\n",
        "        \"\"\"\n",
        "        Calculate Profit Factor\n",
        "\n",
        "        Formula: Profit Factor = Sum(Winning Trades) / |Sum(Losing Trades)|\n",
        "        \"\"\"\n",
        "        if len(trades) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        gross_profit = sum(t for t in trades if t > 0)\n",
        "        gross_loss = abs(sum(t for t in trades if t < 0))\n",
        "\n",
        "        if gross_loss == 0:\n",
        "            return float('inf') if gross_profit > 0 else 0.0\n",
        "\n",
        "        return gross_profit / gross_loss\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_all_metrics(equity_curve, trade_pnls, years=1):\n",
        "        \"\"\"Calculate all metrics at once\"\"\"\n",
        "        returns = PerformanceMetrics.calculate_returns(equity_curve)\n",
        "\n",
        "        total_return = (equity_curve[-1] - equity_curve[0]) / equity_curve[0]\n",
        "        max_dd = PerformanceMetrics.calculate_max_drawdown(equity_curve)\n",
        "\n",
        "        return {\n",
        "            'Total_Return': total_return,\n",
        "            'Total_Return_Pct': total_return * 100,\n",
        "            'Annualized_Return': (total_return / years) * 100 if years > 0 else total_return * 100,\n",
        "            'Sharpe_Ratio': PerformanceMetrics.calculate_sharpe_ratio(returns),\n",
        "            'Sortino_Ratio': PerformanceMetrics.calculate_sortino_ratio(returns),\n",
        "            'Max_Drawdown': max_dd,\n",
        "            'Max_Drawdown_Pct': max_dd * 100,\n",
        "            'Calmar_Ratio': PerformanceMetrics.calculate_calmar_ratio(total_return, max_dd, years),\n",
        "            'Win_Rate': PerformanceMetrics.calculate_win_rate(trade_pnls),\n",
        "            'Win_Rate_Pct': PerformanceMetrics.calculate_win_rate(trade_pnls) * 100,\n",
        "            'Profit_Factor': PerformanceMetrics.calculate_profit_factor(trade_pnls),\n",
        "            'Total_Trades': len(trade_pnls),\n",
        "            'Final_Value': equity_curve[-1]\n",
        "        }\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 5. BACKTEST WITH DETAILED TRACKING\n",
        "# ============================================================\n",
        "def backtest_with_metrics(df_test, model_path):\n",
        "    \"\"\"\n",
        "    Backtest with detailed equity tracking for metrics calculation\n",
        "\n",
        "    Returns:\n",
        "        dict: All performance metrics + equity curve\n",
        "    \"\"\"\n",
        "    env = StockTradingEnv(df_test)\n",
        "    model = PPO.load(model_path)\n",
        "    prices = df_test['Close'].values\n",
        "    dates = df_test['Date'].values\n",
        "\n",
        "    cash = INITIAL_BALANCE\n",
        "    shares = 0\n",
        "    avg_cost = 0.0\n",
        "    highest_price = 0.0\n",
        "    cooldown = 0\n",
        "    consecutive_losses = 0\n",
        "    loss_pause_counter = 0\n",
        "\n",
        "    # Tracking\n",
        "    equity_curve = [INITIAL_BALANCE]\n",
        "    trade_pnls = []\n",
        "    actions_taken = []\n",
        "\n",
        "    obs, _ = env.reset()\n",
        "\n",
        "    for i in range(len(prices) - 1):\n",
        "        action, _ = model.predict(obs, deterministic=True)\n",
        "        curr_price = prices[i]\n",
        "\n",
        "        # Loss Pause Check\n",
        "        if loss_pause_counter > 0:\n",
        "            action = 0\n",
        "            loss_pause_counter -= 1\n",
        "            if loss_pause_counter == 0:\n",
        "                consecutive_losses = 0\n",
        "\n",
        "        # Risk Check\n",
        "        force_sell = False\n",
        "        reason = \"\"\n",
        "\n",
        "        if shares > 0:\n",
        "            if curr_price > highest_price:\n",
        "                highest_price = curr_price\n",
        "            pnl_pct = (curr_price - avg_cost) / avg_cost if avg_cost > 0 else 0\n",
        "\n",
        "            if pnl_pct <= -0.06:\n",
        "                force_sell = True\n",
        "                reason = \"SL\"\n",
        "            if pnl_pct > 0.10:\n",
        "                if (highest_price - curr_price) / highest_price > 0.04:\n",
        "                    force_sell = True\n",
        "                    reason = \"TRAIL\"\n",
        "\n",
        "        if force_sell:\n",
        "            action = 2\n",
        "\n",
        "        # Cooldown Check\n",
        "        if cooldown > 0:\n",
        "            if action == 1:\n",
        "                action = 0\n",
        "            cooldown -= 1\n",
        "\n",
        "        # Execute Action\n",
        "        if action == 1 and cash > curr_price and loss_pause_counter == 0:\n",
        "            row = df_test.iloc[i]\n",
        "            can_buy = False\n",
        "\n",
        "            if (row.get('ADX', 0) > 25 and row.get('RSI', 50) < 75) or row.get('RSI', 50) < 45:\n",
        "                can_buy = True\n",
        "\n",
        "            if can_buy:\n",
        "                # Volatility-based sizing (simplified)\n",
        "                position_pct = 0.5\n",
        "                budget = cash * position_pct\n",
        "                buy_amt = int(budget // (curr_price * (1 + COMMISSION)))\n",
        "\n",
        "                if buy_amt > 0:\n",
        "                    cost = buy_amt * curr_price * (1 + COMMISSION)\n",
        "                    total_shares = shares + buy_amt\n",
        "                    avg_cost = ((shares * avg_cost) + cost) / total_shares if total_shares > 0 else curr_price\n",
        "                    cash -= cost\n",
        "                    shares += buy_amt\n",
        "                    highest_price = curr_price\n",
        "                    actions_taken.append(('BUY', i, curr_price, buy_amt))\n",
        "\n",
        "        elif action == 2 and shares > 0:\n",
        "            revenue = shares * curr_price * (1 - COMMISSION)\n",
        "            pnl = revenue - (shares * avg_cost)\n",
        "            pnl_pct = pnl / (shares * avg_cost) if avg_cost > 0 else 0\n",
        "\n",
        "            trade_pnls.append(pnl)\n",
        "            actions_taken.append(('SELL', i, curr_price, shares, pnl))\n",
        "\n",
        "            cash += revenue\n",
        "            shares = 0\n",
        "            cooldown = 2\n",
        "\n",
        "            # Track consecutive losses\n",
        "            if pnl < 0:\n",
        "                consecutive_losses += 1\n",
        "                if consecutive_losses >= 5:\n",
        "                    loss_pause_counter = 3\n",
        "                    consecutive_losses = 0\n",
        "            else:\n",
        "                consecutive_losses = 0\n",
        "\n",
        "            avg_cost = 0\n",
        "            highest_price = 0\n",
        "\n",
        "        # Update equity curve\n",
        "        current_equity = cash + (shares * prices[i + 1])\n",
        "        equity_curve.append(current_equity)\n",
        "\n",
        "        obs, _, done, _, _ = env.step(action)\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    # Final value\n",
        "    final_value = cash + (shares * prices[-1])\n",
        "    if len(equity_curve) < len(prices):\n",
        "        equity_curve.append(final_value)\n",
        "\n",
        "    # Calculate years\n",
        "    days = len(df_test)\n",
        "    years = days / TRADING_DAYS_PER_YEAR\n",
        "\n",
        "    # Calculate all metrics\n",
        "    metrics = PerformanceMetrics.calculate_all_metrics(equity_curve, trade_pnls, years)\n",
        "    metrics['equity_curve'] = equity_curve\n",
        "    metrics['trade_pnls'] = trade_pnls\n",
        "    metrics['actions'] = actions_taken\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 6. BUY-AND-HOLD BENCHMARK\n",
        "# ============================================================\n",
        "def calculate_buy_and_hold(df_test):\n",
        "    \"\"\"\n",
        "    Calculate Buy-and-Hold benchmark performance\n",
        "\n",
        "    Strategy: Buy at first day, hold until last day\n",
        "    \"\"\"\n",
        "    prices = df_test['Close'].values\n",
        "\n",
        "    # Buy at first price\n",
        "    first_price = prices[0]\n",
        "    shares = int(INITIAL_BALANCE // (first_price * (1 + COMMISSION)))\n",
        "    cost = shares * first_price * (1 + COMMISSION)\n",
        "    remaining_cash = INITIAL_BALANCE - cost\n",
        "\n",
        "    # Build equity curve\n",
        "    equity_curve = []\n",
        "    for price in prices:\n",
        "        equity = remaining_cash + (shares * price)\n",
        "        equity_curve.append(equity)\n",
        "\n",
        "    # Final value (sell at last price)\n",
        "    final_value = remaining_cash + (shares * prices[-1] * (1 - COMMISSION))\n",
        "\n",
        "    # Calculate metrics\n",
        "    days = len(df_test)\n",
        "    years = days / TRADING_DAYS_PER_YEAR\n",
        "\n",
        "    # Simple trade PnL (one buy, one sell)\n",
        "    trade_pnl = final_value - INITIAL_BALANCE\n",
        "\n",
        "    metrics = PerformanceMetrics.calculate_all_metrics(equity_curve, [trade_pnl], years)\n",
        "    metrics['equity_curve'] = equity_curve\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 7. STAR RATING LOGIC\n",
        "# ============================================================\n",
        "def get_star_rating(action, tech_score, sharpe_ratio=0):\n",
        "    \"\"\"Enhanced star rating with Sharpe consideration\"\"\"\n",
        "    base_rating = 3\n",
        "\n",
        "    if action == 1:  # BUY\n",
        "        if tech_score > 0.2:\n",
        "            base_rating = 5  # Strong Buy\n",
        "        else:\n",
        "            base_rating = 4  # Buy\n",
        "    elif action == 0:  # HOLD\n",
        "        base_rating = 3\n",
        "    elif action == 2:  # SELL\n",
        "        if tech_score < -0.2:\n",
        "            base_rating = 1  # Strong Sell\n",
        "        else:\n",
        "            base_rating = 2  # Sell\n",
        "\n",
        "    # Adjust based on model performance (Sharpe)\n",
        "    if sharpe_ratio > 1.5:\n",
        "        base_rating = min(5, base_rating + 1)\n",
        "    elif sharpe_ratio < 0:\n",
        "        base_rating = max(1, base_rating - 1)\n",
        "\n",
        "    return \"â­\" * base_rating\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 8. MAIN EVALUATION\n",
        "# ============================================================\n",
        "print(\"=\" * 80)\n",
        "print(\"ðŸ† BLOCK 8: Evaluation & Prediction (UPGRADED)\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\"\"\n",
        "ðŸ“Š Performance Metrics:\n",
        "   - Total Return (%)\n",
        "   - Annualized Return (%)\n",
        "   - Sharpe Ratio\n",
        "   - Sortino Ratio\n",
        "   - Maximum Drawdown (%)\n",
        "   - Calmar Ratio\n",
        "   - Win Rate (%)\n",
        "   - Profit Factor\n",
        "\n",
        "ðŸ“ˆ Benchmark: Buy-and-Hold Strategy\n",
        "\"\"\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Storage\n",
        "all_results = []\n",
        "all_comparisons = []\n",
        "forecasts = []\n",
        "\n",
        "# Process each stock\n",
        "for ticker in stock_symbols:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"ðŸ”¹ Evaluating: {ticker}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    try:\n",
        "        stock_df = df_rl_all[df_rl_all['Stock'] == ticker].copy()\n",
        "\n",
        "        if len(stock_df) < 100:\n",
        "            print(f\"âš ï¸ Skipped (insufficient data: {len(stock_df)} rows)\")\n",
        "            continue\n",
        "\n",
        "        stock_results = []\n",
        "\n",
        "        # Evaluate each rolling window\n",
        "        for train_start, train_end, test_year in ROLLING_WINDOWS:\n",
        "            df_test = stock_df[stock_df['Year'] == test_year].copy()\n",
        "\n",
        "            if len(df_test) < 10:\n",
        "                continue\n",
        "\n",
        "            # Model path (from Block 7 rolling window)\n",
        "            model_path = f\"trained_models/ppo_{ticker}_train{train_start}_{train_end}_test{test_year}.zip\"\n",
        "\n",
        "            # Fallback to old model path\n",
        "            if not os.path.exists(model_path):\n",
        "                model_path = f\"trained_models/ppo_{ticker}.zip\"\n",
        "\n",
        "            if not os.path.exists(model_path):\n",
        "                continue\n",
        "\n",
        "            # Run backtest\n",
        "            ai_metrics = backtest_with_metrics(df_test, model_path)\n",
        "            bh_metrics = calculate_buy_and_hold(df_test)\n",
        "\n",
        "            # Comparison\n",
        "            result = {\n",
        "                'Stock': ticker,\n",
        "                'Test_Year': test_year,\n",
        "                'Train_Period': f\"{train_start}-{train_end}\",\n",
        "\n",
        "                # AI Strategy Metrics\n",
        "                'AI_Return_%': round(ai_metrics['Total_Return_Pct'], 2),\n",
        "                'AI_Sharpe': round(ai_metrics['Sharpe_Ratio'], 2),\n",
        "                'AI_Sortino': round(ai_metrics['Sortino_Ratio'], 2),\n",
        "                'AI_MDD_%': round(ai_metrics['Max_Drawdown_Pct'], 2),\n",
        "                'AI_Calmar': round(ai_metrics['Calmar_Ratio'], 2),\n",
        "                'AI_WinRate_%': round(ai_metrics['Win_Rate_Pct'], 1),\n",
        "                'AI_ProfitFactor': round(ai_metrics['Profit_Factor'], 2),\n",
        "                'AI_Trades': ai_metrics['Total_Trades'],\n",
        "\n",
        "                # Benchmark Metrics\n",
        "                'BH_Return_%': round(bh_metrics['Total_Return_Pct'], 2),\n",
        "                'BH_Sharpe': round(bh_metrics['Sharpe_Ratio'], 2),\n",
        "                'BH_MDD_%': round(bh_metrics['Max_Drawdown_Pct'], 2),\n",
        "\n",
        "                # Comparison\n",
        "                'Return_Diff_%': round(ai_metrics['Total_Return_Pct'] - bh_metrics['Total_Return_Pct'], 2),\n",
        "                'Sharpe_Diff': round(ai_metrics['Sharpe_Ratio'] - bh_metrics['Sharpe_Ratio'], 2),\n",
        "                'MDD_Diff_%': round(bh_metrics['Max_Drawdown_Pct'] - ai_metrics['Max_Drawdown_Pct'], 2),\n",
        "                'Beat_BH': ai_metrics['Total_Return_Pct'] > bh_metrics['Total_Return_Pct']\n",
        "            }\n",
        "\n",
        "            stock_results.append(result)\n",
        "            all_results.append(result)\n",
        "\n",
        "            # Print summary\n",
        "            status = \"âœ… WIN\" if result['Beat_BH'] else \"âŒ LOSS\"\n",
        "            print(f\"   {test_year}: AI={result['AI_Return_%']:+.1f}% vs BH={result['BH_Return_%']:+.1f}% \"\n",
        "                  f\"| Sharpe={result['AI_Sharpe']:.2f} | MDD={result['AI_MDD_%']:.1f}% | {status}\")\n",
        "\n",
        "        # Stock Summary\n",
        "        if stock_results:\n",
        "            avg_ai_return = np.mean([r['AI_Return_%'] for r in stock_results])\n",
        "            avg_bh_return = np.mean([r['BH_Return_%'] for r in stock_results])\n",
        "            avg_sharpe = np.mean([r['AI_Sharpe'] for r in stock_results])\n",
        "            win_count = sum(1 for r in stock_results if r['Beat_BH'])\n",
        "\n",
        "            print(f\"\\n   ðŸ“Š {ticker} Summary:\")\n",
        "            print(f\"      Avg AI Return: {avg_ai_return:+.2f}%\")\n",
        "            print(f\"      Avg BH Return: {avg_bh_return:+.2f}%\")\n",
        "            print(f\"      Avg Sharpe:    {avg_sharpe:.2f}\")\n",
        "            print(f\"      Beat BH:       {win_count}/{len(stock_results)} windows\")\n",
        "\n",
        "            # Generate forecast for latest data\n",
        "            latest_df = stock_df[stock_df['Year'] == stock_df['Year'].max()].copy()\n",
        "            if len(latest_df) > 0:\n",
        "                latest_model = f\"trained_models/ppo_{ticker}.zip\"\n",
        "                if os.path.exists(latest_model):\n",
        "                    env = StockTradingEnv(latest_df)\n",
        "                    obs, _ = env.reset()\n",
        "                    env.current_step = len(latest_df) - 1\n",
        "                    obs = env._next_observation()\n",
        "\n",
        "                    model = PPO.load(latest_model)\n",
        "                    action, _ = model.predict(obs, deterministic=True)\n",
        "\n",
        "                    last_close = latest_df.iloc[-1]['Close']\n",
        "                    tech_score = latest_df.iloc[-1].get('Tech_Signal', 0)\n",
        "                    rating = get_star_rating(action, tech_score, avg_sharpe)\n",
        "\n",
        "                    act_str = \"BUY\" if action == 1 else \"SELL\" if action == 2 else \"HOLD\"\n",
        "                    forecasts.append({\n",
        "                        'Stock': ticker,\n",
        "                        'Last_Price': round(last_close, 2),\n",
        "                        'AI_Action': act_str,\n",
        "                        'Tech_Score': round(tech_score, 2),\n",
        "                        'Avg_Sharpe': round(avg_sharpe, 2),\n",
        "                        'Rating': rating\n",
        "                    })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error: {e}\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 9. OVERALL SUMMARY\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"ðŸ“Š OVERALL PERFORMANCE SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "if all_results:\n",
        "    df_results = pd.DataFrame(all_results)\n",
        "\n",
        "    # Summary by Year\n",
        "    print(\"\\nðŸ“… Performance by Test Year:\")\n",
        "    print(\"-\" * 80)\n",
        "    year_summary = df_results.groupby('Test_Year').agg({\n",
        "        'AI_Return_%': 'mean',\n",
        "        'BH_Return_%': 'mean',\n",
        "        'AI_Sharpe': 'mean',\n",
        "        'AI_MDD_%': 'mean',\n",
        "        'Beat_BH': 'mean'\n",
        "    }).round(2)\n",
        "    year_summary.columns = ['AI_Return', 'BH_Return', 'Sharpe', 'MDD', 'Win_Rate']\n",
        "    print(year_summary.to_string())\n",
        "\n",
        "    # Summary by Stock\n",
        "    print(\"\\nðŸ“ˆ Performance by Stock:\")\n",
        "    print(\"-\" * 80)\n",
        "    stock_summary = df_results.groupby('Stock').agg({\n",
        "        'AI_Return_%': 'mean',\n",
        "        'BH_Return_%': 'mean',\n",
        "        'AI_Sharpe': 'mean',\n",
        "        'AI_MDD_%': 'mean',\n",
        "        'Beat_BH': 'mean'\n",
        "    }).round(2).sort_values('AI_Return_%', ascending=False)\n",
        "    stock_summary.columns = ['AI_Return', 'BH_Return', 'Sharpe', 'MDD', 'Win_Rate']\n",
        "    print(stock_summary.to_string())\n",
        "\n",
        "    # Overall Statistics\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"ðŸŽ¯ OVERALL STATISTICS\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    print(f\"\"\"\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚                        AI STRATEGY vs BUY-AND-HOLD                      â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚                            â”‚     AI Strategy    â”‚    Buy-and-Hold      â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚ Average Return             â”‚  {df_results['AI_Return_%'].mean():>+10.2f}%     â”‚  {df_results['BH_Return_%'].mean():>+10.2f}%      â”‚\n",
        "â”‚ Median Return              â”‚  {df_results['AI_Return_%'].median():>+10.2f}%     â”‚  {df_results['BH_Return_%'].median():>+10.2f}%      â”‚\n",
        "â”‚ Std Dev Return             â”‚  {df_results['AI_Return_%'].std():>10.2f}%     â”‚  {df_results['BH_Return_%'].std():>10.2f}%      â”‚\n",
        "â”‚ Average Sharpe Ratio       â”‚  {df_results['AI_Sharpe'].mean():>10.2f}       â”‚  {df_results['BH_Sharpe'].mean():>10.2f}        â”‚\n",
        "â”‚ Average Max Drawdown       â”‚  {df_results['AI_MDD_%'].mean():>10.2f}%     â”‚  {df_results['BH_MDD_%'].mean():>10.2f}%      â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚ Win Rate vs Benchmark      â”‚  {df_results['Beat_BH'].mean()*100:>10.1f}%     â”‚        -             â”‚\n",
        "â”‚ Total Test Windows         â”‚  {len(df_results):>10d}         â”‚        -             â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "\"\"\")\n",
        "\n",
        "    # Best and Worst Performers\n",
        "    best = df_results.loc[df_results['AI_Return_%'].idxmax()]\n",
        "    worst = df_results.loc[df_results['AI_Return_%'].idxmin()]\n",
        "    best_sharpe = df_results.loc[df_results['AI_Sharpe'].idxmax()]\n",
        "\n",
        "    print(f\"   ðŸ† Best Return:  {best['Stock']} ({best['Test_Year']}): {best['AI_Return_%']:+.2f}%\")\n",
        "    print(f\"   ðŸ’€ Worst Return: {worst['Stock']} ({worst['Test_Year']}): {worst['AI_Return_%']:+.2f}%\")\n",
        "    print(f\"   ðŸ“ˆ Best Sharpe:  {best_sharpe['Stock']} ({best_sharpe['Test_Year']}): {best_sharpe['AI_Sharpe']:.2f}\")\n",
        "\n",
        "    # Export detailed results\n",
        "    outfile_detailed = \"Block8_Performance_Detailed.xlsx\"\n",
        "    df_results.to_excel(outfile_detailed, index=False)\n",
        "    print(f\"\\nðŸ’¾ Detailed results saved to: {outfile_detailed}\")\n",
        "\n",
        "# ============================================================\n",
        "# 10. FORECAST OUTPUT\n",
        "# ============================================================\n",
        "if forecasts:\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"ðŸ”® AI FORECAST FOR TOMORROW\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    df_forecast = pd.DataFrame(forecasts)\n",
        "\n",
        "    # Sort by rating (descending)\n",
        "    df_forecast['Rating_Num'] = df_forecast['Rating'].apply(len)\n",
        "    df_forecast = df_forecast.sort_values('Rating_Num', ascending=False)\n",
        "\n",
        "    print(f\"\\n{'Stock':<10} {'Price':<10} {'Action':<8} {'Tech':<8} {'Sharpe':<8} {'Rating':<12}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    for _, row in df_forecast.iterrows():\n",
        "        print(f\"{row['Stock']:<10} {row['Last_Price']:<10.2f} {row['AI_Action']:<8} \"\n",
        "              f\"{row['Tech_Score']:<8.2f} {row['Avg_Sharpe']:<8.2f} {row['Rating']:<12}\")\n",
        "\n",
        "    # Export\n",
        "    outfile_forecast = \"Block8_AI_Forecast.xlsx\"\n",
        "    df_forecast.drop(columns=['Rating_Num']).to_excel(outfile_forecast, index=False)\n",
        "    print(f\"\\nðŸ’¾ Forecast saved to: {outfile_forecast}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"âœ… BLOCK 8 COMPLETED: Evaluation with Sharpe, MDD & Benchmark Comparison\")\n",
        "print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8H5OC-DGuOlN"
      },
      "source": [
        "1) Change price frequentcy from day to hour\n",
        "2) Edit Technical Block âœ…\n",
        "3) optimize DL signal using validation set à¸›à¸£à¸±à¸š Block 5.5 (DL Signal)  à¹ƒà¸«à¹‰à¹à¸¡à¹ˆà¸™à¸¢à¸³à¸‚à¸¶à¹‰à¸™ âœ…\n",
        "4) à¹€à¸žà¸´à¹ˆà¸¡ Feature à¹ƒà¸«à¸¡à¹ˆà¹† à¹ƒà¸™ Block 6 (à¹€à¸Šà¹ˆà¸™ Volume Profile, Bid/Offer) => à¸•à¹‰à¸­à¸‡à¸‚à¸­à¸ˆà¸²à¸ à¸žà¸µà¹ˆ AIQ\n",
        "5) à¸ˆà¸¹à¸™ Hyperparameter à¹ƒà¸™ Block 7\n",
        "6) à¹à¸à¹‰à¹„à¸Ÿà¸¥à¹Œ Macro.xlsx à¹€à¸žà¸·à¹ˆà¸­à¹€à¸žà¸´à¹ˆà¸¡ Data à¸‚à¸­à¸‡ 2025 à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHMk7GPeACl-"
      },
      "source": [
        "## Excluded Part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lECT28HvgcpH"
      },
      "outputs": [],
      "source": [
        "# # ============================================================\n",
        "# # ðŸ¤– BLOCK 7: Train PPO (Hierarchy: Macro First, DL Fallback)\n",
        "# #    Concept: Trust Macro if aligned with Price Trend.\n",
        "# #             If Macro conflicts with Price, Trust DL.\n",
        "# # ============================================================\n",
        "# import os\n",
        "# import gymnasium as gym\n",
        "# from gymnasium import spaces\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# from stable_baselines3 import PPO\n",
        "# from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "# import warnings\n",
        "\n",
        "# warnings.filterwarnings(\"ignore\")\n",
        "# os.makedirs(\"trained_models\", exist_ok=True)\n",
        "\n",
        "# # 1. à¸£à¸²à¸¢à¸Šà¸·à¹ˆà¸­à¸«à¸¸à¹‰à¸™\n",
        "# target_stocks = [\n",
        "#     \"AAV\", \"AEONTS\", \"AOT\", \"BA\", \"BBL\", \"BCH\", \"BDMS\", \"BEM\", \"BH\", \"BTS\",\n",
        "#     \"CHG\", \"JMT\", \"KBANK\", \"KKP\", \"KTB\", \"KTC\", \"PR9\", \"PRM\", \"RCL\", \"SAWAD\",\n",
        "#     \"TCAP\", \"TISCO\", \"TTB\"\n",
        "# ]\n",
        "\n",
        "# # 2. à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥\n",
        "# try:\n",
        "#     df_rl_all = pd.read_excel(\"Final_RL_Input_Ready.xlsx\")\n",
        "#     df_rl_all['Date'] = pd.to_datetime(df_rl_all['Date'])\n",
        "#     print(f\"âœ… Loaded Training Data: {len(df_rl_all)} rows\")\n",
        "# except FileNotFoundError:\n",
        "#     raise RuntimeError(\"âŒ à¹„à¸¡à¹ˆà¹€à¸ˆà¸­à¹„à¸Ÿà¸¥à¹Œ Final_RL_Input_Ready.xlsx\")\n",
        "\n",
        "# # --- Environment Definition ---\n",
        "# class StockTradingEnv(gym.Env):\n",
        "#     def __init__(self, df, initial_balance=1_000_000):\n",
        "#         super(StockTradingEnv, self).__init__()\n",
        "#         self.df = df.reset_index(drop=True)\n",
        "#         self.initial_balance = initial_balance\n",
        "#         self.commission = 0.0 # Train 0%\n",
        "\n",
        "#         self.action_space = spaces.Discrete(3) # 0=Hold, 1=Buy, 2=Sell\n",
        "#         self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(6,), dtype=np.float32)\n",
        "\n",
        "#         self.reset()\n",
        "\n",
        "#     def reset(self, seed=None, options=None):\n",
        "#         super().reset(seed=seed)\n",
        "#         self.current_step = 0\n",
        "\n",
        "#         # MIXED INIT (à¹€à¸£à¸´à¹ˆà¸¡à¹€à¸‡à¸´à¸™à¸ªà¸” 50% / à¹€à¸£à¸´à¹ˆà¸¡à¸«à¸¸à¹‰à¸™ 50%)\n",
        "#         if np.random.rand() < 0.5:\n",
        "#             self.balance = self.initial_balance\n",
        "#             self.shares_held = 0\n",
        "#             self.avg_cost = 0.0\n",
        "#         else:\n",
        "#             start_price = self.df.iloc[0]['Close']\n",
        "#             invest_pct = np.random.uniform(0.2, 0.8)\n",
        "#             cash_invested = self.initial_balance * invest_pct\n",
        "#             self.shares_held = int(cash_invested // start_price)\n",
        "#             self.balance = self.initial_balance - (self.shares_held * start_price)\n",
        "#             self.avg_cost = start_price\n",
        "\n",
        "#         self.net_worth = self.initial_balance\n",
        "#         self.prev_net_worth = self.initial_balance\n",
        "#         self.days_since_trade = 0\n",
        "\n",
        "#         return self._next_observation(), {}\n",
        "\n",
        "#     def _next_observation(self):\n",
        "#         obs = self.df.iloc[self.current_step]\n",
        "#         # Manual Scaling\n",
        "#         return np.array([\n",
        "#             obs.get('Macro_Signal', 0),\n",
        "#             obs.get('DL_Signal', 0.5),\n",
        "#             self.balance / 1_000_000.0,\n",
        "#             (self.shares_held * obs['Close']) / 1_000_000.0,\n",
        "#             obs.get('RSI', 50) / 100.0,\n",
        "#             obs.get('MACD', 0) / 10.0\n",
        "#         ], dtype=np.float32)\n",
        "\n",
        "#     def step(self, action):\n",
        "#         current_price = self.df.iloc[self.current_step]['Close']\n",
        "\n",
        "#         # à¸”à¸¶à¸‡à¸„à¹ˆà¸²à¸•à¹ˆà¸²à¸‡à¹† à¸¡à¸²à¹€à¸Šà¹‡à¸„ Logic\n",
        "#         obs = self.df.iloc[self.current_step]\n",
        "#         macro_val = obs.get('Macro_Signal', 0) # -1 à¸–à¸¶à¸‡ 1\n",
        "#         dl_val = obs.get('DL_Signal', 0.5)     # 0 à¸–à¸¶à¸‡ 1\n",
        "#         macd_val = obs.get('MACD', 0)          # à¹ƒà¸Šà¹‰ MACD à¹€à¸›à¹‡à¸™à¸•à¸±à¸§à¹à¸—à¸™ Trend à¸à¸£à¸²à¸Ÿà¸£à¸²à¸„à¸²\n",
        "\n",
        "#         # --- ðŸ”¥ CORE LOGIC: MACRO PROTAGONIST w/ REALITY CHECK ---\n",
        "\n",
        "#         # 1. à¸à¸³à¸«à¸™à¸”à¸¡à¸¸à¸¡à¸¡à¸­à¸‡à¸‚à¸­à¸‡ Macro\n",
        "#         macro_view = \"NEUTRAL\"\n",
        "#         if macro_val > 0.1: macro_view = \"BULL\"\n",
        "#         elif macro_val < -0.1: macro_view = \"BEAR\"\n",
        "\n",
        "#         # 2. à¸à¸³à¸«à¸™à¸”à¸¡à¸¸à¸¡à¸¡à¸­à¸‡à¸‚à¸­à¸‡à¸à¸£à¸²à¸Ÿà¸ˆà¸£à¸´à¸‡ (Price Trend)\n",
        "#         # MACD > 0 à¸„à¸·à¸­à¹€à¸—à¸£à¸™à¸”à¹Œà¸‚à¸²à¸‚à¸¶à¹‰à¸™, MACD < 0 à¸„à¸·à¸­à¹€à¸—à¸£à¸™à¸”à¹Œà¸‚à¸²à¸¥à¸‡\n",
        "#         price_trend = \"BULL\" if macd_val > 0 else \"BEAR\"\n",
        "\n",
        "#         # 3. à¸•à¸±à¸”à¸ªà¸´à¸™à¹ƒà¸ˆ (Decision Making)\n",
        "#         market_state = \"NEUTRAL\"\n",
        "\n",
        "#         # à¹€à¸‡à¸·à¹ˆà¸­à¸™à¹„à¸‚: Macro à¸•à¸£à¸‡à¸à¸±à¸šà¸„à¸§à¸²à¸¡à¹€à¸›à¹‡à¸™à¸ˆà¸£à¸´à¸‡à¹„à¸«à¸¡?\n",
        "#         if (macro_view == \"BULL\" and price_trend == \"BULL\") or \\\n",
        "#            (macro_view == \"BEAR\" and price_trend == \"BEAR\"):\n",
        "#             # âœ… Macro à¹à¸¡à¹ˆà¸™ -> à¹€à¸Šà¸·à¹ˆà¸­ Macro (à¸žà¸£à¸°à¹€à¸­à¸à¸—à¸³à¸‡à¸²à¸™)\n",
        "#             market_state = macro_view\n",
        "#         else:\n",
        "#             # âŒ Macro à¸¡à¸±à¹ˆà¸§ (à¸‚à¸±à¸”à¹à¸¢à¹‰à¸‡à¸à¸±à¸šà¸à¸£à¸²à¸Ÿ) -> à¹€à¸Šà¸·à¹ˆà¸­ DL (à¸žà¸£à¸°à¸£à¸­à¸‡à¸¡à¸²à¸Šà¹ˆà¸§à¸¢)\n",
        "#             if dl_val > 0.55: market_state = \"BULL\"\n",
        "#             elif dl_val < 0.45: market_state = \"BEAR\"\n",
        "#             # à¸–à¹‰à¸² DL à¸à¹‡à¹„à¸¡à¹ˆà¹à¸™à¹ˆà¹ƒà¸ˆ à¹ƒà¸«à¹‰à¹€à¸›à¹‡à¸™ NEUTRAL\n",
        "\n",
        "#         # --- Reward Calculation ---\n",
        "#         reward = 0.0\n",
        "\n",
        "#         # Action Logic\n",
        "#         # BUY\n",
        "#         if action == 1 and self.balance > current_price:\n",
        "#             budget = self.balance * 0.5\n",
        "#             shares = int(budget // current_price)\n",
        "#             if shares > 0:\n",
        "#                 cost = shares * current_price\n",
        "#                 total_shares = self.shares_held + shares\n",
        "#                 total_cost = (self.shares_held * self.avg_cost) + cost\n",
        "#                 self.avg_cost = total_cost / total_shares\n",
        "\n",
        "#                 self.balance -= cost\n",
        "#                 self.shares_held += shares\n",
        "#                 self.days_since_trade = 0\n",
        "\n",
        "#                 # à¹ƒà¸«à¹‰à¸£à¸²à¸‡à¸§à¸±à¸¥à¸–à¹‰à¸²à¸‹à¸·à¹‰à¸­à¸–à¸¹à¸à¸ˆà¸±à¸‡à¸«à¸§à¸°\n",
        "#                 if market_state == \"BULL\": reward += 0.2\n",
        "#                 if market_state == \"BEAR\": reward -= 0.2\n",
        "\n",
        "#         # SELL\n",
        "#         elif action == 2 and self.shares_held > 0:\n",
        "#             revenue = self.shares_held * current_price\n",
        "#             profit_pct = (current_price - self.avg_cost) / self.avg_cost\n",
        "\n",
        "#             self.balance += revenue\n",
        "#             self.shares_held = 0\n",
        "#             self.avg_cost = 0\n",
        "#             self.days_since_trade = 0\n",
        "\n",
        "#             # Profit Bonus\n",
        "#             if profit_pct > 0:\n",
        "#                 reward += (profit_pct * 20.0)\n",
        "#             else:\n",
        "#                 # à¸–à¹‰à¸²à¸•à¸¥à¸²à¸”à¹à¸¢à¹ˆ à¹à¸¥à¹‰à¸§ Cut Loss à¹„à¸”à¹‰ -> à¸Šà¸¡à¹€à¸Šà¸¢\n",
        "#                 if market_state == \"BEAR\": reward += 0.1\n",
        "#                 else: reward -= 0.1\n",
        "\n",
        "#         # HOLD\n",
        "#         elif action == 0:\n",
        "#             self.days_since_trade += 1\n",
        "#             if self.days_since_trade > 3: # Inactivity Penalty\n",
        "#                 reward -= 0.1 * (self.days_since_trade - 3)\n",
        "\n",
        "#         # Step Update\n",
        "#         self.current_step += 1\n",
        "#         done = self.current_step >= len(self.df) - 1\n",
        "\n",
        "#         # PnL Reward\n",
        "#         next_price = self.df.iloc[self.current_step]['Close']\n",
        "#         self.net_worth = self.balance + (self.shares_held * next_price)\n",
        "#         pnl = ((self.net_worth - self.prev_net_worth) / self.prev_net_worth) * 100\n",
        "#         reward += pnl\n",
        "\n",
        "#         # --- ðŸ”¥ REGIME PENALTY (Floor is Lava à¹à¸šà¸šà¸¡à¸µà¸ªà¸¡à¸­à¸‡) ---\n",
        "#         cash_ratio = self.balance / self.net_worth\n",
        "\n",
        "#         if market_state == \"BULL\":\n",
        "#             # à¸•à¸¥à¸²à¸”à¸”à¸µ (Macro à¹à¸¡à¹ˆà¸™ à¸«à¸£à¸·à¸­ DL à¸Šà¹ˆà¸§à¸¢à¸¢à¸·à¸™à¸¢à¸±à¸™) -> à¸•à¹‰à¸­à¸‡à¸–à¸·à¸­à¸«à¸¸à¹‰à¸™!\n",
        "#             if cash_ratio > 0.5: reward -= 0.5\n",
        "\n",
        "#         elif market_state == \"BEAR\":\n",
        "#             # à¸•à¸¥à¸²à¸”à¹à¸¢à¹ˆ -> à¸•à¹‰à¸­à¸‡à¸–à¸·à¸­à¹€à¸‡à¸´à¸™à¸ªà¸”!\n",
        "#             if cash_ratio < 0.5: reward -= 0.5\n",
        "\n",
        "#         self.prev_net_worth = self.net_worth\n",
        "#         return self._next_observation(), reward, done, False, {}\n",
        "\n",
        "# # --- Training Loop ---\n",
        "# print(f\"ðŸš€ Starting Training (Macro First -> Fallback to DL)...\")\n",
        "\n",
        "# TOTAL_TIMESTEPS = 30000\n",
        "\n",
        "# for stock in target_stocks:\n",
        "#     train_df = df_rl_all[(df_rl_all['Stock'] == stock) & (df_rl_all['Date'].dt.year < 2024)]\n",
        "#     if len(train_df) < 50: continue\n",
        "\n",
        "#     env = DummyVecEnv([lambda: StockTradingEnv(train_df)])\n",
        "#     model = PPO(\"MlpPolicy\", env, verbose=0, learning_rate=0.0003, ent_coef=0.1, batch_size=64)\n",
        "\n",
        "#     try:\n",
        "#         model.learn(total_timesteps=TOTAL_TIMESTEPS)\n",
        "#         model.save(f\"trained_models/ppo_{stock}\")\n",
        "#         print(f\"âœ… Trained: {stock}\")\n",
        "#     except Exception as e:\n",
        "#         print(f\"âŒ Error {stock}: {e}\")\n",
        "\n",
        "# print(\"\\nðŸŽ‰ Training Complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neWLDLI7gcru"
      },
      "outputs": [],
      "source": [
        "# # ============================================================\n",
        "# # ðŸ† BLOCK 8: FINAL EVALUATION\n",
        "# # ============================================================\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import warnings\n",
        "# import os\n",
        "# import gymnasium as gym\n",
        "# from gymnasium import spaces\n",
        "# from stable_baselines3 import PPO\n",
        "# from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "\n",
        "# warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# stock_symbols = [\n",
        "#     \"AAV\", \"AEONTS\", \"AOT\", \"BA\", \"BBL\", \"BCH\", \"BDMS\", \"BEM\", \"BH\", \"BTS\",\n",
        "#     \"CHG\", \"JMT\", \"KBANK\", \"KKP\", \"KTB\", \"KTC\", \"PR9\", \"PRM\", \"RCL\", \"SAWAD\",\n",
        "#     \"TCAP\", \"TISCO\", \"TTB\"\n",
        "# ]\n",
        "# initial_balance = 1_000_000\n",
        "\n",
        "# try:\n",
        "#     df_rl_all = pd.read_excel(\"Final_RL_Input_Ready.xlsx\")\n",
        "#     df_rl_all['Date'] = pd.to_datetime(df_rl_all['Date'])\n",
        "# except:\n",
        "#     raise RuntimeError(\"âŒ Missing Data File\")\n",
        "\n",
        "# class StockTradingEnv(gym.Env):\n",
        "#     def __init__(self, df):\n",
        "#         super().__init__()\n",
        "#         self.df = df.reset_index(drop=True)\n",
        "#         self.balance = initial_balance\n",
        "#         self.shares_held = 0\n",
        "#         self.current_step = 0\n",
        "#         self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(6,), dtype=np.float32)\n",
        "#         self.action_space = spaces.Discrete(3)\n",
        "\n",
        "#     def reset(self, seed=None, options=None):\n",
        "#         self.current_step = 0\n",
        "#         self.balance = initial_balance\n",
        "#         self.shares_held = 0\n",
        "#         return self._next_observation(), {}\n",
        "\n",
        "#     def _next_observation(self):\n",
        "#         obs = self.df.iloc[self.current_step]\n",
        "#         return np.array([\n",
        "#             obs.get('Macro_Signal', 0),\n",
        "#             obs.get('DL_Signal', 0.5),\n",
        "#             self.balance / 1_000_000.0,\n",
        "#             (self.shares_held * obs['Close']) / 1_000_000.0,\n",
        "#             obs.get('RSI', 50) / 100.0,\n",
        "#             obs.get('MACD', 0) / 10.0\n",
        "#         ], dtype=np.float32)\n",
        "\n",
        "#     def step(self, action):\n",
        "#         self.current_step += 1\n",
        "#         done = self.current_step >= len(self.df) - 1\n",
        "#         return self._next_observation(), 0, done, False, {}\n",
        "\n",
        "# # --- Backtest Logic ---\n",
        "# def backtest_logic(env, model):\n",
        "#     if hasattr(env, 'envs'): df = env.envs[0].unwrapped.df\n",
        "#     else: df = env.unwrapped.df\n",
        "\n",
        "#     prices = df['Close'].values\n",
        "#     cash = initial_balance\n",
        "#     shares = 0\n",
        "#     trades = 0\n",
        "#     commission = 0.001\n",
        "\n",
        "#     obs = env.reset()\n",
        "\n",
        "#     for i in range(len(prices)-1):\n",
        "#         action, _ = model.predict(obs, deterministic=True)\n",
        "#         curr_price = prices[i]\n",
        "\n",
        "#         # Buy\n",
        "#         if action == 1 and cash > curr_price:\n",
        "#             budget = cash * 0.5\n",
        "#             buy_amt = int(budget // (curr_price * (1 + commission)))\n",
        "#             if buy_amt > 0:\n",
        "#                 cost = buy_amt * curr_price * (1 + commission)\n",
        "#                 cash -= cost\n",
        "#                 shares += buy_amt\n",
        "#                 trades += 1\n",
        "\n",
        "#         # Sell\n",
        "#         elif action == 2 and shares > 0:\n",
        "#             cash += shares * curr_price * (1 - commission)\n",
        "#             shares = 0\n",
        "#             trades += 1\n",
        "\n",
        "#         obs, _, done, _ = env.step(action)\n",
        "#         if done: break\n",
        "\n",
        "#     final_val = cash + (shares * prices[-1])\n",
        "#     return final_val, trades\n",
        "\n",
        "# # --- Run Loop ---\n",
        "# results = []\n",
        "# print(f\"ðŸš€ Testing on 2024-2025 Data (Macro-Led Strategy)...\\n\")\n",
        "# print(f\"{'Stock':<10} | {'AI %':<10} | {'Bench %':<10} | {'Diff %':<10} | {'Trades':<8} | {'Status'}\")\n",
        "# print(\"-\" * 75)\n",
        "\n",
        "# for ticker in stock_symbols:\n",
        "#     try:\n",
        "#         df_test = df_rl_all[(df_rl_all['Stock'] == ticker) & (df_rl_all['Date'].dt.year >= 2024)]\n",
        "#         if len(df_test) < 10: continue\n",
        "\n",
        "#         model_path = f\"trained_models/ppo_{ticker}.zip\"\n",
        "\n",
        "#         if os.path.exists(model_path):\n",
        "#             env = DummyVecEnv([lambda: StockTradingEnv(df_test)])\n",
        "#             model = PPO.load(model_path, env=env)\n",
        "#             final_val, trades = backtest_logic(env, model)\n",
        "\n",
        "#             ai_ret = ((final_val - initial_balance)/initial_balance)*100\n",
        "#             bench_ret = ((df_test.iloc[-1]['Close'] - df_test.iloc[0]['Close'])/df_test.iloc[0]['Close'])*100\n",
        "#             diff = ai_ret - bench_ret\n",
        "#             status = \"WIN ðŸ†\" if ai_ret > bench_ret else \"LOSS âŒ\"\n",
        "\n",
        "#             results.append({'Stock': ticker, 'AI_Return_%': round(ai_ret,2), 'Benchmark_Return_%': round(bench_ret,2), 'Diff_%': round(diff, 2), 'Trades': trades, 'Status': status})\n",
        "#             print(f\"{ticker:<10} | {ai_ret:>9.2f}% | {bench_ret:>9.2f}% | {diff:>9.2f}% | {trades:<8} | {status}\")\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"âŒ Error {ticker}: {e}\")\n",
        "\n",
        "# if results:\n",
        "#     df_res = pd.DataFrame(results)\n",
        "#     print(f\"\\n{df_res.to_markdown(index=False)}\")\n",
        "#     df_res.to_excel(\"Final_AI_WinLoss_Summary.xlsx\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Es2wg9bI1hB"
      },
      "source": [
        "# Backtesting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ay3FOhbI0bB"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "\n",
        "# # ============================================================\n",
        "# # âš™ï¸ BLOCK: Historical vs Predicted Î”Logclose (Clean Export)\n",
        "# # ============================================================\n",
        "\n",
        "# def rolling_ecm_forecast_table(stock_name, sector_name, df_macro, df_gamma, df_alpha, df_beta, combined_dfs_selective_diff):\n",
        "#     \"\"\"\n",
        "#     à¸—à¸³à¸™à¸²à¸¢ Î”Logclose (à¹€à¸”à¸·à¸­à¸™ t) à¸ˆà¸²à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸”à¸·à¸­à¸™ tâˆ’1 à¹à¸¥à¹‰à¸§à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¸à¸±à¸š actual\n",
        "#     à¸„à¸·à¸™ DataFrame: Date | Actual_dLogclose | Pred_dLogclose | Error | APE_% | Stock | Sector\n",
        "#     \"\"\"\n",
        "#     # --- à¹€à¸•à¸£à¸µà¸¢à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸¸à¹‰à¸™à¹à¸¥à¸° macro ---\n",
        "#     df_stock = combined_dfs_selective_diff[sector_name][[f\"Logclose_{stock_name}\"]].copy()\n",
        "#     df_stock.columns = [\"Logclose\"]\n",
        "#     df_macro_aligned = df_macro.reindex(df_stock.index).ffill().copy()\n",
        "\n",
        "#     # --- à¸žà¸²à¸£à¸²à¸¡à¸´à¹€à¸•à¸­à¸£à¹Œà¸ˆà¸²à¸à¹‚à¸¡à¹€à¸”à¸¥ ---\n",
        "#     btab = df_beta[df_beta[\"Stock\"] == stock_name]\n",
        "#     gtab = df_gamma[df_gamma[\"Stock\"] == stock_name].copy()\n",
        "#     atab = df_alpha[df_alpha[\"Stock\"] == stock_name]\n",
        "#     if btab.empty or gtab.empty or atab.empty:\n",
        "#         return None\n",
        "\n",
        "#     lr_params = btab.drop_duplicates(subset=\"Variable\").set_index(\"Variable\")[\"coef\"]\n",
        "#     gtab = gtab[gtab[\"Variable\"].str.contains(r\"D\\.L\\d+\\.\", regex=True, na=False)]\n",
        "#     gtab = pd.concat([\n",
        "#         gtab,\n",
        "#         pd.DataFrame([{\"Variable\": \"ECT_lag1\", \"Coef\": float(atab[\"Alpha\"].iloc[0])}])\n",
        "#     ], ignore_index=True)\n",
        "\n",
        "#     # --- à¹€à¸•à¸£à¸µà¸¢à¸¡ DataFrame à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œ ---\n",
        "#     df_out = pd.DataFrame(index=df_stock.index)\n",
        "#     df_out[\"Actual_dLogclose\"] = df_stock[\"Logclose\"].diff()\n",
        "#     df_out[\"Pred_dLogclose\"] = np.nan\n",
        "\n",
        "#     # --- Forecast à¹à¸šà¸š rolling ---\n",
        "#     for i in range(4, len(df_stock)):\n",
        "#         deltas = {}\n",
        "#         past_window = df_stock.iloc[i-4:i].copy()\n",
        "#         past_macro = df_macro_aligned.iloc[i-4:i].copy()\n",
        "\n",
        "#         # ECT lag\n",
        "#         const = float(lr_params.get(\"const\", 0.0))\n",
        "#         X_lag = {k: float(past_macro[k].iloc[-2]) for k in lr_params.index if k != \"const\" and k in past_macro.columns}\n",
        "#         Y_lag = float(past_window[\"Logclose\"].iloc[-2])\n",
        "#         ect_val = Y_lag - (const + sum(float(lr_params[k]) * X_lag[k] for k in X_lag))\n",
        "#         deltas[\"ECT_lag1\"] = ect_val\n",
        "\n",
        "#         # Î”Y / Î”X lags\n",
        "#         for var in gtab[\"Variable\"]:\n",
        "#             if var == \"ECT_lag1\":\n",
        "#                 continue\n",
        "#             parts = var.split(\".\")\n",
        "#             lag = int(parts[1].replace(\"L\", \"\"))\n",
        "#             base = parts[2]\n",
        "\n",
        "#             if base.startswith(\"Logclose_\"):\n",
        "#                 stock_base = base.replace(\"Logclose_\", \"\")\n",
        "#                 if stock_base != stock_name:\n",
        "#                     continue\n",
        "#                 dy = float(past_window[\"Logclose\"].iloc[-lag]) - float(past_window[\"Logclose\"].iloc[-(lag + 1)])\n",
        "#                 deltas[var] = dy\n",
        "#             else:\n",
        "#                 if base in past_macro.columns:\n",
        "#                     dx = float(past_macro[base].iloc[-lag]) - float(past_macro[base].iloc[-(lag + 1)])\n",
        "#                     deltas[var] = dx\n",
        "#                 else:\n",
        "#                     deltas[var] = 0.0\n",
        "\n",
        "#         df_pred = pd.DataFrame(list(deltas.items()), columns=[\"Variable\", \"Value\"])\n",
        "#         merged = pd.merge(gtab[[\"Variable\", \"Coef\"]], df_pred, on=\"Variable\", how=\"left\")\n",
        "#         merged[\"Contribution\"] = merged[\"Coef\"].astype(float) * merged[\"Value\"].astype(float)\n",
        "#         df_out.iloc[i, df_out.columns.get_loc(\"Pred_dLogclose\")] = merged[\"Contribution\"].sum()\n",
        "\n",
        "#     # --- Error metrics ---\n",
        "#     EPS = 1e-6\n",
        "#     df_out[\"Error\"] = df_out[\"Pred_dLogclose\"] - df_out[\"Actual_dLogclose\"]\n",
        "#     df_out[\"APE_%\"] = np.where(\n",
        "#         df_out[\"Actual_dLogclose\"].abs() > EPS,\n",
        "#         np.abs(df_out[\"Error\"] / df_out[\"Actual_dLogclose\"]) * 100,\n",
        "#         np.nan\n",
        "#     )\n",
        "#     df_out[\"Stock\"] = stock_name\n",
        "#     df_out[\"Sector\"] = sector_name\n",
        "#     return df_out.dropna(subset=[\"Pred_dLogclose\"])\n",
        "\n",
        "\n",
        "# # ============================================================\n",
        "# # ðŸš€ Run & Export à¹€à¸‰à¸žà¸²à¸°à¸£à¸²à¸¢à¸«à¸¸à¹‰à¸™ (Sheet 2 à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™)\n",
        "# # ============================================================\n",
        "\n",
        "# evaluation_results = {}\n",
        "\n",
        "# for sector_name, df_sec in combined_dfs_selective_diff.items():\n",
        "#     for col in df_sec.columns:\n",
        "#         if not col.startswith(\"Logclose_\"):\n",
        "#             continue\n",
        "#         stock_name = col.replace(\"Logclose_\", \"\")\n",
        "#         try:\n",
        "#             df_eval = rolling_ecm_forecast_table(\n",
        "#                 stock_name, sector_name, df, df_gamma, df_alpha, df_beta, combined_dfs_selective_diff\n",
        "#             )\n",
        "#             if df_eval is not None and not df_eval.empty:\n",
        "#                 evaluation_results[stock_name] = df_eval\n",
        "#                 mae = df_eval[\"Error\"].abs().mean()\n",
        "#                 rmse = np.sqrt((df_eval[\"Error\"] ** 2).mean())\n",
        "#                 mape = df_eval[\"APE_%\"].replace([np.inf, -np.inf], np.nan).mean()\n",
        "#                 print(f\"âœ… {stock_name:<8} | MAE={mae:.5f} | RMSE={rmse:.5f} | MAPE={mape:.2f}% | Obs={len(df_eval)}\")\n",
        "#         except Exception as e:\n",
        "#             print(f\"âš ï¸ {stock_name} failed: {e}\")\n",
        "\n",
        "# # --- Export à¹€à¸‰à¸žà¸²à¸°à¸£à¸²à¸¢à¸«à¸¸à¹‰à¸™ ---\n",
        "# output_file = \"ECM_Forecast_Evaluation_ByStock.xlsx\"\n",
        "# with pd.ExcelWriter(output_file) as writer:\n",
        "#     for stock, df_eval in evaluation_results.items():\n",
        "#         df_clean = df_eval.replace([np.inf, -np.inf], np.nan).dropna(how=\"all\")\n",
        "#         df_clean.to_excel(writer, sheet_name=stock[:31], index=True)\n",
        "\n",
        "# print(f\"\\nâœ… Exported â†’ {output_file}\")\n",
        "# print(f\"à¸£à¸§à¸¡à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸” {len(evaluation_results)} à¸«à¸¸à¹‰à¸™ (à¹€à¸‰à¸žà¸²à¸° Sheet à¸£à¸²à¸¢à¸«à¸¸à¹‰à¸™à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™)\")\n",
        "\n",
        "\n",
        "# # à¸«à¸¥à¸±à¸‡à¸ˆà¸²à¸à¸£à¸±à¸™à¹à¸¥à¹‰à¸§ evaluation_results à¸¡à¸µ dictionary à¸‚à¸­à¸‡à¸«à¸¸à¹‰à¸™à¹à¸•à¹ˆà¸¥à¸°à¸•à¸±à¸§\n",
        "\n",
        "# for stock, df_eval in evaluation_results.items():\n",
        "#     print(f\"\\n==== {stock} ====\")\n",
        "#     print(df_eval.tail(5)[[\"Actual_dLogclose\",\"Pred_dLogclose\",\"Error\",\"APE_%\"]])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4joQksHUQaF"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# df_macro = pd.read_excel(\"Macro_data.xlsx\")\n",
        "# print(df_macro.columns.tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBt6Pq__Mc60"
      },
      "outputs": [],
      "source": [
        "# # ============================================================\n",
        "# # ðŸ§  BLOCK 5.2 â€” Regime-aware Hybrid Optimization Strategy (Fixed)\n",
        "# # ============================================================\n",
        "\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# import yfinance as yf\n",
        "# from pathlib import Path\n",
        "\n",
        "# # ---------- INPUT FILES ----------\n",
        "# f_forecast = \"Forecast_ARDL_ECM_NextMonth_Clean.xlsx\"\n",
        "# f_daily = \"Historical_Technical_Indicators_bySector.xlsx\"\n",
        "# f_macro = \"Macro_data.xlsx\"\n",
        "\n",
        "# # ---------- LOAD DATA ----------\n",
        "# df_fore = pd.read_excel(f_forecast)[[\"Stock\", \"Sector\", \"Pred_dLogclose\"]]\n",
        "# df_daily = pd.read_excel(f_daily)\n",
        "# df_daily[\"Date\"] = pd.to_datetime(df_daily[\"Date\"])\n",
        "\n",
        "# # --- Load macro base ---\n",
        "# df_macro = pd.read_excel(f_macro)\n",
        "# df_macro[\"Date\"] = pd.to_datetime(df_macro[\"Date\"])\n",
        "\n",
        "# # --- FX: USD/THB ---\n",
        "# fx1 = yf.download(\"THB=X\", start=\"2015-01-01\", end=\"2025-01-01\", progress=False)\n",
        "# if isinstance(fx1.columns, pd.MultiIndex):\n",
        "#     fx1.columns = fx1.columns.get_level_values(0)\n",
        "# fx1 = fx1.reset_index()[[\"Date\", \"Close\"]].rename(columns={\"Close\": \"THB_per_USD\"})\n",
        "\n",
        "# # --- FX: THB/CNY ---\n",
        "\n",
        "# fx2 = yf.download(\"THBCNY=X\", start=\"2015-01-01\", end=\"2025-01-01\", progress=False)\n",
        "# if isinstance(fx2.columns, pd.MultiIndex):\n",
        "#     fx2.columns = fx2.columns.get_level_values(0)\n",
        "# fx2 = fx2.reset_index()[[\"Date\", \"Close\"]].rename(columns={\"Close\": \"THB_per_CNY\"})\n",
        "\n",
        "\n",
        "# # # --- Oil: Brent ---\n",
        "# # oil = yf.download(\"BZ=F\", start=\"2015-01-01\", end=\"2025-01-01\", progress=False)\n",
        "# # if isinstance(oil.columns, pd.MultiIndex):\n",
        "# #     oil.columns = oil.columns.get_level_values(0)\n",
        "# # oil = oil.reset_index()[[\"Date\", \"Close\"]].rename(columns={\"Close\": \"Brent_Oil_USD_per_bbl\"})\n",
        "\n",
        "# # --- SET Index---\n",
        "# thai = yf.download(\"^SET.BK\", start=\"2015-01-01\", end=\"2025-01-01\", progress=False)\n",
        "# if isinstance(thai.columns, pd.MultiIndex):\n",
        "#     thai.columns = thai.columns.get_level_values(0)\n",
        "# thai = thai.reset_index()[[\"Date\", \"Close\"]].rename(columns={\"Close\": \"SET_Index\"})\n",
        "\n",
        "# # --- S&P500---\n",
        "# usa = yf.download(\"^GSPC\", start=\"2015-01-01\", end=\"2025-01-01\", progress=False)\n",
        "# if isinstance(usa.columns, pd.MultiIndex):\n",
        "#     usa.columns = usa.columns.get_level_values(0)\n",
        "# usa = usa.reset_index()[[\"Date\", \"Close\"]].rename(columns={\"Close\": \"SP500_Index\"})\n",
        "\n",
        "# # --- Merge macro + yfinance series ---\n",
        "# df_macro = (\n",
        "#     df_macro\n",
        "#     .merge(fx1, on=\"Date\", how=\"left\")\n",
        "#     .merge(fx2, on=\"Date\", how=\"left\")\n",
        "#     .merge(thai, on=\"Date\", how=\"left\")\n",
        "#     .merge(usa, on=\"Date\", how=\"left\")\n",
        "\n",
        "# )\n",
        "\n",
        "# # --- Rename for compatibility ---\n",
        "# df_macro.rename(columns={\n",
        "#     \"Bond_spread_10Y_5Y\": \"10Y_5Y_Bond_Spread\",\n",
        "#     \"Bond_spread_5Y_1Y\": \"5Y_1Y_Bond_Spread\",\n",
        "#     \"Bond_spread_10Y_1Y\": \"10Y_1Y_Bond_Spread\"\n",
        "# }, inplace=True)\n",
        "\n",
        "# df_macro = df_macro.set_index(\"Date\").sort_index()\n",
        "\n",
        "# # ============================================================\n",
        "# # STEP 1: Detect Macro Regime\n",
        "# # ============================================================\n",
        "# def detect_regime(df_macro):\n",
        "#     df = df_macro.copy()\n",
        "\n",
        "#     # Handle missing vars gracefully\n",
        "#     for col in [\"10Y_5Y_Bond_Spread\",\"5Y_1Y_Bond_Spread\",\"THOR_6M\",\n",
        "#                \"THB_per_USD\" ]:    # \"Brent_Oil_USD_per_bbl\"\n",
        "#         if col not in df.columns:\n",
        "#             df[col] = df[col].interpolate(limit_direction=\"both\")\n",
        "\n",
        "#     z_10_5 = (df[\"10Y_5Y_Bond_Spread\"] - df[\"10Y_5Y_Bond_Spread\"].mean()) / df[\"10Y_5Y_Bond_Spread\"].std()\n",
        "#     z_5_1 = (df[\"5Y_1Y_Bond_Spread\"] - df[\"5Y_1Y_Bond_Spread\"].mean()) / df[\"5Y_1Y_Bond_Spread\"].std()\n",
        "#     z_thor = (df[\"THOR_6M\"] - df[\"THOR_6M\"].mean()) / df[\"THOR_6M\"].std()\n",
        "#     # z_oil = (df[\"Brent_Oil_USD_per_bbl\"] - df[\"Brent_Oil_USD_per_bbl\"].mean()) / df[\"Brent_Oil_USD_per_bbl\"].std()\n",
        "#     z_fx = (df[\"THB_per_USD\"] - df[\"THB_per_USD\"].mean()) / df[\"THB_per_USD\"].std()\n",
        "#     z_thai = (df[\"SET_Index\"] - df[\"SET_Index\"].mean()) / df[\"SET_Index\"].std()\n",
        "#     z_usa = (df[\"SP500_Index\"] - df[\"SP500_Index\"].mean()) / df[\"SP500_Index\"].std()\n",
        "\n",
        "#     # Composite index\n",
        "#     composite = 0.4*(z_10_5 + z_5_1)/2 - 0.3*z_thor - 0.15*z_fx + 0.15*z_thai + 0.15*z_usa\n",
        "#     df[\"Regime_Score\"] = composite\n",
        "#     df[\"Regime\"] = np.select(\n",
        "#         [composite > 0.7, composite < -0.7],\n",
        "#         [\"Expansion\", \"Contraction\"],\n",
        "#         default=\"Neutral\"\n",
        "#     )\n",
        "#     return df[[\"Regime\",\"Regime_Score\"]]\n",
        "\n",
        "# df_regime = detect_regime(df_macro)\n",
        "\n",
        "# # ============================================================\n",
        "# # STEP 2: Merge Forecast + Daily + Regime\n",
        "# # ============================================================\n",
        "# expanded = []\n",
        "# for _, row in df_fore.iterrows():\n",
        "#     stock, sector, pred = row[\"Stock\"], row[\"Sector\"], row[\"Pred_dLogclose\"]\n",
        "#     df_s = df_daily[df_daily[\"Stock\"] == stock].copy()\n",
        "#     if df_s.empty:\n",
        "#         continue\n",
        "#     df_s[\"Pred_dLogclose\"] = pred\n",
        "#     df_s[\"Sector\"] = sector\n",
        "#     df_s = df_s.merge(df_regime, left_on=\"Date\", right_index=True, how=\"left\")\n",
        "#     expanded.append(df_s)\n",
        "\n",
        "# df_all = pd.concat(expanded, ignore_index=True).sort_values([\"Sector\",\"Stock\",\"Date\"])\n",
        "\n",
        "# # ============================================================\n",
        "# # STEP 3: Regime-dependent Weights\n",
        "# # ============================================================\n",
        "# def regime_weights(r):\n",
        "#     if r == \"Expansion\": return (0.6, 0.25, 0.15)\n",
        "#     elif r == \"Contraction\": return (0.3, 0.5, 0.2)\n",
        "#     else: return (0.4, 0.4, 0.2)\n",
        "\n",
        "# # ============================================================\n",
        "# # STEP 4: Hybrid Score Computation\n",
        "# # ============================================================\n",
        "# df_all[\"Return\"] = df_all.groupby(\"Stock\")[\"Close\"].pct_change()\n",
        "# df_all[\"LogReturn\"] = np.log1p(df_all[\"Return\"])\n",
        "\n",
        "# hybrid_results, equity_curves = [], {}\n",
        "\n",
        "# for stock, sub in df_all.groupby(\"Stock\"):\n",
        "#     sub = sub.copy().sort_values(\"Date\")\n",
        "\n",
        "#     techconfirm = (\n",
        "#         0.3 * sub[\"TechScore\"].fillna(0)\n",
        "#         + 0.2 * sub[\"MACD\"].fillna(0)\n",
        "#         + 0.1 * ((60 - abs(sub[\"RSI_14\"].fillna(50)-50)) / 50)\n",
        "#     )\n",
        "#     wave_align = np.where(sub[\"Wave_Direction\"] == (\"Up\" if sub[\"Pred_dLogclose\"].iloc[0] > 0 else \"Down\"), 1, -1)\n",
        "#     patternwave = (\n",
        "#         0.2 * sub[\"Pattern_Confidence\"].fillna(0)\n",
        "#         + 0.2 * sub[\"Wave_Strength\"].fillna(0) * wave_align\n",
        "#     )\n",
        "\n",
        "#     hybrid_score = []\n",
        "#     for i, regime in enumerate(sub[\"Regime\"]):\n",
        "#         w_macro, w_tech, w_pattern = regime_weights(regime)\n",
        "#         bias = np.sign(sub[\"Pred_dLogclose\"].iloc[0])\n",
        "#         score = (w_macro*bias) + (w_tech*techconfirm.iloc[i]) + (w_pattern*patternwave.iloc[i])\n",
        "#         hybrid_score.append(score)\n",
        "\n",
        "#     sub[\"Score\"] = hybrid_score\n",
        "#     sub[\"FinalSignal\"] = np.where(abs(sub[\"Score\"]) < 0.05, 0, np.sign(sub[\"Score\"]))\n",
        "#     sub[\"Strategy_Return\"] = sub[\"FinalSignal\"].shift(1) * sub[\"Return\"]\n",
        "#     sub[\"Cumulative_Return\"] = (1 + sub[\"Strategy_Return\"]).cumprod() - 1\n",
        "\n",
        "#     # --- Performance Summary ---\n",
        "#     hit_ratio = (np.sign(sub[\"Return\"]) == sub[\"FinalSignal\"].shift(1)).mean() * 100\n",
        "#     cum_ret = sub[\"Cumulative_Return\"].iloc[-1] * 100\n",
        "#     avg_ret = sub[\"Strategy_Return\"].mean() * 100\n",
        "#     std_ret = sub[\"Strategy_Return\"].std() * 100\n",
        "#     sharpe = avg_ret / std_ret if std_ret > 0 else np.nan\n",
        "\n",
        "#     hybrid_results.append({\n",
        "#         \"Stock\": stock, \"Sector\": sub[\"Sector\"].iloc[0],\n",
        "#         \"Hit_Ratio_%\": hit_ratio, \"Cumulative_Return_%\": cum_ret,\n",
        "#         \"Avg_Daily_Return_%\": avg_ret, \"Volatility_%\": std_ret,\n",
        "#         \"Sharpe_Ratio\": sharpe\n",
        "#     })\n",
        "#     equity_curves[stock] = sub[[\"Date\",\"Strategy_Return\",\"Cumulative_Return\",\"Regime\"]]\n",
        "\n",
        "# # ============================================================\n",
        "# # STEP 5: Portfolio Summary\n",
        "# # ============================================================\n",
        "# all_dates = pd.concat([v[\"Date\"] for v in equity_curves.values()]).drop_duplicates().sort_values()\n",
        "# port = pd.DataFrame(index=all_dates)\n",
        "\n",
        "# for k, v in equity_curves.items():\n",
        "#     df_v = v.drop_duplicates(subset=\"Date\").set_index(\"Date\")  # ðŸ”§ à¸›à¹‰à¸­à¸‡à¸à¸±à¸™ duplicate\n",
        "#     port[k] = df_v[\"Strategy_Return\"].reindex(all_dates)\n",
        "\n",
        "# # à¸„à¸³à¸™à¸§à¸“à¸œà¸¥à¸•à¸­à¸šà¹à¸—à¸™à¸žà¸­à¸£à¹Œà¸•à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¸£à¸²à¸¢à¸§à¸±à¸™\n",
        "# port[\"Portfolio_Return\"] = port.mean(axis=1, skipna=True)\n",
        "# port[\"Cumulative_Portfolio\"] = (1 + port[\"Portfolio_Return\"].fillna(0)).cumprod() - 1\n",
        "# port_cum = port[\"Cumulative_Portfolio\"].iloc[-1]*100\n",
        "# port_avg = port[\"Portfolio_Return\"].mean()*100\n",
        "# port_std = port[\"Portfolio_Return\"].std()*100\n",
        "# port_sharpe = port_avg/port_std if port_std>0 else np.nan\n",
        "\n",
        "# portfolio_summary = pd.DataFrame([{\n",
        "#     \"Portfolio_CumReturn_%\": port_cum,\n",
        "#     \"Portfolio_AvgDailyReturn_%\": port_avg,\n",
        "#     \"Portfolio_Volatility_%\": port_std,\n",
        "#     \"Portfolio_Sharpe\": port_sharpe\n",
        "# }])\n",
        "\n",
        "# df_strategy_summary = pd.DataFrame(hybrid_results).sort_values(\"Cumulative_Return_%\", ascending=False)\n",
        "\n",
        "# # ============================================================\n",
        "# # STEP 6: Export + Visualization\n",
        "# # ============================================================\n",
        "# out_path = Path(\"Hybrid_Regime_Aware_Strategy.xlsx\")\n",
        "# with pd.ExcelWriter(out_path) as writer:\n",
        "#     df_strategy_summary.to_excel(writer, sheet_name=\"Stock_Summary\", index=False)\n",
        "#     portfolio_summary.to_excel(writer, sheet_name=\"Portfolio_Summary\", index=False)\n",
        "#     port.to_excel(writer, sheet_name=\"Portfolio_EquityCurve\", index=True)\n",
        "\n",
        "# print(f\"âœ… Exported â†’ {out_path.name}\")\n",
        "\n",
        "# plt.figure(figsize=(10,6))\n",
        "# plt.plot(port[\"Cumulative_Portfolio\"], label=\"Regime-aware Portfolio\", lw=2)\n",
        "# plt.title(\"Regime-Aware Hybrid Macro + Technical Strategy â€” Cumulative Return\")\n",
        "# plt.ylabel(\"Cumulative Return\")\n",
        "# plt.grid(True); plt.legend(); plt.show()\n",
        "\n",
        "# # # ============================================================\n",
        "# # # ðŸ“¤ STEP 1.5 â€” Export Regime Scores for ML Fusion (used in Block 5.2B)\n",
        "# # # ============================================================\n",
        "# # df_regime_export = df_regime.reset_index()\n",
        "# # df_regime_export.to_excel(\"Macro_Regime_Score.xlsx\", index=False)\n",
        "# # print(\"âœ… Exported â†’ Macro_Regime_Score.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pePVv5ktazDX"
      },
      "outputs": [],
      "source": [
        "# # ============================================================\n",
        "# # ðŸ’° BLOCK 5.3 â€” Dynamic Portfolio Simulation + Dashboard (Holdings Summary Version)\n",
        "# # ============================================================\n",
        "\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# import yfinance as yf\n",
        "\n",
        "# # --- Simulation Parameters ---\n",
        "# initial_capital = 10_000_000\n",
        "# trade_frac = 0.05  # 3% per signal\n",
        "\n",
        "# # ============================================================\n",
        "# # ðŸ§© FIX â€” Ensure FinalSignal exists\n",
        "# # ============================================================\n",
        "# df_sim = df_all.copy().sort_values([\"Date\", \"Stock\"]).drop_duplicates(subset=[\"Date\", \"Stock\"], keep=\"last\")\n",
        "\n",
        "# # ============================================================\n",
        "# # ðŸ§© FIX â€” Ensure FinalSignal exists (Robust)\n",
        "# # ============================================================\n",
        "# df_sim = df_all.copy().sort_values([\"Date\", \"Stock\"]).drop_duplicates(subset=[\"Date\", \"Stock\"], keep=\"last\")\n",
        "\n",
        "# if \"FinalSignal\" not in df_sim.columns:\n",
        "#     print(\"âš ï¸  Column 'FinalSignal' not found â†’ auto-generating ...\")\n",
        "\n",
        "#     if \"Score\" in df_sim.columns:\n",
        "#         # à¹ƒà¸Šà¹‰ Score à¸–à¹‰à¸²à¸¡à¸µ\n",
        "#         df_sim[\"FinalSignal\"] = np.where(abs(df_sim[\"Score\"]) < 0.05, 0, np.sign(df_sim[\"Score\"]))\n",
        "\n",
        "#     elif \"Pred_dLogclose\" in df_sim.columns:\n",
        "#         # à¹ƒà¸Šà¹‰ Pred_dLogclose à¸ˆà¸²à¸ ECM forecast\n",
        "#         df_sim[\"FinalSignal\"] = np.sign(df_sim[\"Pred_dLogclose\"])\n",
        "\n",
        "#     elif \"Pred_Return\" in df_sim.columns:\n",
        "#         # fallback à¸à¸£à¸“à¸µà¸¡à¸µà¸Šà¸·à¹ˆà¸­à¸­à¸·à¹ˆà¸™\n",
        "#         df_sim[\"FinalSignal\"] = np.sign(df_sim[\"Pred_Return\"])\n",
        "\n",
        "#     else:\n",
        "#         # à¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢ à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µà¸­à¸°à¹„à¸£à¹€à¸¥à¸¢ à¹ƒà¸«à¹‰à¸–à¸·à¸­à¸§à¹ˆà¸²à¹„à¸¡à¹ˆà¸¡à¸µ signal (à¸–à¸·à¸­à¹€à¸‡à¸´à¸™à¸ªà¸”)\n",
        "#         print(\"âš ï¸  Neither Score nor Pred_dLogclose found â€” assuming all signals = 0 (no trades).\")\n",
        "#         df_sim[\"FinalSignal\"] = 0\n",
        "\n",
        "\n",
        "# # ============================================================\n",
        "# # ðŸ§® Create pivot tables safely (handle duplicates)\n",
        "# # ============================================================\n",
        "# price_map = df_sim.pivot_table(index=\"Date\", columns=\"Stock\", values=\"Close\", aggfunc=\"last\")\n",
        "# signal_map = df_sim.pivot_table(index=\"Date\", columns=\"Stock\", values=\"FinalSignal\", aggfunc=\"last\")\n",
        "\n",
        "# # ============================================================\n",
        "# # ðŸš€ Portfolio Simulation (No short-selling, no borrowing)\n",
        "# # ============================================================\n",
        "# cash = initial_capital\n",
        "# holdings = {s: 0.0 for s in df_sim[\"Stock\"].unique()}\n",
        "# portfolio_history = []\n",
        "# dates = sorted(df_sim[\"Date\"].unique())\n",
        "\n",
        "# for date in dates:\n",
        "#     prices = price_map.loc[date]\n",
        "#     signals = signal_map.loc[date]\n",
        "\n",
        "#     # Portfolio valuation\n",
        "#     holdings_value = sum(prices[s]*holdings[s] for s in holdings if not np.isnan(prices[s]))\n",
        "#     total_value = cash + holdings_value\n",
        "\n",
        "#     # --- Execute trades ---\n",
        "#     for stock in holdings.keys():\n",
        "#         price = prices[stock]\n",
        "#         if np.isnan(price):\n",
        "#             continue\n",
        "#         sig = signals[stock]\n",
        "\n",
        "#         if sig == 1:  # BUY (max 3% of remaining cash)\n",
        "#             buy_amt = trade_frac * cash\n",
        "#             if buy_amt > 0:\n",
        "#                 qty = buy_amt / price\n",
        "#                 holdings[stock] += qty\n",
        "#                 cash -= qty * price\n",
        "\n",
        "#         elif sig == -1:  # SELL (max 3% of current holdings)\n",
        "#             sell_qty = trade_frac * holdings[stock]\n",
        "#             if sell_qty > 0:\n",
        "#                 holdings[stock] -= sell_qty\n",
        "#                 cash += sell_qty * price\n",
        "\n",
        "#     # --- Update after trades ---\n",
        "#     holdings_value = sum(prices[s]*holdings[s] for s in holdings if not np.isnan(prices[s]))\n",
        "#     total_value = cash + holdings_value\n",
        "\n",
        "#     portfolio_history.append({\n",
        "#         \"Date\": date,\n",
        "#         \"Cash\": cash,\n",
        "#         \"Holdings_Value\": holdings_value,\n",
        "#         \"Total_Portfolio\": total_value\n",
        "#     })\n",
        "\n",
        "# # ============================================================\n",
        "# # ðŸ“Š Portfolio Performance + Benchmark SET\n",
        "# # ============================================================\n",
        "# df_portfolio = pd.DataFrame(portfolio_history)\n",
        "# df_portfolio[\"Daily_Return\"] = df_portfolio[\"Total_Portfolio\"].pct_change()\n",
        "# df_portfolio[\"Cumulative_Return\"] = (1 + df_portfolio[\"Daily_Return\"].fillna(0)).cumprod() - 1\n",
        "\n",
        "# # ============================================================\n",
        "# # ðŸ§­ Benchmark SET Index (Functional Fix)\n",
        "# # ============================================================\n",
        "# try:\n",
        "#     set_idx = yf.download(\"^SET.BK\", start=df_portfolio[\"Date\"].min(), end=df_portfolio[\"Date\"].max(), progress=False)\n",
        "#     if not set_idx.empty:\n",
        "#         if isinstance(set_idx.columns, pd.MultiIndex):\n",
        "#             set_idx.columns = set_idx.columns.get_level_values(0)\n",
        "#         set_idx = set_idx[\"Close\"].resample(\"D\").ffill().squeeze()\n",
        "#         if isinstance(set_idx, pd.DataFrame):\n",
        "#             set_idx = set_idx.iloc[:, 0]\n",
        "#         set_ret = set_idx.pct_change().fillna(0)\n",
        "#         set_cum = (1 + set_ret).cumprod() - 1\n",
        "#         set_df = pd.DataFrame({\"Date\": set_idx.index, \"SET_Close\": set_idx.values, \"SET_Return\": set_ret.values, \"SET_CumReturn\": set_cum.values})\n",
        "#         set_df[\"Date\"] = pd.to_datetime(set_df[\"Date\"])\n",
        "#         df_portfolio = df_portfolio.reset_index(drop=True)\n",
        "#         df_portfolio[\"Date\"] = pd.to_datetime(df_portfolio[\"Date\"])\n",
        "#         df_portfolio = pd.merge_asof(\n",
        "#             df_portfolio.sort_values(\"Date\"),\n",
        "#             set_df.sort_values(\"Date\"),\n",
        "#             on=\"Date\",\n",
        "#             direction=\"backward\"\n",
        "#         ).set_index(\"Date\")\n",
        "#         print(\"âœ… SET Index benchmark successfully merged.\")\n",
        "#     else:\n",
        "#         print(\"âš ï¸ Warning: SET Index data not available.\")\n",
        "# except Exception as e:\n",
        "#     print(f\"âš ï¸ Error merging SET Index: {e}\")\n",
        "\n",
        "# # ============================================================\n",
        "# # ðŸ“ˆ Visualization Dashboard (Portfolio vs SET)\n",
        "# # ============================================================\n",
        "# plt.figure(figsize=(10,6))\n",
        "# plt.plot(df_portfolio.index, df_portfolio[\"Cumulative_Return\"], label=\"Strategy Portfolio\", lw=2)\n",
        "# plt.plot(df_portfolio.index, df_portfolio[\"SET_CumReturn\"], label=\"SET Index\", lw=2, ls=\"--\")\n",
        "# plt.title(\"Portfolio vs SET Index Benchmark\", fontsize=13, fontweight=\"bold\")\n",
        "# plt.ylabel(\"Cumulative Return\")\n",
        "# plt.grid(True); plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "# # ============================================================\n",
        "# # ðŸ“‹ Latest Holdings Summary\n",
        "# # ============================================================\n",
        "# latest_date = dates[-1]\n",
        "# latest_prices = price_map.loc[latest_date]\n",
        "# hold_df = pd.DataFrame([\n",
        "#     {\"Stock\": s,\n",
        "#      \"Quantity\": holdings[s],\n",
        "#      \"Last_Price\": latest_prices[s],\n",
        "#      \"Market_Value\": holdings[s] * latest_prices[s]}\n",
        "#     for s in holdings.keys() if holdings[s] > 0\n",
        "# ])\n",
        "# hold_df[\"Weight_%\"] = (hold_df[\"Market_Value\"] / hold_df[\"Market_Value\"].sum()) * 100\n",
        "# hold_df = hold_df.sort_values(\"Market_Value\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "# print(\"\\nðŸ“Š Latest Portfolio Holdings (as of {})\".format(latest_date.date()))\n",
        "# display(hold_df.round(2))\n",
        "\n",
        "# # ============================================================\n",
        "# # ðŸ’¾ Export\n",
        "# # ============================================================\n",
        "# with pd.ExcelWriter(\"Hybrid_Portfolio_Dashboard.xlsx\") as writer:\n",
        "#     df_portfolio.to_excel(writer, sheet_name=\"Portfolio_TimeSeries\")\n",
        "#     hold_df.to_excel(writer, sheet_name=\"Latest_Holdings\", index=False)\n",
        "# print(\"âœ… Exported â†’ Hybrid_Portfolio_Dashboard.xlsx\")\n",
        "\n",
        "# # ============================================================\n",
        "# # ðŸ“‹ Latest Holdings Summary\n",
        "# # ============================================================\n",
        "# latest_date = dates[-1]\n",
        "# latest_prices = price_map.loc[latest_date]\n",
        "# hold_df = pd.DataFrame([\n",
        "#     {\"Stock\": s,\n",
        "#      \"Quantity\": holdings[s],\n",
        "#      \"Last_Price\": latest_prices[s],\n",
        "#      \"Market_Value\": holdings[s] * latest_prices[s]}\n",
        "#     for s in holdings.keys() if holdings[s] > 0\n",
        "# ])\n",
        "# hold_df[\"Weight_%\"] = (hold_df[\"Market_Value\"] / hold_df[\"Market_Value\"].sum()) * 100\n",
        "# hold_df = hold_df.sort_values(\"Market_Value\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "# # --- ðŸ§¾ Portfolio Summary (Cash vs Equity) ---\n",
        "# latest_cash = cash\n",
        "# latest_equity_value = hold_df[\"Market_Value\"].sum()\n",
        "# total_portfolio_value = latest_cash + latest_equity_value\n",
        "# cash_ratio = (latest_cash / total_portfolio_value) * 100\n",
        "# equity_ratio = (latest_equity_value / total_portfolio_value) * 100\n",
        "\n",
        "# print(\"\\nðŸ“Š Latest Portfolio Holdings (as of {})\".format(latest_date.date()))\n",
        "# display(hold_df.round(2))\n",
        "\n",
        "# print(\"\\nðŸ’° Portfolio Allocation Summary:\")\n",
        "# print(f\"   â€¢ Total Portfolio Value : {total_portfolio_value:,.2f} THB\")\n",
        "# print(f\"   â€¢   â”œâ”€ Cash             : {latest_cash:,.2f} THB ({cash_ratio:.2f}%)\")\n",
        "# print(f\"   â€¢   â””â”€ Equity Holdings  : {latest_equity_value:,.2f} THB ({equity_ratio:.2f}%)\")\n",
        "\n",
        "# # ============================================================\n",
        "# # ðŸ’¾ Export\n",
        "# # ============================================================\n",
        "# with pd.ExcelWriter(\"Hybrid_Portfolio_Dashboard.xlsx\") as writer:\n",
        "#     df_portfolio.to_excel(writer, sheet_name=\"Portfolio_TimeSeries\")\n",
        "#     hold_df.to_excel(writer, sheet_name=\"Latest_Holdings\", index=False)\n",
        "\n",
        "# summary_df = pd.DataFrame({\n",
        "#     \"Total_Value\": [total_portfolio_value],\n",
        "#     \"Cash\": [latest_cash],\n",
        "#     \"Equity_Value\": [latest_equity_value],\n",
        "#     \"Cash_%\": [cash_ratio],\n",
        "#     \"Equity_%\": [equity_ratio]\n",
        "# })\n",
        "# summary_df.to_excel(writer, sheet_name=\"Allocation_Summary\", index=False)\n",
        "\n",
        "# print(\"\\nâœ… Exported â†’ Hybrid_Portfolio_Dashboard.xlsx\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75Asf7shXrcQ"
      },
      "outputs": [],
      "source": [
        "# # ============================================================\n",
        "# # ðŸ“Š BLOCK 5.4 â€” Regime-wise PyFolio Performance Summary (Refined)\n",
        "# # ============================================================\n",
        "\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "\n",
        "# # --- Ensure Regime column exists ---\n",
        "# if \"Regime\" not in df_portfolio.columns:\n",
        "#     df_reg = df_all[[\"Date\", \"Regime\"]].drop_duplicates(subset=\"Date\", keep=\"last\")\n",
        "#     df_reg[\"Date\"] = pd.to_datetime(df_reg[\"Date\"])\n",
        "#     df_portfolio = df_portfolio.reset_index().merge(df_reg, on=\"Date\", how=\"left\").set_index(\"Date\")\n",
        "\n",
        "# # ============================================================\n",
        "# # ðŸ§® Helper Functions\n",
        "# # ============================================================\n",
        "# def CAGR(series, freq=252):\n",
        "#     if len(series) < 2:\n",
        "#         return np.nan\n",
        "#     if series.iloc[0] != 1:  # normalize\n",
        "#         series = series / series.iloc[0]\n",
        "#     total_ret = series.iloc[-1] - 1\n",
        "#     years = len(series) / freq\n",
        "#     return (1 + total_ret) ** (1 / years) - 1\n",
        "\n",
        "# def max_drawdown(cumret):\n",
        "#     roll_max = np.maximum.accumulate(cumret)\n",
        "#     drawdown = (cumret - roll_max) / roll_max\n",
        "#     return abs(drawdown.min())\n",
        "\n",
        "# def win_rate(returns):\n",
        "#     return (returns > 0).mean()\n",
        "\n",
        "# def sortino_ratio(returns, rf=0.0):\n",
        "#     downside = returns[returns < 0].std()\n",
        "#     if downside == 0 or np.isnan(downside):\n",
        "#         return np.nan\n",
        "#     return (returns.mean() - rf) / downside\n",
        "\n",
        "# def calmar_ratio(cagr, mdd):\n",
        "#     if mdd == 0 or np.isnan(mdd):\n",
        "#         return np.nan\n",
        "#     return cagr / mdd\n",
        "\n",
        "# # ============================================================\n",
        "# # ðŸ§¾ Compute Metrics per Regime\n",
        "# # ============================================================\n",
        "# regime_stats = []\n",
        "\n",
        "# for regime, df_reg in df_portfolio.groupby(\"Regime\"):\n",
        "#     if df_reg.empty:\n",
        "#         continue\n",
        "\n",
        "#     df_reg = df_reg.copy().sort_index()\n",
        "#     cum = (1 + df_reg[\"Daily_Return\"].fillna(0)).cumprod()\n",
        "\n",
        "#     # --- Monthly compounded returns ---\n",
        "#     monthly_ret = (1 + df_reg[\"Daily_Return\"]).resample(\"M\").prod() - 1\n",
        "#     monthly_vol = df_reg[\"Daily_Return\"].resample(\"M\").std() * np.sqrt(21)\n",
        "\n",
        "#     cagr = CAGR(cum)\n",
        "#     mdd = max_drawdown(cum)\n",
        "#     wr = win_rate(df_reg[\"Daily_Return\"])\n",
        "#     sortino = sortino_ratio(df_reg[\"Daily_Return\"])\n",
        "#     calmar = calmar_ratio(cagr, mdd)\n",
        "\n",
        "#     regime_stats.append({\n",
        "#         \"Regime\": regime,\n",
        "#         \"CAGR_%\": cagr * 100,\n",
        "#         \"Max_Drawdown_%\": mdd * 100,\n",
        "#         \"Win_Rate_%\": wr * 100,\n",
        "#         \"Monthly_Return_%\": np.nanmean(monthly_ret) * 100,\n",
        "#         # \"Monthly_Volatility_%\": np.nanmean(monthly_vol) * 100,\n",
        "#         \"Sortino\": sortino,\n",
        "#         \"Calmar\": calmar\n",
        "#     })\n",
        "\n",
        "# # ============================================================\n",
        "# # ðŸ“‹ Summary Table\n",
        "# # ============================================================\n",
        "# df_regime_stats = pd.DataFrame(regime_stats).round(3)\n",
        "# cols = [\"Regime\", \"CAGR_%\", \"Max_Drawdown_%\", \"Win_Rate_%\",\n",
        "#         \"Monthly_Return_%\", \"Sortino\", \"Calmar\"]\n",
        "# df_regime_stats = df_regime_stats[cols]\n",
        "\n",
        "# print(\"\\nðŸ“ˆ Regime-wise Performance Summary (PyFolio Style)\")\n",
        "# display(df_regime_stats)\n",
        "\n",
        "# # ============================================================\n",
        "# # ðŸ’¾ Export\n",
        "# # ============================================================\n",
        "# df_regime_stats.to_excel(\"Hybrid_PyFolio_Regime_Summary.xlsx\", index=False)\n",
        "# print(\"âœ… Exported â†’ Hybrid_PyFolio_Regime_Summary.xlsx\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5itb0OTkjW2I"
      },
      "outputs": [],
      "source": [
        "# # ============================================================\n",
        "# # ðŸ“ˆ BLOCK 5.5 â€” Regime-wise Equity Curve & Performance Visualization\n",
        "# # ============================================================\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "\n",
        "# # --- Ensure regime alignment with portfolio ---\n",
        "# if \"Regime\" not in df_portfolio.columns:\n",
        "#     df_reg = df_all[[\"Date\", \"Regime\"]].drop_duplicates(subset=\"Date\", keep=\"last\")\n",
        "#     df_reg[\"Date\"] = pd.to_datetime(df_reg[\"Date\"])\n",
        "#     df_portfolio = df_portfolio.reset_index().merge(df_reg, on=\"Date\", how=\"left\").set_index(\"Date\")\n",
        "\n",
        "# # --- à¸ªà¸£à¹‰à¸²à¸‡ cumulative return à¹ƒà¸™à¹à¸•à¹ˆà¸¥à¸° regime ---\n",
        "# regime_curves = {}\n",
        "# for regime, df_reg in df_portfolio.groupby(\"Regime\"):\n",
        "#     if df_reg.empty:\n",
        "#         continue\n",
        "#     cum = (1 + df_reg[\"Daily_Return\"].fillna(0)).cumprod() - 1\n",
        "#     regime_curves[regime] = cum\n",
        "\n",
        "# # ============================================================\n",
        "# # ðŸ§¾ Summary Table (à¸£à¸§à¸¡à¸—à¸¸à¸ Regime)\n",
        "# # ============================================================\n",
        "# regime_summary = []\n",
        "# for regime, cum in regime_curves.items():\n",
        "#     ann_ret = (1 + cum.iloc[-1]) ** (252 / len(cum)) - 1\n",
        "#     mdd = abs(((1 + cum).cummax() - (1 + cum)) / (1 + cum).cummax()).max()\n",
        "#     sharpe = df_portfolio[df_portfolio[\"Regime\"] == regime][\"Daily_Return\"].mean() / df_portfolio[df_portfolio[\"Regime\"] == regime][\"Daily_Return\"].std()\n",
        "#     regime_summary.append({\n",
        "#         \"Regime\": regime,\n",
        "#         \"Final_Return_%\": cum.iloc[-1] * 100,\n",
        "#         \"Annualized_Return_%\": ann_ret * 100,\n",
        "#         \"Max_Drawdown_%\": mdd * 100,\n",
        "#         \"Sharpe\": sharpe\n",
        "#     })\n",
        "\n",
        "# df_regime_equity = pd.DataFrame(regime_summary).round(3)\n",
        "# print(\"\\nðŸ“Š Regime-wise Equity Curve Summary\")\n",
        "# display(df_regime_equity)\n",
        "\n",
        "# # ============================================================\n",
        "# # ðŸŽ¨ Visualization â€” Overlayed Regime Equity Curves\n",
        "# # ============================================================\n",
        "# palette = {\"Expansion\": \"#2ecc71\", \"Neutral\": \"#f1c40f\", \"Contraction\": \"#e74c3c\"}\n",
        "\n",
        "# plt.figure(figsize=(12, 6))\n",
        "# for regime, cum in regime_curves.items():\n",
        "#     plt.plot(cum.index, cum, label=regime, lw=2, color=palette.get(regime, \"gray\"))\n",
        "\n",
        "# plt.axhline(0, color=\"black\", lw=1)\n",
        "# plt.title(\"Regime-wise Equity Curves (Cumulative Return)\", fontsize=14, fontweight=\"bold\")\n",
        "# plt.ylabel(\"Cumulative Return\")\n",
        "# plt.legend(title=\"Regime\")\n",
        "# plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n",
        "\n",
        "# # ============================================================\n",
        "# # ðŸ“¦ Export\n",
        "# # ============================================================\n",
        "# with pd.ExcelWriter(\"Hybrid_Regime_Equity_Summary.xlsx\") as writer:\n",
        "#     df_regime_equity.to_excel(writer, sheet_name=\"Regime_Equity_Summary\", index=False)\n",
        "#     for regime, cum in regime_curves.items():\n",
        "#         cum_df = cum.reset_index()\n",
        "#         cum_df.columns = [\"Date\", f\"{regime}_Cumulative_Return\"]\n",
        "#         cum_df.to_excel(writer, sheet_name=f\"{regime}_Curve\", index=False)\n",
        "\n",
        "# print(\"âœ… Exported â†’ Hybrid_Regime_Equity_Summary.xlsx\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZdrW4XpZCuS"
      },
      "outputs": [],
      "source": [
        "# # ============================================================\n",
        "# # ðŸ“Š BLOCK 5.6 â€” Stock-wise Profit/Loss per Regime (Linked + Ranking Table)\n",
        "# # ============================================================\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "\n",
        "# # --- à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸ªà¸±à¸à¸à¸²à¸“ FinalSignal ---\n",
        "# df_price_sig = df_all.copy()\n",
        "# if \"FinalSignal\" not in df_price_sig.columns:\n",
        "#     print(\"âš ï¸ Auto-generating FinalSignal from Score / Pred_dLogclose ...\")\n",
        "#     if \"Score\" in df_price_sig.columns:\n",
        "#         df_price_sig[\"FinalSignal\"] = np.where(abs(df_price_sig[\"Score\"]) < 0.05, 0, np.sign(df_price_sig[\"Score\"]))\n",
        "#     elif \"Pred_dLogclose\" in df_price_sig.columns:\n",
        "#         df_price_sig[\"FinalSignal\"] = np.sign(df_price_sig[\"Pred_dLogclose\"])\n",
        "#     else:\n",
        "#         raise KeyError(\"No Score or Pred_dLogclose found to create FinalSignal.\")\n",
        "\n",
        "# # --- à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š Regime ---\n",
        "# if \"Regime\" not in df_price_sig.columns:\n",
        "#     df_reg = df_portfolio.reset_index()[[\"Date\", \"Regime\"]].drop_duplicates()\n",
        "#     df_price_sig = df_price_sig.merge(df_reg, on=\"Date\", how=\"left\")\n",
        "\n",
        "# # --- à¹€à¸žà¸´à¹ˆà¸¡ Weight à¸ˆà¸²à¸à¸žà¸­à¸£à¹Œà¸•à¸ˆà¸£à¸´à¸‡ (à¸–à¸·à¸­à¸«à¸¸à¹‰à¸™à¸¡à¸²à¸à¸™à¹‰à¸­à¸¢à¹à¸„à¹ˆà¹„à¸«à¸™) ---\n",
        "# df_portfolio_reset = df_portfolio.reset_index()[[\"Date\", \"Total_Portfolio\", \"Holdings_Value\", \"Cash\"]].copy()\n",
        "# df_price_sig = df_price_sig.merge(df_portfolio_reset, on=\"Date\", how=\"left\")\n",
        "\n",
        "# # à¸ªà¸¡à¸¡à¸•à¸´à¹ƒà¸«à¹‰ Weight à¸•à¹ˆà¸­à¸«à¸¸à¹‰à¸™ (position fraction) à¸ªà¸±à¸”à¸ªà¹ˆà¸§à¸™à¸ˆà¸²à¸à¸à¸¥à¸¢à¸¸à¸—à¸˜à¹Œà¸ˆà¸£à¸´à¸‡ (3%)\n",
        "# df_price_sig[\"Weight\"] = 0.03 * (df_price_sig[\"FinalSignal\"].shift(1) != 0).astype(int)\n",
        "\n",
        "# # --- à¸„à¸³à¸™à¸§à¸“ Return à¸‚à¸­à¸‡à¹à¸•à¹ˆà¸¥à¸°à¸«à¸¸à¹‰à¸™à¸•à¸²à¸¡à¸™à¹‰à¸³à¸«à¸™à¸±à¸à¸ˆà¸£à¸´à¸‡ ---\n",
        "# df_price_sig[\"Return\"] = df_price_sig.groupby(\"Stock\")[\"Close\"].pct_change()\n",
        "# df_price_sig[\"Strategy_Return\"] = df_price_sig[\"Return\"] * df_price_sig[\"Weight\"] * df_price_sig[\"FinalSignal\"].shift(1)\n",
        "\n",
        "# # ============================================================\n",
        "# # ðŸ§® à¸„à¸³à¸™à¸§à¸“à¸œà¸¥à¸•à¸­à¸šà¹à¸—à¸™à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¸•à¹ˆà¸­à¸«à¸¸à¹‰à¸™à¹à¸¢à¸à¸•à¸²à¸¡ Regime\n",
        "# # ============================================================\n",
        "# regime_profit = (\n",
        "#     df_price_sig.groupby([\"Regime\", \"Stock\"])[\"Strategy_Return\"]\n",
        "#     .mean()\n",
        "#     .reset_index()\n",
        "# )\n",
        "\n",
        "# # Annualize (à¸›à¸£à¸°à¸¡à¸²à¸“ 252 à¸§à¸±à¸™)\n",
        "# regime_profit[\"Avg_Ann_Return_%\"] = regime_profit[\"Strategy_Return\"] * 252 * 100\n",
        "\n",
        "# # ============================================================\n",
        "# # ðŸŽ¨ Visualization + Ranking\n",
        "# # ============================================================\n",
        "# regime_order = [\"Expansion\", \"Neutral\", \"Contraction\"]\n",
        "# palette = {\"Expansion\": \"#2ecc71\", \"Neutral\": \"#f1c40f\", \"Contraction\": \"#e74c3c\"}\n",
        "\n",
        "# ranking_tables = []\n",
        "\n",
        "# for regime in regime_order:\n",
        "#     sub = regime_profit[regime_profit[\"Regime\"] == regime]\n",
        "#     if sub.empty:\n",
        "#         continue\n",
        "\n",
        "#     sub_sorted = sub.sort_values(\"Avg_Ann_Return_%\", ascending=False)\n",
        "\n",
        "#     # --- Plot Bar Chart ---\n",
        "#     plt.figure(figsize=(10, 5))\n",
        "#     sns.barplot(\n",
        "#         data=sub_sorted,\n",
        "#         x=\"Stock\", y=\"Avg_Ann_Return_%\", color=palette[regime]\n",
        "#     )\n",
        "#     plt.axhline(0, color=\"black\", linewidth=1)\n",
        "#     plt.title(f\"Strategy Profit/Loss by Stock â€” {regime} Regime\", fontsize=14, fontweight='bold')\n",
        "#     plt.ylabel(\"Average Annualized Return (%)\")\n",
        "#     plt.xlabel(\"Stock\")\n",
        "#     plt.xticks(rotation=45, ha=\"right\")\n",
        "#     plt.tight_layout()\n",
        "#     plt.show()\n",
        "\n",
        "#     # --- Top & Bottom 3 Ranking ---\n",
        "#     top3 = sub_sorted.head(3).assign(Rank=\"Top 3\")\n",
        "#     worst3 = sub_sorted.tail(3).assign(Rank=\"Bottom 3\")\n",
        "#     ranking_tables.append(pd.concat([top3, worst3], ignore_index=True))\n",
        "\n",
        "# # ============================================================\n",
        "# # ðŸ“‹ Combine Ranking Table\n",
        "# # ============================================================\n",
        "# df_ranking = pd.concat(ranking_tables, ignore_index=True)[\n",
        "#     [\"Regime\", \"Rank\", \"Stock\", \"Avg_Ann_Return_%\"]\n",
        "# ]\n",
        "# df_ranking = df_ranking.sort_values([\"Regime\", \"Rank\", \"Avg_Ann_Return_%\"], ascending=[True, True, False])\n",
        "\n",
        "# print(\"\\nðŸ† Top 3 / Bottom 3 Stocks by Regime (based on Avg Annualized Return %)\")\n",
        "# display(df_ranking.round(2))\n",
        "\n",
        "# # ============================================================\n",
        "# # ðŸ’¾ Export\n",
        "# # ============================================================\n",
        "# with pd.ExcelWriter(\"Hybrid_Regime_StockPerformance_Linked.xlsx\") as writer:\n",
        "#     regime_profit.to_excel(writer, sheet_name=\"Stock_Returns\", index=False)\n",
        "#     df_ranking.to_excel(writer, sheet_name=\"Ranking_TopBottom\", index=False)\n",
        "\n",
        "# print(\"âœ… Exported â†’ Hybrid_Regime_StockPerformance_Linked.xlsx\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9qyuzYMWaAe"
      },
      "source": [
        "# Next period signal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wmv7nRibnd_1",
        "outputId": "bae2fe61-7bba-4383-b553-f18ccfb15802"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting minisom\n",
            "  Downloading minisom-2.3.5.tar.gz (12 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: minisom\n",
            "  Building wheel for minisom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for minisom: filename=MiniSom-2.3.5-py3-none-any.whl size=12031 sha256=2ecc501c7fb756b6991bb3887d7a7413fe68a86a67a1969541689e7810c44151\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/8c/a4/5b7aa56fa6ef11d536d45da775bcc5a2a1c163ff0f8f11990b\n",
            "Successfully built minisom\n",
            "Installing collected packages: minisom\n",
            "Successfully installed minisom-2.3.5\n"
          ]
        }
      ],
      "source": [
        "!pip install minisom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZS2XNdNrWfGR"
      },
      "outputs": [],
      "source": [
        "# # ============================================================\n",
        "# # ðŸ§­ BLOCK 5.7 â€” Next-Month Signal + Technical + SOM Suggestion\n",
        "# # ============================================================\n",
        "\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "\n",
        "# # ============================================================\n",
        "# # 1ï¸âƒ£ à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸«à¸£à¸·à¸­à¸ªà¸£à¹‰à¸²à¸‡ Technical Summary\n",
        "# # ============================================================\n",
        "\n",
        "# try:\n",
        "#     df_technical_latest\n",
        "#     print(\"âœ… Using existing df_technical_latest.\")\n",
        "# except NameError:\n",
        "#     print(\"âš ï¸ df_technical_latest not found â€” auto-generating mock version...\")\n",
        "#     df_technical_latest = pd.DataFrame({\n",
        "#         \"Stock\": df_forecast_summary[\"Stock\"].unique(),\n",
        "#         \"TechScore\": np.random.uniform(-1, 1, len(df_forecast_summary[\"Stock\"].unique())),\n",
        "#         \"MACD\": np.random.uniform(-1, 1, len(df_forecast_summary[\"Stock\"].unique())),\n",
        "#         \"RSI_14\": np.random.uniform(30, 70, len(df_forecast_summary[\"Stock\"].unique())),\n",
        "#         \"Pattern_Confidence\": np.random.uniform(0, 1, len(df_forecast_summary[\"Stock\"].unique())),\n",
        "#         \"Wave_Direction\": np.random.choice([\"Up\", \"Down\"], len(df_forecast_summary[\"Stock\"].unique())),\n",
        "#         \"Wave_Strength\": np.random.uniform(0, 1, len(df_forecast_summary[\"Stock\"].unique()))\n",
        "#     })\n",
        "#     print(\"âœ… df_technical_latest mock created.\")\n",
        "\n",
        "# # ============================================================\n",
        "# # 2ï¸âƒ£ à¸£à¸§à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ Macro + Technical â†’ Hybrid Signal\n",
        "# # ============================================================\n",
        "\n",
        "# df_signal = df_forecast_summary.copy()\n",
        "# df_signal = df_signal.merge(df_technical_latest, on=\"Stock\", how=\"left\")\n",
        "\n",
        "# # --- Macro bias ---\n",
        "# bias = np.sign(df_signal[\"Pred_dLogclose\"])\n",
        "\n",
        "# # --- Technical confirmation ---\n",
        "# techconfirm = (\n",
        "#     0.3 * df_signal[\"TechScore\"].fillna(0)\n",
        "#     + 0.2 * df_signal[\"MACD\"].fillna(0)\n",
        "#     + 0.1 * ((60 - abs(df_signal[\"RSI_14\"].fillna(50) - 50)) / 50)\n",
        "# )\n",
        "\n",
        "# # --- Pattern + Wave alignment ---\n",
        "# wave_align = np.where(df_signal[\"Wave_Direction\"] == np.where(bias>0, \"Up\", \"Down\"), 1, -1)\n",
        "# patternwave = (\n",
        "#     0.2 * df_signal[\"Pattern_Confidence\"].fillna(0)\n",
        "#     + 0.2 * df_signal[\"Wave_Strength\"].fillna(0) * wave_align\n",
        "# )\n",
        "\n",
        "# # --- Hybrid score ---\n",
        "# df_signal[\"Hybrid_Score\"] = 0.5*bias + 0.3*techconfirm + 0.2*patternwave\n",
        "\n",
        "# # --- Expected Return ---\n",
        "# df_signal[\"Expected_Return_%\"] = df_signal[\"Pred_dLogclose\"] * 100\n",
        "\n",
        "# # ============================================================\n",
        "# # 3ï¸âƒ£ Self-Organizing Map (SOM-style) Decision Zone\n",
        "# # ============================================================\n",
        "\n",
        "# def som_zone(row):\n",
        "#     if row[\"Hybrid_Score\"] > 0.1 and row[\"Pred_dLogclose\"] > 0:\n",
        "#         return \"BUY\"\n",
        "#     elif -0.1 <= row[\"Hybrid_Score\"] <= 0.1:\n",
        "#         return \"HOLD\"\n",
        "#     elif row[\"Hybrid_Score\"] < -0.1 and row[\"Pred_dLogclose\"] < 0:\n",
        "#         return \"SELL\"\n",
        "#     else:\n",
        "#         return \"HOLD\"\n",
        "\n",
        "# df_signal[\"SOM_Action\"] = df_signal.apply(som_zone, axis=1)\n",
        "\n",
        "# # ============================================================\n",
        "# # 4ï¸âƒ£ Sector Summary Table\n",
        "# # ============================================================\n",
        "\n",
        "# sector_summary = (\n",
        "#     df_signal.groupby(\"Sector\")\n",
        "#     .agg(\n",
        "#         N_Stocks=(\"Stock\", \"count\"),\n",
        "#         Avg_Hybrid_Score=(\"Hybrid_Score\", \"mean\"),\n",
        "#         Avg_Exp_Return=(\"Expected_Return_%\", \"mean\"),\n",
        "#         N_BUY=(\"SOM_Action\", lambda x: (x == \"BUY\").sum()),\n",
        "#         N_HOLD=(\"SOM_Action\", lambda x: (x == \"HOLD\").sum()),\n",
        "#         N_SELL=(\"SOM_Action\", lambda x: (x == \"SELL\").sum())\n",
        "#     )\n",
        "#     .reset_index()\n",
        "# )\n",
        "\n",
        "# sector_summary[\"%BUY\"] = sector_summary[\"N_BUY\"] / sector_summary[\"N_Stocks\"] * 100\n",
        "# sector_summary[\"%SELL\"] = sector_summary[\"N_SELL\"] / sector_summary[\"N_Stocks\"] * 100\n",
        "\n",
        "# def suggest_position(row):\n",
        "#     if row[\"%BUY\"] > 60 and row[\"Avg_Hybrid_Score\"] > 0.1:\n",
        "#         return \"Overweight\"\n",
        "#     elif row[\"%SELL\"] > 60 and row[\"Avg_Hybrid_Score\"] < -0.1:\n",
        "#         return \"Underweight\"\n",
        "#     else:\n",
        "#         return \"Neutral\"\n",
        "\n",
        "# sector_summary[\"Position_Suggestion\"] = sector_summary.apply(suggest_position, axis=1)\n",
        "# sector_summary = sector_summary.sort_values(\"Avg_Hybrid_Score\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "# # ============================================================\n",
        "# # 5ï¸âƒ£ à¹à¸ªà¸”à¸‡à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸£à¸§à¸¡\n",
        "# # ============================================================\n",
        "\n",
        "# print(\"\\n=== ðŸ“ˆ Next-Month Hybrid Trading Signals (Stock Level) ===\")\n",
        "# display(\n",
        "#     df_signal[[\n",
        "#         \"Stock\",\"Sector\",\"Pred_dLogclose\",\"Expected_Return_%\",\n",
        "#         \"TechScore\",\"Hybrid_Score\",\"SOM_Action\"\n",
        "#     ]].sort_values(\"Hybrid_Score\", ascending=False).round(3)\n",
        "# )\n",
        "\n",
        "# print(\"\\n=== ðŸ’¼ Sector Position Suggestion Table ===\")\n",
        "# display(\n",
        "#     sector_summary[[\n",
        "#         \"Sector\",\"N_Stocks\",\"N_BUY\",\"N_HOLD\",\"N_SELL\",\n",
        "#         \"%BUY\",\"%SELL\",\"Avg_Hybrid_Score\",\"Avg_Exp_Return\",\"Position_Suggestion\"\n",
        "#     ]].round(3)\n",
        "# )\n",
        "\n",
        "# # ============================================================\n",
        "# # ðŸŽ¨ SOM Visualization â€” Stock Labels + Hybrid Score\n",
        "# # ============================================================\n",
        "\n",
        "# from minisom import MiniSom\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# import numpy as np\n",
        "\n",
        "# # --- à¹€à¸•à¸£à¸µà¸¢à¸¡ features à¸ªà¸³à¸«à¸£à¸±à¸š SOM ---\n",
        "# features = [\"Pred_dLogclose\", \"TechScore\", \"MACD\", \"RSI_14\", \"Pattern_Confidence\", \"Wave_Strength\"]\n",
        "# X = StandardScaler().fit_transform(df_signal[features].fillna(0))\n",
        "\n",
        "# # --- Train SOM ---\n",
        "# som_x, som_y = 8, 8\n",
        "# som = MiniSom(x=som_x, y=som_y, input_len=X.shape[1],\n",
        "#               sigma=1.0, learning_rate=0.5,\n",
        "#               neighborhood_function='gaussian', random_seed=42)\n",
        "# som.random_weights_init(X)\n",
        "# som.train_random(X, 1000, verbose=False)\n",
        "\n",
        "# # --- à¸„à¸³à¸™à¸§à¸“à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡ node à¸‚à¸­à¸‡à¹à¸•à¹ˆà¸¥à¸°à¸«à¸¸à¹‰à¸™ ---\n",
        "# win_map = np.array([som.winner(x) for x in X])\n",
        "# df_signal[\"SOM_X\"] = win_map[:,0]\n",
        "# df_signal[\"SOM_Y\"] = win_map[:,1]\n",
        "\n",
        "# # --- à¸ªà¸µà¸‚à¸­à¸‡ Action ---\n",
        "# color_map = {\"BUY\": \"#2ecc71\", \"HOLD\": \"#f1c40f\", \"SELL\": \"#e74c3c\"}\n",
        "\n",
        "# # --- à¸ªà¸£à¹‰à¸²à¸‡à¸„à¹ˆà¸²à¹€à¸‰à¸¥à¸µà¹ˆà¸¢ Hybrid Score à¸•à¹ˆà¸­ node ---\n",
        "# node_mean = (\n",
        "#     df_signal.groupby([\"SOM_X\",\"SOM_Y\"])[\"Hybrid_Score\"]\n",
        "#     .mean().unstack().fillna(0)\n",
        "# )\n",
        "\n",
        "# # ============================================================\n",
        "# # ðŸ§  BLOCK 5.7 â€” Enhanced SOM Cluster Map (Hybrid + Technical)\n",
        "# # ============================================================\n",
        "\n",
        "# from minisom import MiniSom\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# import numpy as np\n",
        "\n",
        "# # --- âš™ï¸ à¹€à¸•à¸£à¸µà¸¢à¸¡ features à¸ªà¸³à¸«à¸£à¸±à¸š SOM ---\n",
        "# df_signal[\"RSI_14_scaled\"] = (df_signal[\"RSI_14\"] - 50) / 25           # RSI 25â€“75 â†’ -1 à¸–à¸¶à¸‡ +1\n",
        "# df_signal[\"Hybrid_Score_Scaled\"] = df_signal[\"Hybrid_Score\"] * 2.5     # à¸‚à¸¢à¸²à¸¢ dynamic range\n",
        "\n",
        "# features = [\n",
        "#     \"Pred_dLogclose\", \"TechScore\", \"MACD\",\n",
        "#     \"RSI_14_scaled\", \"Pattern_Confidence\", \"Wave_Strength\"\n",
        "# ]\n",
        "# X = StandardScaler().fit_transform(df_signal[features].fillna(0))\n",
        "\n",
        "# # --- ðŸ”„ Train SOM ---\n",
        "# som_x, som_y = 8, 8\n",
        "# som = MiniSom(\n",
        "#     x=som_x, y=som_y, input_len=X.shape[1],\n",
        "#     sigma=1.0, learning_rate=0.5,\n",
        "#     neighborhood_function='gaussian', random_seed=42\n",
        "# )\n",
        "# som.random_weights_init(X)\n",
        "# som.train_random(X, 1000, verbose=False)\n",
        "\n",
        "# # --- ðŸ“ à¸«à¸² node à¸‚à¸­à¸‡à¹à¸•à¹ˆà¸¥à¸°à¸«à¸¸à¹‰à¸™ ---\n",
        "# win_map = np.array([som.winner(x) for x in X])\n",
        "# df_signal[\"SOM_X\"] = win_map[:, 0]\n",
        "# df_signal[\"SOM_Y\"] = win_map[:, 1]\n",
        "\n",
        "# # --- ðŸŽ¨ à¸ªà¸µ Action ---\n",
        "# color_map = {\"BUY\": \"#2ecc71\", \"HOLD\": \"#f1c40f\", \"SELL\": \"#e74c3c\"}\n",
        "\n",
        "# # --- ðŸ§® à¸„à¸³à¸™à¸§à¸“à¸„à¹ˆà¸²à¹€à¸‰à¸¥à¸µà¹ˆà¸¢ Hybrid Score à¸•à¹ˆà¸­ node ---\n",
        "# node_mean = (\n",
        "#     df_signal.groupby([\"SOM_X\", \"SOM_Y\"])[\"Hybrid_Score_Scaled\"]\n",
        "#     .mean().unstack().fillna(0)\n",
        "# )\n",
        "\n",
        "# # ============================================================\n",
        "# # ðŸŽ¨ Visualization â€” SOM Heatmap + Stock Labels + Score\n",
        "# # ============================================================\n",
        "# plt.figure(figsize=(9, 8))\n",
        "# plt.title(\"ðŸ§  SOM Cluster Map â€” Hybrid (Macro + Technical)\", fontsize=14, fontweight=\"bold\")\n",
        "\n",
        "# # --- Heatmap à¸žà¸·à¹‰à¸™à¸«à¸¥à¸±à¸‡ (Dynamic scale) ---\n",
        "# vmin, vmax = node_mean.min().min(), node_mean.max().max()\n",
        "# sns.heatmap(\n",
        "#     node_mean,\n",
        "#     cmap=\"RdYlGn\", vmin=vmin, vmax=vmax,\n",
        "#     cbar_kws={\"label\": \"Mean Hybrid Score\"},\n",
        "#     square=True, linewidths=0.5, alpha=0.25\n",
        "# )\n",
        "\n",
        "# # --- Plot à¸«à¸¸à¹‰à¸™à¹à¸•à¹ˆà¸¥à¸°à¸•à¸±à¸§ (à¸Šà¸·à¹ˆà¸­ + Score + à¸ªà¸µ Action) ---\n",
        "# for _, row in df_signal.iterrows():\n",
        "#     x, y = row[\"SOM_X\"] + 0.5, row[\"SOM_Y\"] + 0.5\n",
        "#     color = color_map.get(row[\"SOM_Action\"], \"gray\")\n",
        "#     plt.scatter(x, y, s=200, color=color, edgecolor=\"black\", alpha=0.9, zorder=3)\n",
        "#     plt.text(\n",
        "#         x, y,\n",
        "#         f\"{row['Stock']} ({row['Hybrid_Score']:+.2f})\",\n",
        "#         fontsize=8, ha=\"center\", va=\"center\",\n",
        "#         color=\"black\", fontweight=\"bold\"\n",
        "#     )\n",
        "\n",
        "# plt.xlabel(\"SOM X (Cluster Column)\")\n",
        "# plt.ylabel(\"SOM Y (Cluster Row)\")\n",
        "# plt.grid(False)\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # ============================================================\n",
        "# # 7ï¸âƒ£ Export Excel\n",
        "# # ============================================================\n",
        "\n",
        "# with pd.ExcelWriter(\"Hybrid_SOM_Position_Suggestion.xlsx\") as writer:\n",
        "#     df_signal.to_excel(writer, sheet_name=\"Stock_Signals\", index=False)\n",
        "#     sector_summary.to_excel(writer, sheet_name=\"Sector_Suggestion\", index=False)\n",
        "\n",
        "# print(\"âœ… Exported â†’ Hybrid_SOM_Position_Suggestion.xlsx\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUCqn-QRRbre"
      },
      "source": [
        "# Dynamic portfolio = Quantitative deterministic (Sharpe-weighted + Signal flip)\n",
        "\n",
        "=> à¹€à¸£à¹‡à¸§à¸à¸§à¹ˆà¸², à¹ƒà¸Šà¹‰à¹à¸™à¸§ Bellman update à¹€à¸šà¸·à¹‰à¸­à¸‡à¸•à¹‰à¸™à¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡ train RL model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ttADXjSRby9"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "\n",
        "# # ============================================================\n",
        "# # âš™ï¸ BLOCK 6 (Revised): Long-Only RL Deterministic Allocation (All outputs in %)\n",
        "# # ============================================================\n",
        "\n",
        "# def adaptive_portfolio_rl_longonly(evaluation_results, window_corr=12, window_sharpe=6):\n",
        "#     all_dates = sorted(list(set().union(*[df.index for df in evaluation_results.values()])))\n",
        "#     portfolio_returns = pd.DataFrame(index=all_dates)\n",
        "\n",
        "#     adj_signals = {}\n",
        "#     sh_ratio = {}\n",
        "\n",
        "#     # --- Step 1: Compute adjusted signal and Sharpe ---\n",
        "#     for stock, df_eval in evaluation_results.items():\n",
        "#         df = df_eval.copy()\n",
        "#         df[\"Signal_raw\"] = np.sign(df[\"Pred_dLogclose\"])\n",
        "#         df[\"Corr_Pred_Actual\"] = df[\"Pred_dLogclose\"].rolling(window_corr).corr(df[\"Actual_dLogclose\"])\n",
        "#         df[\"Signal_adj\"] = np.where(df[\"Corr_Pred_Actual\"] < 0, -df[\"Signal_raw\"], df[\"Signal_raw\"])\n",
        "#         df[\"Return\"] = df[\"Actual_dLogclose\"]\n",
        "#         df[\"Sharpe\"] = (\n",
        "#             df[\"Return\"].rolling(window_sharpe).mean() / df[\"Return\"].rolling(window_sharpe).std()\n",
        "#         )\n",
        "#         adj_signals[stock] = df[\"Signal_adj\"]\n",
        "#         sh_ratio[stock] = df[\"Sharpe\"]\n",
        "#         portfolio_returns[stock] = df[\"Return\"]\n",
        "\n",
        "#     weights_df = pd.DataFrame(index=all_dates, columns=list(evaluation_results.keys()))\n",
        "#     port_ret_series = []\n",
        "\n",
        "#     # --- Step 2: Compute weights (non-negative long-only) ---\n",
        "#     for t, date in enumerate(all_dates):\n",
        "#         w_list, r_list = [], []\n",
        "\n",
        "#         for stock in evaluation_results.keys():\n",
        "#             sig = adj_signals[stock].reindex(all_dates).iloc[t]\n",
        "#             shrp = sh_ratio[stock].reindex(all_dates).iloc[t]\n",
        "#             ret = portfolio_returns[stock].reindex(all_dates).iloc[t]\n",
        "\n",
        "#             if np.isnan(sig) or np.isnan(shrp) or np.isnan(ret):\n",
        "#                 continue\n",
        "\n",
        "#             w_val = sig * abs(shrp)\n",
        "#             w_list.append((stock, w_val))\n",
        "#             r_list.append((stock, ret))\n",
        "\n",
        "#         if not w_list:\n",
        "#             port_ret_series.append(0.0)\n",
        "#             continue\n",
        "\n",
        "#         w_df = pd.DataFrame(w_list, columns=[\"Stock\", \"w\"])\n",
        "#         w_df[\"w\"] = np.clip(w_df[\"w\"], 0, None)\n",
        "\n",
        "#         if w_df[\"w\"].sum() > 0:\n",
        "#             w_df[\"w\"] /= w_df[\"w\"].sum()\n",
        "#         else:\n",
        "#             w_df[\"w\"] = 1.0 / len(w_df)\n",
        "\n",
        "#         for s in w_df[\"Stock\"]:\n",
        "#             weights_df.loc[date, s] = w_df.loc[w_df[\"Stock\"] == s, \"w\"].iloc[0]\n",
        "\n",
        "#         r_df = pd.DataFrame(r_list, columns=[\"Stock\", \"Return\"])\n",
        "#         merged = pd.merge(w_df, r_df, on=\"Stock\")\n",
        "#         port_ret = np.sum(merged[\"w\"] * merged[\"Return\"])\n",
        "#         port_ret_series.append(port_ret)\n",
        "\n",
        "#     # --- Step 3: Portfolio performance summary ---\n",
        "#     portfolio_returns[\"Portfolio_Return\"] = port_ret_series\n",
        "#     portfolio_returns[\"Cumulative_Portfolio\"] = np.exp(portfolio_returns[\"Portfolio_Return\"].cumsum()) - 1\n",
        "\n",
        "#     # âœ… Convert ALL numeric columns to percentage\n",
        "#     portfolio_returns_pct = portfolio_returns.copy() * 100\n",
        "#     portfolio_returns_pct.columns = [col + \"(%)\" for col in portfolio_returns.columns]\n",
        "\n",
        "#     # Compute summary statistics in %\n",
        "#     avg_r = portfolio_returns[\"Portfolio_Return\"].mean() * 100\n",
        "#     std_r = portfolio_returns[\"Portfolio_Return\"].std() * 100\n",
        "#     sharpe_r = avg_r / std_r if std_r > 0 else np.nan\n",
        "#     cum_r = portfolio_returns[\"Cumulative_Portfolio\"].iloc[-1] * 100\n",
        "\n",
        "#     summary = pd.DataFrame([{\n",
        "#         \"CumReturn_%\": cum_r,\n",
        "#         \"AvgMonthlyReturn_%\": avg_r,\n",
        "#         \"Volatility_%\": std_r,\n",
        "#         \"Sharpe\": sharpe_r\n",
        "#     }])\n",
        "\n",
        "#     weights_df = weights_df * 100  # export weights in %\n",
        "#     return portfolio_returns_pct, weights_df, summary\n",
        "\n",
        "\n",
        "# # ============================================================\n",
        "# # ðŸš€ Run Adaptive Allocation (Long-only, % export)\n",
        "# # ============================================================\n",
        "\n",
        "# portfolio_rl, weights_rl, summary_rl = adaptive_portfolio_rl_longonly(evaluation_results)\n",
        "\n",
        "# with pd.ExcelWriter(\"ECM_RL_AdaptivePortfolio_LongOnly_Percent.xlsx\") as writer:\n",
        "#     summary_rl.to_excel(writer, sheet_name=\"Portfolio_Summary\", index=False)\n",
        "#     weights_rl.to_excel(writer, sheet_name=\"Dynamic_Weights(%)\")\n",
        "#     portfolio_rl.to_excel(writer, sheet_name=\"Portfolio_Returns(%)\")\n",
        "\n",
        "# print(\"\\nâœ… Exported â†’ ECM_RL_AdaptivePortfolio_LongOnly_Percent.xlsx\")\n",
        "\n",
        "# print(\"\\n=== ðŸ’¼ Portfolio Summary ===\")\n",
        "# display(summary_rl)\n",
        "\n",
        "# print(\"\\n=== ðŸ“Š Dynamic Weights (last 5 dates, %) ===\")\n",
        "# display(weights_rl.tail(5))\n",
        "\n",
        "# print(\"\\n=== ðŸ“ˆ Portfolio Return Curve (last 10, in %) ===\")\n",
        "# display(portfolio_rl.tail(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJhOJJ0JS_MH"
      },
      "outputs": [],
      "source": [
        "# # ============================================================\n",
        "# # ðŸŽ¨ BLOCK 7: Visualization of Dynamic Portfolio Allocation (By Sector)\n",
        "# # ============================================================\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "\n",
        "# plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
        "# sns.set(font_scale=0.9)\n",
        "\n",
        "# # ============================================================\n",
        "# # ðŸ”¹ STEP 1: Prepare sector mapping\n",
        "# # ============================================================\n",
        "\n",
        "# # à¸ªà¸£à¹‰à¸²à¸‡ DataFrame mapping à¸ˆà¸²à¸ evaluation_results (à¸«à¸£à¸·à¸­ summary à¹€à¸”à¸´à¸¡)\n",
        "# sector_map = {}\n",
        "# for stock, df_eval in evaluation_results.items():\n",
        "#     sector = df_eval[\"Sector\"].iloc[0]\n",
        "#     sector_map[stock] = sector\n",
        "\n",
        "# # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸¡à¸µ mapping à¸„à¸£à¸šà¹„à¸«à¸¡\n",
        "# print(\"ðŸ“Š Sector mapping:\", sector_map)\n",
        "\n",
        "# # ============================================================\n",
        "# # ðŸ”¹ STEP 2: Convert weights_rl à¹€à¸›à¹‡à¸™à¸£à¸²à¸¢ Sector\n",
        "# # ============================================================\n",
        "\n",
        "# weights_sector = pd.DataFrame(index=weights_rl.index)\n",
        "\n",
        "# for stock in weights_rl.columns:\n",
        "#     sector = sector_map.get(stock, \"Unknown\")\n",
        "#     if sector not in weights_sector.columns:\n",
        "#         weights_sector[sector] = 0.0\n",
        "#     weights_sector[sector] += pd.to_numeric(weights_rl[stock], errors=\"coerce\").fillna(0)\n",
        "\n",
        "# # Normalize à¹ƒà¸«à¹‰ sum à¸•à¹ˆà¸­à¹à¸–à¸§ = 100%\n",
        "# weights_sector = weights_sector.div(weights_sector.sum(axis=1), axis=0) * 100\n",
        "\n",
        "# print(\"\\nâœ… Sector-level weights created:\")\n",
        "# display(weights_sector.tail(3))\n",
        "\n",
        "# # ============================================================\n",
        "# # ðŸ”¹ STEP 3: Heatmap by Sector\n",
        "# # ============================================================\n",
        "\n",
        "# fig, ax = plt.subplots(figsize=(10, 5))\n",
        "# sns.heatmap(weights_sector.T, cmap=\"YlOrRd\", cbar_kws={'label': 'Weight (%)'}, ax=ax)\n",
        "# ax.set_title(\"Dynamic Portfolio Allocation by Sector (%)\", fontsize=14, weight=\"bold\")\n",
        "# ax.set_xlabel(\"Date\")\n",
        "# ax.set_ylabel(\"Sector\")\n",
        "# plt.xticks(rotation=45)\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n",
        "\n",
        "# # ============================================================\n",
        "# # ðŸ”¹ STEP 4: Area Chart by Sector\n",
        "# # ============================================================\n",
        "\n",
        "# fig, ax = plt.subplots(figsize=(12, 6))\n",
        "# weights_sector.plot.area(ax=ax, stacked=True, alpha=0.8)\n",
        "# ax.set_title(\"Portfolio Allocation Composition by Sector (%)\", fontsize=14, weight=\"bold\")\n",
        "# ax.set_ylabel(\"Weight (%)\")\n",
        "# ax.set_xlabel(\"Date\")\n",
        "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', title=\"Sector\")\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n",
        "\n",
        "# # ============================================================\n",
        "# # ðŸ”¹ STEP 5: Pie Chart (à¸¥à¹ˆà¸²à¸ªà¸¸à¸”)\n",
        "# # ============================================================\n",
        "\n",
        "# last_date = weights_sector.index[-1]\n",
        "# last_weights = weights_sector.loc[last_date].dropna()\n",
        "# fig, ax = plt.subplots(figsize=(6, 6))\n",
        "# ax.pie(last_weights, labels=last_weights.index, autopct='%1.1f%%', startangle=90)\n",
        "# ax.set_title(f\"Sector Allocation on {last_date.strftime('%Y-%m')}\", fontsize=13, weight=\"bold\")\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdJUB1kDXoET"
      },
      "source": [
        "# Next-Month Trading Plan after Bellman theory  => Exclude it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFOUxtSMVvM4"
      },
      "outputs": [],
      "source": [
        "# # ============================================================\n",
        "# # ðŸ“ˆ BLOCK: Sharpe-weighted + Signal Flip (with Flip Info + Comments)\n",
        "# # ============================================================\n",
        "\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "\n",
        "# # ===== 1ï¸âƒ£ Sharpe-weighted Portfolio Allocation =====\n",
        "# df_perf = df_strategy_summary.copy()\n",
        "# df_perf[\"Sharpe_Positive\"] = np.where(df_perf[\"Sharpe_Ratio\"] > 0, df_perf[\"Sharpe_Ratio\"], 0)\n",
        "# total_sharpe = df_perf[\"Sharpe_Positive\"].sum()\n",
        "# df_perf[\"Weight_Sharpe\"] = np.where(total_sharpe > 0, df_perf[\"Sharpe_Positive\"] / total_sharpe, 0)\n",
        "\n",
        "# # ===== 2ï¸âƒ£ à¸ªà¸±à¸à¸à¸²à¸“à¸žà¸¢à¸²à¸à¸£à¸“à¹Œà¸¥à¹ˆà¸²à¸ªà¸¸à¸” =====\n",
        "# df_signal_next = df_forecast_summary.copy()\n",
        "# df_signal_next = df_signal_next.merge(df_perf[[\"Stock\", \"Sharpe_Ratio\", \"Weight_Sharpe\"]], on=\"Stock\", how=\"left\")\n",
        "\n",
        "# # ===== 3ï¸âƒ£ à¸ªà¸£à¹‰à¸²à¸‡à¸ªà¸±à¸à¸à¸²à¸“à¹à¸¥à¸°à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸šà¸à¸²à¸£ Flip =====\n",
        "# df_signal_next[\"Raw_Signal\"] = np.where(df_signal_next[\"Pred_dLogclose\"] > 0, \"BUY\", \"SELL\")\n",
        "# df_signal_next[\"Flip_Flag\"] = np.where(df_signal_next[\"Sharpe_Ratio\"] < 0, True, False)\n",
        "# df_signal_next[\"Final_Signal\"] = np.where(\n",
        "#     df_signal_next[\"Flip_Flag\"],\n",
        "#     np.where(df_signal_next[\"Raw_Signal\"] == \"BUY\", \"SELL\", \"BUY\"),\n",
        "#     df_signal_next[\"Raw_Signal\"]\n",
        "# )\n",
        "\n",
        "# # ===== 4ï¸âƒ£ à¹€à¸žà¸´à¹ˆà¸¡ Comment / Interpretation =====\n",
        "# df_signal_next[\"Flip_Status\"] = np.where(df_signal_next[\"Flip_Flag\"], \"ðŸ” Flipped\", \"âœ… Normal\")\n",
        "# df_signal_next[\"Comment\"] = np.where(\n",
        "#     df_signal_next[\"Flip_Flag\"],\n",
        "#     \"Model weak (Sharpe < 0) â†’ Contrarian signal\",\n",
        "#     \"Model consistent (Sharpe > 0)\"\n",
        "# )\n",
        "\n",
        "# df_signal_next[\"Expected_Return_%\"] = df_signal_next[\"Pred_dLogclose\"] * 100\n",
        "# df_signal_next[\"Weighted_Exp_Return_%\"] = df_signal_next[\"Expected_Return_%\"] * df_signal_next[\"Weight_Sharpe\"]\n",
        "\n",
        "# # ===== 5ï¸âƒ£ Export & Display =====\n",
        "# cols_show = [\n",
        "#     \"Stock\", \"Sector\", \"Sharpe_Ratio\", \"Weight_Sharpe\",\n",
        "#     \"Pred_dLogclose\", \"Expected_Return_%\",\n",
        "#     \"Raw_Signal\", \"Final_Signal\", \"Flip_Status\", \"Comment\"\n",
        "# ]\n",
        "\n",
        "# # ðŸ”¹ à¹€à¸£à¸µà¸¢à¸‡à¸•à¸²à¸¡ Expected_Return_% à¸ˆà¸²à¸à¸¡à¸²à¸à¹„à¸›à¸™à¹‰à¸­à¸¢\n",
        "# df_signal_next = df_signal_next[cols_show].sort_values(\"Expected_Return_%\", ascending=False)\n",
        "\n",
        "# df_signal_next.to_excel(\"NextMonth_SignalPlan_SharpeWeighted_FlipInfo.xlsx\", index=False)\n",
        "# print(\"âœ… Exported â†’ NextMonth_SignalPlan_SharpeWeighted_FlipInfo.xlsx\")\n",
        "\n",
        "# # ===== 6ï¸âƒ£ PRINT TABLE =====\n",
        "# print(\"\\n=== ðŸ“ˆ Next-Month Trading Signals (Sharpe-weighted + Flip Info, Sorted by Expected Return) ===\")\n",
        "# display(df_signal_next)\n",
        "\n",
        "# # ===== 7ï¸âƒ£ Visualization =====\n",
        "# plt.figure(figsize=(10,6))\n",
        "# sns.barplot(\n",
        "#     data=df_signal_next,\n",
        "#     x=\"Stock\",\n",
        "#     y=\"Expected_Return_%\",\n",
        "#     hue=\"Final_Signal\",\n",
        "#     dodge=False,\n",
        "#     order=df_signal_next[\"Stock\"]  # à¹ƒà¸Šà¹‰à¸¥à¸³à¸”à¸±à¸šà¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸šà¸—à¸µà¹ˆà¹€à¸£à¸µà¸¢à¸‡à¹ƒà¸™à¸•à¸²à¸£à¸²à¸‡\n",
        "# )\n",
        "# plt.axhline(0, color=\"black\", lw=1)\n",
        "# plt.title(\"Next-Month Expected Return by Stock (Sharpe-weighted + Flip)\", weight=\"bold\")\n",
        "# plt.xticks(rotation=45, ha='right')\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHz_qdv85r_M"
      },
      "source": [
        "1. à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸¡à¹€à¸”à¸¥ Deep Learning (Technical Side) [à¸‡à¸²à¸™à¸«à¸¥à¸±à¸à¸‚à¸­à¸‡à¸„à¸¸à¸“]à¸ªà¹ˆà¸§à¸™à¸™à¸µà¹‰à¸„à¸·à¸­à¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡ \"à¸•à¸²\" à¸‚à¹‰à¸²à¸‡à¸—à¸µà¹ˆà¸ªà¸­à¸‡à¹ƒà¸«à¹‰ AI (à¸‚à¹‰à¸²à¸‡à¹à¸£à¸à¸„à¸·à¸­ ARDL à¸‚à¸­à¸‡à¹€à¸žà¸·à¹ˆà¸­à¸™)à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸¡à¹€à¸”à¸¥ LSTM à¸«à¸£à¸·à¸­ GRU: à¹€à¸‚à¸µà¸¢à¸™ Code à¹à¸¢à¸à¸­à¸­à¸à¸¡à¸²à¹€à¸žà¸·à¹ˆà¸­à¸£à¸±à¸šà¸à¸£à¸²à¸Ÿà¸£à¸²à¸„à¸²à¹à¸¥à¸° Technical Indicators (RSI, MACD) 1à¸à¸³à¸«à¸™à¸”à¸„à¹ˆà¸² Output ($b_t$): à¸•à¹‰à¸­à¸‡à¹€à¸—à¸£à¸™à¹ƒà¸«à¹‰à¹‚à¸¡à¹€à¸”à¸¥à¸—à¸³à¸™à¸²à¸¢à¸­à¸­à¸à¸¡à¸²à¹€à¸›à¹‡à¸™ à¸„à¸§à¸²à¸¡à¸™à¹ˆà¸²à¸ˆà¸°à¹€à¸›à¹‡à¸™ (Probability) à¸§à¹ˆà¸²à¹€à¸”à¸·à¸­à¸™à¸–à¸±à¸”à¹„à¸›à¸•à¸¥à¸²à¸”à¸ˆà¸° Bull, Bear à¸«à¸£à¸·à¸­ Neutral 2à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸£à¸°à¸§à¸±à¸‡: à¸­à¸¢à¹ˆà¸²à¹€à¸œà¸¥à¸­à¸—à¸³à¸™à¸²à¸¢à¹€à¸›à¹‡à¸™ \"à¸£à¸²à¸„à¸²à¸›à¸´à¸”\" (Price Regression) à¹€à¸žà¸£à¸²à¸°à¹ƒà¸™ Proposal à¸£à¸°à¸šà¸¸à¸Šà¸±à¸”à¹€à¸ˆà¸™à¸§à¹ˆà¸²à¸•à¹‰à¸­à¸‡à¹€à¸›à¹‡à¸™à¸ªà¸±à¸à¸à¸²à¸“à¸„à¸§à¸²à¸¡à¸™à¹ˆà¸²à¸ˆà¸°à¹€à¸›à¹‡à¸™ (Classification/Probability) à¹€à¸žà¸·à¹ˆà¸­à¸ªà¹ˆà¸‡à¸•à¹ˆà¸­à¹ƒà¸«à¹‰ RL2. à¸ªà¸£à¹‰à¸²à¸‡à¸£à¸°à¸šà¸š Reinforcement Learning (The Brain) [à¸‡à¸²à¸™à¸«à¸¥à¸±à¸à¸‚à¸­à¸‡à¸„à¸¸à¸“]à¸™à¸µà¹ˆà¸„à¸·à¸­ \"à¸ªà¸¡à¸­à¸‡\" à¸‚à¸­à¸‡à¸£à¸°à¸šà¸šà¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¹€à¸­à¸²à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸¸à¸à¸­à¸¢à¹ˆà¸²à¸‡à¸¡à¸²à¸£à¸§à¸¡à¸à¸±à¸™à¸­à¸­à¸à¹à¸šà¸š Environment: à¹€à¸‚à¸µà¸¢à¸™ Class Env à¹ƒà¸™ Python à¹ƒà¸«à¹‰à¸£à¸±à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥ 2 à¸—à¸²à¸‡:Macro Signals ($m_t$): à¸£à¸±à¸šà¸„à¹ˆà¸²à¸—à¸µà¹ˆà¹€à¸žà¸·à¹ˆà¸­à¸™à¸„à¸¸à¸“à¸—à¸³à¹€à¸ªà¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§ (à¸ˆà¸²à¸ ARDL)Technical Signals ($b_t$): à¸£à¸±à¸šà¸„à¹ˆà¸²à¸ˆà¸²à¸à¹‚à¸¡à¹€à¸”à¸¥ Deep Learning à¸—à¸µà¹ˆà¸„à¸¸à¸“à¸—à¸³à¹ƒà¸™à¸‚à¹‰à¸­ 1à¸£à¸§à¸¡ State ($S_t$): à¸ˆà¸±à¸šà¸ªà¸­à¸‡à¸„à¹ˆà¸²à¸‚à¹‰à¸²à¸‡à¸šà¸™à¸¡à¸²à¸£à¸§à¸¡à¸à¸±à¸™à¹€à¸›à¹‡à¸™ State à¹€à¸”à¸µà¸¢à¸§ 3Train PPO Agent: à¸£à¸±à¸™à¸à¸²à¸£à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰ AI à¸•à¸±à¸”à¸ªà¸´à¸™à¹ƒà¸ˆ (Buy/Hold/Sell) à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰ Reward Function à¸—à¸µà¹ˆà¸«à¸±à¸à¸¥à¸šà¸„à¹ˆà¸² Drawdown 43. à¸à¸²à¸£à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¸±à¸šà¹€à¸žà¸·à¹ˆà¸­à¸™ (Data Interface)à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¸‡à¸²à¸™à¸›à¸£à¸°à¸à¸­à¸šà¸à¸±à¸™à¹„à¸”à¹‰à¸‡à¹ˆà¸²à¸¢ à¸„à¸¸à¸“à¸•à¹‰à¸­à¸‡à¸•à¸à¸¥à¸‡à¸à¸±à¸šà¹€à¸žà¸·à¹ˆà¸­à¸™à¹ƒà¸«à¹‰à¸Šà¸±à¸”à¹€à¸ˆà¸™à¸„à¸£à¸±à¸š:Request: à¸šà¸­à¸à¹€à¸žà¸·à¹ˆà¸­à¸™à¸§à¹ˆà¸² \"à¸‚à¸­à¹„à¸Ÿà¸¥à¹Œ Excel/CSV à¸—à¸µà¹ˆà¸¡à¸µà¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ Predicted Return à¸«à¸£à¸·à¸­ Macro Signal à¸ˆà¸²à¸ ARDL à¸£à¸²à¸¢à¹€à¸”à¸·à¸­à¸™ à¸¡à¸²à¹ƒà¸«à¹‰à¸‰à¸±à¸™à¸«à¸™à¹ˆà¸­à¸¢\"Action: à¸„à¸¸à¸“à¸ˆà¸°à¹€à¸­à¸²à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸™à¸±à¹‰à¸™à¸¡à¸²à¹€à¸›à¹‡à¸™ Input à¸ªà¹ˆà¸§à¸™ $m_t$ à¹ƒà¸™ Code RL à¸‚à¸­à¸‡à¸„à¸¸à¸“à¸„à¸£à¸±à¸š4. Backtesting & Reportà¸™à¸³ AI à¸—à¸µà¹ˆà¹€à¸—à¸£à¸™à¹€à¸ªà¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§ à¸¡à¸²à¹€à¸—à¸£à¸”à¸ˆà¸³à¸¥à¸­à¸‡à¸à¸±à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸›à¸µ 2025 à¹à¸¥à¸°à¸ªà¸£à¸¸à¸›à¸œà¸¥à¸§à¸±à¸”à¸„à¹ˆà¸² Sharpe Ratio, Drawdown à¹€à¸—à¸µà¸¢à¸šà¸à¸±à¸šà¸•à¸¥à¸²à¸” 5à¸ªà¸£à¸¸à¸›: à¸‡à¸²à¸™à¸„à¸¸à¸“à¸•à¸­à¸™à¸™à¸µà¹‰à¸¥à¸”à¸¥à¸‡à¹€à¸«à¸¥à¸·à¸­à¹à¸„à¹ˆà¸ªà¸²à¸¢ Programming & AI à¸¥à¹‰à¸§à¸™à¹† à¸„à¸·à¸­ \"à¸—à¸³ DL à¹ƒà¸«à¹‰à¹€à¸ªà¸£à¹‡à¸ˆ -> à¹€à¸­à¸² ARDL à¸‚à¸­à¸‡à¹€à¸žà¸·à¹ˆà¸­à¸™à¸¡à¸²à¸¢à¸±à¸”à¹ƒà¸ªà¹ˆ RL -> à¹€à¸—à¸£à¸™ AI -> à¸§à¸±à¸”à¸œà¸¥\" à¸„à¸£à¸±à¸š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EU79AUs_ywur",
        "outputId": "8a1b50a7-19d3-4220-8725-47db2c975665"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NbConvertApp] WARNING | pattern 'Semester2_V1_AQT_ARDLTrading_Macro&Technical.ipynb' matched no files\n",
            "This application is used to convert notebook files (*.ipynb)\n",
            "        to various other formats.\n",
            "\n",
            "        WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\n",
            "\n",
            "Options\n",
            "=======\n",
            "The options below are convenience aliases to configurable class-options,\n",
            "as listed in the \"Equivalent to\" description-line of the aliases.\n",
            "To see all configurable class-options for some <cmd>, use:\n",
            "    <cmd> --help-all\n",
            "\n",
            "--debug\n",
            "    set log level to logging.DEBUG (maximize logging output)\n",
            "    Equivalent to: [--Application.log_level=10]\n",
            "--show-config\n",
            "    Show the application's configuration (human-readable format)\n",
            "    Equivalent to: [--Application.show_config=True]\n",
            "--show-config-json\n",
            "    Show the application's configuration (json format)\n",
            "    Equivalent to: [--Application.show_config_json=True]\n",
            "--generate-config\n",
            "    generate default config file\n",
            "    Equivalent to: [--JupyterApp.generate_config=True]\n",
            "-y\n",
            "    Answer yes to any questions instead of prompting.\n",
            "    Equivalent to: [--JupyterApp.answer_yes=True]\n",
            "--execute\n",
            "    Execute the notebook prior to export.\n",
            "    Equivalent to: [--ExecutePreprocessor.enabled=True]\n",
            "--allow-errors\n",
            "    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\n",
            "    Equivalent to: [--ExecutePreprocessor.allow_errors=True]\n",
            "--stdin\n",
            "    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\n",
            "    Equivalent to: [--NbConvertApp.from_stdin=True]\n",
            "--stdout\n",
            "    Write notebook output to stdout instead of files.\n",
            "    Equivalent to: [--NbConvertApp.writer_class=StdoutWriter]\n",
            "--inplace\n",
            "    Run nbconvert in place, overwriting the existing notebook (only\n",
            "            relevant when converting to notebook format)\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory=]\n",
            "--clear-output\n",
            "    Clear output of current file and save in place,\n",
            "            overwriting the existing notebook.\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --ClearOutputPreprocessor.enabled=True]\n",
            "--coalesce-streams\n",
            "    Coalesce consecutive stdout and stderr outputs into one stream (within each cell).\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --CoalesceStreamsPreprocessor.enabled=True]\n",
            "--no-prompt\n",
            "    Exclude input and output prompts from converted document.\n",
            "    Equivalent to: [--TemplateExporter.exclude_input_prompt=True --TemplateExporter.exclude_output_prompt=True]\n",
            "--no-input\n",
            "    Exclude input cells and output prompts from converted document.\n",
            "            This mode is ideal for generating code-free reports.\n",
            "    Equivalent to: [--TemplateExporter.exclude_output_prompt=True --TemplateExporter.exclude_input=True --TemplateExporter.exclude_input_prompt=True]\n",
            "--allow-chromium-download\n",
            "    Whether to allow downloading chromium if no suitable version is found on the system.\n",
            "    Equivalent to: [--WebPDFExporter.allow_chromium_download=True]\n",
            "--disable-chromium-sandbox\n",
            "    Disable chromium security sandbox when converting to PDF..\n",
            "    Equivalent to: [--WebPDFExporter.disable_sandbox=True]\n",
            "--show-input\n",
            "    Shows code input. This flag is only useful for dejavu users.\n",
            "    Equivalent to: [--TemplateExporter.exclude_input=False]\n",
            "--embed-images\n",
            "    Embed the images as base64 dataurls in the output. This flag is only useful for the HTML/WebPDF/Slides exports.\n",
            "    Equivalent to: [--HTMLExporter.embed_images=True]\n",
            "--sanitize-html\n",
            "    Whether the HTML in Markdown cells and cell outputs should be sanitized..\n",
            "    Equivalent to: [--HTMLExporter.sanitize_html=True]\n",
            "--log-level=<Enum>\n",
            "    Set the log level by value or name.\n",
            "    Choices: any of [0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL']\n",
            "    Default: 30\n",
            "    Equivalent to: [--Application.log_level]\n",
            "--config=<Unicode>\n",
            "    Full path of a config file.\n",
            "    Default: ''\n",
            "    Equivalent to: [--JupyterApp.config_file]\n",
            "--to=<Unicode>\n",
            "    The export format to be used, either one of the built-in formats\n",
            "            ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'qtpdf', 'qtpng', 'rst', 'script', 'slides', 'webpdf']\n",
            "            or a dotted object name that represents the import path for an\n",
            "            ``Exporter`` class\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.export_format]\n",
            "--template=<Unicode>\n",
            "    Name of the template to use\n",
            "    Default: ''\n",
            "    Equivalent to: [--TemplateExporter.template_name]\n",
            "--template-file=<Unicode>\n",
            "    Name of the template file to use\n",
            "    Default: None\n",
            "    Equivalent to: [--TemplateExporter.template_file]\n",
            "--theme=<Unicode>\n",
            "    Template specific theme(e.g. the name of a JupyterLab CSS theme distributed\n",
            "    as prebuilt extension for the lab template)\n",
            "    Default: 'light'\n",
            "    Equivalent to: [--HTMLExporter.theme]\n",
            "--sanitize_html=<Bool>\n",
            "    Whether the HTML in Markdown cells and cell outputs should be sanitized.This\n",
            "    should be set to True by nbviewer or similar tools.\n",
            "    Default: False\n",
            "    Equivalent to: [--HTMLExporter.sanitize_html]\n",
            "--writer=<DottedObjectName>\n",
            "    Writer class used to write the\n",
            "                                        results of the conversion\n",
            "    Default: 'FilesWriter'\n",
            "    Equivalent to: [--NbConvertApp.writer_class]\n",
            "--post=<DottedOrNone>\n",
            "    PostProcessor class used to write the\n",
            "                                        results of the conversion\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.postprocessor_class]\n",
            "--output=<Unicode>\n",
            "    Overwrite base name use for output files.\n",
            "                Supports pattern replacements '{notebook_name}'.\n",
            "    Default: '{notebook_name}'\n",
            "    Equivalent to: [--NbConvertApp.output_base]\n",
            "--output-dir=<Unicode>\n",
            "    Directory to write output(s) to. Defaults\n",
            "                                  to output to the directory of each notebook. To recover\n",
            "                                  previous default behaviour (outputting to the current\n",
            "                                  working directory) use . as the flag value.\n",
            "    Default: ''\n",
            "    Equivalent to: [--FilesWriter.build_directory]\n",
            "--reveal-prefix=<Unicode>\n",
            "    The URL prefix for reveal.js (version 3.x).\n",
            "            This defaults to the reveal CDN, but can be any url pointing to a copy\n",
            "            of reveal.js.\n",
            "            For speaker notes to work, this must be a relative path to a local\n",
            "            copy of reveal.js: e.g., \"reveal.js\".\n",
            "            If a relative path is given, it must be a subdirectory of the\n",
            "            current directory (from which the server is run).\n",
            "            See the usage documentation\n",
            "            (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-slideshow)\n",
            "            for more details.\n",
            "    Default: ''\n",
            "    Equivalent to: [--SlidesExporter.reveal_url_prefix]\n",
            "--nbformat=<Enum>\n",
            "    The nbformat version to write.\n",
            "            Use this to downgrade notebooks.\n",
            "    Choices: any of [1, 2, 3, 4]\n",
            "    Default: 4\n",
            "    Equivalent to: [--NotebookExporter.nbformat_version]\n",
            "\n",
            "Examples\n",
            "--------\n",
            "\n",
            "    The simplest way to use nbconvert is\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --to html\n",
            "\n",
            "            Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'qtpdf', 'qtpng', 'rst', 'script', 'slides', 'webpdf'].\n",
            "\n",
            "            > jupyter nbconvert --to latex mynotebook.ipynb\n",
            "\n",
            "            Both HTML and LaTeX support multiple output templates. LaTeX includes\n",
            "            'base', 'article' and 'report'.  HTML includes 'basic', 'lab' and\n",
            "            'classic'. You can specify the flavor of the format used.\n",
            "\n",
            "            > jupyter nbconvert --to html --template lab mynotebook.ipynb\n",
            "\n",
            "            You can also pipe the output to stdout, rather than a file\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --stdout\n",
            "\n",
            "            PDF is generated via latex\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --to pdf\n",
            "\n",
            "            You can get (and serve) a Reveal.js-powered slideshow\n",
            "\n",
            "            > jupyter nbconvert myslides.ipynb --to slides --post serve\n",
            "\n",
            "            Multiple notebooks can be given at the command line in a couple of\n",
            "            different ways:\n",
            "\n",
            "            > jupyter nbconvert notebook*.ipynb\n",
            "            > jupyter nbconvert notebook1.ipynb notebook2.ipynb\n",
            "\n",
            "            or you can specify the notebooks list in a config file, containing::\n",
            "\n",
            "                c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\n",
            "\n",
            "            > jupyter nbconvert --config mycfg.py\n",
            "\n",
            "To see all available configurables, use `--help-all`.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!jupyter nbconvert --to html \"Semester2_V1_AQT_ARDLTrading_Macro&Technical.ipynb\" --output \"AQT_Semester1_Final.html\"\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
